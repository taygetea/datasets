Waterman behind the scenes!  Partying hard with the National Science Board

A few months ago, I got a surprise call from Subra Suresh, director of the National Science Foundation, who told me I was going to share this years Alan T. Waterman Award with Robert Wood of Harvard. (At first I assumed it was a telemarketing call, since pretty much no one calls my office phone; I use my iPhone exclusively and have trouble even operating my desk phone.) Dr. Suresh explained that this was the first time the Waterman would ever be awarded to two people the same year, but that the committee was unanimous in supporting both me and Rob. Looking up my co-winner, I quickly learned that Rob was a leader in the field of robot bees (see here for video)and that his work, despite having obvious military applications, had been singled out by Sean Hannity as the latters #1 example of government waste (!). That fact, alone, made me deeply honored to share the award with Rob, and eager to meet him in person.
Happily, I finally got to do that this past Thursday, at the Waterman award ceremony in Washington DC. The festivities started in the morning, with talks by me and Rob to the National Science Board. (I just performed my usual shtick. I was hoping Rob would bring some actual RoboBees, but he said he no longer does that due to an unfortunate run-in with airport security.) Then, after lunch and meetings at the NSF, it was back to the hotel to change into a tux, an item Id never worn before in my life (not even at my wedding). Fortunately, my dad was there to help me insert the cufflinks and buttons, a task much more complicated than anything I was allegedly getting the award for. Then Dana and I were picked up by a limo, to begin the arduous mile-long journey from Dupont Circle to the State Department for the awards dinner.
Besides me and Rob, there were three other awardees that night:

Leon Lederman, the 89-year-old Nobel physicist whose popular book (The God Particle) I enjoyed as a kid, received the Vannevar Bush Award.
Lawrence Krauss, physicist and popular science writer, andNational Public Radios science desk shared the National Science Board Public Service Award. Some readers of science blogs might recognize Lawrence Krauss from his recent brouhaha over literally nothing with the philosopher of science David Albert. (For whatever its worth, I have little to add to Sean Carrolls diplomatic yet magisterial summary of the issues over on Cosmic Variance.)

Speaking of diplomacy, the awards dinner was held in the diplomatic reception rooms on the top floor of the State Departments Harry S. Truman Building. These were pretty awesome rooms: full of original portraits of George Washington, Ben Franklin, etc., as well as antique furniture pieces like a desk that Thomas Jefferson allegedly used while writing the Declaration of Independence. I could easily eat dinner there on a regular basis.
Carl Wieman, the Nobel physicist and Associate Director for Science at the White House Office of Science and Technology Policy, read out a congratulatory message from President Obama. I feel certain the President remembered I was the same dude he shook hands with a while back.
Anyway, cutting past dinner and dessert, here was my short acceptance speech:
Thanks for this honor, and huge congratulations to my co-winners, wherever in the alphabet they might lie [a reference to my getting called up before Rob Wood, simply because Aaronson<Wood lexicographically]. I like to describe my research, on the limits of quantum computers, as the study of what we cant do with computers we dont have. Why would I or anyone else study such a bizarre thing? Mostly because were inspired by history. In the 1930s, before electronic computers even existed, a few people like Alan Turing were already trying to understand mathematically what such devices would or wouldnt be able to do. Their work ultimately made possible the information age. Today, we dont know exactly where curiosity about (say) quantum computers or the P versus NP question is going to lead, but Im grateful to live in a country thats able to support this kind of thing. I thank the NSF and the Obama administration for supporting basic science even in difficult times. I thank Subra Suresh (my former dean at MIT), and my phenomenal program officer Dmitry Maslov. I thank the teachers and mentors to whom I owe almost everything, including Chris Lynch, Bart Selman, Avi Wigderson, and Umesh Vazirani. I thank my wonderful colleagues at MITincluding my department head Anantha Chandrakasan, whos here nowand my students and postdocs. I thank my collaborators, and the entire theory of computing and quantum information communities, which Im so proud to be part of. I thank my students in 6.045 for understanding why I had to miss class today. Most of all, I thank four people who are here with me nowmy mom, dad, and my brother David, whove always believed in me, whether justified or not, and my wife, Dana Moshkovitz Aaronson, whos enriched my life ever since she came into it three years ago. Thank you.
The next day, I had the privilege of giving a quantum computing talk to more than 100 students at the Thomas Jefferson High School for Science and Technology in nearby Alexandria, VA. Visiting TJ had special meaning for me, since while I was suffering through high school, TJ was my dream school: I wished my parents lived in the DC area so that I could go there. I told the TJ students never to forget just how good they had it. (To this day, when I meet fellow American-raised scientists, and they tell me theyre surprised I had such an unhappy time in high school, since they themselves had a great time, I always ask them which high school they went to. In a large fraction of cases, the answer turns out to be TJand when it isnt, its often the Bronx High School of Science or another similar place.) As should surprise no one, the students had vastly more detailed questions about my talk than did the National Science Board (for example, they wanted to know whether I thought progress in group theory would lead to new quantum algorithms).
Without doubt, the most surreal aspect of this trip was the contrast between what was going on in my real and virtual lives. Again and again, Id be shaking hands with the Undersecretary of Defense, Director of the National Institute of Prestigiousness, etc. etc., and warmly accepting these fine peoples congratulations. Then Id sneak away for a minute to moderate my blog comments on my iPhone, where Id invariably find a fresh round of insults about my deeply ignorant lesser brain from entanglement denier Joy Christian.
Perhaps the funniest contrast had to do with a MathOverflow question that I posted just before I left for DC, and which was quickly answered, just as I had hoped. During the limo ride back from the dinner, I got the following polite inquiry from a blog commenter calling himself Mike:
Hey Scott, Im wondering how you got the courage to post that question on [MathOverflow]. In truth it wasnt that hard of a question and if you have trouble solving it thenwell, no offense, but you see what I mean. Reputation matters.
As I contemplated Mikes question, a profound sense of peace came over me. Probably for the first time in my life, I realized just how lucky I really am. Im lucky that I feel free to ask nave, simpleminded questions, toss out speculations, and most importantly, admit when I dont know something or made a mistake, without worrying too much about whether those actions will make me look foolish before the Mikes of the world. If I want to work on a problem myself, I can do that; if I prefer giving the problem out to others, I can do that as well. Let Mike, with his greater wisdom, sit in judgment of me for my failure to see all the answers that no doubt are obvious to him. I dont mind. In science, like in everything else, Ill continue being an unabashed doofuspartly because it seems to work OK, but mostly just because its the only way I know.
Thanks so much to all of you for your support.

			#gallery-1 {
				margin: auto;
			}
			#gallery-1 .gallery-item {
				float: left;
				margin-top: 10px;
				text-align: center;
				width: 33%;
			}
			#gallery-1 img {
				border: 2px solid #cfcfcf;
			}
			#gallery-1 .gallery-caption {
				margin-left: 0;
			}
			/* see gallery_shortcode() in wp-includes/media.php */Something to munch on while I take a long, succulent post out of the procrastination oven

Im convinced that the following diagram means something precise:
My question is, what does it mean?
Intuitively, it means that if your software package can solve SDPs, then you can easily use it to solve LPs; if it can solve LPs, you can easily use it to invert matrices, and so on, but not vice versa.  But it cant mean (for example) that SDPs are harder than LPs in the usual complexity theory sense, since both problems are P-complete!
Maybe it means that, if your axiom system is strong enough to prove SDP is in P, then its also strong enough to prove LP is in P, and so on  but not necessarily vice versa.  But how would we show such a separation?
(Sorry, no money this time.  Well see if it makes any difference  Im guessing that it doesnt.)Best anthropicism contest

I arrived this morning in Prague for the 2006 Complexity conference.  Soon Ill have the photos to prove it.  For now, though, I wish to blog neither about the breathtakingly beautiful city in which I find myself, nor about the meaty, succulent topic alluded to in my previous post, but instead about anthropicisms.
Inspired by Peter Woits almost-daily anti-anthropic broadsides, and in the spirit of my earlier Best Umeshism Contest, I hereby announce a new contest for Best Application of the Anthropic Principle.  Here are a few samples to get the self-selected tautological ball rolling, not that it could do otherwise than roll:
Why do so many people seem to care about being remembered after they die?  Because we only remember the ones who cared about being remembered.
Academics comprise only a tiny portion of humanity, so what are the chances of being an academic as opposed to someone else?  Conditioned on asking such a question in the first place, pretty high.
Why is the moon round?  Because if it were square, you wouldnt be you  you would instead be a being extremely similar to you, except that he or she lives in a universe with a square moon.
Why am I a blogger?  Because if I werent, you wouldnt be reading this.
The rules are similar to the Best Umeshism Contest: up to three entries per person.  Please include a name  despite the nature of the contest, He Who Posted This doesnt count.  Entries must be in by July 22nd.  The winner (as chosen by me) gets to ask any question and have me answer it here.I was wrong about Joy Christian

Update: I decided to close comments on this post and the previous Joy Christian post, because they simply became too depressing for me.
Ive further decided to impose a moratorium, on this blog, on all discussions about the validity of quantum mechanics in the microscopic realm, the reality of quantum entanglement, or the correctness of theorems such as Bells Theorem. I might lift the moratorium at some future time. For now, though, life simply feels too short to me, and the actually-interesting questions too numerous. Imagine, for example, that there existed a devoted band of crackpots who believed, for complicated, impossible-to-pin-down reasons of topology and geometric algebra, that triangles actually have five corners. These crackpots couldnt be persuaded by rational argumentindeed, they didnt even use words and sentences the same way you do, to convey definite meaning. And crucially, they had infinite energy: you could argue with them for weeks, and they would happily argue back, until you finally threw up your hands in despair for all humanity, at which point the crackpots would gleefully declare, haha, we won! the silly triangles have 3 corners establishment cabal has admitted defeat! And, in a sense, they would have won: with one or two exceptions, the vast majority who know full well how many corners a triangle has simply never showed up to the debate, thereby conceding to the 5-cornerists by default.
What would you in such a situation? What would you do? If you figure it out, please let me know (but by email, not by blog comment).

In response to my post criticizing his disproof of Bells Theorem, Joy Christian taunted me that all I knew was words. By this, he meant that my criticisms were entirely based on circumstantial evidence, for example that (1) Joy clearly didnt understand what the word theorem even meant, (2) every other sentence he uttered contained howling misconceptions, (3) his papers were written in an obscure, crackpot way, and (4) several people had written very clear papers pointing out mathematical errors in his work, to which Joy had responded only with bluster. But I hadnt actually studied Joys work at a technical level. Well, yesterday I finally did, and I confess that I was astonished by what I found. Before, Id actually given Joy some tiny benefit of the doubtpossibly misled by the length and semi-respectful tone of the papers refuting his claims. I had assumed that Joys errors, though ultimately trivial (how could they not be, when hes claiming to contradict such a well-understood fact provable with a few lines of arithmetic?), would nevertheless be artfully concealed, and would require some expertise in geometric algebra to spot. Id also assumed that of course Joy would have some well-defined hidden-variable model that reproduced the quantum-mechanical predictions for the Bell/CHSH experiment (how could he not?), and that the only problem would be that, due to cleverly-hidden mistakes, his model would be subtly nonlocal.
What I actually found was a thousand times worse: closer to the stuff freshmen scrawl on an exam when they have no clue what theyre talking about but are hoping for a few pity points. Its so bad that I dont understand how even Joys fellow crackpots havent laughed this off the stage. Look, Joy has a hidden variable , which is either 1 or -1 uniformly at random. He also has a measurement choice a of Alice, and a measurement choice b of Bob. He then defines Alice and Bobs measurement outcomes A and B via the following functions:
A(a,) = something complicated = (as Joy correctly observes) 
B(b,) = something complicated = (as Joy correctly observes) -
I shit you not. A(a,) = , and B(b,) = -. Neither A nor B has any dependence on the choices of measurement a and b, and the complicated definitions that he gives for them turn out to be completely superfluous. No matter what measurements are made, A and B are always perfectly anticorrelated with each other.
You might wonder: what could lead anyoneno matter how deludedeven to think such a thing could violate the Bell/CHSH inequalities? Aha, Joy says you only ask such a nave question because, lacking his deep topological insight, you make the rookie mistake of looking at the actual outcomes that his model actually predicts for the actual measurements that are actually made. What you should do, instead, is compute a correlation function E(a,b) thats defined by dividing A(a,)B(b,) by a normalizing factor thats a product of the quaternions a and b, with a divided on the left and b divided on the right. Joy seems to have obtained this normalizing factor via the technique of pulling it out of his rear end. Now, as Gill shows, Joy actually makes an algebra mistake while computing his nonsensical correlation function. The answer should be -a.b-ab, not -a.b. But thats truthfully beside the point. Its as if someone announced his revolutionary discovery that P=NP implies N=1, and then critics soberly replied that, no, the equation P=NP can also be solved by P=0.
So, after 400+ comments on my previous threadincluding heady speculations about M-theory, the topology of spacetime, the Copenhagen interpretation, continuity versus discreteness, etc., as well numerous comparisons to Einsteinthis is what it boils down to. A(a,) =  and B(b,) = -.
I call on FQXi, in the strongest possible terms, to stop lending its legitimacy to this now completely-unmasked charlatan. If it fails to do so, then I will resign from FQXi, and will encourage fellow FQXi members to do the same.
While I dont know the exact nature of Joys relationship to Oxford University or to the Perimeter Institute, I also call on those institutions to sever any connections they still have with him.
Finally, with this post Im going to try a new experiment. I will allow comments through the moderation filter if, and only if, they exceed a minimum threshold of sanity and comprehensibility, and do not randomly throw around terms like M-theory with no apparent understanding of what they mean. Comments below the sanity threshold can continue to appear freely in the previous Joy Christian thread (which already has a record-setting number of comments).
Update (May 11): A commenter pointed me to a beautiful preprint by James Owen Weatherall, which tries sympathetically to make as much sense as possible out of Joy Christians ideas, and then carefully explains why the attempt fails (long story short: because of Bells theorem!). Notice the contrast between the precision and clarity of Weatheralls prosethe way he defines and justifies each concept before using itand the obscurity of Christians prose.
Another Update: Over on the previous Joy Christian thread, some commenters are now using an extremely amusing term for people who believe that theories in physics ought to say something comprehensible about the predicted outcomes of physics experiments. The term: computer nerd.
Third Update: Quite a few commenters seem to assume that I inappropriately used my blog to pick a fight with poor defenseless Joy Christian, who was minding his own business disproving and re-disproving Bells Theorem. So let me reiterate that I wasnt looking for this confrontation, and in fact took great pains to avoid it for six years, even as Joy became more and more vocal. It was Joy, not me, who finally forced matters to a head through his absurd demand that I pay him $100,000 with interest, and then his subsequent attacks.Two John-related announcements

A year ago, I relinquished my dictatorial control of the Complexity Zoo, accepting an offer from John Stockton to convert the Zoo into wiki format.  Unfortunately, the wiki site has been down for days and shows no signs of coming back anytime soon.  So for now, Ive put the old Zoo back up at www.complexityzoo.com.  Ive learned my lesson: in times of crisis, it takes a leader with an iron fist to keep the trains running on time and the animals in their cages.
John Baez is back on the scene, with an account of his recent visit to our quantum computing group at Waterloo.  Among other things, he gives a lucid explanation of how, while its generally impossible to keep information from leaking out of a computer, it is possible to arrange things so that the information that does leak is irrelevant to the computation.  Baez links to the papers that prove this is true for quantum computing as well as classical, but complains that most of it speaks the language of error correction rather than thermodynamics.  Question for the audience: can the fault-tolerance theorems be reproved more physicsly?  (We now define a PHYSICAL SYSTEM called the concatenated Steane code)
Baezs semi-conversion to the Church of Knill, Laflamme, and Zurek (or the Shul of Aharonov and Ben-Or) has inspired me to propose a far-reaching hypothesis:
While its generally impossible to explain computer science concepts to physicists so that they understand them on your terms, it is sometimes possible to explain them so that they understand on their terms.

Naturally, it helps if the physicist in question is Baez.And they say complexity has no philosophical implications

From these lecture notes by Harvey Friedman comes one of the best metamathematical anecdotes Ive ever heard (and yes, Ive heard my share).  Apparently Friedman was attending a talk by the ultra-finitist Alexander Yessenin-Volpin, who challenged the Platonic existence not only of infinity, but even of large integers like 2100.  So Friedman raised the obvious draw the line objection: in the sequence 21,22,,2100, which is the first integer that Yessenin-Volpin would say doesnt exist?
Yessenin-Volpin asked Friedman to be more specific.
Okay, then.  Does 21 exist?
Yessenin-Volpin quickly answered yes.
What about 22?
After a noticeable delay: yes.
23?
After a longer delay: yes.
It soon became clear that Yessenin-Volpin would answer yes to every question, but would take twice as long for each one as for the one before it.Enough with Bells Theorem.  New topic: Psychopathic killer robots!

A few days ago, a writer named John Rico emailed me the following question, which hes kindly given me permission to share.
If a computer, or robot, was able to achieve true Artificial Intelligence, but it did not have a parallel programming or capacity for empathy, would that then necessarily make the computer psychopathic? And if so, would it then follow the rule devised by forensic psychologists that it would necessarily then become predatory? This then moves us into territory covered by science-fiction films like The Terminator. Would this psychopathic computer decide to kill us? (Or would that merely be a rational logical decision that wouldnt require psychopathy?)
See, now this is precisely why I became a CS professor: so that if anyone asked, I could give not merely my opinion, but my professional, expert opinion, on the question of whether psychopathic Terminators will kill us all.
My response (slightly edited) is below.
Dear John,
I fear that your question presupposes way too much anthropomorphizing of an AI machinethat is, imagining that it would even be understandable in terms of human categories like empathetic versus psychopathic. Sure, an AI might be understandable in those sorts of terms, but only if it had been programmed to act like a human. In that case, though, I personally find it no easier or harder to imagine an empathetic humanoid robot than a psychopathic robot! (If you want a rich imagining of empathetic robots in science fiction, of course you need look no further than Isaac Asimov.)
On the other hand, I personally also think its possible even likelythat an AI would pursue its goals (whatever they happened to be) in a way so different from what humans are used to that the AI couldnt be usefully compared to any particular type of human, even a human psychopath. To drive home this point, the AI visionary Eliezer Yudkowsky likes to use the example of the paperclip maximizer. This is an AI whose programming would cause it to use its unimaginably-vast intelligence in the service of one goal only: namely, converting as much matter as it possibly can into paperclips!
Now, if such an AI were created, it would indeed likely spell doom for humanity, since the AI would think nothing of destroying the entire Earth to get more iron for paperclips. But terrible though it was, would you really want to describe such an entity as a psychopath, any more than youd describe (say) a nuclear weapon as a psychopath? The word psychopath connotes some sort of deviation from the human norm, but human norms were never applicable to the paperclip maximizer in the first place  all that was ever relevant was the paperclip norm!
Motivated by these sorts of observations, Yudkowsky has thought and written a great deal about how the question of how to create a friendly AI, by which he means one that would use its vast intelligence to improve human welfare, instead of maximizing some arbitrary other objective like the total number of paperclips in existence that might be at odds with our welfare. While I dont always agree with himfor example, I dont think AI has a single key, and I certainly dont think such a key will be discovered anytime soonIm sure youd find his writings at yudkowsky.net, lesswrong.com, and overcomingbias.com to be of interest to you.
I should mention, in passing, that parallel programming has nothing at all to do with your other (fun) questions. You could perfectly well have a murderous robot with parallel programming, or a kind, loving robot with serial programming only.
Hope that helps,
ScottMihai Ptracu (1982-2012)

Yesterday brought the tragic news that Mihai Ptracuwho revolutionized the field of data structures since he burst onto the scene a decade agohas passed away at the age of 29, after a year-and-a-half-long battle with brain cancer. Mihai was not only an outstanding researcher but a fun-loving, larger-than-life personality in the computer science theory community. For more information, see Lance and Bills or Michael Mitzenmachers blogs.
Mihai was an MIT CS PhD student (advised by Erik Demaine), who worked on the same floor as me for the first couple years I was here. Im still in shock over his lossI hadnt even known about the cancer before yesterday.  Mihai and I had pretty big disagreements, mostly over the viability of quantum computing, the technical versus conceptual theory debate, various things he wrote on his blog and various things I wrote on mine. But it seems terribly stupid now to have let this stuff get in the way of collegiality. I feel guilty for not trying to mend bridges with him when I had the chance.
Rest in peace, Mihai.The anthropicism that had to win

So, my Best Anthropicism Contest elicited almost 50 submissions.  Thanks so much to everyone who entered  if not for you, this tautological tug-of-war wouldve been something other than what it was!
To choose the winning entry, the first rule I adopted was that, when I did find the winning entry, conditions would have to be such as to make it the winning entry, since otherwise it wouldnt be the winning entry in the first place, but rather a losing entry.  Since that didnt get me very far, I quickly fell back on other criteria.
First, the winning entry would have to be short  longwinded explanations were out right away.
Second, it would have to make sense.
Third, it would have to illustrate the anthropic principle specifically, not some sort of generic Zen wisdom.
That already killed most of the entries.  Among the ones left, many dealt Hofstadterifically with the contest itself:
wolfgang: Applying the principle of mediocrity I have to conclude that it is unlikely that I will win this contest.
Matt Wedel: Oh, cmon! Just give me the prize! If I wasnt going to win, Id be living in a different universe where I didnt win. BUT  Im not. So give me the prize.
MX: Why am I entering this contest? Because if I werent, I wouldnt be me, I would be a being very similar to me living in a universe in which I did not enter this contest.

Other entries worked well as parody:
sockatume: How much wood could a woodchuck chuck if a woodchuck could chuck would?  As much wood as a woodchuck could chuck if a woodchuck could chuck would, otherwise it wouldnt be a woodchuck.
Bram Cohen: Why have all dates thus far come before January 1, 3000? Because the universe will cease to exist on that day.

In the end, though, I decided that what I was looking for wasnt mere wit, but the real, genuine illusion of explanatory insight.  And thats why Lev R. takes the prize, with the following perspicacious pearl:
why arent physicists too interested in computational complexity? because if they were, theyd be computer scientists.Two announcements

Tomorrow, at 9AM EST (or an hour before teatime in Britain), Ill be giving an online talk on Quantum Money from Hidden Subspaces (see here for PowerPoint slides) at the Q+ hangout on Google+. To watch the talk, go here, then click the Play button on the video that will be there tomorrow. Abstract:
Forty years ago, Wiesner pointed out that quantum mechanics raises the striking possibility of money that cannot be counterfeited according to the laws of physics. We propose the first quantum money scheme that is (1) public-key, meaning that anyone can verify a banknote as genuine, not only the bank that printed it, and (2) cryptographically secure, under a classical hardness assumption that has nothing to do with quantum money. Our scheme is based on hidden subspaces, encoded as the zero-sets of random multivariate polynomials. A main technical advance is to show that the black-box version of our scheme, where the polynomials are replaced by classical oracles, is unconditionally secure. Previously, such a result had only been known relative to a quantum oracle (and even there, the proof was never published). Even in Wiesners original setting  quantum money that can only be verified by the bank  we are able to use our techniques to patch a major security hole in Wiesners scheme. We give the first private-key quantum money scheme that allows unlimited verifications and that remains unconditionally secure, even if the counterfeiter can interact adaptively with the bank. Our money scheme is simpler than previous public-key quantum money schemes, including a knot-based scheme of Farhi et al. The verifier needs to perform only two tests, one in the standard basis and one in the Hadamard basis  matching the original intuition for quantum money, based on the existence of complementary observables. Our security proofs use a new variant of Ambainiss quantum adversary method, and several other tools that might be of independent interest. Joint work with Paul Christiano.
Update: Heres a YouTube video of the talk.
In unrelated news, Alistair Sinclair asked me to announce that UC Berkeleys new Simons Institute for Theoretical Computer Scienceyou know, the thing Berkeley recently defeated MIT (among others) to getis soliciting proposals for programs. The deadline is July 15, so be sure to get your proposal in soon.Prague-ing

Why do I procrastinate so much on blog posts, even to the extent of not blogging about a trip until well after its over?  Because, while coming up with the ideas (i.e., the jokes) is trivial, writing the connective tissue is a pain in the ass.


Bulleted lists are easier.  Expect me to fall back on them more often.


So, Prague.  It was nice.  Really nice.  Nicer than Amsterdam even.


Like a fool, I somehow expected that, since its been less than two decades since the Velvet Revolution, Prague would still be some sort of backwards city in consonant-intensive Eastern Europe, grateful for any tourists it could get.


I dramatically overestimated how long it would take for a former Communist stronghold to become Disneyland, a.k.a. the college backpacker capital of the world.


Im told there are two reasons for this transformation: (1) castles and cathedrals that werent completely reduced to rubble by WWII, and (2) cheap beer (less than $1 a pint).  Of course, factoring in the cost of airfare and hotels, youd have to drink hundreds of beers to save money.  But we are talking about college backpackers.


Have you heard of Jan Hus?  A century before Martin Luther, he was already pulling the same shtick: condemning the selling of indulgences, advocating a return to Christs original teachings, etc.  Of course the Catholics burned him at the stake.  This led to the Hussite Wars, which I guess I wouldve learned about had I stayed in high school long enough to take AP Euro.   Anyway, theres a big statue of Mr. Hus in Pragues Old Town Square (you can see a photo of it on Huss Wikipedia page).  Get this: the statue is glaring angrily at a nearby Catholic church.  As you might have gathered, Ive never been much of an art critic, but I think I more-or-less understood what the sculptor was getting at.


I also saw the biggest telescope in the Czech Republic.


Oh, yeah: there was a conference.  It was about complexity or something.


Seriously, it was an excellent conference, except that the lecture room wasnt air-conditioned.  As a direct result, I can remember very little of the talks.  (Is it better to contribute to global warming or to experience it?)


If youre ever in Prague, definitely visit the Museum of Communism (back-handed bribes accepted in our gift shop), especially if youve never been to a Soviet-bloc country before (as I hadnt).  Learning about the 19th centurys worst idea on a North American campus is different from learning about it on Wenceslas Square.


Unfortunately, when I visit European cities like Amsterdam and Prague, I can never completely forget that Im walking through a big murder scene.  (Thank you, waiter, for bringing me my chicken!   And thank you, as well, for not deporting me to Theresienstadt or shooting me into an open pit! When you get a chance, could you maybe refill my water?)


Why does Prague have one the best Judaica collections in the world?  Because the Nazis shipped their loot there, expecting to open a historical museum about the human bacillus they had  successfully eradicated.   (There is such a museum today, but run by the bacillus itself.)


Speaking of which, have you heard of the Golem?  It was a clay robot allegedly built in the 1500s by Rabbi Judah Lw of Prague.  This robot, you see, went rampaging around, causing random destruction, until the townspeople agreed to halt their anti-Semitic attacks.  (A bit like the IDF in Lebanon.)  According to legend, the Golems remains are still in the attic of Pragues Old-New Synagogue, and can be reanimated if necessary.  The attic is closed to visitors, but the guidebooks say that recently some great rabbi was allowed to ascend to the attic, and returned white and trembling.  (As a friend of mine remarked, they forgot to mention that the old fellow was also white and trembling before he went up the attic.)  In any case, the Golem was apparently out of service when most needed.Scott in Scotland

Im in Edinburgh this week to visit my wonderful old friends Elham Kashefi and Rahul Santhanam, and to give a series of talks. Its my first visit to my ancestral homeland, and as you can see above, Ive enjoyed visiting my namesake monument and eating some freshly-ground haggis.
Earlier today, I was delighted to meet the matrix-multiplication-exponent-lowerer and unwilling Shtetl-Optimized celebrity Andrew Stothers, and to treat him to lunch. (Id promised to buy Andrew a beer if I was ever in Edinburgh, to apologize for the blog-circus I somehow dragged him into, but he only wanted a diet Coke.) Im now convinced that Andrews not publicizing his lowering of was mostly a very simple matter of his not being in contact with the theoretical computer science community. One factor might be that, here at U. of Edinburgh, the math and CS buildings are on different campuses two miles away from each other!
I apologize for the light-to-nonexistent blogging. To tide you over until I have time to post something real, here are some extremely-interesting quantum information papers that appeared on the arXiv just recently: A multi-prover interactive proof for NEXP sound against entangled proversby Tsuyoshi Ito and my postdoc Thomas Vidick, and Bells Theorem Without Free Will by Tobias Fritz.America the nonexistent

A commenter on a previous post writes:
A lot of great discoveries came from non-scientific losers. E=MCC. Airplanes. America. Someone discovered how to make an airplane by playing with a box. Physics is mostly theoretical. America, I guess, is the most scientific discovery. They applied the scientific method to determine its existence, but they used no control group, and no placebo. For that, Americas existence is not yet proven. There seem to be other ways of establishing truth than just the scientific method. Scientists are contemporary soothsayers. They should use every means possible of proving a fact.
Despite its insightfulness and coherence, the above argument raises some immediate questions:

What does it have to do with anything I said?
E=MCC?
What would mean to use a placebo or control group to test Americas existence?  Would it mean sending a ship in a different direction, and checking that it didnt also reach America?  Would it mean verifying that America cant be reached from Europe by foot  since if it could, then it wouldnt be America, but rather part of Eurasia?
Has Englands existence been scientifically proven?  What about Frances?
Where do so many people get the cockamamie idea that theres such a thing as a scientific method  that science is not just really, really, really careful thinking?  (I blame the school system.)Complexity Zoo is down  anyone willing to help?

Update (August 5):  Sorry for the delay!  Now that the Zoo is back up, my sense of urgency has decreased, but we still do need a long-term solution.  Thanks so much to everyone who offered hosting.  Alas, I was persuaded by the argument that its too complicated to have a wiki mirrored at multiple locations, so I should really choose oneand ideally it should be someplace where I retain control of the files, in case anything goes wrong again.  Following the helpful directions of Eric Price, I set up a MediaWiki installation at http://scottaar.scripts.mit.edu/zoo.  Is anyone interested in helping me transfer over the content from the qwiki Zoo?

Update (August 1): Thanks to the efforts of Gopal Sarma at Stanford, the Zoo is back up and running!! However, I believe the only long-term solution is to get the Zoo mirrored at other locations. I can then direct the domain complexityzoo.com to point to any of them that are currently up. So, to all of those who volunteered to mirror the Zoo: thanks so much, and please go ahead and do so! Let me know what you need for that (I can ask Gopal to get the source files).

As some of you have noticed, the Complexity Zoo(well, dont bother clicking the link!) has been down for the past couple weeks. Some Stanford students volunteered to host the Zoo years ago but then graduated, and these sorts of outages have been a frustrating reality since then. So my co-zookeeper Greg Kuperberg and I are looking for a volunteer to help us get the Zoo back online. The reward? Eternal gratitude and a co-zookeeper title for yourself. In principle, I could host the Zoo on my Bluehost account, but I dont know how to set up the wiki software, and Im not even sure how to retrieve the Zoo pages prior to its going down (Google Cache?). If youre interested or have ideas, leave a comment or send me an email.
Thanks!!Merneptah and Spinoza

A reader from Istanbul wrote in, asking me to comment on the war in Israel and Lebanon. In other words, he wants me to make this blog the scene of yet another intellectual bloodbath, with insult-laden rockets launched from untraceable IP addresses and complexity-theoretic civilians trapped in the crossfire. What a neat idea! Why didnt I think of it before?
Alright, let me start with some context.  No, Im not talking about the Gaza pullout, or Camp David, or the last Lebanon invasion, or the Yom Kippur War, or the Six-Day War, or the War of Independence, or the UN partition plan, or the 1939 White Paper.   Im talking about the first appearance of Israel in the extrabiblical historical record, which seems to have been around 1200 BC.  Boasting in a  victory stele about his recent military conquests in Canaan, the Egyptian pharaoh Merneptah included a single sentence about Israel:
Israel is laid waste; his seed is destroyed.
Sure, the pharoah was a bit premature.  But give him credit for prescience if not for accuracy. Unlike (say) pyramid-building or Ra-worship, Merneptahs Jew-killing idea has remained consistently popular for 3.2 millennia.
Today, in the year 2006, as the LHC prepares to find the Higgs boson and the New Horizons probe heads to Pluto, Am Yisrael (literally, the people that argues with God) is once again surrounded by enemies whose stated goal is to wipe it off the face of the Earth.  And, in the familiar process of fighting for its existence, that people is grievously, inexplicably, incompetently, blowing up six-year-olds and farmers while failing to make any visible progress on its military objectives.
So what is there to say about this that hasnt already been said Ackermann(50) times?  Instead of cluttering the blogosphere any further, Ill simply point you to a beautiful New York Times op-ed by Rebecca Goldstein, commemorating the 350th anniversary of Spinozas excommunication from the Jewish community of Amsterdam.   Actually, Ill quote a few passages:
Spinozas reaction to the religious intolerance he saw around him was to try to think his way out of all sectarian thinking. He understood the powerful tendency in each of us toward developing a view of the truth that favors the circumstances into which we happened to have been born. Self-aggrandizement can be the invisible scaffolding of religion, politics or ideology.
Against this tendency we have no defense but the relentless application of reason.
Spinozas system is a long deductive argument for a conclusion as radical in our day as it was in his, namely that to the extent that we are rational, we each partake in exactly the same identity.
Spinozas dream of making us susceptible to the voice of reason might seem hopelessly quixotic at this moment, with religion-infested politics on the march. But imagine how much more impossible a dream it would have seemed on that day 350 years ago.Ten reasons why the Olympics suck

1. The 1936 Berlin Olympics, in which American participation was ensured by the racist, sexist, antisemitic, Nazi-sympathizing future decades-long IOC presidentAvery Brundage(also, the IOCs subsequent failure to accept responsibility for its role in legimitizing Hitler).
2. The 1972 Munich Olympics (and the IOCs subsequent refusal even to memorialize the victims, apparently for fear of antagonizing those Olympic countries that still celebrate the murder of the 11 Israeli athletes).
3. Even after you leave out 1936 and 1972, the repeated granting of unearned legitimacy to the worlds murderous dictatorshipsas well as glory to those countries most able to coerce their children into lives of athletic near-slavery (or, in the case of more civilized countries, outspend their rivals).
4. The sanctimonious fiction that, after all this, we need the Olympics because of their contributions to world peace and brotherhood (a claim about which we now arguably have a century of empirical data).
5. The double-standard that holds winning a medal is everything to be a perfectly-reasonable life philosophy for a gymnast, yet would denounce the same attitude if expressed by a scientist or mathematician.
6. The increasingly-convoluted nature of what it is that the athletes are supposed to be optimizing (run the fastest, but having taken at most these performance-enhancing substances and not those, unless of course youre a woman with unusually-high testosterone, in which case you must artificially decrease your testosterone before competing in order to even things out)
7. The IOCs notorious corruption, and the fact that hosting the Olympics is nevertheless considered such a wonderful honor and goal for any aspiring city.
8. The IOCs farcical attempts to control others use of five interlocked rings and of the word Olympics.
9. The fact that swimmers have to use a particular stroke, rather than whichever stroke will propel them through the water the fastest (alright, while the freestyle rules still seem weird to me, Im taking this one out given the amount of flak its gotten)
10. The fact that someone like me, who knows all the above, and who has less interest in sports than almost anyone on earth, is still able to watch an Olympic event and care about its outcome.The right to bear ICBMs

(Note for non-US readers: This will be another one of my America-centric posts. But dont worry, its probably one youll agree with.)
Theres one argument in favor of gun control thats always seemed to me to trump all others.
In your opinion, should private citizens should be allowed to own thermonuclear warheads together with state-of-the-art delivery systems? Does the Second Amendment give them the right to purchase ICBMs on the open market, maybe after a brief cooling-off period? No? Why not?
OK, whatever grounds you just gave, Id give precisely the same grounds for saying that private citizens shouldnt be allowed to own assault weapons, and that the Second Amendment shouldnt be construed as giving them that right. (Personally, Id ban all guns except for the bare minimum used for sport-shooting, and even that Id regulate pretty tightly.)
Now, it might be replied that the above argument can be turned on its head: Should private citizens be allowed to own pocket knives? Yes, they should? OK then, whatever grounds you gave for that, Id give the precisely same grounds for saying that they should be allowed to own assault weapons.
But crucially, I claim thats a losing argument for the gun-rights crowd. For as soon as were anywhere on the slippery slopethat is, as soon as its conceded that the question hinges, not on absolute rights, but on an actual tradeoffs in actual empirical realitythen the facts make it blindingly obvious that letting possibly-deranged private citizens buy assault weapons is only marginally less crazy than letting them buy ICBMs.
[Related Onion story]CIA, NSA, FBI, DoD, SZK, RNC, QMA, BPE

Sorry for the long delay!  I had to be in Washington D.C. this week, for reasons Im not at liberty to disclose.  (Yes, Im serious, and no, its not as interesting as it sounds.)  Oh: on my way back to Canada, for some strange reason they confiscated my Blistex.  I guess airport security guards get chapped lips a lot.
As our world descends even further into war, terror, and Armageddon, I have an exciting complexity-theoretic announcement.  Building on the Complexity Zoo, Greg Kuperberg has created a Robozoologist: an expert system for reasoning about complexity classes.  Whats more, Greg is releasing some spinoffs of his project to the masses, including a JavaScript-powered inclusion graph, and an automatically-generated RoboZoo.  I can still remember them frontier days of 2002, when I had to herd the BP operators with my two bare handsDown with municipal government

Forgive me if this post isnt particularly timely  I just started blogging, so Im still clearing out my cognitive backlog.
A month ago, the economist Steven Landsburg wrote a Slate column arguing that we shouldnt help Hurricane Katrina victims too much. His reasoning? Presumably, the hurricane risk in New Orleans and surrounding areas was already reflected in property values being lower than what they would have been were there no such risk. So if the US spends federal tax dollars on hurricane relief, then its artificially subsidizing people who choose to live in hurricane-prone areas  thereby

raising taxes for everyone, including those who live in safe areas, and
raising property values in the hurricane-prone areas, which limits peoples freedom to select cheap but risky housing over expensive but safer housing.

Id had some pleasant correspondence with Landsburg in the past, so I emailed him to say that, while I could find no flaw in his logic, I was confused as to why he didnt take the argument even further. For example, what are fire departments, if not an artificial subsidy for people who choose to live in wooden houses rather than stone ones? And police departments? Clearly a lose-lose proposition. If you have a personal bodyguard, then youre forced to pay for protection you dont need. And if you dont have a bodyguard, then youre deprived of the freedom to choose lower taxes in exchange for having no one to call if you get stabbed.
See, in my view, if youre going to be a radical libertarian, then you might as well go all the way. For  just like the denial of relief to hurricane victims  such consistency makes all parties better off than otherwise. Those willing to follow you all the way into Galts Gulch get the genuine Ayn Rand experience, with no wussy collectivist compromises. And for others, youre all the more valuable as a walking, talking reductio ad absurdum.Why Many-Worlds is not like Copernicanism

[Update (8/26):Inspired by the great responses to my last Physics StackExchange question, I just asked a new onealso about the possibilities for gravitational decoherence, but now focused on Gambini et al.s Montevideo interpretation of quantum mechanics.
Also, on a completely unrelated topic, my friend Jonah Sinick has created a memorial YouTube video for the great mathematician Bill Thurston, who sadly passed away last week. Maybe I should cave in and set up a Twitter feed for this sort of thing]
[Update (8/26): Ive now posted what I see as one of the main physics questions in this discussion on Physics StackExchange: Reversing gravitational decoherence. Check it out, and help answer if you can!]
[Update (8/23):If you like this blog, and havent yet read the comments on this post, you should probably do so! To those whove complained about not enough meaty quantum debates on this blog lately, the comment section of this post is my answer.]
[Update: Argh! For some bizarre reason, comments were turned off for this post. Theyre on now. Sorry about that.]
Im in Anaheim, CA for a greatconferencecelebrating the 80th birthday of the physicist Yakir Aharonov. Ill be happy to discuss the conference in the comments ifpeople are interested.
In the meantime, though, since my flight here was delayed 4 hours, I decided to (1) pass the time, (2) distract myself from the inanities blaring on CNN at the airport gate, (3) honor Yakirs half-century of work on the foundations of quantum mechanics, and (4) honor the commenters who wanted me to stop ranting and get back to quantum stuff, by sharing some thoughts about a topic that, unlike gun control or the Olympics, is completely uncontroversial: the Many-Worlds Interpretation of quantum mechanics.
Proponents of MWI, such as David Deutsch, often argue that MWI is a lot like Copernican astronomy: anexhilaratingexpansion in our picture of the universe, which follows straightforwardly from Occams Razor applied to certain observed facts (the motions of the planets in one case, the double-slit experiment in the other). Yes, many holdouts stubbornly refuse to accept the new picture, but their skepticism says more about sociology than science. If you want, you candescribe all the quantum-mechanical experiments anyone has ever done, or will do for the foreseeable future, by treating measurement as an unanalyzed primitive and never invoking parallel universes. But you can also describe all astronomical observations using a reference frame that places the earth is the center of the universe. In both cases, say the MWIers, the problem with your choice is its unmotivated perversity: you mangle the theorys mathematical simplicity, for no better reason than a narrow parochial urge to place yourself and your own experiences at the center of creation. The observed motions of the planets clearly want a sun-centered model. In the same way, Schrdingers equation clearly wants measurement to be just another special case of unitary evolutionone that happens to cause your own brain and measuring apparatus to get entangled with the system youre measuring, thereby splitting the world into decoherent branches that will never again meet. History has never been kind to people who put what they want over what the equations want, and it wont be kind to the MWI-deniers either.
This is an important argument, which demands a response by anyone who isnt 100% on-board with MWI. Unlike some people, I happily accept this arguments framing of the issue: no, MWI is not some crazy speculative idea that runs afoul of Occams razor. On the contrary, MWI really is just the obvious, straightforward reading of quantum mechanics itself, if you take quantum mechanics literally as a description of the whole universe, and assume nothing new will ever be discovered that changes the picture.
Nevertheless, I claim that the analogy between MWI and Copernican astronomy fails in two major respects.
The first is simply that the inference, from interference experiments to the reality of many-worlds, strikes me as much more brittle than the inference from astronomical observations to the Copernican system, and in particular, too brittle to bear the weight that the MWIers place on it. Once you know anything about the dynamics of the solar system, its hard to imagine what could possibly be discovered in the future, that would ever again make it reasonable to put the earth at the center. By contrast, we do more-or-less know what could be discovered that would make it reasonable to privilege our world over the other MWI branches. Namely, any kind of dynamical collapse process, any source of fundamentally-irreversible decoherence between the microscopic realm and that of experience, any physical account of the origin of the Born rule, would do the trick.
Admittedly, like most quantum folks, I used to dismiss the notion of dynamical collapse as so contrived and ugly as not to be worth bothering with. But while I remain unimpressed by the specific models on the table (like the GRW theory), Im now agnostic about the possibility itself. Yes, the linearity of quantum mechanics does indeed seem incredibly hard to tinker with. But as Roger Penrose never tires of pointing out, theres at least one phenomenongravitythat we understand how to combine with quantum-mechanical linearity only in various special cases (like 2+1 dimensions, or supersymmetric anti-deSitter space), and whose reconciliation with quantum mechanics seems to raise fundamental problems (i.e., what does it even mean to have a superposition over different causal structures, with different Hilbert spaces potentially associated to them?).
To make the discussion more concrete, consider the proposed experiment of Bouwmeester et al., which seeks to test (loosely) whether one can have a coherent superposition over two states of the gravitational field that differ by a single Planck length or more. This experiment hasnt been done yet, but some people think it will become feasible within a decade or two. Most likelyit will just confirm quantum mechanics, like every previous attempt to test the theory for the last century. But its not a giventhat it will; quantum mechanics has really, truly never been tested in this regime. So suppose the interference pattern isnt seen. Then poof! The whole vast ensemble of parallel universes spoken about by the MWI folks would have disappeared with a single experiment. In the case of Copernicanism, I cant think of any analogous hypothetical discovery with even a shred of plausibility: maybe a vector field that pervades the universe but whose unique source was the earth? So, this is what I mean in saying that the inference from existing QM experiments to parallel worlds seems too brittle.
As you might remember, I wagered $100,000 that scalable quantum computing will indeed turn out to be compatible with the laws of physics. Some people considered thatfoolhardy, and they might be rightbut I think the evidence seems pretty compelling that quantum mechanics can be extrapolated at least that far. (We can already make condensed-matter states involving entanglement among millions of particles; for that to be possible but not quantum computing would seem to require a nasty conspiracy.) On the other hand, when it comes to extending quantum-mechanical linearity all the way up to the scale of everyday life, or to the gravitational metric of the entire universeas is needed for MWIeven my nerve falters. Maybe quantum mechanics does go that far up; or maybe, as has happened several times in physics when exploring a new scale, we have something profoundly new to learn. I wouldnt give much more informative odds than 50/50.
The second way Id say the MWI/Copernicus analogy breaks down arises from a closer examination of one of the MWIers favorite notions: that of parochial-ness. Why, exactly, do people say that putting the earth at the center of creation is parochialgiven that relativity assures us that we can put it there, if we want, with perfect mathematical consistency? I think the answer is: because once you understand the Copernican system, its obvious that the only thing that could possibly make it natural to place the earth at the center, is the accident of happening to live on the earth. If you could fly a spaceship far above the plane of the solar system, and watch the tiny earth circling the sun alongside Mercury, Venus, and the suns other tiny satellites, the geocentric theory would seem as arbitrary to you as holding Cheez-Its to be the sole aim and purpose of human civilization. Now, as a practical matter, youll probably never fly that spaceship beyond the solar system. But thats irrelevant: firstly, because you can very easily imagine flying the spaceship, and secondly, because theres no in-principle obstacle to your descendants doing it for real.
Now lets compare to the situation with MWI. Consider the belief that our universe is more real than all the other MWI branches. If you want to describe that belief as parochial, then from which standpoint is it parochial? The standpoint of some hypothetical godlike being who sees the entire wavefunction of the universe? The problem is that, unlike with my solar system story, its not at all obvious that such an observer can even exist, or that the concept of such an observer makes sense. You cant look in on the multiverse from the outside in the same way you can look in on the solar system from the outside, without violating the quantum-mechanical linearity on which the multiverse picture depends in the first place.
The closest you could come, probably, is to perform a Wigners friend experiment, wherein youd verify via an interference experiment that some other person was placed into a superposition of two different brain states. But Im not willing to say with confidence that the Wigners friend experiment can even be done, in principle, on a conscious being: what if irreversible decoherence is somehow anecessary conditionfor consciousness? (We know that increase in entropy, of which decoherence is one example, seems intertwined with and possibly responsible for our subjective sense of the passage of time.) In any case, it seems clear that we cant talk about Wigners-friend-type experiments without also talking, at least implicitly, about consciousness and the mind/body problemand that that fact ought to make us exceedingly reluctant to declare that the right answer is obvious and that anyone who doesnt see it is an idiot. In the case of Copernicanism, the flying outside the solar system thought experiment isnt similarly entangled with any of the mysteries of personal identity.
Theres a reason why Nobel Prizes are regularly awarded for confirmations of effects that were predicted decades earlier by theorists, and that therefore surprised almost no one when they were finally found. Were we smart enough, its possible that we could deduce almost everything interesting about the worlda priori. Alas, history has shown that were usuallynot smart enough: that even in theoretical physics, our tendencies to introduce hidden premises and to handwave across gaps in argument are so overwhelming that we rarely get far without constant sanity checks from nature.
I cant think of any better summary of the empirical attitude than the famous comment by Donald Knuth: Beware of bugs in the above code. Ive only proved it correct; I havent tried it. In the same way, I hereby declare myself ready to support MWI, but only with the following disclaimer: Beware of bugs in my argument for parallel copies of myself. Ive only proved that they exist; I havent heard a thing from them.Breaking Mahmoud news  too hot for Slashdot

If you hadnt been reading the comments on my last post, you might not know that my old chum Mahmoud Ahmadinejad had launched his own blog on Sunday.  Along with a rambling autobiography, this exciting new blog (which Ive added to my linklog on the right) also includes a poll:
Do you think that the US and Israeli intention and goal by attacking Lebanon is pulling the trigger for another word [sic] war?

When I first visited, only 5% had voted yes, though its now up to 50%.
But wait, it gets better: if Mahmouds site identifies your IP address as coming from Israel, then it tries to install a virus on your computer by exploiting an Internet Explorer vulnerability.  (Thanks to an anonymous commenter for bringing this to my attention.)
I suppose we should grateful that, at least for now, defending oneself against the modern-day Hitler is as simple as installing Firefox.Is it possible to write a competent newspaper article about math?

Yes.The Toaster-Enhanced Turing Machine

Over at Theoretical Computer Science StackExchange, an entertaining debate has erupted about the meaning and validity of the Church-Turing Thesis. The prompt for this debate was a question asking for opinions about Peter Wegner and Dina Goldins repetitive diatribes claiming to refute the myth of the Church-Turing Thesison the grounds that, you see, Turing machines can only handle computations with static inputs and outputs, not interactivity,or programs like operating systems that run continuously. For a demolition of this simple misunderstanding, see Lance Fortnows CACM article. Anyway, I wrote my ownparodic response to the question, which generated so many comments that the moderators started shooing people away. So I decided to repost my answer on my blog. That way, after youre done upvoting my answer over at CS Theory StackExchange :-), you can come back here and continue the discussion in the comments section.

Heres my favorite analogy. Suppose I spent a decade publishing books and papers arguing that, contrary to theoretical computer sciences dogma, the Church-Turing Thesis fails to capture all of computation, becauseTuring machines cant toast bread. Therefore, you need my revolutionarynewmodel, the Toaster-Enhanced Turing Machine (TETM), which allows bread as a possible input and includes toasting it as a primitive operation.
You might say: sure, I have a point, but its a totally uninteresting one. No one ever claimed that a Turing machine could handle every possible interaction with the external world, without first hooking it up to suitable peripherals. If you want a Turing machine to toast bread, you need to connect it to a toaster; then the TM can easily handle the toastersinternal logic(unless this particular toaster requires solving the halting problem or something like that to determine how brown the bread should be!). In exactly the same way, if you want a TM to handle interactive communication, then you need to hook it up to suitable communication devices, as Neel discussed in his answer. In neither case are we saying anything that wouldnt have been obvious to Turing himself.
So, Id say the reason why theres been no followup to Wegner and Goldins diatribes is that theoretical computer science has known how to model interactivity whenever needed, and has happily done so, since the very beginning of the field.
Update (8/30):A related point is as follows. Does it ever give the critics pause that, here inside the Elite Church-Turing Ivory Tower (the ECTIT), the major research themes for the past two decades have included interactive proofs, multiparty cryptographic protocols, codes for interactive communication, asynchronous protocols for routing, consensus, rumor-spreading, leader-election, etc., and the price of anarchy in economic networks? If putting Turings notion of computation at the center of the field makes it so hard to discuss interaction, how is it that so few of us have noticed?
Another Update:To the people who keep banging the drum about higher-level formalisms being vastly more intuitive than TMs, and no one thinking in terms of TMs as a practical matter, let me ask an extremely simple question. What is it that lets all those high-level languagesexistin the first place, that ensures they can always be compiled down to machine code? Could it be  err THE CHURCH-TURING THESIS, the very same one youve been ragging on? To clarify, the Church-Turing Thesis is not the claim that TURING MACHINEZ RULE!! Rather, its the claim that any reasonable programming language will be equivalent in expressive power to Turing machines  andas a consequence, that you might as well think in terms of the higher-level languages if its more convenient to do so. This, of course, was a radical new insight 60-75 years ago.
Update (Sept. 6): Check out this awesome comment by Lou Scheffer, describing his own tale of conversion from a Church-Turing skeptic to believer, and making an extremely apt comparison to the experience of conversion to the belief that R, R2, and so on all have the same cardinality (an experience I also underwent!).The ten most annoying questions in quantum computing

Given an n-qubit pure state, is there always a way to apply Hadamard gates to some subset of the qubits, so as to make all 2n computational basis states have nonzero amplitudes?
Can we get any upper bound on QMIP (quantum multi-prover interactive proofs with unlimited prior entanglement)?  It would suffice to show (for example) that the provers never need more than Ackermann(n) ebits of entanglement.
Can any QMA(2) (QMA with two unentangled yes-provers) protocol be amplified to exponentially small error probability?  If you think the answer is trivially yes, think about it some more!
If a unitary operation U can be applied in polynomial time, then can some square root of U also be applied in polynomial time?
Suppose Alice and Bob are playing n parallel CHSH games, with no communication or entanglement.  Is the probability that theyll win all n games at most pn, for some p bounded below 0.853?
Forget about an oracle relative to which BQP is not in PH.   Forget about an oracle relative to which BQP is not in AM.  Is there an oracle relative to which BQP is not in SZK?
Given any n-qubit unitary operation U, does there exist an oracle relative to which U can be (approximately) applied in polynomial time?
How many mutually unbiased bases are there in non-prime-power dimensions?  (Alright, I dont care about this one, but so many people do that I figured Id put it in.)
Is there an n-qubit pure state that can be prepared by a circuit of size n3, and that cant be distinguished from the maximally mixed state by any circuit of size n2?
Fill this space with your own annoying question!  Here are the rules: the question must involve quantum.  It must be annoying.  It must be clearly-stated  no open-ended pontificating allowed.  It cant be an Everest of the field, like graph isomorphism or increasing the fault-tolerance threshold.  Instead it should be a dinky little molehill, thats nevertheless caused all would-be climbers to fall flat on their asses.Two quick announcements

ThePennsylvania Governors School for the Sciences (PGSS)was an incredibly-successful summer program for gifted high school students in my birth-state of Pennsylvania. PGSS ran from 1982 to 2009 and then was shuttered due to state budget cuts. A group of alumni is now trying toraise enough private funds to restart the program(they need $100,000). Please visit their site, watch their video, and make a small (or large) donation if you feel moved to.
In other news, Ill be speaking at a workshop on Quantum Information Science in Computer and Natural Sciences, organized by Umesh Vazirani and Carl Williams, to be held September 28-29 at the University of Maryland College Park. This workshop is specifically designed for computer scientists, mathematicians, physicists, and others who havent worked in quantum information, but whod like to know more about current research in the area, and to look for connections between quantum information and their own fields. Umesh writes:
The initiative comesat a particularly opportune moment for researchers in complexity theory, given the increasing relevance of quantum techniques in complexity theory  the 2-4 norm paper of Barak, et al (SDPs, Lasserre), exponential lower bounds for TSP polytope via quantum communicationcomplexity arguments (de Wolf et al), quantum Hamiltonian complexity as a generalization of CSPs, lattice-based cryptography whose security is based on quantum arguments, etc.

Hope to see some of you there!Quantum computing in the newz

Update (10/10). In case anyone is interested, heres a comment I posted over at Cosmic Variance, responding to a question about the relevance of Haroche and Winelands work for the interpretation of quantum mechanics.
The experiments of Haroche and Wineland, phenomenal as they are, have zero implications one way or the other for the MWI/Copenhagen debate (nor, for that matter, for third-party candidates like Bohm ). In other words, while doing these experiments is a tremendous challenge requiring lots of new ideas, no sane proponent ofanyinterpretation would have made predictions for their outcomes other than the ones that were observed. To do an experiment about which the proponents of different interpretations mightconceivablydiverge, it would be necessary to try to demonstrate quantum interference in a much,muchlarger system  for example, a brain or an artificially-intelligent quantum computer. And even then, the different interpretations arguably dont make differing predictions about what the publishedresultsof such an experiment would be. If they differ at all, its in what they claim, or refuse to claim, about the experiences of thesubjectof the experiment, while the experiment is underway. But if quantum mechanics is right, then the subject would necessarily haveforgottenthose experiences by the end of the experiment  since otherwise, no interference could be observed!
So, yeah, barring any change to the framework of quantum mechanics itself, it seems likely that people will be arguing about its interpretation forever. Sorry about that.

Where is he? So many wild claims being leveled, so many opportunities to set the record straight, and yet he completely fails to respond. Wheres the passion he showed just four years ago? Doesnt he realize that having the facts on his side isnt enough, has never been enough? Its as if his mind is off somewhere else, or as if hes tired of his role as a public communicator and no longer feels like performing it. Is his silence part of some devious master plan? Is he simply suffering from a lack of oxygen in the brain? Whats going on?
Yeah, yeah, I know. I should blog more. Ill have more coming soon, but for now, two big announcements related to quantum computing.
Today the 2012 Nobel Prize in Physics was awarded jointly to Serge Haroche and David Wineland, for for ground-breaking experimental methods that enable measuring and manipulation of individual quantum systems. Im not very familiar with Haroches work, but Ive known of Wineland for a long time as possibly the top quantum computing experimentalist in the business, setting one record after another in trapped-ion experiments. In awarding this prize, the Swedes have recognized the phenomenal advances in atomic, molecular, and optical physics that have already happenedover the last two decades, largely motivated by the goal of building a scalable quantum computer (along with other, not entirely unrelated goals, like more accurate atomic clocks). In so doing, theyve given whats arguably the first-ever Nobel Prize for quantum computing research, withoutviolating their policy to reward only work thats been directly confirmed by experiment. Huge congratulations to Haroche and Wineland!!
In other quantum computing developments: yes, Im aware of the latest news from D-Wave, which includes millions of dollars in new funding from Jeff Bezos (the founder of Amazon.com, recipients of a large fraction of my salary). Despite having officially retired as Chief D-Wave Skeptic, I posted a comment on Tom Simonites article in MIT Technology Review, and also sent the following email to a journalist.
Im probably not a good person to comment on the business aspects ofD-Wave. Theyve been extremely successful raising money in the past,so its not surprising to me that they continue to be successful. Forme, three crucial points to keep in mind are:
(1) D-Wave still hasnt demonstrated 2-qubit entanglement, which I seeas one of the non-negotiable sanity checks for scalable quantumcomputing. In other words: if youre producing entanglement, then youmight or might not be getting quantum speedups, but if youre notproducing entanglement, then our current understanding fails toexplain how you could possibly be getting quantum speedups.
(2) Unfortunately, the fact that D-Waves machine solves someparticular problem in some amount of time, and a specific classicalcomputer running (say) simulated annealing took more time, is not (byitself) good evidence that D-Wave was achieving the speedup because ofquantum effects. Keep in mind that D-Wave has now spent ~$100 millionand ~10 years of effort on a highly-optimized, special-purpose computerfor solving one specific optimization problem. So, as I like to putit, quantum effects could be playing the role of the stone ina stone soup: attracting interest, investment, talented people, etc. to builda device that performs quite well at its specialized task, but notultimately because of quantum coherence in that device.
(3) The quantum algorithm on which D-Waves business model isbased  namely, the quantum adiabatic algorithm  has the propertythat it degrades gracefully to classical simulated annealing whenthe decoherence rate goes up. This, fundamentally, is the thing thatmakes it difficult to know what role, if any, quantum coherence isplaying in the performance of their device. If they were trying touse Shors algorithm to factor numbers, the situation would be muchmore clear-cut: a decoherent version of Shors algorithm just givesyou random garbage. But a decoherent version of the adiabaticalgorithm still gives you a pretty good (but now essentiallyclassical) algorithm, and thats what makes it hard to understandwhats going on here.
As Ive said before, I no longer feel like playing an adversarialrole. I really, genuinely hope D-Wave succeeds. But the burden is onthem to demonstrate that their device uses quantum effects to obtain aspeedup, and they still havent met that burden. When and if thesituation changes, Ill be happy to say so. Until then, though, Iseem to have the unenviable task of repeating the same observationover and over, for 6+ years, and confirming that, no, the latest sale,VC round, announcement of another application (which, once again,might or might not exploit quantum effects), etc., hasntchanged the truth of that observation.
Best,
ScottPipin-hot learnin theorems

Ive decided to launch my latest paper on the blogosphere even before posting it to quant-ph  so that you, my loyal readers, can be the very first to lay eyes on it.  (True fact: as I was writing, I didnt look once at the screen.)  Comments more than welcome.
The Learnability of Quantum States [PS] [PDF]
Scott Aaronson
Abstract: Let me warn you up-front, this is one big-ass mother of a paper.  Its got learning.  Its got quantum.  Its got philosophy.  Its got weird complexity classes (naturally).  Its even got experimental physics applications (dont worry, I showered afterward).  And dude.  When I say experimental, Im not talking wormholes or anthropic postselection.  Im talking stuff that you, the quantum state tomographer, can try in your lab today.  And no, this is not the real abstract.
Update (8/20): Ive posted a slightly revised version, mostly in response to the comments I received here.Silver lining

Update (10/31): While I continue to engage in surreal arguments in the comments sectionScott, Im profoundly disappointed that a scientist like you, who surely knows better, would be so sloppy as to assert without any real proof that just because it has tusks and a trunk, and looks and sounds like an elephant, and is the size of the elephant, that it therefore is an elephant, completely ignoring the blah blah blah blah blahwhile I do that, there are a few glimmerings that the rest of the world is finally starting to get it. A new story from The Onion, which I regard as almost the only real newspaper left:
Nation Suddenly Realizes This Just Going To Be A Thing That Happens From Now On
Update (11/1): OK, and this morning from Nicholas Kristof, whos long been one of the rare nonOnion practitioners of journalism: Will Climate Get Some Respect Now?

Im writing from the abstract, hypothetical future that climate-change alarmists talk aboutthe one where huge tropical storms batter the northeastern US, coastal cities are flooded, hundreds of thousands are evacuated from their homes, etc. I always imagined that, when this future finally showed up, at least Id have the satisfaction of seeing the deniers admit they were grievously wrong, and that I and those who think similarly were right. Which, for an academic, is a satisfaction that has to be balanced carefully against the possible destruction of the world. I dont think I had the imagination to foresee that the prophesied future would actually arrive, and that climate change would simultaneously disappear as a political issuewith the forces of know-nothingism bolder than ever, pressing their advantage into questions like whether or not raped women can get pregnant, as the President weakly pleads that he too favors more oil drilling. I should have known from years of blogging that, if you hope for the consolation of seeing those who are wrong admit to being wrong, you hope for a form of happiness all but unattainable in this world.
Yet, if the transformation of the eastern seaboard into something out of the Jurassic hasnt brought me that satisfaction, it has brought a different, completely unanticipated benefit. Trapped in my apartment, with the campus closed and all meetings cancelled, Ive found, for the first time in months, that I actually have some time to write papers. (And, well, blog posts.) Because of this, part of me wishes that the hurricane would continue all week, even a month or two (minus, of course, the power outages, evacuations, and other nasty side effects). I could learn to like this future.
At this point in the post, I was going to transition cleverly into an almost (but not completely) unrelated question about the nature of causality. But I now realize that the mention of hurricanes and (especially) climate change will overshadow anything I have to say about more abstract matters. So Ill save the causality stuff for tomorrow or Wednesday. Hopefully the hurricane will still be here, and Ill have time to write.Low-hanging fruit from two conjoined trees

Alright, I can give an oracle relative to which BQP is not in SZK, thereby knocking off one of the Ten Most Annoying Questions in Quantum Computing.
Its a forehead-slapper.  Just take the problem from the paper Exponential algorithmic speedup by quantum walk by Andrew Childs et al. Here the oracle encodes an exponentially large graph, consisting of two binary trees conjoined at the leaves by a random cycle:

(I hope Childs et al. will forgive me for swiping their graphic.)
Each vertex is labeled by a random string, and given the label of a vertex, the oracle tells us the labels of its neighbors.  Then, given the label of the Entrance vertex, the problem is to decide (lets say) whether the label of the Exit vertex starts with a 1 or a 0.
Childs et al. proved that this oracle problem is in BQP but not in BPP.  Intuitively, any classical random walk on the graph will get stuck for an exponentially long time in the enormous middle region, but because of interference effects, a quantum walk will tunnel right through to the Exit vertex with 1/polynomial probability.
Now, its easy to generalize their proof that the problem is not in BPP, to show that its not in SZK.  One way to see this is that, for a prover to convince a verifier of the solution, the prover will (basically) have to reveal where the Exit vertex is, thereby violating the zero-knowledge property.  Another way to see it is that, if we consider the Sahai-Vadhan characterization of SZK in terms of the Statistical Difference problem, then neither of the two distributions were comparing will depend non-negligibly on the Exit vertex.
Disappointingly, this solution is way too trivial to publish, and almost too trivial even to blog.  On the other hand, so far Ive been unable to extend the solution to get an oracle relative to which BQP is not in AM.  Every variant of the problem Ive come up with is in AM intersect coAM, sometimes for non-obvious reasons.  Anyone want to help me?A causality post, for no particular reason

The following question emerged from a conversation with the machine learning theorist Pedro Domingos a month ago.
Consider a hypothetical race of intelligent beings, the Armchairians, who never take any actions: never intervene in the world, never do controlled experiments, never try to build anything and see if it works. The sole goal of the Armchairians is to observe the world around them and, crucially, to make accurate predictions about whats going to happen next. Would the Armchairians ever develop the notion of cause and effect? Or would they be satisfied with the notion of statistical correlation? Or is the question kind of silly, the answer depending entirely on what we mean by developing the notion of cause and effect? Feel free to opine away in the comments section.Fruitcake fields

So, this years Fields Medals go to Terence Tao and Grisha Perelman (duhhhh), as well as to Andrei Okounkov and Wendelin Werner.  The Nevanlinna Prize goes to an already-prize-bedecked Jon Kleinberg, my professor at Cornell way back in 97.  Congratulations to all!
Meanwhile, theres a long article in yesterdays New Yorker about Perelman and the Poincar conjecture, by Sylvia Nasar (the medias go-to person for reclusive mathematical geniuses) and David Gruber.  Unfortunately the articles not on the web, but fearless detective that I am, I was able to track it down in a so-called bookstore.
Nasar and Gruber find Perelman in a St. Petersburg apartment, where he lives with his mom, doesnt check his mail, and just generally makes Andrew Wiles look like a hard-partying, elliptic-curve-modularizing regular dude.  Perelman is nevertheless happy to grant Nasar and Gruber an interview, to confirm that he intends to be the first person in history to turn down the Fields, and to complain about his fellow mathematicians lax ethical standards.
What exactly is he talking about?  It wasnt clear to me, but Nasar and Gruber devote much of their article to an indictment of 1982 Fields Medalist Shing-Tung Yau, who they portray as trying to usurp credit from Perelman for the benefit of his students Xi-Ping Zhu and Huai-Dong Cao.  (Zhu and Cao wrote a 328-page exposition of Perelmans ideas, complementing other expositions by Bruce Kleiner and John Lott and by John Morgan and Gang Tian.)  I have no idea to what extent, if any, the criticism of Yau is justified.  But to my mind, failing to write up your result properly, and then getting upset when those who do write it up properly try to share credit, is a bit like leaving your wallet on the sidewalk and then shaking your head at human depravity when someone tries to steal it.
Nasar and Gruber also dont comment on the obvious irony of Perelmans unworldliness: that, by being such a fruitcake, hes guaranteeing hell draw vastly more attention to himself than he would by just accepting the goddamned medal.  (Feynman, though not exactly publicity-shy, employed similar reasoning to conclude that turning down the Nobel Prize would be a bad idea.)  Indeed, supposing Perelman did aspire to celebrity status, my public-relations advice to him would be to do exactly what hes doing right now.
Update: The New Yorker article is now online.The $10 billion voter

Update (Nov. 8): Slates pundit scoreboard.

Update (Nov. 6): In crucial election news, a Florida woman wearing an MIT T-shirt was barred from voting, because the election supervisor thought her shirt was advertising Mitt Romney.

At the time of writing, Nate Silver is giving Obama an 86.3% chance. I accept his estimate, while vividly remembering various admittedly-cruder forecasts the night of November 5, 2000, which gave Gore an 80% chance. (Of course, those forecasts need not have been wrong; an event with 20% probability really does happen 20% of the time.) For me, the main uncertainties concern turnout and the effects of various voter-suppression tactics.
In the meantime, I wanted to call the attention of any American citizens reading this blog to the wonderful Election FAQ of Peter Norvig, director of research at Google and a person well-known for being right about pretty much everything. The following passage in particular is worth quoting.
Is it rational to vote?
Yes. Voting for president is one of the most cost-effective actions any patriotic American can take.
Let me explain what the question means. For your vote to have an effect on the outcome of the election, you would have to live in a decisive state, meaning a state that would give one candidate or the other the required 270th electoral vote. More importantly, your vote would have to break an exact tie in your state (or, more likely, shift the way that the lawyers and judges will sort out how to count and recount the votes). With 100 million voters nationwide, what are the chances of that? If the chance is so small, why bother voting at all?
Historically, most voters either didnt worry about this problem, or figured they would vote despite the fact that they werent likely to change the outcome, or vote because they want to register the degree of support for their candidate (even a vote that is not decisive is a vote that helps establish whether or not the winner has a mandate). But then the 2000 Florida election changed all that, with its slim 537 vote (0.009%) margin.
What is the probability that there will be a decisive state with a very close vote total, where a single vote could make a difference? Statistician Andrew Gelman of Columbia University says about one in 10 million.
Thats a small chance, but what is the value of getting to break the tie? We can estimate the total monetary value by noting that President George W. Bush presided over a $3 trillion war and at least a $1 trillion economic melt-down. Senator Sheldon Whitehouse (D-RI) estimated the cost of the Bush presidency at $7.7 trillion. Lets compromise and call it $6 trillion, and assume that the other candidate would have been revenue neutral, so the net difference of the presidential choice is $6 trillion.
The value of not voting is that you save, say, an hour of your time. If youre an average American wage-earner, thats about $20. In contrast, the value of voting is the probability that your vote will decide the election (1 in 10 million if you live in a swing state) times the cost difference (potentially $6 trillion). That means the expected value of your vote (in that election) was $600,000. What else have you ever done in your life with an expected value of $600,000 per hour? Not even Warren Buffett makes that much. (One caveat: you need to be certain that your contribution is positive, not negative. If you vote for a candidate who makes things worse, then you have a negative expected value. So do your homework before voting. If you havent already done that, then youll need to add maybe 100 hours to the cost of voting, and the expected value goes down to $6,000 per hour.)
Id like to embellish Norvigs analysis with one further thought experiment. While I favor a higher figure, for arguments sake lets accept Norvigs estimate that the cost George W. Bush inflicted on the country was something like $6 trillion. Now, imagine that a delegation of concerned citizens from 2012 were able to go back in time to November 5, 2000, round up 538 lazy Gore supporters in Florida who otherwise would have stayed home, and bribe them to go to the polls. Set aside the illegality of the time-travelers action: theyre already violating the laws of space, time, and causality, which are well-known to be considerably more reliable than Florida state election law! Set aside all the other interventions that also wouldve swayed the 2000 election outcome, and the 20/20 nature of hindsight, and the insanity of Floridas recount process. Instead, lets simply ask: how much should each of those 538 lazy Floridian Gore supporters have been paid, in order for the delegation from the future to have gotten its moneys worth?
The answer is a mind-boggling ~$10 billion per voter. Think about that: just for peeling their backsides off the couch, heading to the local library or school gymnasium, and punching a few chads (all the way through, hopefully), each of those 538 voters would have instantly received the sort of wealth normally associated with Saudi princes or founders of Google or Facebook. And the country and the world would have benefited from that bargain.
No, this isnt really a decisive argument for anything (Ill leave it to the commenters to point out the many possible objections). All it is, is an image worth keeping in mind the next time someone knowingly explains to you why voting is a waste of time.A far-off dream: automating a problem in P

In a comment on my last post, Bram Cohen writes:
This whole business of formality and review is really kind of dumb. A mathematical theorem is only really proven when a computer can verify the proof. Until then, its just hand-waving which has some degree of utility when generating a real proof.
Were it standard to present proofs in computer-checkable form, there would be no review process at all. In fact it would be possible to send a proof to a theorem server which would automatically accept any proof which checked out. Had Perelman submitted to one of those, we wouldnt have had any review process at all, and had complete confidence from day 1, and there wouldnt be any of this stupid game of who really proved it by making the arguments sufficiently formal or detailed.
I view the switch to doing mathematics in the style just described as inevitable
Like Bram, I also hope and expect that mathematicians will eventually switch to machine-readable proofs supplemented by human-readable explanations.  That would certainly beat the current standard, proofs that are readable by neither machines nor humans.
So then why hasnt it happened already? Probably the best way to answer this question is to show you the proof, in a state-of-the-art formal verification system called HOL Light, that the square root of 2 is irrational.

let rational = new_definition
`rational(r) = ?p q. ~(q = 0) / abs(r) = &p; / &q;`;;

let NSQRT_2 = prove
(`!p q. p * p = 2 * q * q ==> q = 0`,
MATCH_MP_TAC num_WF THEN REWRITE_TAC[RIGHT_IMP_FORALL_THM] THEN
REPEAT STRIP_TAC THEN FIRST_ASSUM(MP_TAC o AP_TERM `EVEN`) THEN
REWRITE_TAC[EVEN_MULT; ARITH] THEN REWRITE_TAC[EVEN_EXISTS] THEN
DISCH_THEN(X_CHOOSE_THEN `m:num` SUBST_ALL_TAC) THEN
FIRST_X_ASSUM(MP_TAC o SPECL [`q:num`; `m:num`]) THEN
POP_ASSUM MP_TAC THEN CONV_TAC SOS_RULE);;

let SQRT_2_IRRATIONAL = prove
(`~rational(sqrt(&2))`,
SIMP_TAC[rational; real_abs; SQRT_POS_LE; REAL_POS; NOT_EXISTS_THM] THEN
REPEAT GEN_TAC THEN DISCH_THEN(CONJUNCTS_THEN2 ASSUME_TAC MP_TAC) THEN
DISCH_THEN(MP_TAC o AP_TERM `x. x pow 2`) THEN
ASM_SIMP_TAC[SQRT_POW_2; REAL_POS; REAL_POW_DIV; REAL_POW_2; REAL_LT_SQUARE;
REAL_OF_NUM_EQ; REAL_EQ_RDIV_EQ] THEN
ASM_MESON_TAC[NSQRT_2; REAL_OF_NUM_EQ; REAL_OF_NUM_MUL]);;

Cool  now lets do Fermat and Poincar!  Any volunteers?
Seriously, the biggest accomplishments to date have included formal proofs of the Jordan Curve Theorem (75,000 lines) and the Prime Number Theorem (30,000 lines).  If you want to know which other famous theorems have been formalized, check out this excellent page.  Or look at these notes by Harvey Friedman, which cut through the crap and tell us exactly where things stand.
A huge part of the problem in this field seems to be that theres neither a standard proof format nor a standard proof repository  no TeX or HTML, no arXiv or Wikipedia.   Besides HOL Light, theres also ProofPower, Isabelle, Coq, Mizar, and several other competitors.  Id probably go with Mizar, simply because the proofs in it look the most to me like actual math.
Friedman gives machine-readable proofs fifty years to catch on among real mathematicians.  That seems about right  though the time could be reduced if the Don Knuth, Tim Berners-Lee, Paul Ginsparg, or Jimmy Wales of proof-checking were to appear between now and then.  As usual, it mostly comes down to humans.
Update: Freek Wiedijk put together a fantastic online book, which shows the proofs that the square root of 2 is irrational in 17 different formal systems.  The QED Manifesto is also worth a look.  This manifesto makes it clear that there are people in the formal verification world with a broad enough vision  if you like, the Ted Nelsons of proof-checking.  Nelson is the guy who dreamed in 1960 of creating a global hypertext network.  In his case, it took 35 years for the dream to turn into software and protocols that people actually wanted to use (not that Nelson himself is at all happy with the result).  How long will it take in the case of proof-checking?Proving Without Explaining, and Verifying Without Understanding

Last Friday, I was at a Symposium on the Nature of Proof at UPenn, to give a popular talk about theoretical computer scientists expansions of the notion of mathematical proof (to encompass things like probabilistic, interactive, zero-knowledge, and quantum proofs). This really is some of the easiest, best, and most fun material in all of CS theory to popularize. Here are iTunes videos of my talk and the three others in the symposium: Im video #2, logician Solomon Feferman is #3, attorney David Rudovsky is #4, and mathematician Dennis DeTurck is #5. Also, here are my PowerPoint slides. Thanks very much to Scott Weinstein at Penn for organizing the symposium.
In other news, the Complexity Zoo went down yet again this week, in a disaster that left vulnerable communities without access to vital resources like nondeterminism and multi-prover interaction. Luckily, computational power has since been restored: with help from some volunteers, I managed to get the Zoo up and running again on my BlueHost account. But while the content is there, it looks horrendously ugly; all the formatting seems to be gone. And the day I agreed to let the Zoo be ported to MediaWiki was the day I lost the ability to fix such problems. What I really need, going forward, is for someone else simply to take charge of maintaining the Zoo: its become painfully apparent both that it needs to be done and that I lack the requisite IT skills. If you want to take a crack at it, heres an XML dump of the Zoo from a few months ago (I dont think its really changed since then). You dont even need to ask my permission: just get something running, and if it looks good, Ill anoint you the next Zookeeper and redirect complexityzoo.com to point to your URL.
Update (Nov. 18): The Zoo is back up with the old formatting and graphics!! Thanks so much to Charles Fu for setting up the new complexity-zoo.net (as well as Ethan, who set up a slower site that tided us over). Ive redirected complexityzoo.com to point to complexity-zoo.net, though it might take some time for your browser cache to clear.The Boson Apocalypse

If the world ends today, at least it wont do so without three identical photons having been used to sample from a probability distribution defined in terms of the permanents of 33 matrices, thereby demonstrating the Aaronson-Arkhipov BosonSampling protocol. And the results were obtained by no fewer than four independent experimental groups, some of whom have now published in Science. One of the groups is based in Brisbane, Australia, one in Oxford, one in Vienna, and one in Rome; they coordinated to release their results the same day. Thats right, the number of papers (4) that these groups managed to choreograph to appear simultaneously actually exceeds the number of photons that they so managed (3). The Brisbane group was even generous enough to ask me to coauthor: I havent been within 10,000 miles of their lab, but I did try to make myself useful to them as a complexity theory consultant.
Here are links to the four experimental BosonSampling papers released in the past week:

Experimental BosonSampling by Broome et al. (Brisbane)
Experimental Boson Sampling by Tillmann et al. (Vienna)
Experimental Boson Sampling by Walmsley et al. (Oxford)
Experimental boson sampling in arbitrary integrated photonic circuits by Crespi et al. (Italy)

For those who want to know the theoretical background to this work:

My and Alexs original 100-page BosonSampling paper(to appear soon in the journalTheory of Computing)
The 10-page STOC2011 versionof our paper
My PowerPoint slides
Alexs slides
Theoretical Computer Science StackExchange question and answer
Gil Kalais blog post
Old Shtetl-Optimized post

For those just tuning in, here are some popular-level articles about BosonSampling:

Larry Hardestys MIT News article (from last year)
University of Queensland press release
Victorian counting device gets speedy quantum makeover (this week, from New Scientist; the article is not bad except that it ought to credit Alex Arkhipov)
New Form of Quantum Computation Promises Showdown with Ordinary Computers, by Adrian Cho (from Science)

Ill be happy to answer further questions in the comments; for now, heres a brief FAQ:
Q: Why do you need photons in particular for these experiments?
A: What we need is identical bosons, whose transition amplitudes are given by the permanents of matrices. If it were practical to do this experiment with Higgs bosons, they would work too! But photons are more readily available.
Q:But a BosonSampling device isnt really a computer, is it?
A: It depends what you mean by computer! If you mean a physical system that you load input into, let evolve according to the laws of physics, then measure to get an answer to a well-defined mathematical problem, then sure, its a computer!  The only question is whether its a useful computer. We dont believe it can be used as a universal quantum computeror even, for that matter, as a universal classical computer. More than that, Alex and I werent able to show that solving the BosonSampling problem has any practical use for anything. However, we did manage to amass evidence that, despite being useless, the BosonSampling problem is also hard (at least for a classical computer). And for us, the hardness of classical simulation was the entire point.
Q: So, these experiments reported in Science this week have done something that no classical computer could feasibly simulate?
A: No, a classical computer can handle the simulation of 3 photons without muchor really, anydifficulty. This is only a first step: before this, the analogous experiment (called the Hong-Ou-Mandel dip) had only ever been performed with 2 photons, for which theres not even any difference in complexity between the permanent and the determinant (i.e., between bosons and fermions). However, if you could scale this experiment up to about 30 photons, then its likely that the experiment would be solving the BosonSampling problem faster than any existing classical computer (though the latter could eventually solve the problem as well). And if you could scale it up to 100 photons, then you might never even know if your experiment was working correctly, because a classical computer would need such an astronomical amount of time to check the results.Chasmgasm

The most important research question in astronomy, to judge from the news websites, is neither the nature of dark matter and energy, nor the origin of the Pioneer anomaly or gamma-ray bursts beyond the GZK cutoff, nor the possible existence of Earth-like extrasolar planets.  No, the big question is whether Pluto is really a planet, and if so, whether Charon and Ceres are really planets, and whether something has to be round to be a planet, and if so, how round.
I was going to propose we bring in Wittgenstein to settle this.  But I guess the astronomers have already ruled.
Richard Dawkins often rails against what he calls the tyranny of the discontinuous mind.  As far as I know, hes not complaining about those of us who like our Hilbert spaces finite-dimensional and our quantum gravity theories discrete.  Rather, hes complaining about those who insist on knowing, for every humanoid fossil, whether its really human or really an ape.  Ironically, its often the same people who then complain about the embarrassing lack of transitional forms!
Can anyone suggest a word for a person obsessed with drawing firm but arbitrary lines through a real-valued parameter space?  (Lawyer is already taken.)  Ive already figured out the word for a debate about such lines, like the one we saw in Prague: chasmgasm.Quantum Complexity Theory Student Project Showcase 2!

(Note: The 2! in the title of this post really does mean 2 factorial, if you want it to.)
With the end of the semester upon us, its time for a once-every-two-year tradition: showcasing student projects from my 6.845 Quantum Complexity Theory graduate course at MIT. For my previous showcase, in 2010, I chose six projects that I thought were especially outstanding. This year, however, there were so many great projectsand so many, in particular, that could actually be useful to people in quantum computingthat I decided simply to open up the showcase to the whole class. I had 17 takers; their project reports and 10-minute presentation slides are below.
Let me mention a few projects that tried to do something new and audacious. Jenny Barry generalizes the notion of Partially Observable Markov Decision Processes (POMDPs) to the quantum case, and uses a recent result of Eisert et al., showing that certain problems in quantum measurement theory are undecidable (like, literally Turing-undecidable), to show that goal state reachability for QOMDPs is also Turing-undecidable (despite being decidable for classical POMDPs). Matt Falk suggests a novel quantum algorithm for spatial search on the 2D grid, and gives some numerical evidence that the algorithm finds a marked item in O(n) time (which, if true, would be the optimal bound, beating the previous runtime of O((n log n))). Matt Coudron and Henry Yuen set out to prove that the Vazirani-Vidick protocol for quantum randomness expansion is optimal, and achieve some interesting partial results. Mohammad Bavarian (well, jointly with me) asks whether theres a fast quantum algorithm for PARITY that gets the right answer on just slightly more than 50% of the inputsand shows, rather surprisingly, that this question is closely related to some of the hardest open problems about Boolean functions, like sensitivity versus block sensitivity.
This year, though, I also want to call special attention to the survey projects, since some of them resulted in review articles that could be of real use to students and researchers in quantum computing theory. Notably, Adam Bookatz compiled the first list of essentially all known QMA-complete problems, analogous to (but shorter than!) Garey and Johnsons listing of known NP-complete problems in 1979. Chris Graves surveyed the known quantum fault-tolerance bounds. Finally, three projects took on the task of understanding and explaining some of the most important recent results in quantum complexity theory: Travis Hance on Thomas Vidick and Tsuyoshi Itos NEXP in MIP* breakthrough; Emily Stark on Mark Zhandrys phenomenal results on the security of classical cryptographic constructions against quantum attack; and Max Zimet on Jordan-Lee-Preskills major work on simulation of quantum field theories.
(Oops, sorry  did I use words like important, breakthrough, and phenomenal too often in that last sentence, thereby triggering the wrath of the theoretical computer science excitement police? Well then, come over to my apartment and friggin arrest me.)
Anyway, thanks so much to all the students for making 6.845 such an awesome class (at least on my end)! Without further ado, heres the complete project showcase:

Arturs Backurs. Influences in Low-Degree Polynomials. [Report] [Slides]


Jenny Barry. Quantum POMDPs (Partially Observable Markov Decision Processes). [Report] [Slides]


Mohammad Bavarian. The Quantum Weak Parity Problem. [Report] [Slides]


Shalev Ben-David. Decision-Tree Complexity. [Report] [Slides]


Adam Bookatz. QMA-Complete Problems. [Report] [Slides]


Adam Bouland. Classifying Beamsplitters. [Report] [Slides]


Matt Coudron and Henry Yuen. Some Limits on Non-Local Randomness Expansion. [Report] [Slides]


Charles Epstein. Adiabatic Quantum Computing. [Report] [Slides]


Matt Falk. Quantum Search on the Spatial Grid. [Report] [Slides]


Badih Ghazi. Quantum Query Complexity of PARITY with Small Bias. [Report] [Slides]


Chris Graves. Survey on Bounds on the Quantum Fault-Tolerance Threshold. [Report] [Slides]


Travis Hance. Multiprover Interactive Protocols with Quantum Entanglement. [Report] [Slides]


Charles Herder. Blind Quantum Computation. [Report] [Slides]


Vincent Liew. On the Complexity of Manipulating Quantum Boolean Circuits. [Report] [Slides]


Emily Stark. Classical Crypto, Quantum Queries. [Report] [Slides]


Ted Yoder. Generalized Stabilizers. [Report] [Slides]


Max Zimet. Complexity of Quantum Field Theories. [Report] [Slides]Why Im not a physicist: reason #4328

Theres a trivial question about particle accelerators that bugged me for a while.   Today I finally figured out the answer, and Im so excited by my doofus discovery that I want to tell the world.
In Ye Olde Times, accelerators used to smash particles against a fixed target.  But todays accelerators smash one particle moving at almost the speed of light against another particle moving at almost the speed of light  thats why theyre called particle colliders (duhhh).  Now, youd think this trick would increase the collision energy by a constant factor, but according to the physicists, it does asymptotically better than that: it squares the energy!
My question was, how could that be?  Even if both particles are moving, we can clearly imagine that one of them is stationary, since the particles motion with respect to the Earth is irrelevant.  So then whats the physical difference between a particle hitting a fixed target and two moving particles hitting each other, that could possibly produce a quadratic improvement in energy?
[Warning: Spoiler Ahead]
The answer pops out if we consider the rule for adding velocities in special relativity.  If in our reference frame, particle 1 is headed left at a v fraction of the speed of light, while particle 2 is headed right at a w fraction of the speed of light, then in particle 1s reference frame, particle 2 is headed right at a (v+w)/(1+vw) fraction of the speed of light.  Here 1+vw is the relativistic correction, the thing you put in to keep the fraction less than 1.   If v and w are both close to 0, then of course we get v+w, the Newtonian answer.
Now set v=w=1-.  Then (v+w)/(1+vw) = 1  2/(2-2+2), which scales like 1-2.  Aha!
To finish the argument, remember that relativistic energy increases with speed like 1/sqrt(1-v2).  If we plug in v=1-, then we get 1/sqrt(2-2), while if we plug in v=1-2, then we get 1/sqrt(22-4).  So in the case of a fixed target the energy scales like 1/sqrt(), while in the case of two colliding particles it scales like 1/.
In summary, nothings going on here except relativistic addition of velocities.  As with Grovers algorithm, as with the quantum Zeno effect, its our intuition about linear versus quadratic that once again leads us astray.Why Im not a physicist: reason #4329

I botched the calculation.  While I got the answer I wanted (a quadratic improvement in energy), and while I more-or-less correctly identified the reason for that answer (unintuitive properties of the relativistic velocity addition formula), I did the calculation in the rest frame of one of the particles instead of the zero-momentum rest frame, and thereby obtained a scaling of 1/sqrt() versus 1/ instead of 1/1/4 versus 1/sqrt().   As a result, my answer flagrantly violates conservation of energy.
Thanks to rrtucci and perseph0ne.  In my defense, I did call it a doofus discovery.Run free, my animal friends!

In August of 2002 I opened the Complexity Zoo: an online bestiary of 196 complexity classes, since expanded to 443. Yesterday I entrusted the Zoo to anyone on Earth who wants to feed the animals or contribute their own. This was possible because of John Stockton, who graciously converted the Zoo to wiki form.
The decision to relinquish control of my best-known work was tinged with regret. But at age 3, my baby is all grown up, and its time to send it off to grad school so I can move on to other things.
This seems like a good occasion to ask a potentially heretical question:
Did theoretical computer science take a wrong turn when it introduced complexity classes?
For readers with social lives, I should explain that a complexity class is a class of problems solvable by some sort of idealized computer. For example, P (Polynomial-Time) consists of all problems that an ordinary computer could solve in a reasonable amount of time, meaning an amount that increases like the problem size raised to a fixed power. To illustrate, a few years ago Agrawal, Kayal, and Saxena made international headlines for showing that PRIMES is in P. What this means is that they found a general method to decide if an n-digit number is prime or composite, using only about n12 steps  much less than youd need to try all possible divisors. Faster methods were known before, but they had a small chance of not producing an answer.
Other complexity classes include PSPACE (Polynomial Space), BQP (Bounded-Error Quantum Polynomial Time), EXP, NP, coNP, BPP, RP, ZPP, PH, 2P, P/poly, L, NL, PP, AWPP, LWPP, BQNC,  QMA, QCMA, S2P, SZK, NISZK, and many more.
The advantage of this alphabet soup is that it lets us express complicated insights in an incredibly compact way:

If NP is in BPP then NP=RP.
If NP is in P/poly then PH = 2P.
PH is in P#P.
NL=coNL.

The disadvantage, of course, is that it makes us sound like the fabled prisoners who tell each other jokes by calling out their code numbers. Again and again, Ive had trouble getting across to outsiders that complexity theory is not about capital letters, any more than chemistry is about weird strings like NaCl-KCl-MgCl2-H20. Why is it so hard to explain that we dont worry about EXP vs. P/poly because were eccentric anal-retentives, but because we want to know whether a never-ending cavalcade of machines, each richer and more complicated than the last, might possibly succeed at a task on which any one machine must inevitably founder  namely, the task of outracing time itself, of simulating cosmic history in an eyeblink, of seeing in the unformed clumps of an embryonic universe the swirl of every galaxy and flight of every hummingbird billions of years hence, like Almighty God Himself?
(Alright, maybe I meant BQEXP vs. BQP/poly.)
In the early 70s, there was apparently a suggestion that NP be called PET, which could stand for three things: Probably Exponential Time, Provably Exponential Time (if P!=NP), or Previously Exponential Time (if P=NP). If this silly name had stuck, would our field have developed in a different direction?Lincoln Blogs

Sorry for the terrible pun. Todays post started out as a comment on a review of the movie Lincoln on Sean Carrolls blog, but it quickly become too long, so I made it into a post on my own blog. Apparently I lack Abes gift for concision.
I just saw Lincoln  largely inspired by Seans review  and loved it. It struck me as the movie that Lincoln might have wanted to be made about himself: it doesnt show any of his evolution, but at least it shows the final result of that evolution, and conveys the stories, parables, and insight into human nature that he had accumulated by the end of his life in a highly efficient manner.
Interestingly, the Wikipedia page says that Spielberg commissioned, but then ultimately rejected, two earlier scripts that would have covered the whole Civil War period, and (one can assume) Lincolns process of evolution. I think that also could have been a great movie, but I can sort-of understand why Spielberg and Tony Kushner made the unusual choice they did: at the level of detail they wanted, it seems like it would be impossible to do justice to Lincolns whole life, or even the last five years of it, in anything less than a miniseries.
I agree with the many people who pointed out that the movie could have given more credit to those who were committed antislavery crusaders from the beginningrather than those like Lincoln, who eventually came around to the positions we now associate with him after a lot of toying with ideas like blacks self-deporting to Liberia. But in a way, the movie didnt need to dole out such credit: today, we know (for example) that Thaddeus Stevens had history and justice 3000% on his side, so the movie is free to show him as the nutty radical that he seemed to most others at the time. And theres even a larger point: never the most diligent student of history, I (to take one embarrassing example) had only the vaguest idea who Thaddeus Stevens even was before seeing the movie. Now Ive spent hours reading about him, as well as about Charles Sumner, and being moved by their stories.
(At least I knew about the great Frederick Douglass, having studied his Narrative in freshman English class. Douglass and I have something in common: just as a single sentence he wrote, I would unite with anybody to do right and with nobody to do wrong, will reverberate through the ages, so too, I predict, will a single sentence I wrote: Australian actresses are plagiarizing my quantum mechanics lecture to sell printers.)
More broadly, I think its easy for history buffs to overestimate how much people already know about this stuff. Indeed, I can easily imagine that millions of Americans who know Lincoln mostly as the dude on the $5 bill (who freed some slaves, wore a top hat, used the word fourscore, and got shot) will walk out of the cineplex with a new and ~85% accurate appreciation for what Lincoln did to merit all that fuss, and why his choices werent obvious to everyone else at the time.
Truthfully, though, nothing made me appreciate the movie more than coming home and reading countless comments on movie review sites denouncing Abraham Lincoln as a bloodthirsty war criminal, and the movie as yet more propaganda by the victors rewriting history. Even on Seans blog we find this, by a commenter named Tony:
Im not one who believes we have to go to war to solve every problem we come across, I cant believe that Lincoln couldnt have found a solution to states rights and slavery in a more peaceful course of action. It seems from the American Revolutionary war to the present it has been one war after another  The loss of life of all wars is simply staggering, what a waste of humanity.
Well look, successive presidential administrations did spend decades trying to find a peaceful solution to the states rights and slavery issue; the massive failure of their efforts might make one suspect that a peaceful solution didnt exist. Indeed, even if Lincoln had simply let the South secede, my reading of history is that issues like the return of fugitive slaves, or competition over Western territories, would have eventually led to a war anyway. Im skeptical that, in the limit t, free and slave civilizations could coexist on the same continent, no matter how you juggled their political organization.
Ill go further: it even seems possible to me that the Civil War ended too early, with the South not decimated enough. After World War II, Japan and Germany were successfully dissuaded even from lite versions of their previous plans, and rebuilt themselves on very different principles. By contrast, as we all know, the American South basically refused for the next century to admit it had lost: it didnt try to secede again, but it did use every means available to it to reinstate de facto slavery or something as close to that as possible. All the civil-rights ideals of the 1960s had already been clearly articulated in the 1860s, but it took another hundred years for them to get implemented. Even today, with a black President, the intellectual heirs of the Confederacy remain a force to be reckoned with in the US, trying (for example) to depress minority voter turnout through ID laws, gerrymandering, and anything else they think they can possibly get away with. The irony, of course, is that the neo-Confederates now constitute a nontrivial fraction of what they proudly call the party of Lincoln. (Look at the map of blue vs. red states, and compare it to the Mason-Dixon line. Even the purple states correspond reasonably well to the vacillating border states of 1861.)
So thats why it seems important to have a movieevery once in a while that shows the moral courage of people like Lincoln and Thaddeus Stevens, and that names and shames the enthusiastic defenders of slaverybecause while the abolitionists won the battle, on some fronts were still fighting the war.Bananas

In the wake of my very public relativity humiliation, Ive decided to sentence myself to a one-month punishment term of only blogging about things that I actually understand.  That means, unfortunately, that from now until September 27 this blog is going to be quite boring and limited in scope.  It also means that Lev R.s prizewinning question, about the survival prospects of the human race, will need to be deferred until after the punishment term.
To be clear: No string theory.  No global warming.  No biting vaginas.  No Mahmoud.  Quantum complexity classes are probably kosher.
The remainder of todays entry will be about the topic of bananas.  Bananas are long, yellow fruits that grow in bunches on some sort of plant or other.  They consist of two components: the peel, and the meat.  Well, there are probably other components as well, but those two are the most readily identifiable.  The meat is delicious when fresh, even more so if covered with chocolate.  When not fresh, on the other hand, it tends to form brown spots.  The peel is not so good to eat, but is reputed to good for tripping dumb, careless, unwary people.  Like me.Happy New Year!  My response to M. I. Dyakonov

A couple weeks ago M. I. Dyakonov, a longtime quantum computing skeptic, published a new paper setting out his arguments (maybe grievances is a more accurate word) against quantum computing research. Looking for a way to procrastinate from other work I have to do, I decided to offer some thoughts in response.
To me, perhaps the most striking aspect of Dyakonovs paper is what it doesnt claim. Unlike Leonid Levin, Oded Goldreich, and several other quantum computing skeptics Ive engaged, Dyakonov never seriously entertains the possibility of a general principle that would explain why scalable quantum computing is not possible. (Thus, my $100K prize presumably isnt relevant to him.) He even ridicules discussion of such a principle (see the end of this post). The unwillingness to say that scalable QC cant work, or to articulate a reason why, saves Dyakonov from the need to explore what else would need to be true about the physical world if scalable QC were impossible. For example, would there then be an efficient algorithm to simulate arbitrary quantum systems on a classical computeror at least, all quantum systems that can plausibly arise in Nature? Dyakonov need not, and does not, evince any curiosity about such questions. In his game, its only the quantum computing proponents who are on trial; theres no need for examination of the other side.
That being so, Dyakonov focuses on what he sees as unrealistic assumptions in known versions of the Quantum Fault-Tolerance Theorem, covering well-trodden ground but with some strange twists. He accuses quantum computing researchers of a widespread belief that the |0 and |1 states in the computational basis are something absolute, akin to the on/off states of an electrical switch, or of a transistor in a digital computer. He then follows with a somewhat-patronizing discussion of how no continuous quantity can be manipulated perfectly, and how |0 and |1 are just arbitrary labels whose meanings could change over time due to drift in the preparation and measurement devices. Well, yes, its obvious that |0 and |1 dont have absolute meanings, but is it not equally obvious that we can give them meanings, through suitable choices of initial states, gates, and measurement settings? And if the meanings of|0 and |1 drift over time, due to the imprecision of our devices  well, if the amount of drift is upper-bounded by some sufficiently small constant, then we can regard it as simply yet another source of noise, and apply standard fault-tolerance methods to correct it. If the drift is unbounded, then we do need better devices.
(Fault-tolerance mavens: please use the comments for more detailed discussion! To my inexpert eyes, Dyakonov doesnt seem to engage the generality of the already-known fault-tolerance theoremsa generality traceable to the fact that what powers those results is ultimately just the linearity of quantum mechanics, not some fragile coincidence that one expects to disappear with the slightest change in assumptions. But Im sure others can say more.)
Anyway, from his discussion of fault-tolerance, Dyakonov concludes only that the possibility of scalable quantum computing in the real world should be considered an open question.
Surprisinglysince many QC skeptics wouldnt be caught dead making such an argumentDyakonov next turns around and says that, well, OK, fine, even if scalable QCs can be built, they still wont be good for much. Shors factoring algorithm is irrelevant, since people would simply switch to other public-key cryptosystems that appear secure even against quantum attack. Simulating quantum physics would be an interesting and useful achievement, but hardly revolutionary, unless we understand this term in some very narrow sense. And what about Grovers algorithm? In an endnote, Dyakonov writes:
Quantum algorithms that provide (with an ideal quantum computer!) only polynomial speed-up compared to digital computing, like the Grover algorithm, became obsolete due to the polynomial slow-down imposed by error correction.
The above is flat-out mistaken. The slowdown imposed by quantum error-correction is polylogarithmic, not polynomial, so it doesnt come close to wiping out the Grover speedup (or the subexponential speedups that might be achievable, e.g., with the adiabatic algorithm, which Dyakonov doesnt mention).
But disregarding the polylog/polynomial confusion (which recurs elsewhere in the article), and other technical issues about fault-tolerance, up to this point many quantum computing researchers could happily agree with Dyakonovand have said similar things many times themselves. Dyakonov even quotes Dorit Aharonov, one of the discoverers of quantum fault-tolerance, writing, In a sense, the question of noisy quantum computation is theoretically closed. But a question still ponders our minds: Are the assumptions on the noise correct?
(And as for QC researchers coming clean about limitations of quantum computers? This is just hearsay, but Im told theres a QC researcher who actually chose Quantum computers are not known to be able to solve NP-complete problems in polynomial time as the tagline for his blog!)
Dyakonov fumes about how popular articles, funding agency reports, and so forth have overhyped progress in quantum computing, leaving the conditions out of theorems and presenting incremental advances as breakthroughs. Here I sadly agree. As readers ofShtetl-Optimized can hopefully attest, Ive seen it as my professional duty to spend part of my life battlingcringeworthy quantum computing claims. Every week, it feels like I talk to another journalist who tries to get me to say that this or that QC result will lead to huge practical applications in the near future, since thats what the editor is looking for. And every week I refuse to say it, and try to steer the conversation toward deeper scientific questions. Sometimes I succeed and sometimes not, but at least I never hang up the phone feeling dirty.
On the other hand, it would be interesting to know whether, in the history of science, theres ever been a rapidly-developing field, of interest to large numbers of scientists and laypeople alike, that wasnt surrounded by noxious clouds of exaggeration, incomprehension, and BS. I can imagine that, when Isaac Newton published his Principia, a Cambridge University publicist was there to explain to reporters that the new work proved that the Moon was basically an apple.
But none of that is where Dyakonov loses me. Heres where he does: from the statements
A) The feasibility of scalable quantum computing in the physical world remains open, and
B) The applications of quantum computing would probably be real but specialized,
he somehow, unaided by argument, arrives at the conclusion
C) Quantum computing is a failed, pathological research program, which will soon die out and be of interest only to sociologists.
Let me quote from his conclusion at length:
I believe that, in spite of appearances, the quantum computing story is nearing its end, not because somebody proves that it is impossible, but rather because 20 years is a typical lifetime of any big bubble in science, because too many unfounded promises have been made, because people get tired and annoyed by almost daily announcements of new breakthroughs, because all the tenure positions in quantum computing are already occupied, and because the proponents are growing older and less zealous, while the younger generation seeks for something new 
In fact, quantum computing is not so much a scientific, as a sociological problem which has expanded out of all proportion due to the US system of funding scientific research (which is now being copied all over the world). While having some positive sides, this system is unstable against spontaneous formation of bubbles and mafia-like structures. It pushes the average researcher to wild exaggerations on the border of fraud and sometimes beyond. Also, it is much easier to understand the workings of the funding system, than the workings of Nature, and these two skills only rarely come together.
The QC story says a lot about human nature, the scientific community, and the society as a whole, so it deserves profound psycho-sociological studies, which should begin right now, while the main actors are still alive and can be questioned.
In case the message isnt yet clear enough, Dyakonov ends by comparing quantum computing to the legend of Nasreddin, who promised the Sultan that he could teach a donkey how to read.
Had he [Nasreddin] the modern degree of sophistication, he could say, first, that there is no theorem forbidding donkeys to read. And, since this does not contradict any known fundamental principles, the failure to achieve this goal would reveal new laws of Nature. So, it is a win-win strategy: either the donkey learns to read, or new laws will be discovered.
Second, he could say that his research may, with some modifications, be generalized to other animals, like goats and sheep, as well as to insects, like ants, gnats, and flies, and this will have a tremendous potential for improving national security: these beasts could easily cross the enemy lines, read the secret plans, and report them back to us.
Dyakonov chose his example carefully. Turnabout: consider the first person who had the idea of domesticating a wild donkey, teaching the beast to haul peoples stuff on its back. If youd never seen a domestic animal before, that idea would sound every bit as insane as donkey literacy. And indeed, it probably took hundreds of years of selective breeding before it worked well.
In general, if theres no general principle saying that X cant work, the truth might be that X can probably never work, but the reasons are too messy to articulate.  Or the truth might be that X can work. How can you ever find out, except by, yknow, science? Try doing X. If you fail, try to figure out why. If you figure it out, share the lessons with others. Look for an easier related problem Y that you can solve. Think about whether X is impossible; if you could show its impossibility, that might advance human knowledge even more than X itself would have. If the methods you invented for X dont work, see if they work for some other, unrelated problem Z. Congratulations! Youve just reinvented quantum computing research. Or really, any kind of research.
But theres something else that bothers me about Dyakonovs donkey story: its specificity. Why fixate on teaching a donkey, only a donkey, how to read? Earlier in his article, Dyakonov ridicules the diversity of physical systems that have been considered as qubitselectron spin qubits, nuclear spin qubits, Josephson superconducting qubits, cavity photon qubits, etc.seeing the long list as symptomatic of some deep pathology in the field. Yet he never notices the tension with his donkey story. Isnt it obvious that, if Nasreddin had been a quantum computing experimentalist, then after failing to get good results with donkeys, hed simply turn his attention to teaching cows, parrots, snakes, elephants, dolphins, or gorillas how to read? Furthermore, while going through the zoo,Nasreddin might discover that he could teach gorillas how to recognize dozens of pictorial symbols: surely a nice partial result. But maybe hed have an even better idea: why not build his own reading machine? The machine could use a camera to photograph the pages of a book, and a computer chip to decode the letters. If one wanted, the machine could be even be the size and shape of a donkey, and could emit braying sounds. Now, maybe Nasreddin would fail to build this reading machine, but even then, we know today that it would have been a noble failure, like those of Charles Babbage or Ted Nelson. Nasreddin wouldve failed only by being too far ahead of his time.
Update (Jan. 7): See Dyakonovs response to this post, and my response to his response.If challenge is what you seek

From left: Amnon Ta-Shma, your humble blogger, David Zuckerman, Adi Akavia, Adam Klivans.  Behind us: the majestic mountains of Banff, Canada, site of yet another complexity workshop, which I just returned from a couple days ago, after which I immediately had to move out of my apartment, which explains the delay in updating the blog.  Thanks to Oded Regev for the photo.
A few highlights from the workshop:

Rahul Santhanam presented a proof that for every fixed k, there exists a language in PromiseMA with no circuits of size nk.  This is a problem I spent some time on last year and failed to solve.
Dmitry Gavinsky discussed the question of whether quantum one-way communication complexity can be exponentially smaller than randomized two-way communication complexity.  Richard Cleve has a candidate problem that might yield such a separation.
Ryan ODonnell presented a proof that one can decide, using poly(1/) queries, whether a Boolean function is a threhold function or is -far from any threshold function.  This is much harder than it sounds.
I took a gondola to the top of Sulphur Mountain, where the above photo was taken.  While walking amidst some slanty rocks, I slipped and twisted my ankle.  I was hobbling around for several days afterward, but seem to be OK now.

Overwhelming everything else, alas, was a memorial session for Misha Alekhnovich.  Misha, who loved extreme sports, went on a whitewater kayaking trip in Russia a month ago.   At a dangerous bend in the river, his three companions apparently made it to shore safely, while Misha did not.  He was 28, and was to get married a few days from now.
Misha and I overlapped as postdocs at IAS, and I wish Id gotten to know him better then.  From the conversations we did have, it was clear that Misha missed Russia and wanted to go back as soon as possible.  The truth, though, is that I knew Misha less on a personal level than through his groundbreaking work, and particularly his beautiful paper with Razborov, where they show that the Resolution proof system is not automatizable unless FPT = W[P].  I still find it incredible that they were able to prove such a thing.
Lance has already discussed the memorial session, in which Eli Ben-Sasson and Sasha Razborov offered their personal remembrances, while Toni Pitassi and Russell Impagliazzo gave talks about Mishas work, emphasizing how the P versus NP question always lay just beneath the surface.  It occurred to me that an outsider might find these talks odd, or even off-putting.  Here we were, at a memorial for a dead colleague, talking in detail about the definition of automatizability and the the performance of the DPLL algorithm on satisfiable CNF instances.  Personally, I found it moving.  At a funeral for a brilliant musician, would one discuss his passion for music in the abstract without playing any of his songs?
The tragic loss of Misha has reinforced a view Ive long held: that if challenge is what you seek, then the thing to do is to tackle difficult open problems in math and computer science (or possibly physics).  Unlike the skydiver, the kayaker, or the mountain-climber, the theorem-prover makes a permanent contribution in the best case, and is down a few months and a few hundred cups of coffee in the worst case.  As for physical challenges, walking around heavily-populated tourist areas with slanty rocks has always presented more than enough of them for me.Zorks bloogorithm

If you have opinions about quantum computing, and havent yet read through the discussion following my response to Dyakonov post, youre missing out. The commentsby QC researchers (Preskill, Kuperberg, Gottesman, Fitzsimons), skeptics (Dyakonov, Kalai, ), and interested outsiders alikeare some of the most interesting Ive seen in this two-decade-old debate.
At the risk of crass immodesty, I just posted a comment whose ending amused me so much, I had to promote it to its own post. My starting point was an idea that several skeptics, including Dyakonov, have articulated in this debate, and which Ill paraphrase as follows:
Sure, quantum computing might be possible in principle. But only in the same sense that teaching a donkey how to read, transmuting large amounts of lead into gold, or doing a classical computation in the center of the Sun are possible in principle. In other words, the task is at the same time phenomenally difficult, and fundamentally arbitrary and quixotic even if you did somehow achieve it.
Since I considered this argument an important one, I wrote a response, which stressed how quantum computing is different both because it strives to solve problems that flat-out cant feasibly be solved any other way if standard complexity conjectures are correct, and because the goalnamely, expanding the human races computational powers beyond classical polynomial timeis not at all an arbitrary one. However, I then felt the need to expand on the last point, since it occurred to me that its both central to this debate and almost never discussed explicitly.
How do I know that the desire for computational power isnt just an arbitrary human quirk?
Well, the reason I know is that math isnt arbitrary, and computation is nothing more or less than the mechanizable part of solving math problems.
Let me put it this way: if we ever make contact with an advanced extraterrestrial civilization, they might have three sexes and five heads. But they, too, will have encountered the problem of factoring integers into primes. Indeed, because theyll inhabit the same physical universe as we do, theyll even have encountered the problem of simulating quantum physics. And therefore, putting the two together, theyll almost certainly have discovered something like Shors algorithm  though theyll call it Zorks bloogorithm or whatever.Reasons to believe

More often than I can remember, Ive been asked some form of the following question: If you computer scientists cant prove P=NP or P!=NP, then why arent we justified in believing whichever one we want?  And why is the consensus that P!=NP anything more than a shared prejudice  something you repeat to each other so your work wont seem irrelevant?
Its time to assume the mantle of Defender of the Faith. Im going to give you ten arguments for believing P!=NP: arguments that are pretty much obvious to those who have thought seriously about the question, but that (with few exceptions) seem never to be laid out explicitly for those who havent.  Youre welcome to believe P=NP if you choose.  My job is to make you understand the conceptual price you have to pay for that belief.
Without further ado:

The Obvious Argument.  After half a century, we still dont know any algorithm for an NP-complete problem that runs in subexponential time.  For Circuit-SAT, the canonical NP-complete problem, we dont know any algorithm essentially better than brute-force search.  In math, if decades of research fail to turn up an object, and theres no a priori reason to suppose the object exists, its usually a good strategy to conjecture that the object doesnt exist.  We can all list counterexamples to this thesis, but the examples are much more numerous (though usually less famous, for obvious reasons).
The Empirical Argument.  While the argument based on decades of mathematical work can stand on its own, in the case of P versus NP we also have half a century of evidence from the computer industry.  In a few cases  like linear programming and primality testing  people wanted fast ways to solve a problem in practice, and they came up with them, long before the problem was proved to be tractable theoretically. Well, people certainly want fast ways to solve NP-complete problems in practice, and they havent been able to invent them.  The best-known satisfiability algorithms  such as DPLL, GSAT, and Survey Propagation  work surprisingly well on certain instance distributions, but croak (for example) on instances derived from factoring or automated theorem proving.
The Bayesian Argument.  Why cant we turn the last two arguments on their heads, and say that, if our failure to find a fast SAT algorithm is evidence that P!=NP, then our failure to prove P!=NP is likewise evidence that P=NP? The answer is, because lower bounds are harder to prove than upper bounds.  Assuming P=NP, its difficult to come up with a good reason why an efficient algorithm for NP-complete problems wouldnt yet have been discovered.  But assuming P!=NP, we understand in great detail why a proof hasnt yet been discovered: because any proof will need to overcome specific and staggering obstacles.  It will need to know how 3SAT differs from 2SAT, how quadratic programming differs from linear programming, and how approximating set cover within o(log|S|) differs from approximating it within log|S|.  It will need to look inside computations in a way that doesnt relativize.  It will need to argue that NP-complete problems are hard, not because they look like random Boolean functions, but because they dont look like random Boolean functions.  While we have no reason to think such a proof is impossible  indeed, we have proofs satisfying some of the desiderata  we do have reason to think it will be extremely difficult.Whatever your nave prior probability was that P=NP, the above considerations, together with Bayes Rule, suggest revising it downward.
The Multiple-Surprises Argument.  Heres a point thats not often stressed: for P to equal NP, not just one but many astonishing things would need to be true simultaneously. First, factoring would have to be in P.  Second, factoring would have to be as hard as breaking one-way functions.  Third, breaking one-way functions would have to be as hard as solving NP-complete problems on average.  Fourth, solving NP-complete problems on average would have to be as hard as solving them in the worst case.  Fifth, NP would have to have polynomial-size circuits.  Sixth, NP would have to equal coNP.  And so on.  Any one of these statements, by itself, would overturn much of what we think we know about complexity.
The Hierarchy Argument.  This argument goes back to the early days of P versus NP.   We know that P is strictly contained in EXP by the time hierarchy theorem.  It follows that either P is strictly contained in NP, or NP is strictly contained in PSPACE, or PSPACE is strictly contained in EXP.  Likewise, since NL is strictly contained in PSPACE=NPSPACE by the space hierarchy theorem, either NL is strictly contained in P, or P is strictly contained in NP, or NP is strictly contained in PSPACE.  But if some of these separations hold, then why not all of them?   To put the point differently, we know that collapse is not the general rule of the Complexity Zoo: even between P and EXP, there really are infinitely many distinct species.   Indeed for some pairs of species, like E and PSPACE, we know theyre not equal even though we dont know if either one contains the other!  The burden of evidence, then, is on those who believe that two seemingly-distinct species are the same, not on those who believe theyre different.
The Known-Algorithms Argument. We do have nontrivial efficient algorithms for  several problems in NP, such as matching, stable marriage, minimum spanning tree, matrix inversion, planarity testing, and semidefinite programming.  But every one of these algorithms depends, in a crucial way, on some special combinatorial or algebraic structure of the problem being solved.  Is this just a fancy way of repeating that we dont know yet how to solve NP-complete problems?  I dont think it is.  Its possible to imagine a situation where we knew generic techniques for achieving exponential speedups, which worked for objects as complicated as Turing machines, and the only problem was that we didnt yet know how to apply those techniques to prove P=NP.  But this is nothing like the actual situation.
The Known-Lower-Bounds Argument.  It could be that the dream of proving superpolynomial lower bounds on circuit size is no more than that: a pipe dream.  But the fact remains we can prove superpolynomial lower bounds, albeit in weaker models of computation that are easier to analyze. To give some examples, superpolynomial lower bounds have been proven on the sizes of resolution proofs, monotone circuits, constant-depth circuits, read-once branching programs, and multilinear formulas.
The Self-Referential Argument.  If P=NP, then by that very fact, one would on general grounds expect a proof of P=NP to be easy to find.  On the other hand, if P!=NP, then one would on general grounds expect a proof of P!=NP to be difficult to find.  So believing P!=NP seems to yield a more consistent picture of mathematical reality.
The Philosophical Argument.  If P=NP, then the world would be a profoundly different place than we usually assume it to be.  There would be no special value in creative leaps, no fundamental gap between solving a problem and recognizing the solution once its found.  Everyone who could appreciate a symphony would be Mozart; everyone who could follow a step-by-step argument would be Gauss; everyone who could recognize a good investment strategy would be Warren Buffett.  Its possible to put the point in Darwinian terms: if this is the sort of universe we inhabited, why wouldnt we already have evolved to take advantage of it?  (Indeed, this is an argument not only for P!=NP, but for NP-complete problems not being efficiently solvable in the physical world.)
The Utilitarian Argument. Suppose you believe P!=NP.  Then there are only two possibilities, both of which are deeply gratifying: either youre right, or else theres a way to solve NP-complete problems in polynomial time.   (I realize that Ive given a general argument for pessimism.)

There are several questions that the above arguments dont pretend to address: first, why is P versus NP a reasonable question?   Second, even if P!=NP, why should we expect there to be a proof in ZF set theory?  Third, even if there is a proof, why should we expect it to be within reach of the human intellect?  Im really not cut out for this C. S. Lewis role, but look for further installments of Mere Complexity as the need arisesAaron Swartz (1986-2013)

Update (1/18):Some more information has emerged. First, its looking like the prosecutions strategy was to threaten Aaron with decades of prison time, in order to force him to accept a plea bargain involving at most 6 months. (Carmen Ortiz issued a statement that conveniently skips the first part of the strategy and focuses on the second.) This is standard operating procedure in our wonderful American justice system, due (in part) to the lack of resources actually to bring most cases to trial. The only thing unusual about the practice is the spotlight being shone on it, now that it was done not to some poor unknown schmuck but to a tortured prodigy and nerd hero. Fixing the problem would require far-reaching changes to our justice system.
Second, while I still strongly feel that we should await the results of Hal Abelsons investigation, Ive now heard from several sources that there was some sort of high-level decision at MITby whom, I have no ideanot to come out in support of Aaron. Crucially, though, Im unaware of the faculty (or students, for that matter) ever being consulted about this decision, or even knowing that there was anything for MIT to decide. Yesterday, feeling guilty about having done nothing to save Aaron, I found myself wishing that either he or his friends or parents had made an end run around the official channels, and informed MIT faculty and students directly of the situation and of MITs ability to help. (Or maybe they did, and I simply wasnt involved?)
Just to make sure I hadnt missed anything, I searched my inbox for Swartz, but all I found relevant to the case were a couple emails from a high-school student shortly after the arrest (for a project he was doing about the case), and then the flurry of emails after Aaron had already committed suicide. By far the most interesting thing that I found was the following:
Aaron Swartz (December 12, 2007): Im really enjoying the Democritus lecture notes. Any chance wellever see lecture 12?
My response: Its a-comin!

As I wrote on this blog at the time of Aarons arrest: I would never have advised him to do what he did. Civil disobedience can be an effective tactic, but off-campus access to research papers simply isnt worth throwing your life away forespecially if your life holds as much spectacular promise as Aarons did, judging from everything Ive read about him. At the same time, I feel certain that the world will eventually catch up to Aarons passionate belief that the results of publicly-funded research should be freely available to the public. We can honor Aarons memory by supporting the open science movement, and helping the world catch up with him sooner.Statement on Aaron Swartz

We are deeply saddened by Aaron Swartzs death, and send our condolences to all who knew him. We are very mindful of his commitment to the open access movement. It inspires our own commitment to work for a situation where academic knowledge is freely available, so that others are not menaced by the kind of prosecution that he faced. We encourage everyone to visit www.rememberaaronsw.com, a memorial site created by Aarons family and friends.
Scott Aaronson
 Sasha Costanza-Chock
 Kai von Fintel
 Richard Holton
 George Stephanopoulos
 Anne Whiston Spirn

Members of the MIT Open Access Working GroupThe quantum-complexity bathroom reader

A reader named Lewis K. wrote in to ask for a brief list of required reading for someone with a normal CS degree under his belt who wants to be taken to the research front in quantum complexity.  Alright then:
[Deutsch] [Bernstein-Vazirani] [BBBV] [Simon] [Shor] [Grover] [BBHT] [BBCMW] [Ambainis] [Watrous] [ANTV] [Fortnow-Rogers] [Abrams-Lloyd] [Childs et al.] [DMV] [EHK] [BJK] [Gottesman] [KKR] [Marriott-Watrous]
(Sprinkle in some textbooks, survey articles, and course lecture notes to taste.)
Commenters will boil me alive for leaving out huge swaths of the field, and theyll be right.  Ive merely listed some papers that had a definite impact on how I, personally, attack problems.  But hey, Im the one you asked.  So print em out, take em to the toilet, and sit there for a long time.  When youre finished, you wont be at the research front  for that you obviously have to read my papers  but hopefully youll have seen enough to visit the big bad arXiv on your own.  Happy Hadamards!Lily Rebecca Aaronson

In 7+ years of blogging, one lesson Ive learned is to go easy on the highly-personal stuff. But sometimes one does need to make an exception. Lily Rebecca Aaronson was born today (Jan. 20), at 6:55am, to me and Dana, weighing 3.3kg. (After seeing her placenta, the blog category Adventures in Meatspace never seemed more appropriate.) Im blogging from the postpartum ward, which has free wifi and excellent foodwell probably stay here as long as theyll let us.
Given that her parents are both complexity theorists, one question people will have is whether Lily demonstrates any early aptitude in that field. All I can say is that, so far, shes never once confused quantum computing with classical exponential parallelism, treated relativization as acting on a complexity class rather than on its definition, or made any other mathematical mistake that I can see. (She has, on the other hand, repeatedly mistaken her hand for food.)Quantum Information and the Brain

A month and a half ago, I gave a 45-minute lecture / attempted standup act with the intentionally-nutty title above, for my invited talk at the wonderful NIPS (Neural Information Processing Systems) conference at Lake Tahoe. Video of the talk is now available at VideoLectures net. That site also did a short written interview with me, where they asked about the message of my talk (which is unfortunately hard to summarize, though I tried!), as well as the Aaron Swartz case and various other things. If you just want the PowerPoint slides from my talk, you can get those here.
Now, I couldve just given my usual talk on quantum computing and complexity. But besides increasing boredom with that talk, one reason for my unusual topic was that, when I sent in the abstract, I was under the mistaken impression that NIPS was at least half a neuroscience conference. So, I felt a responsibility to address how quantum information science might intersect the study of the brain, even if the intersection ultimately turned out to be the empty set! (As I say in the talk, the fact that people have speculated about connections between the two, and have sometimes been wrong but for interesting reasons, could easily give me 45 minutes worth of material.)
Anyway, it turned out that, while NIPS wasfounded by people interested in modeling the brain, these days its more of a straight machine learning conference. Still, I hope the audience there at least found my talk an amusing appetizer to their hearty meal of kernels, sparsity, and Bayesian nonparametric regression. I certainly learned a lot from them; while this was my first machine learning conference, Ill try to make sure it isnt my last.
(Incidentally, the full set of NIPS videos is here; it includes great talks by Terry Sejnowski, Stanislas Dehaene, Geoffrey Hinton, and many others. It was a weird honor to be in such distinguished company  I wouldnt have invited myself!)Reasons to believe II: quantum edition

At Greg Kuperbergs request, Ive decided to follow my Ten Reasons To Believe P!=NP with
Thirteen Reasons Why Id Be Surprised If Quantum Computing Were Fundamentally Impossible
So that theres no question about exactly where I stand, Ill start out by repeating, for the ten billionth time, the Official Scott Aaronson Quantum Computing Position Statement.

Its entirely conceivable that quantum computing will turn out to be impossible for a fundamental reason.
This would be much more interesting than if its possible, since it would overturn our most basic ideas about the physical world.
The only real way to find out is to try to build a quantum computer.
Such an effort seems to me at least as scientifically important as (say) the search for supersymmetry or the Higgs boson.
I have no idea  none  how far it will get in my lifetime.

I now offer thirteen arguments to support the above views.

The Obvious Argument.  Quantum mechanics has been the foundation for all non-gravitational physics since 1926.  Hoping that it would just go away has been one of the most consistently losing strategies in the history of science.  If physicists and engineers didnt take quantum mechanics seriously as a description of the world, they wouldnt have been able to invent the laser, transistor, or classical computer.  For that matter, they wouldnt be able to explain why all the atoms in the universe dont instantly disintegrate.  Now, if you start with quantum mechanics, and write down the model of computation that directly flows from it, what do you end up with?  BQP: Bounded-Error Quantum Polynomial-Time.
The Experimental Argument.  Ten years ago, one wouldnt have been able to do much more than mount a general defense of quantum mechanics.   But by now, liquid-NMR quantum computers have been built that not only factored 15 into 3 x 5 with small probability of error, but also searched 8-item databases.   Ive seen some of the machines that performed these staggering computational feats right here in Waterloo; they look like big-ass cylinders with the word Bruker on them.  Seriously, while liquid-NMR (at least for now) doesnt seem to be scalable, theres been lots of recent work on solid-state NMR, photonics, and ion traps, all of which (if Im not mistaken) are up to at least 3 qubits.  While I dont think the experimentalists are anywhere close to succeeding, these are smart people who havent been sitting on their asses (or if they have, then no doubt hard at work at a lab table or something).
The Better-Shor-Than-More Argument.  Why do skeptics always assume that, if quantum mechanics turns out to be only approximate, then whatever theory supersedes it will reinstate the Extended Church-Turing Thesis?  Why isnt it just as likely, a priori, that the new theory would yield even more computational power than BQP?  This isnt merely a logical point: to the extent that people have tried to propose serious alternatives to quantum mechanics (where serious means agreeing with known experiments), those alternatives often do involve more computational power than BQP.
The Sure/Shor Argument.  If you believe quantum mechanics is going to break down before nontrivial quantum computing becomes possible, then you must believe theres some point where it will break down  some level of size, or complexity, or whatever, at which it will cease to be a useful description of the world.  What is that point?   In other words, where is the line  possibly a fuzzy, asymptotic, resource-dependent line  that puts the quantum states that have already been observed on one side, and the quantum states that arise in Shors factoring algorithm on the other?  In a paper I wrote three years ago, I called such a line a Sure/Shor separator, and challenged skeptics to come up with some example of what it might be.  I even tried to get the ball rolling by studying such separators myself. My idea was that having a Sure/Shor separator could motivate further research: once they knew where the barrier was, the experimentalists could set to work trying to cross it; then, if they succeeded, the skeptics could come back with a new barrier, and so on.  Unfortunately, no skeptic has yet risen to the challenge.  Its not hard to see why: if you start with the many-particle entangled states that have already been observed (for example, by the Zeilinger group and by Ghosh et al.) and then throw in a few closure properties, you quickly end up with  well, the set of all quantum states.  Coming up with a reasonable set of states that includes Sure states but doesnt include Shor states turns out to be an extremely hard problem.
The Linearity Argument.  In my experience, at least 70% of all objections to quantum computing boil down to the idea that a quantum computer would be a souped-up analog computer  a machine that would store information not in voltage differences or the positions of pulleys, but instead in exponentially-small amplitudes.   From this idea it follows readily that, just as old-school analog computers have always run up against scalability problems, so too will quantum computers.  To see why the analogy fails, think about classical probabilities.  If you flip a coin a thousand times, youll end up with a probability distribution over outcomes that requires real numbers of order 2-1000 to describe.  Does it follow from this that classical probabilistic computers are really analog computers in disguise, or that classical probability theory must be a mere approximation to some deeper, underlying theory? Of course not  for, unlike voltages or pulleys, probabilities evolve in time by means of norm-preserving linear transformations, which are insensitive to small errors.  Well, quantum amplitudes also evolve by means of norm-preserving linear transformations, and this is what makes them behave like probabilities with respect to error, and not like the state variables of an analog computer.
The Fault-Tolerance Argument. Among the many nontrivial consequences of this linearity, theres one that probably counts as a separate argument: the Threshold Theorem.  This theorem states that even if a quantum computer is subject to noise, we can still use it to do universal computation, provided we have parallel processing and a supply of fresh qubits, and provided the error rate is at most  per qubit per time step, for some constant >0 independent of the length of the computation.  The original lower bound on  was about 10-6, but recently Knill and others have brought it up to 1-3% under plausible assumptions. Many quantum computing researchers talk about this theorem as the knight in shining armor who rode in unexpectedly to vindicate all their hopes.  Theyre entitled to do so, but to me, the theorem has always felt more like a beautiful, detailed working-out of something that couldnt possibly have been false.  (And not just because its a theorem.)
The What-A-Waste Argument.  Why do I say that the threshold theorem couldnt possibly have been false?  Well, suppose quantum mechanics were an accurate description of reality, yet quantum computing was still impossible for some fundamental reason.  In that case, wed have to accept that Nature was doing a staggering amount of quantum computation that could never be extracted, even in principle.  Indeed, even assuming that life is (and always will be) confined to the vicinity of one planet, the resulting computational waste would make the waste of 1011 uninhabited galaxies look like chickenfeed.  I dont deny that such a possibility is logically consistent, but my complexity-theoretic instincts rebel against it.
The Non-Extravagance Argument.  In my opinion, if quantum computers could solve NP-complete problems in polynomial time, then there really would be grounds for regarding them as physically extravagant.   Like coming up with theories that allow causality violations and superluminal signalling, coming up with models of computation that can simulate NP, #P, and PSPACE is just too easy.  Its not interesting.  The interesting task is to come up with a model of computation thats stronger than the usual ones (P, BPP, and P/poly), but not so strong that it encompasses NP-complete problems.  If it werent for BQP, I dont think Id have any clear idea of what such a model could look like.  (Sure, we have problems and complexity classes below NP, but thats different from a full-fledged model of computation.)
The Turn-The-Tables Argument.  If building quantum computers that outperform classical ones is fundamentally impossible, then it must be possible to write classical computer programs that efficiently simulate any quantum system found in Nature.  And yet, even though this way of looking at the question is perfectly equivalent, theres a reason quantum computing skeptics avoid it.  This is that, as soon as you frame the issue this way, they (the skeptics) are the ones who look like wild-eyed technological optimists  believing well be able to simulate superconductors and quark-gluon plasmas on an ordinary desktop PC!  The staid, conservative position is that such a simulation wont be possible  or, equivalently, that the systems being simulated have more computational power than the PC doing the simulating.
The Island-In-Theoryspace Argument.  String theorists have been ridiculed for claiming that string theory is too beautiful to be wrong.  But as Peter Woit points out in his fascinating new book, this is not at all a bad argument.  Its a fine argument; the real question is whether string theory  with its perturbation series, ten dimensions of which six are compactified for unknown reasons, landscape of vacua, etc.  really is as beautiful as its proponents think it is.    At the risk of breaking my vow, let me hasten to say that Im in no position to judge.  What I do know is that theres something mathematically unique about quantum mechanics: how it takes advantage of special properties of the L2 norm that fail for other p-norms, how the parameter-counting for mixed states that works perfectly with complex numbers fails with real numbers and quaternions, and so on.   Crucially, it seems all but impossible to change quantum mechanics while retaining its nice properties.  More so than general relativity or any other theory we have, quantum mechanics gives every indication of being an island in theoryspace.
The Only-Game-In-Town Argument. However one feels about the alternatives to string theory  loop quantum gravity, spin foams, twistors, and so on  at least each one has a developer base, a community of physicists who are actively trying to make it work.   By contrast, I dont know of any picture of the world in which quantum computing is impossible, thats being actively developed by any research community anywhere.  (Gerard t Hooft and Stephen Wolfram are not research communities.) All the skepticism of quantum computing that Im aware of is purely negative in character.
The Historical Argument. If the above arguments are sound, then why havent people already succeeded in building quantum computers?  Its been what, ten years already?   Some historical perspective might be helpful here: in Samuel Johnsons The History of Rasselas, Prince of Abissinia, written in 1759, Johnson has one of his characters give a correct explanation of why heavier-than-air flying machines should be physically possible, and then build a test plane that promptly plummets into a lake. Johnson was safe in ridiculing the idea; it would be another 144 years before Kitty Hawk.  Closer to our topic, Darwin wrote in his autobiography about an eccentric loon of his acquaintance, who dreamed of building an engine to automate routine human thought.  Though the loon  a certain Charles Babbage  hadnt run afoul of any fundamental theory, his proposal to build a classical computer was a century ahead of its time.  Since the 1600s, science has often been generations ahead of technology. History gives us no reason at all to assume that a technology will be discovered to be compatible with known laws of physics at about the same time as it becomes possible to implement.
The Trademark-Twist Argument.  This last argument is the hardest one to articulate, but possibly the most compelling to my mind. In my view, Nature has been telling us, over and over and over, that our everyday intuitions will match the physical world if and only if we first apply a little twist to them.  Often this twist involves an unusual symmetry, or switching from the L1 to the L2 norm, or inserting negative or complex numbers where our intuition says that only nonnegative real numbers would make sense.  We see such a twist in special relativity, in the metric thats not positive definite but instead has a (-1,1,1,1) signature.  We see it in the -1 phase that the universe picks up when you swap a fermion with its identical twin.   We see it in the fact that, to rotate an electron back to where it was, you have to turn it not 360o but 720o.  We see it in the Dirac equation.  We see it, of course, in quantum mechanics itself.  And what is BQP, if not P=BPP with Natures trademark little twist?TCS+ online seminars

Good news, everyone! Anindya De, Oded Regev, and my postdoc Thomas Vidick are launching an online theoretical computer science seminar series called TCS+, modeled after the successful Q+ quantum information seminars run by Daniel Burgarth and Matt Leifer. The inaugural TCS+ lecture will be on Wednesday Feb. 6, at noon Eastern Standard Time. Ronald de Wolf, longtime friend both of this blog and of its author, will be speaking on Exponential Lower Bounds for Polytopes in Combinatorial Optimization, his STOC2012 Best Paper with Samuel Fiorini, Serge Massar, Sebastian Pokutta and Hans Raj Tiwary. This is the paper that used ideas originally from quantum communication complexity to solve a 20-year-old problem in classical optimization: namely, to rule out the possibility of proving P=NP by reducing the Traveling Salesman Problem to certain kinds of linear programs. Ronald previously gave the talk at MIT, and it rocked. See Thomass blog for details about how to watch.Collaborative Refutation

At least eight peoplejournalists, colleagues, blog readershave now asked my opinion of a recent paper by Ross Anderson and Robert Brady, entitled Why quantum computing is hard and quantum cryptography is not provably secure. Where to begin?

Based on a soliton modelwhich seems to be almost a local-hidden-variable model, though not quitethe paper advances the prediction that quantum computation will never be possible with more than 3 or 4 qubits. (Where 3 or 4 are not just convenient small numbers, but actually arise from the geometry of spacetime.) I wonder: before uploading their paper, did the authors check whether their prediction was, yknow, already falsified? How do they reconcile their proposal with (for example) the 8-qubit entanglement observed by Haffner et al. with trapped ionsnot to mention the famous experiments with superconducting Josephson junctions, buckyballs, and so forth that have demonstrated the reality of entanglement among many thousands of particles (albeit not yet in a controllable form)?
The paper also predicts that, even with 3 qubits, general entanglement will only be possible if the qubits are not collinear; with 4 qubits, general entanglement will only be possible if the qubits are not coplanar. Are the authors aware that, in ion-trap experiments (like those of David Wineland that recently won the Nobel Prize), the qubits generally are arranged in a line? See for example this paper, whose abstract reads in part: Here we experimentally demonstrate quantum error correction using three beryllium atomic-ion qubits confined to a linear, multi-zone trap.
Finally, the paper argues that, because entanglement might not be a real phenomenon, the security of quantum key distribution remains an open question. Again: are the authors aware that the most practical QKD schemes, like BB84, never use entanglement at all? And that therefore, even if the papers quasi-local-hidden-variable model were viable (which its not), it still wouldnt justify the claim in the title that quantum cryptography is not provably secure?

Yeah, this paper is pretty uninformed even by the usual standards of attempted quantum-mechanics-overthrowings. Let me now offer three more general thoughts.
First thought: its ironic that Im increasingly seeing eye-to-eye with Lubos Motlwho once called me the most corrupt piece of moral trashin his rantings against the worlds anti-quantum-mechanical crackpots. Let me put it this way: David Deutsch, Chris Fuchs, Sheldon Goldstein, and Roger Penrose hold views about quantum mechanics that are diametrically opposed to one anothers. Yet each of these very different physicists has earned my admiration, because each, in his own way, is trying to listen to whatever quantum mechanics is saying about how the world works. However, there are also people all of whose thoughts about quantum mechanics are motivated by the urge to plug their ears and shut out whatever quantum mechanics is sayingto show how whatever nave ideas they had before learning QM might still be right, and how all the experiments of the last century that seem to indicate otherwise might still be wiggled around. Like monarchists or segregationists, these people have been consistently on the losing side of history for generationsso its surprising, to someone like me, that they continue to show up totally unfazed and itching for battle, like the knight from Monty Python and the Holy Grail with his arms and legs hacked off. (Bells Theorem? Just a flesh wound!)
Like any physical theory, of course quantum mechanics might someday be superseded by an even deeper theory. If and when that happens, it will rank alongside Newtons apple, Einsteins elevator, and the discovery of QM itself among the great turning points in the history of physics. But its crucial to understand that thats not what were discussing here. Here were discussing the possibility that quantum mechanics is wrong, not for some deep reason, but for a trivial reason that was somehow overlooked since the 1920sthat theres some simple classical model that would make everyone exclaim, oh! well, I guess that whole framework of exponentially-large Hilbert space was completely superfluous, then. why did anyone ever imagine it was needed? And the probability of that is comparable to the probability that the Moon is made of Gruyre. If youre a Bayesian with a sane prior, stuff like this shouldnt even register.
Second thought: this paper illustrates, better than any other Ive seen, how despite appearances, the quantum computing will clearly be practical in a few years! camp and the quantum computing is clearly impossible! camp arent actually opposed to each other. Instead, theyre simply two sides of the same coin. Anderson and Brady start from the puzzling fact that, despite what they call the investment of tremendous funding resources worldwide over the last decade, quantum computing still hasnt progressed beyond a few qubits, and propose to overthrow quantum mechanics as a way to resolve the puzzle. To me, this is like arguing in 1835 that, since Charles Babbage still hasnt succeeded in building a scalable classical computer, we need to rewrite the laws of physics in order to explain why classical computing is impossible. I.e., its a form of argument that only makes sense if youve adopted what one might call the Hype Axiom: the axiom that any technology thats possible sometime in the future, must in fact be possible within the next few years.
Third thought: its worth noting that, if (for example) you found Michel Dyakonovs arguments against QC (discussed on this blog a month ago) persuasive, then you shouldnt find Andersons and Bradys persuasive, and vice versa. Dyakonov agrees that scalable QC will never work, but he ridicules the idea that wed need to modify quantum mechanics itself to explain why. Anderson and Brady, by contrast, are so eager to modify QM that they dont mind contradicting a mountain of existing experiments. Indeed, the question occurs to me of whether theres any pair of quantum computing skeptics whose arguments for why QC cant work are compatible with one anothers. (Maybe Alicki and Dyakonov?)
But enough of this. The truth is that, at this point in my life, I find it infinitely more interesting to watch my two-week-old daughter Lily, as she discovers the wonderful world of shapes, colors, sounds, and smells, than to watch Anderson and Brady, as they fail to discover the wonderful world of many-particle quantum mechanics. So Im issuing an appeal to the quantum computing and information community. Please, in the comments section of this post, explain what you thought of the Anderson-Brady paper. Dont leave me alone to respond to this stuff; I dont have the time or the energy. If you get quantum probability, then stand up and be measured!When modular arithmetic was a STOC result

So, it seems the arXiv is now so popular that even Leonhard Euler has contributed 25 papers, despite being dead since 1783.  (Thanks to Ars Mathematica   for this important news item, as well as for the hours of procrastination on my part that led to its rediscovery.)  Since Id long been curious about the mathematical research interests of the nonliving, I decided to check out Leonhards most recent preprint, math.HO/0608467 (Theorems on residues obtained by the division of powers).  The paper starts out slow: explaining in detail why, if a mod p is nonzero, then a2 mod p, a3 mod p, and so on are also nonzero.  By the end, though, its worked out most of the basics of modular arithmetic, enough (for example) to analyze RSA.  Furthermore, the exposition, while retro in style, is sufficiently elegant that I might even recommend acceptance at a minor theory conference, even though the basic results have of course been known for like 200 years.
Oh  you say that Mr. Es papers were as difficult and abstract for their time as Wiles and Perelmans papers are for our own time?  BULLSHIT.  Reading the old master brings home the truth: that, for better and worse, math has gotten harder.  Much, much harder.  And we havent gotten any smarter.Silvio and Shafi win Turing Award

Today I break long radio silence to deliver some phenomenal news. Two of the people who I eat lunch with every weekmy MIT CSAIL colleagues Silvio Micali and Shafi Goldwasserhave won a well-deserved Turing Award, for their fundamental contributions to cryptography from the 1980s till today. (I see that Lance just now beat me to a blog post about this. Dammit, Lance!)
I wont have to tell many readers of this blog that the names Goldwasser and Micalior more often, the initials G and Mare as ubiquitous as Alice and Bob in modern cryptography, from the GGM construction of pseudorandom functions (discussed before on this blog), to the classic GMR paper that introduced the world to interactive proofs. Besides that, Shafi and Silvio are known as two of the more opinionated and colorful characters of theoretical computer scienceand as I learned last week, Silvio is also an awesome party host, who has perfect taste in sushi (as well as furniture and many other things).
I wish I could go on right now talking about Shafi and Silvioand even more, that I could join the celebration that will happen at MIT this afternoon. But Im about to board a flight to LAX, to attend the 60th birthday symposium of longtime friend, extraordinary physicist, and sometime Shtetl-Optimized commenter John Preskill. (Ill also be bringing you coverage of that symposium, including slides from my talk there on hidden variables.) So, leave your congratulations, etc. in the comments section, and Ill see them when I land!Obligatory retrospective

I woke up at my normal time  probably around 2PM  in my room at Berkeleys International House, to find an avalanche of email: from a fellow grad student, urging everyone to check the news; from Christos Papadimitriou, reminding us that we have a community here, and communities can comfort; from Luca Trevisan, announcing that the class that he taught and I TAed would be canceled, since on a day like this it was impossible to think about algorithms.  I then clicked over to news sites to find out what had happened.
After confirming that my friends and family were safe, I walked over to my office in Soda Hall, mostly to find people to talk to.  Technically I had office hours for the algorithms class that afternoon, but I didnt expect students actually to come.  Yet come they did: begging for hints on the problem set, asking what would and wouldnt be on the test, pointing to passages in the CLRS textbook that they didnt understand.  I pored over their textbook, shaking my head in disbelief, glancing up every minute or so at the picture of the burning buildings on the computer screen.
That night there was a big memorial service in Sproul Plaza.  When I arrived, a woman offered me a candle, which I took, and a man standing next to her offered me a flyer, which I also took.  The flyer, which turned out to be from a socialist organization, sought to place the events of that morning in context, describing the World Trade Center victims as mostly white-collar executives and those who tried to save them.
After a few songs and eulogies, a woman got up to explain that, on this terrible day, what was really important was that we try to understand the root causes of violence  namely poverty and despair  and not use this tragedy as a pretext to start another war.  The crowd thunderously applauded.
While the speeches continued, I got up and wandered off by myself in the direction of Bancroft Way.  Much as I did the year before, when the area around Telegraph was festooned with Nader for President posters, I felt palpably that I wasnt living in an outcomes-based region of reality.  The Peoples Republic of Berkeley was proving to be a staunch ally of the Oilmens Oligarchy of Crawford, undermining the only sorts of opposition to it that had any possibility of succeeding.
I decided to forget about politics for a while and concentrate exclusively on research.  I cant say I succeeded at this.  But I did pass my prelim exam three days later (on September 14), and a few weeks afterward proved the quantum lower bound for the collision problem.
Note: Feel free to post your own retrospective in the comments section.  Andris Ambainis has already done so.John Preskill: My Lodestar of Awesomeness

I got back a couple days ago from John Preskills 60th birthday symposium at Caltech. To the general public, Preskill is probably best known for winning two bets against Stephen Hawking. To readers of Shtetl-Optimized, he might be known for his leadership in quantum information science, his pioneering work in quantum error-correction, his beautiful lecture notes, or even his occasional comments here (though these days he has his own group blog and Twitter feed to keep him busy). I know John as a friend, colleague, and mentor whos done more for me than I can say.
The symposium was a blasta chance to hear phenomenal talks, enjoy the California sun, and catch up with old friends like Dave Bacon (who stepped down as Pontiff before stepping down as Pontiff was cool). The only bad part was that I inadvertently insulted John in my talk, by calling him my lodestar of sanity. What I meant was that, for 13 years, Ive known plenty of physicists who can be arbitrarily off-base when they talk about computer science and vice versa, but Ive only ever known John to be on-base about either. If you asked him a question involving, say, both Barringtons Theorem and Majorana fermions, hes one of the few people on earth who would know both, seem totally unfazed by your juxtaposing them, and probably have an answer that hed carefully tailor to your level of knowledge and interest. In a polyglot field like quantum information, that alone makes him invaluable. But along with his penetrating insight comes enviable judgment and felicity of expression: unlike some of us (me), John always manages to tell the truth without offending his listeners. If I were somehow entrusted with choosing a President of the United States, hed be one of my first choices, certainly ahead of myself.
Anyway, it turned out that John didnt like my use of the word sane to summarize the above: for him (understandably, in retrospect), it had connotations of being humorless and boring, two qualities Ive never seen in him. (Also, as I pointed out later, the amount of time John has spent helping me and patiently explaining stuff to me does weigh heavily against his sanity.) So I hereby rename John my Lodestar of Awesomeness.
In case anyone cares, my talk was entitled Hidden Variables as Fruitful Dead Ends; the PowerPoint slides are here. I spoke about a new preprint by Adam Bouland, Lynn Chua, George Lowther, and myself, on possibility and impossibility results for -epistemic theories (a class of hidden-variable theories that was also the subject of the recent PBR Theorem, discussed previously on this blog). My talk also included material from my old paper Quantum Computing and Hidden Variables.
The complete program is here. A few highlights (feel free to mention others in the comments):

Patrick Hayden spoke about a beautiful result of himself and Alex May, on where and when a qubit can be. After the talk, I commented that its lucky for the sake of Hayden and Mays induction proof that 3 happens to be the next integer after 2. If you get that joke, then I think youll understand their result and vice versa.
Lenny Susskindwhose bestselling The Theoretical Minimum is on my to-read listspoke about his views on the AMPS firewall argument. As you know if youve been reading physics blogs, the firewall argument has been burning up (har, har) the world of quantum gravity for months, putting up for grabs aspects of black hole physics long considered settled (or not, depending on who you ask). Lenny gave a typically-masterful summary, which for the first time enabled me to understand the role played in the AMPS argument by the Zone (a region near the black hole but outside its event horizon, in which the Hawking radiation behaves a little differently than it does when its further away). I was particularly struck by Lennys comment that whether an observer falling into a black hole encounters a firewall might be physics Axiom of Choice: that is, we can only follow the logical consequences of theories we formulate outside black-hole event horizons, and maybe those theories simply dont decide the firewall question one way or the other. (Then again, maybe they do.) Lenny also briefly mentioned a striking recent paper by Harlow and Hayden, which argues that the true resolution of the AMPS paradox might involve  wait for it  computational complexity, and specifically, the difficulty of solving QSZK (Quantum Statistical Zero Knowledge) problems in BQP. And whats a main piece evidence that QSZKBQP? Why, the collision lower bound, which I proved 12 years ago while a summer student at Caltech and an awestruck attendee of Preskills weekly group meetings. Good thing no one told me back then that black holes were involved.
Charlie Bennett talked about things that Ive never had the courage to give a talk about, like the Doomsday Argument and the Fermi Paradox. But his disarming, avuncular manner made it all seem less crazy than it was.
Paul Ginsparg, founder of the arXiv, presented the results of a stylometric analysis of John Preskills and Alexei Kitaevs research papers. The main results were as follows: (1) John and Alexei are easily distinguishable from each other, due in part to the more latters Russian use of function words (the, which, that, etc.). (2) Alexei, despite having lived in the US for more than a decade, is if anything becoming more Russian in his function word use over time. (3) Even more interestingly, John is also becoming more Russian in his function word usea possible result of his long interaction with Alexei. (4) A joint paper by Kitaev and Preskill was indeed written by both of them. (Update: While detained at the airport, Paul decided to post an online video of his talk.)

Speaking of which, the great Alexei Kitaev himselfthe $3 million manspoke about Berry curvature for many-body systems, but unfortunately I had to fly back early (yknow, 2-month-old baby) and missed his talk. Maybe someone else can provide a summary.
Happy 60th birthday, John!

Two unrelated announcements.
1. Everyone who reads this blog should buy Sean Carrolls two recent books: From Eternity to Here (about the arrow of time) and The Particle at the End of the Universe (about the Higgs boson and quantum field theory more generally). Theyre two of the best popular physics books Ive ever readin their honesty, humor, clarity, and total lack of pretense, they exemplify what every book in this genre should be but very few are. If you need even more inducement, go watch Sean hit it out of the park on the Colbert Report (and then do it again). I cant watch those videos without seething with jealousy: given how many OKs and yknows lard my every spoken utterance, Ill probably never get invited to hawk a book on Colbert. Which is a shame, because as it happens, my Quantum Computing Since Democritus book will finally be released in the US by Cambridge University Press on April 30th! (Its already available in the UK, but apparently needs to be shipped to the US by boat.) And its loaded with new material, not contained in the online lecture notes. And you can preorder it now. And my hawking of Seans books is in no way whatsoever related to any hope that Sean might return the favor with my book.
2. Recent Turing Award winner Silvio Micali asks me to advertise the Second Cambridge Area Economics and Computation Day (CAEC13), which will be held on Friday April 26 at MIT. Anything for you, Silvio! (At least for the next week or two.)Quantum Computing Since Democritus: The Buzz Intensifies

Update (March 22): The Kindle edition of Quantum Computing Since Democritus is now available, for the low price of $15.40! (Not factorial.) Click here to get it from amazon.com, or here to get it from amazon.co.uk. And let me know how it looks (I havent seen it yet). Another Update: Just saw the Kindle edition, and the figures and formulas came out great! Its a product I stand behind with pride.
In the meantime, I regret to say that the marketing for this book is getting crasser and more exploitative by the day.



It seems like wherever I go these days, all anyone wants to talk about is Quantum Computing Since Democritusthe sprawling new book by Scott Aaronson, published by Cambridge University Press and available for order now. Among leading figures in quantum information sciencemany of them well-known to Shtetl-Optimized readersthe book is garnering the sort of hyperbolic praise that would make Shakespeare or Tolstoy blush:
I laughed, I cried, I fell off my chair  and that was just reading the chapter on Computational Complexity. Aaronson is a tornado of intellectual activity: he rips our brains from their intellectual foundations; twists them through a tour of physics, mathematics, computer science, and philosophy; stuffs them full of facts and theorems; tickles them until they cry Uncle; and then drops them, quivering, back into our skulls. Aaronson raises deep questions of how the physical universe is put together and why it is put together the way it is. While we read his lucid explanations we can believe  at least while we hold the book in our hands  that we understand the answers, too. Seth Lloyd
Scott Aaronson has written a beautiful and highly original synthesis of what we know about some of the most fundamental questions in science: What is information? What does it mean to compute? What is the nature of mind and of free will? Michael Nielsen
Not since Richard Feynmans Lectures on Physics has there been a set of lecture notes as brilliant and as entertaining. Aaronson leads the reader on a wild romp through the most important intellectual achievements in computing and physics, weaving these seemingly disparate fields into a captivating narrative for our modern age of information. Aaronson wildly runs through the fields of physics and computers, showing us how they are connected, how to understand our computational universe, and what questions exist on the borders of these fields that we still dont understand. This book is a poem disguised as a set of lecture notes. The lectures are on computing and physics, complexity theory and mathematical logic and quantum physics. The poem is made up of proofs, jokes, stories, and revelations, synthesizing the two towering fields of computer science and physics into a coherent tapestry of sheer intellectual awesomeness. Dave Bacon
After months of overhearing people saying things like the abovein the halls of MIT, the checkout line at Trader Joes, the bathroom, anywhereI finally had to ask in annoyance: is all this buzz justified? I mean, Im sure the book is as deep, hilarious, and worldview-changing as everyone says it is. But, after all, its based off lecture notes that have long been available for free on the web. And Aaronson, being the magnanimous, open-access-loving saint that he is, has no plans to remove the online notes, even though he could really use the royalties from book sales to feed his growing family. Nor does Cambridge University Press object to his principled decision.
No, you dont understand, they told me. Word on the street has it that the book is extensively updated for 2013that its packed with new discussions of things like algebrization, lattice-based cryptography, the QIP=PSPACE theorem, the quantum time travel controversy, BosonSampling, black-hole firewalls, and even the Australian models episode. They say it took years of painstaking work, by Aaronson and his student Alex Arkhipov, to get the notes into book form: fixing mistakes, clarifying difficult points, smoothing out rough edges, all while leaving intact the originals inimitable humor. I even heard Aaronson reveals hes changed his mind about certain things since 2006. How could you not want such a labor of love on your bookshelf?
Exasperated, I finally exclaimed: But the book isnt even out yet in North America! Amazon.com says it wont ship until April 30.
Sure, one gas-station attendant replied to me, but the secret is, its available now from Amazon.co.uk. Personally, I couldnt wait a month, so I ordered it shipped to me from across the pond. But if youre a less hardcore quantum complexity theory fan, and you live in North America, you can also preorder the book from Amazon.com, and theyll send it to you when it arrives.
Much as the hype still grated, I had to admit that Id run out of counterarguments, so I looked into ordering a copy for myself.Sen. Tom Coburn, the National Science Foundation, and Antarctican Jello Wrestling

As some of you probably heard, last week Sen. Tom Coburn (R-Oklahoma) managed to get an amendment passed prohibiting the US National Science Foundation from funding any research in political science, unless the research can be certified as promoting national security or the economic interests of the United States. This sort of political interference with the peer-review process, of course, sets a chilling precedent for all academic research, regardless of discipline. (Whats next, an amendment banning computer science research, unless it has applications to scheduling baseball games or slicing apple pies?) But on researching further, I discovered that Sen. Coburn has long had it in for the NSF, and even has a whole webpage listing his grievances against the agency. Most of it is the usual can you believe they wasted money to study something so silly or obvious?, but by far my favorite tidbit is the following:
Inappropriate staff behavior including porn surfing and Jello wrestling and skinny-dipping at NSF-operated facilities in Antarctica.
It occurred to me that the NSF really has no need to explain this one, since a complete explanation is contained in a single word of the charge itself: Antarctica. Personally, Id support launching an investigation of NSFs Antarctica facilities, were it discovered that the people stuck in them werent porn surfing and Jello wrestling and skinny-dipping.PHYS771 Quantum Computing Since Democritus

That, for better or worse, is the name of a course Im teaching this semester at the University of Waterloo.  Im going to post all of the lecture notes online, so that you too can enjoy an e-learning cyber-experience in my virtual classroom, even if you live as far away as Toronto.  Ive already posted Lecture 1, Atoms and the Void.  Coming up next: Lecture 2.Two P vs. NP updates (neither of them technical)

Meme courtesy of my brother David
First news item: its come to my attention that yesterday, an MIT professor abused his power over students for a cruel April Fools Day prank involving the P vs. NP problem. His email to the students is below.
I assume most of you already heard the news that a Caltech grad student, April Felsen, announced a 400-page proof of PNP last week. While I havent yet completely digested the argument, its already clear that Felsen (who I actually knew back when she was an MIT undergrad) has changed theoretical computer science forever, bringing in new tools from K-theory to higher topos theory to solve the biggest problem there was.
Alas, Felsens proof has the short-term effect of making the existing 6.045 seem badly outdated. So, after long reflection, Ive made a decision that not all of you are going to like, but that I believe is the right one intellectually. Ive decided to reorient the entire course to focus on Felsens result, starting with tomorrows lecture.
And further, I decided to rewrite Thursdays midterm to focus almost entirely on this new material. That means that, yes, youre going to have THREE DAYS to learn at least the basics of algebraic topology and operator algebras, as used in Felsens proof. To do that, you might need to drop everything else (including sleep, unfortunately), and this might prove to be the most strenuous and intense thing youve ever done. But it will also be an experience that will enrich your minds and ennoble your souls, and that youll be proud to tell your grandchildren about. And of course well be there to help out. So lets get started!
All the best,
Scott

Second news item: many of you have probably heard that Lance Fortnows The Golden Ticketthe first popular book about the P vs. NP problemis now out. (The title refers to Roald Dahls Charlie and the Chocolate Factory, which involved a few chocolate bars that had coveted golden tickets inside the wrappers, along with millions of chocolate bars that didnt.) I read it last week, and I think its excellent: a book Ill happily recommend to family and friends who want the gentlest introduction to complexity theory that exists.
Some context: for more than a decade, people have been telling me that I should write a popular book about P vs. NP, and I never did, and now Lance has. So Im delighted to say that reading Lances book quickly cured me of any regrets I might have felt. For not only is The Golden Ticket a great book, but better yet, its not a book that I ever couldve written.
Heres why: every time I would have succumbed to the temptation to explain something too complicated for the worlds journalists, literary humanists, and pointy-haired bossessomething like relativization, or natural proofs, or arithmetization, or Shannons counting argument, or Ladners Theorem, or coNP, or the reasons to focus on polynomial timeevery time, Lance somehow manages to resist the temptation, and to stick to cute stories, anecdotes, and practical applications. This is really, truly a popular book: as Lance points out himself, in 162 pages of discussing the P vs. NP question, he never even formally defines P and NP!
But it goes beyond that: in the world of The Golden Ticket, P vs. NP is important because, if P=NP, then people could design more effective cancer therapies, solve more crimes, and better predict which baseball games would be closely-matched and exciting (yes, really). P vs. NP is also important because it provides a unifying framework for understanding current technological trends, like massively-parallel computing, cloud computing, big data, and the Internet of things. Meanwhile, quantum computing might or might not be possible in principle, but either way, its probably not that relevant because it wont be practical for a long time.
In short, Lance has written precisely the book about P vs. NP that the interested layperson or IT professional wants and needs, and precisely the book that I couldnt have written. I wouldve lost patience by around page 20, and exclaimed:
You want me to justify the P vs. NP problem by its relevance to baseball?? Why shouldnt baseball have to justify itself by its relevance to P vs. NP? Pshaw! Begone from the house of study, you cretinous fools, and never return!
My favorite aspect of The Golden Ticket was its carefully-researched treatment of the history of the P vs. NP problem in the 50s, 60s, and 70s, both in the West and in the Soviet Union (where it was called the perebor problem). Even complexity theorists will learn countless tidbitslike how Leonid Levin was discovered at age 15, and how the powerful Sergey Yablonsky stalled Soviet perebor research by claiming to have solved the problem when hed done nothing of the kind. The historical chapter (Chapter 5) is alone worth the price of the book.
I have two quibbles. First, throughout the book, Lance refers to a hypothetical world where P=NP as the Beautiful World. I wouldve called that world the Hideous World! For its a world where technical creativity is mostly worthless, and where the mathematical universe is boring, flat, and incomprehensibly comprehensible. Heres an analogy: suppose a video game turned out to have a bug that let you accumulate unlimited points just by holding down a certain button. Would anyone call that game the Beautiful Game?
My second disagreement concerns quantum computing. Overall, Lance gives an admirably-accurate summary, and I was happy to see him throw cold water on breathless predictions about QC and other quantum-information technologies finding practical applications in the near future. However, I think he goes beyond the truth when he writes:
[W]e do not know how to create a significant amount of entanglement in more than a handful of quantum bits. It might be some fundamental rule of nature that prevents significant entanglement for any reasonable length of time. Or it could just be a tricky engineering problem. Well have to let the physicists sort that out.
The thing is, physicists do know how to create entanglement among many thousands or even millions of qubitsfor example, in condensed-matter systems like spin lattices, and in superconducting Josephson junctions. The problem is merely that they dont know how to control the entanglement in the precise ways needed for quantum computing. But as with much quantum computing skepticism, the passage above doesnt seem to grapple with just how hard it is to kill off scalable QC. How do you cook up a theory that can account for the massively-entangled states that have already been demonstrated, but that doesnt give you all of BQP?
But let me not harp on these minor points, since The Golden Ticket has so many pleasant features. One of them is its corny humor: even in Lances fantasy world where a proof of P=NP has led to a cure for cancer, it still hasnt led to a cure for the common cold. Another nice feature is the books refreshing matter-of-factness: Lance makes it clear that he believes that
(a) PNP,
(b) the conjecture is provable but wont be proven in the near future, and
(c) if we ever meet an advanced extraterrestrial civilization, theyll also have asked the P vs. NP question or something similar to it.
Of course we cant currently prove any of the above statements, just like we cant prove the nonexistence of Bigfoot. But Lance refuses to patronize his readers by pretending to harbor doubts that he quite reasonably doesnt.
In summary, if youre the sort of person who stops me in elevators to say that you like my blog even though you never actually understand anything in it, then stop reading Shtetl-Optimized right now and go read Lances book. Youll understand it and youll enjoy it.
And now its off to class, to apologize for my April Fools prank and to teach the Cook-Levin Theorem.How to rig an election

My friend Alex Halderman is now after bigger fish than copy-protected music CDs.  Watch this video, in which he, Ed Felten, and Ariel Feldman demonstrate how to rig a Diebold voting machine (and also watch Alex show off his lock-picking skills).  Reading the groups paper, one becomes painfully aware of a yawning cultural divide between nerds and the rest of the world.  Within the nerd universe, that voting machines need to have a verifiable paper trail, that they need to be open to inspection by researchers, etc., are points so obvious as to be scarcely worth stating.  If a company (Diebold) refuses to take these most trivial of precautions, then even without a demonstration of the sort Alex et al. provide, the presumption must be that their machines are insecure.  Now Alex et al. are trying to take whats obvious to nerds into a universe  local election boards, the courts, etc.  that operates by entirely different rules.  Within this other universe, the burden is not on Diebold to prove its voting machines are secure; its on Alex et al. to prove theyre insecure.  And even if they do prove theyre insecure  well, if it werent for those pesky researchers telling the bad guys how to cheat, what would we have to worry about?
So, how does one bridge this divide?  How does one explain the obvious to those who, were they capable of understanding it, would presumably have understood it already?  I wish I had an easy answer, but I fear theres nothing to do but what Alex, Ed, and Ariel are doing already  namely, fight with everything youve got.Derandomizing BBQ

An addendum to my last post: a few days ago, I got an email with the subject line BBQ,
Awesome! I thought.  Free food!  Where?
But no, the email was from someone who had read one of my papers, and who wanted references for the strange, unfamiliar terms that littered the text  terms like BBP and BBQ. I wasnt sure what to tell him, except that the class BBQ contains BYOB and is conjectured to be incomparable with BLT.Pigs sprouted wings, Hell froze over, and I guest-posted on Lubo Motls blog

Furthermore, the last of those things actually happened. What wont I do to promote Quantum Computing Since Democritus? Enjoy!
Update: I submitted the following response to the comments over on Luboss blog. Since it has some bits of general interest, I thought Id crosspost it here while it awaits Luboss moderation.

Since Lubos officially invited me to respond to the comments here, let me now do so.
1. On loopholes in quantum mechanics: I completely agree with Luboss observation that the actual contents of my book are conservative about the truth of QM. Indeed, I predict that, when Lubos reads his free copy, hell agree with (or at least, have no objections to) the vast majority of whats in the book. On the other hand, because I was guest-blogging about the story of me and Lubos, I found it interesting to highlight one area of disagreement regarding QM, rather than the larger areas of agreement.
2. On Gene Days patronizing accusation that I dont get the basics of QM or even comprehend the role of mathematics in physics: his misreading of what I wrote is so off-base that I dont know whether a response is even necessary. Briefly, though: of course two formulations of QM are mathematically equivalent if theyre mathematically equivalent! I wasnt asking why we dont use different mathematical structures (quaternions, the 3-norm, etc.) to describe the same physical world. I was asking why the physical world itself shouldnt have been different, in such a way that those other mathematical structures would have described it. In other words: if you were God, and you tried to invent a theory that was like QM but based on those other structures, would the result necessarily be less nice than QM? Would you have to give up various desirable properties of QM? Yes? Can you prove it? The balls in your court, Mr. Day  or else you can just read my book! 
3. On Lord Nelsons accusation that Im a poseur: on reflection, someone who only knew me from blog stunts like this one could easily be forgiven for getting that impression!  So it might be worth pointing out for the record that I also have a day job outside the blogosphere, whose results you can see here if you care.
4. On my political views: I wish to clarify for Tom Vonk that I despise not only Communists, but the ideology of Communism itself. One of the formative experiences of my life occurred when I was an 8-year-old at Wingate Kirkland summer camp, and all the campers had to relinquish whatever candy theyd brought into a communal bunk trunk. The theory was that all the campers, rich and poor alike, would then share the candy equally during occasional bunk parties. What actually happened was that the counselors stole the candy. So, during a meeting of the entire camp, I got up and gave a speech denouncing the bunk trunk as Communism. The next day, the camp director (who had apparently been a fellow-traveler in the 1950s) sat with me at lunchtime, and told me about a very evil man named Joe McCarthy who I was in danger of becoming like. But the truth was that Id never even heard of McCarthy at that point  I just wanted to eat candy. And Id give exactly the same speech today.
Like (I suppose) several billion of the worlds people, I believe in a dynamic market-based capitalist society, and also in strong environmental and other regulations to safeguard that societys continued existence. And I dont merely believe in that as a cynical compromise, since I cant get the dictatorship of the proletariat that I want in my heart of hearts. Were I emperor of the world, progressive capitalism is precisely what I would institute. In return, perhaps, for paying a candy tax to keep the bunk functioning smoothly, campers could keep their remaining candy and eat or trade it to their hearts delight.
5. On climate change: Im not a professional climatologist, but neither is Lubos, and nor (correct me if Im wrong) is anyone else commenting here. Accordingly, I refuse to get drawn into a debate about ice cores and tree rings and hockey sticks, since my experience is that such debates tend to be profoundly unilluminating when not conducted by experts. My position is an incredibly simple one: just like with the link between smoking and cancer, or the lack of a link between vaccines and autism, or any other issue where I lack the expertise to evaluate the evidence myself, Ill go with what certainly looks like an overwhelming consensus among the scientists whove studied the matter carefully. Period. If the climate skeptics want to win me over, then the way for them to do so is straightforward: they should ignore me, and try instead to win over the academic climatology community, majorities of chemists and physicists, Nobel laureates, the IPCC, National Academies of Science, etc. with superior research and arguments.
To this, the skeptics might respond: but of course we cant win over the mainstream scientific community, since theyre all in the grip of an evil left-wing conspiracy or delusion! Now, that response is precisely where the buck stops for me, and further discussion becomes useless. If Im asked which of the following two groups is more likely to be in the grip of a delusion  (a) Senate Republicans, Freeman Dyson, and a certain excitable string-theory blogger, or (b) virtually every single expert in the relevant fields, and virtually every other chemist and physicist who Ive ever respected or heard of  well then, it comes down to a judgment call, but Im 100% comfortable with my judgment.Yau strikes back

Along with his law firm.  You can read his side of the Poincar story at doctoryau.com.
(Hey, passing along press releases sent to me by law firms sure is easy!  I wonder why more media outlets dont do exactly the same thing.)So You Think Quantum Computing Is Bunk?

On Wednesday, I gave a fun talk with that title down the street at Microsoft Research New England. Disappointingly, no one in the audience did seem to think quantum computing was bunk (or if they did, they didnt speak up): I was basically preaching to the choir. My PowerPoint slides are here. Theres also a streaming video here, but watch it at your own riskmy stuttering and other nerdy mannerisms seemed particularly bad, at least in the short initial segment that I listened to. I really need media training. Anyway, thanks very much to Boaz Barak for inviting me.Quantum Computing Since Democritus Lecture 2: Sets

Cardinals, ordinals, and more.  A whole math course compressed into one handwaving lecture, and a piping-hot story thats only a century old.QStart conference in Jerusalem, June 24-27

Friend-of-the-blog Dorit Aharonov asked me to advertise the QStart Conference, which will be held at Hebrew University of Jerusalem June 24-27 of this year, to celebrate the opening of Hebrew Universitys new Quantum Information Science Center. Speakers include Yakir Aharonov, Jacob Bekenstein, Hans Briegel, Ed Farhi, Patrick Hayden, Ray Laflamme, Elon Lindenstrauss, Alex Lubotzky, John Martinis, Barbara Terhal, Umesh Vazirani, Stephanie Wehner, Andrew Yao  and me, your humble blogger (who will actually be there with Lily, on her first trip abroador for that matter, beyond the Boston metropolitan area). Dorit tells me that the conference should be of interest to mathematicians, physicists, chemists, philosophers, and computer scientists; that registration is open now; and that student travel support is available. Oh, and if youre one of the people who think quantum computing is bunk? As displayed on the poster above, leading QC skeptic Gil Kalai is a co-organizer of the conference.My fortune-cookie wisdom for the day

On Sunday afternoon, Dana, Lily, and I were in Copley Square in Boston for a brunch with friends, at the Mandarin Oriental hotel on Boylston Street. As I now recall, I was complaining bitterly about a number of things. First, Id lost my passport (its since been found). Second, we hadnt correctly timed Lilys feedings, making us extremely late for the brunch, and causing Lily to scream hysterically the entire car ride. Third, parking (and later, locating) our car at the Prudential Center was a logistical nightmare. Fourth, Id recently received by email a profoundly silly paper, claiming that one of my results was wrong based on a trivial misunderstanding. Fifth  well, there were other things that were bothering me, but I dont remember what they were.
Then the next day, maybe 50 feet from where wed been, the bombs went off, three innocent human beings lost their lives and many more were rendered permanently disabled.
Drawing appropriate morals is left as an exercise for the reader.

Update (Friday, 7AM): Maybe the moral is that you shouldnt philosophize while the suspects are still on the loose. Last night (as you can read anywhere else on the web) an MIT police officer was tragically shot and killed in the line of duty, right outside the Stata Center, by one of the marathon bombers (who turn out to be brothers from Chechnya). After a busy nightwhich also included robbing a 7-Eleven (visiting a 7-Eleven that was coincidentally also robbedno novelist could make this stuff up), carjacking a Mercedes two blocks from my apartment, and randomly throwing some more pressure-cooker bombsone of the brothers was killed; the other one escaped to Watertown. A massive hunt for him is now underway. MIT is completely closed today, as is Harvard and pretty much every other university in the areaand now, it seems, all stores and businesses in the entire Boston area. The streets are mostly deserted except for police vehicles. As for us, we heard the sirens through much of the night, but didnt know what they were about until this morning. Heres hoping they catch the second asshole soon.
Another Update (Friday, 9AM): As the sorry details emerge about these Tsarnaev brothers, it occurs to me that theres another moral we can draw: namely, we can remind ourselves that the Hollywood image of the evil criminal genius is almost entirely a myth. Yes, evil and genius have occasionally been found in the same person (as with a few of the Nazi scientists), but its evil and stupidity that are the far more natural allies. Which is the most optimistic statement I can think to make right now about the future of the human race.
Yet More Updates (Friday, 3PM): The whole Boston area is basically a ghost town now, with the streets empty on a beautiful spring day and the sound of helicopters filling the air. I was just up on my roofdeck to watch, and never saw anything like it. I cant help thinking that it sets a terrible precedent to give a couple doofus amateur terrorists the power to shut down an entire metropolitan area. Meanwhile, Andrew Sullivan points to a spectacularly stupid tweet by one Nate Bell:
I wonder how many Boston liberals spent the night cowering in their homes wishing they had an AR-15 with a hi-capacity magazine?
This sounds like a gun nut projecting his own disturbed psychology onto other people. Im not actually scared, but if I was, owning a gun would do nothing whatsoever to make me less scared (quite the contrary). What would make me think I could win a gunfight against a frothing lunaticor that Id want to find out? When it comes to violence, the only thing that calms my nerves is a democratic state having a near-monopoly on it.
What else? It was chilling to watch the Tsarnaev brothers aunt, the one in Toronto, babble incoherently on TV about how wonderful her nephews were (a striking contrast to the remorseful uncle in Maryland). If it emerges that anyone else in this family (including the parents, or the older brothers wife) had any foreknowledge about the killing spree, then I very much hope theyll face justice as well.
In other news, Lily had an eventful day too: she finally figured out how to squeeze her toy ball with her hands.Only eight annoying questions to go

A month ago, I posed the following as the 10th most annoying question in quantum computing:
Given an n-qubit pure state, is there always a way to apply Hadamard gates to some subset of the qubits, so as to make all 2n computational basis states have nonzero amplitudes?
Today Ashley Montanaro and Dan Shepherd of the University of Bristol sent me the answer, in a beautiful 4-page writeup that they were kind enough to let me post here.  (The answer, as I expected, is yes.)
This is a clear advance in humankinds scientific knowledge, which is directly traceable to this blog.  I am in a good mood today.
The obvious next question is to find an >0 such that, for any n-qubit pure state, theres some way to apply Hadamards to a subset of the qubits so as to make all 2n basis states have |amplitude| at least . Clearly we cant do better than =sinn(/8).  Montanaro and Shepherd conjecture that this is tight.
Whats the motivation?  If you have to askMistake of the Week: The Future Is In X

One of the surest signs of the shnood is the portentous repetition of the following two slogans:
Biology will be the physics of the 21st century.
The future of the world is in China and India.
Let me translate for you:
You know the field of Darwin, Pasteur, and Mendel, the field that fills almost every page of Science and Nature, the field that gave rise to modern medicine and transformed the human condition over the last few centuries?  Well, dont count it out entirely!  This plucky newcomer among the sciences is due to make its mark.  Another thing you shouldnt count out is the continent of Asia, which is situated next to Europe.  Did you know that China, far more than a source of General Tsos Chicken, has been one of the centers of human civilization for 4,000 years?  And did you know that Gandhi and Ramanujan both hailed from a spunky little country called India?  Its true!
Let me offer my own counterslogans:
Biology will be the biology of the 21st century.
The future of China and India is in China and India, respectively.I was right: Congresss attack on the NSF widens

Last month, I blogged about Sen. Tom Coburn (R-Oklahoma) passing an amendment blocking the National Science Foundation from funding most political science research. I wrote:
This sort of political interference with the peer-review process, of course, sets a chilling precedent for all academic research, regardless of discipline. (Whats next, an amendment banning computer science research, unless it has applications to scheduling baseball games or slicing apple pies?)
In the comments section of that post, I was pilloried by critics, who ridiculed my delusional fears about an anti-science witch hunt. Obviously, they said, Congressional Republicans only wanted to slash dubious social science research: not computer science or the other hard sciences that people reading this blog really care about, and that everyone agrees are worthy. Well, today I write to inform you that I was right, and my critics were wrong. For the benefit of readers who might have missed it the first time, let me repeat that:
I was right, and my critics were wrong.
In this case, like in countless others, my paranoid fears about what could happen turned out to be preternaturally well-attuned to what would happen.
According to an article in Science, Lamar Smith (R-Texas), the new chair of the ironically-named House Science Committee, held two hearings in which he floated the idea of having every NSF grant application [in every field] include a statement of how the research, if funded, would directly benefit the American people.  Connoisseurs of NSF proposals will know that every proposal already includes a Broader Impacts section, and that that section often borders on comic farce. (We expect further progress on the -approximate shortest vector problem to enthrall middle-school students and other members of the local community, especially if they happen to belong to underrepresented groups.) Now progress on the -approximate shortest vector problem also has to directlydirectlybenefit the American people. Its not enough for such research to benefit sciencearguably the least bad, least wasteful enterprise our sorry species has ever managedand for science, in turn, to be a principal engine of the countrys economic and military strength, something that generally cant be privatized because of a tragedy-of-the-commons problem, and something that economists say has repaid public investments many, many times over. No, the benefit now needs to be direct.
The truth is, I find myself strangely indifferent to whether Smith gets his way or not. On the negative side, sure, a pessimist might worry that this could spell the beginning of the end for American science. But on the positive side, I would have been proven so massively right that, even as I held up my Will Prove Quantum Complexity Theorems For Food sign on a street corner or whatever, Id have something to crow about until the end of my life.Superiority of the Latke: The Unexpected Convergence of Quantum Mechanics and Common Sense

Back in February, I gave a talk with the above title at the Annual MIT Latke-Hamentaschen Debate. Im pleased to announce that streaming video of my talk is now available! (My segment starts about 10 minutes into the video, and lasts for 10 minutes.) You can also download my PowerPoint slides here.
Out of hundreds of talks Ive given in my life, on five continents, this is the single talk of which Im the proudest.
Of course, before you form an opinion about the issue at hand, you should also check out the contributions of my fellow debaters. On the sadly-mistaken hamentasch side, my favorite presentation was that of mathematician Arthur Mattuck, which starts in at 56 minutes and lasts for a full half hour (!!  the allotted time was only 8 minutes). Mattuck relates the shapes of latkes and hamentaschen to the famous Kakeya problem in measure theorythough strangely, his final conclusions seem to provide no support whatsoever for the hamentaschen, even on Mattucks own terms.
Finally, what if youre a reader for whom the very words latke and hamentaschen are just as incomprehensible as the title of this blog? OK, here are some Cliff Notes:

Latkes are fried potato pancakes, traditionally eaten by Jews on Hannukah.
Hamentaschen are triangular fruit-filled cookies, traditionally eaten by Jews on Purim.
Beginning at the University of Chicago in 1946, many universities around the world have held farcical annual debates between faculty members (both Jewish and non-Jewish) about which of those two foods is better. (The reason I say farcical is simply that, as I explain in my talk, the truth has always been overwhelmingly on one side.) The debaters have invoked everything from feminist theory to particle physics to bolster their case.

Thanks very much to Dean of Admissions Stu Schmill for moderating, and to MIT Hillel for organizing the debate.
Update: Lubo has a new blog post announcing that he finally found a chapter in Quantum Computing Since Democritus that he likes! Woohoo! Whether coincidentally or not, the chapter he likes makes exactly the same points about quantum mechanics that I also make in my pro-latke presentation.Admissions unhooked

An anonymous indie-cinema-loving hermit friend from Amsterdam sends me an article in this weeks Economist entitled Poison Ivy: Not so much palaces of learning as bastions of privilege and hypocrisy (unfortunately, only available to subscribers).  The article is a summary of an excellent Wall Street Journal series by Daniel Golden (again, unfortunately, only available to subscribers), which Ive been following with great interest.  Golden has also put out a book about this topic, called The Price of Admission (How Americas Ruling Class Buys Its Way into Elite Colleges  and Who Gets Left Outside the Gates), which I just ordered from Amazon.  In the meantime, Ill simply quote a few passages from the Economist piece:
Mr Golden shows that elite universities do everything in their power to admit the children of privilege. If they cannot get them in through the front door by relaxing their standards, then they smuggle them in through the back. No less than 60% of the places in elite universities are given to candidates who have some sort of extra hook, from rich or alumni parents to sporting prowess. The number of whites who benefit from this affirmative action is far greater than the number of blacks
Most people think of black football and basketball stars when they hear about sports scholarships. But there are also sports scholarships for rich white students who play preppie sports such as fencing, squash, sailing, riding, golf and, of course, lacrosse. The University of Virginia even has scholarships for polo-players, relatively few of whom come from the inner cities
What is one to make of [Senate Majority Leader Bill] Frist, who opposes affirmative action for minorities while practising it for his own son?
Two groups of people overwhelmingly bear the burden of these policies  Asian-Americans and poor whites. Asian-Americans are the new Jews, held to higher standards (they need to score at least 50 points higher than non-Asians even to be in the game) and frequently stigmatised for their characters (Harvard evaluators persistently rated Asian-Americans below whites on personal qualities). When the University of California, Berkeley briefly considered introducing means-based affirmative action, it rejected the idea on the ground that using poverty yields a lot of poor white kids and poor Asian kids.
The article ends with the hope that Americas money-addicted and legacy-loving universities can be shamed into returning to what ought to have been their guiding principle all along: admitting people to university on the basis of their intellectual ability.
I harped about this issue in one of my very first posts, almost a year ago.  I dont know what else to say.  If idealism wont goad us Americans (yes, Im still an American) into overhauling our crooked, anti-intellectual admissions system, then maybe it will help to see just how absurd that system looks to the rest of the world.Quantum Computing Since Democritus now out in the US!  20% discount for Shtetl-Optimized readers

OK, this will be my last blog post hawking Quantum Computing Since Democritus, at least for a while. But I do have four pieces of exciting news about the book that I want to share.

Amazon is finally listing the print version of QCSD as available for shipment in North America, slightly ahead of schedule! Amazons price is $35.27.
Cambridge University Press has very generously offered readers of Shtetl-Optimized a 20% discount off their list pricemeaning $31.99 instead of $39.99if you click this link to order directly from them. Note that CUP has a shipping charge of $6.50. So ordering from CUP might either be slightly cheaper or slightly more expensive than ordering from Amazon, depending (for example) on whether you get free shipping from Amazon Prime.
So far, there have been maybe 1000 orders and preorders for QCSD (not counting hundreds of Kindle sales). The book has also spent a month as one of Amazons top few Quantum Physics sellers, with a fabulous average rating of 4.6 / 5 stars from 9 reviews (or 4.9 if we discount the pseudonymous rant by Joy Christian). Thanks so much to everyone who ordered a copy; I hope you like it! Alas, these sales figures also mean that QCSD still has a long way to go before it enters the rarefied echelon ofto pick a few top Amazon science sellersCosmos, A Brief History of Time,Proof of Heaven (A Neurosurgeons Journey into the Afterlife), Turn On Your SUPER BRAIN, or The Lemon Book (Natural Recipes and Preparations). So, if you believe that QCSD deserves to be with such timeless classics, then put your money where your mouth is and help make it happen!
The most exciting news of all? Lubo Motl is reading the free copy of QCSD that I sent him and blogging his reactions chapter-by-chapter! So, if youd like to learn about how mathematicians and computer scientists simply lack the brainpower to do physicswhich is why we obsess over kindergarten trivialities like the Church-Turing Thesis or the Axiom of Choice, and why we insistidiotically that Nature use only the mathematical structures that our inferior minds can graspthen check out Lubos posts about Chapters 1-3 or Chapters 4-6. If, on the other hand, you want to see our diacritical critic pleasantly surprised by QCSDs later chapters on cryptography, quantum mechanics, and quantum computing, then heres the post for you. Either way, be sure to scroll down to the comments, where I patiently defend the honor of theoretical computer science against Lubos hilarious ad hominem onslaughts.Closer to Truth

Two years ago, when I attended the FQXi conference on a ship from Norway to Denmark, I (along with many other conference participants) was interviewed by Robert Lawrence Kuhn, who produces a late-night TV program called Closer to Truth. Im pleased to announce (hat tip: Sean Carroll) that four videos from my interview are finally available online:

Is the Universe a Computer?
 (like a politician, I steer the question toward what kind of computer is the universe?, then start talking about P vs. NP, quantum computing, and the holographic principle)
What Does Quantum Theory Mean?
 (here I mostly talk about the idea of computational intractability as a principle of physics)
Quantum Computing Mysteries
 (basics of quantum mechanics and quantum computing)
Setting Time Aright (about the differences between time and space, the P vs. PSPACE problem, and computing with closed timelike curves)

(No, I didnt choose the titles!)
For regular readers of this blog, theres probably nothing new in these videos, but for those who are just tuning in, they provide an extremely simple and concise introduction to what I care about and why. Im pretty happy with how they came out.
Once youre finished with me (or maybe even before then), click here for the full list of interviewees, which includes David Albert, Raphael Bousso, Sean Carroll, David Deutsch, Rebecca Goldstein, Seth Lloyd, Marvin Minsky, Roger Penrose, Lenny Susskind, Steven Weinberg, and many, many others who might be of interest to Shtetl-Optimized readers.Is there no other?

O Achilles of Arkansas, O bane of Foxes and Roves, O solitary warrior among Democrats: dasher of hopes, prince of platitudes, felatee of Jewesses, belated friend of Tutsis, toothless tiger of climate change, greatest of all living Americans: how shall we summon thee back?The Tenured Toll-Taker

Update (5/6): In honor of the news below, Boaz Barak has written a beautiful blog post on the reasons to care about the P vs. NP question, offering his responses to several of the most common misconceptions. Thank you so much, Boaz  this is one of the best presents Ive ever gotten from anyone!

On Friday afternoonin the middle of a pizza social for my undergrad adviseesI found out that Ive received tenure at MIT.
Am I happy about the news? Of course! Yet even on such a joyous occasion, I found myself reflecting on a weird juxtaposition. I learned about MITs tenure decision at the tail end of a fierce, weeks-long comment war over on Lubo Motls blog, in which I assumed the task of defending theoretical computer science and quantum information science as a whole: explaining why these fields could have anything whatsoever to contribute to our understanding of the universe. Indeed, I took the title of this post from a comment Lubo made to me in the middle of the melee: that compared to string theorists, quantum computing researchers have as much to say about the nature of reality as toll-takers on the Golden Gate Bridge. (Even though the Golden Gate tolls are apparently all-electronic these days, I still foundLubos analogy striking. I could imagine that staring all day at the breathtaking San Francisco Bay would lead to deep thoughts about the nature of reality.)
Now, some people will ask: why should I even waste my time this wayarguing with Lubo, a blogger infamous for describing the scientists he disagrees with as garbage, worms, fungi, etc., and even calling for their elimination? If I find the limits of computation in the physical universe to be a rich, fascinating, worthwhile subject; if I have hundreds of wonderful colleagues with whom to share the thrill of surprising new discoveries; if a large, growing fraction of the wider scientific community follows this field with interest; if my employer seems to want me doing it for the long haul  then why should I lose sleep just because someone, somewhere, declared that the P vs. NP problem is a random puzzle, of no deeper significance than the question of whether chess is a draw? Or because he characterized the entire fields of quantum computing and information as trivial footnotes to 1920s physics, fit only for mediocre students who couldnt do string theory? Or because, on the other side, a persistent minority calls quantum computers an absurd fantasy, and the quest to build them a taxpayer boondoggle bordering on fraud? Or because some skeptics, going even further, dismiss quantum mechanics itself as nonsensical mumbo-jumbo that physicists made up to conceal their own failure to find a straightforward, mechanical description of Nature? Likewise, why should it bother me if some anti-complexites dismiss the quest to prove PNP as a fashionable-but-irrelevant journey to formalize the obviouseven while others denounce the Soviet-style groupthink that leads the CS establishment to reject the possibility that P=NP? After all, these various naysayers cant all be right! Doesnt it comfort me that, of all the confidently-asserted reasons why everything my colleagues and I study is dead-end, cargo-cult science, so many of the reasons contradict each other?
Sure, but heres the thing. In seven years of teaching and blogging, Ive learned something about my own psychology. Namely, if I meet anyonean undergrad, an anonymous blog commenter, anyonewho claims that the P vs. NP problem is beside the point, since its perfectly plausible that P=NP but the algorithm takes n10000 timeor that, while quantum mechanics works fine for small systems, theres not the slightest reason to expect it to scale up to larger onesor that the limits of computation are plainly no more relevant to fundamental physics than the fact that cucumbers are greentrying to reason with that person will always, till the end of my life, feel like the most pressing task in the world to me.
Why? Because, I confess, a large part of me worries: what if this other person is right? What if I really do have to jettison everything I thought I knew about physics, computation, and pretty much everything else since I was a teenager, toss all my results into the garbage can (or at least the amusing recreations can), and start over from kindergarten? But then, as I fret about that possibility, counterarguments well up in my mind. Like someone pinching himself to make sure hes awake, I remember all the reasons why I was led to think what I think in the first place. And I want the other person to go through that experience with methe experience, if you like, of feeling the foundations of the universe smashed to pieces and then rebuilt, the infinite hierarchy of complexity classes collapsing and then springing back into place, decades worth of books set ablaze and then rewritten on blank pages. I want to say: at least come stand here with mein this place that I spent twenty years of late nights, false starts, and discarded preconceptions getting toand tell me if you still dont see what I see.
Thats how I am; I doubt I can change it any more than I can change my blood type. So I feel profoundly grateful to have been born into a world where I can make a comfortable living just by being this strange, thin-skinned creature that I ama world where there are countless others who do see what I see, indeed see it a thousand times more clearly in many cases, but who still appreciate what little I can do to explore this corner or that, or to describe the view to others. Id say Im grateful to fate, but really Im grateful to my friends and family, my students and teachers, my colleagues at MIT and around the world, and the readers of Shtetl-Optimizedyes, even John Sidles. Fate either doesnt exist or doesnt need my gratitude if it does.Quantum Computing Since Democritus Lecture 3: Gdel, Turing, and Friends

Gdel, Turing, and Friends.  Another whole course compressed into one handwaving lecture.  (This will be a recurring theme.)Holy sh#t  maybe biology doesnt suck!

So said my brother David (MIT math major), on forwarding me this animation of the inner life of a cell.Ask Me Anything!  Tenure Edition

Update (5/7): Enough! Thanks, everyone, for asking so many imaginative questions, and please accept my apologies if yours remains unaddressed. (Its nothing personal: they simply came fast and furious, way faster than I could handle in an online fashionso I gave up on chronological order and simply wrote answers in whatever order they popped into my head.) At this point, Im no longer accepting any new questions. Ill try to answer all the remaining questions by tomorrow night.

By popular request, for the next 36 hoursso, from now until ~11PM on TuesdayIll have a long-overdue edition of Ask Me Anything. (For the previous editions, see here, here, here, and here.) Todays edition is partly to celebratemy new, tenured freedom to do whatever the hell I want (as well as the publication after 7 years of Quantum Computing Since Democritus), but is mostly just to have an excuse to get out of changing diapers (Id love to, honey, but the world is demanding answers!). Here are the ground rules:

One question per person, total.
Please check to see whether your question was already asked in one of the previous editionsif it was, then Ill probably just refer you there.
No questions with complicated backstories, or that require me to watch a video, read a paper, etc. and comment on it.
No questions about D-Wave. (As it happens, Matthias Troyer will be giving a talk at MIT this Wednesday about his groups experiments on the D-Wave machine, and Im planning a blog post about itso just hold your horses for a few more days!)
If your question is offensive, patronizing, nosy, or annoying, I reserve the right to give a flippant non-answer or even delete the question.
Keep in mind that, in past editions, the best questions have almost always been the most goofball ones (Whats up with those painting elephants?).

Thats it: ask away!

Update (5/12): Ive finally answered all ~90 questions, a mere 4 days after the official end of the Ask Me Anything session! Thanks so much to everyone for all the great questions. For your reading convenience, heres a guide to my answers (personal favorites are in bold):

The probability that we live in the Matrix (see followups here, here, here, here)
Glauber dynamics
My behavior as Waterloo lunch organizer
The saddest thing
Quantum cellular automata
P!=NP vs. P!=PSPACE
My knowledge of general relativity
Advantages of Dirac ket notation
The evolution of my career goals
Open problems related to BosonSampling
Book-signing for Quantum Computing Since Democritus
In an infinite universe, must all possible earthlike planets exist?
Was 9/11 an inside job?
The fine-structure constant and quantum computing
Accessible open problems in complexity theory
Tightening Razborovs monotone lower bound for CLIQUE
In what sense is the quadratic Grover speedup provable?
Fisher information
Associate Professor Without Tenure
Is the whole universe just a vector in Hilbert space?
How to initialize a qubit
My knowledge of my tenure case
How Id build a quantum computer in 20-30 years
Could God solve the halting problem?
Whos yer daddy?
How long Id want to live
Could the difficulty of building a QC grow exponentially with number of qubits?
Why does quantum computing require physically different hardware?
The double-slit experiment and lazy evaluation
Bioengineered flying horses vs. flying robot horses: which will be first?
The last program I wrote
How much I sleep
Recent TCS advances with practical applications in the near future
What Id ask Terry Tao
How many digits will the largest known prime have in 10 or 100 years?
Whether I believe in free will
The nature of time
My progress in learning Hebrew
Social science breakthroughs that could bring about world peace
Superquadratic advantage of the quantum adiabatic algorithm over classical search?
Is a classical world also a quantum world?
The name of the blog
John Sidles prognostiquestion
Books and films for Lily to grow up with
Does QM generate true randomness?
Fictitious proofs of P!=NP
The secret of happiness
What I did in college
The blowup in reducing theorem-proving to 3SAT
Whether CUP objected to the free QCSD lecture notes
The top 5 not-yet-written books that Id most like to read
Does the continuum exist in physical reality? (see followup here)
Could Nature itself be inconsistent?
Zen koan about a mouse eating cat food
Maybe, its the equality sign?
Classical computer is to QC as QC is to what?
Why are CS theorists obsessed with polynomial time?
My favorite complexity theorist
A bad approach to factoring large integers
Am I a Bayesian?
How to build an intelligent machine
Will automated theorem provers become as standard as Mathematica/Maple?
My initiation into theoretical computer science
How to get an 8-year-old excited about programming
Am I insane?
Levin universal search
Brain emulation by 2023? A $10,000 bet
How being in communist Berkeley in my formative years shaped my worldview (see followup here)
Israel vs. Apartheid South Africa
Will useful QC precede its public announcement, or vice versa?
My work habits
US immigration policy
My favorite Israeli foods
If I guess randomly, how likely am I to get this question right?
Busy Beaver numbers: is BB(n+1) provably much larger than BB(n)? (see followups here and here)
Computational complexity and biological/social evolution
P vs. NP vs. Shannon capacity of cycles problem
Video games based on my research interests
Bayesian reasoning when there are copies of yourself
Pr[ PH=PSPACE | PH collapses ]
My favorite interpretation of QM
What Id do if I proved P=NP
QM and consciousness
QM and free will
Cultures of Clarkson, Cornell, Berkeley, IAS, Waterloo, MIT
How I decide whats ethical
American vs. Chilean universitiesQuantum Computing Since Democritus Lecture 4: Minds and Machines

Bigger, longer, wackier.  The topic: Minds and Machines.The Quantum PCP Manifesto

Behold the PCP Theorem, one of the crowning achievements of complexity theory:
Given a 3SAT formula , its NP-hard to decide whether (1)  is satisfiable or (2) at most a 1- fraction of the clauses are satisfiable, promised that one of these is the case.  Here  is a constant independent of n.
In recent weeks, Ive become increasingly convinced that a Quantum PCP Theorem like the following will one day be a crowning achievement of quantum complexity theory:
Given a set of local measurements on an n-qubit register, its QMA-hard to decide whether (1) there exists a state such that all of the measurements accept with probability 1, or (2) for every state, at most a 1- fraction of the measurements accept with probability more than 1-, promised that one of these is the case.  Here a local measurement is one that acts on at most (say) 3 qubits, and  and  are constants independent of n.
Im 99% sure that this theorem (alright, conjecture) or something close to it is true.  Im 95% sure that the proof will require a difficult adaptation of classical PCP machinery (whether Iritean or pre-Iritean), in much the same way that the Quantum Fault-Tolerance Theorem required a difficult adaptation of classical fault-tolerance machinery.  Im 85% sure that the proof is achievable in a year or so, should enough people make it a priority.  Im 75% sure that the proof, once achieved, will open up heretofore undreamt-of vistas of understanding and insight.  Im 0.01% sure that I can prove it.  And that is why I hereby bequeath the actual proving part to you, my readers.
Notes:

By analogy to the classical case, one expects that a full-blown Quantum PCP Theorem would be preceded by weaker results (quantum assignment testers, quantum PCPs with weaker parameters, etc).  So these are obviously the place to start.
Why hasnt anyone tackled this question yet?  Well, one reason is that its hard.  But a second reason is that people keep getting hung up on exactly how to formulate the question.  To forestall further nitpicking, I hereby declare it obvious that a Quantum PCP Theorem means nothing more or less than a robust version of Kitaevs QMA-completeness theorem, in exactly the same sense that the classical PCP Theorem was a robust version of the Cook-Levin Theorem.  Any formulation that captures this spirit is fine; mine was only one possibility.Reaching agreement with Aumann

This years Bank of Sweden Prize in Economic Sciences in Memory of Alfred Nobel has been awarded to two game theorists: Robert Aumann of Hebrew University, and Thomas Schelling of the University of Maryland.
In 1976, Aumann wrote a famous paper called Agreeing to Disagree, which proved the following fact. Suppose you and your friend are perfectly rational Bayesians, whod both form the same opinions if given the same information. Then provided your opinions are common knowledge (meaning you both know them, you both know you both know them, etc.), those opinions must be equal  even if neither of you knows the evidence on which the others opinion is based! Loosely speaking, then, you can never agree to disagree.
As an example, suppose Alice offers to sell you some stock.  Then the mere fact that shes trying to sell it gives you useful information  namely, that something mustve convinced her the stock is headed south. So even if you have no idea what that something is, her offer should cause you to decrease your own valuation of the stock. Similarly, if you agree to buy the stock, that should cause Alice to increase her valuation.  As observed by Milgrom and Stokey, the end result of all this second-guessing is that you might as well never trade at all! This is assuming three conditions: (i) that you and Alice would believe the same things if given the same information, (ii) that youre both trying to maximize expected wealth, and (iii) that you both have the same liquidity needs (i.e. neither desperately needs to pay off a mortgage). If youre still confused, read this delightful survey by Cowen and Hanson.
A year ago I proved a complexity-theoretic analogue of Aumanns theorem: that not only will two Bayesians agree in the limit of common knowledge, but theyll also (probably, approximately) agree after a really short conversation. I sent my paper to Aumann just for fun, not expecting any response from the great man. To my surprise, Aumann promptly wrote back with a thoughtful critique  telling me to cut out my philosophical musings and let the math speak for itself. I hated this advice at the time, but eventually came to the grudging realization that it was right.
Interestingly, besides being a world expert on rationality, Aumann is also an Orthodox Jew, whos written several papers applying game theory to the Talmud.  He was born in Germany in 1930 and escaped to the US in 1938.
Congratulations to Aumann and Schelling!D-Wave: Truth finally starts to emerge

Wrap-Up (June 5): This will be my final update on this post (really!!), since the discussion seems to have reached a point where not much progress is being made, and since Id like to oblige the commenters whove asked me to change the subject. Let me try to summarize the main point Ive been trying to get across this whole time. Ill call the point (*).
(*) D-Wave founder Geordie Rose claims that D-Wave has now accomplished its goal of building a quantum computer that, in his words, is better at something than any other option available. This claim has been widely and uncritically repeated in the press, so that much of the nerd world now accepts it as fact. However, the claim is not supported by the evidence currently available. It appears that, while the D-Wave machine does outperform certain off-the-shelf solvers, simulated annealing codes have been written that outperform the D-Wave machine on its own native problem when run on a standard laptop. More research is needed to clarify the issue, but in the meantime, it seems worth knowing that this is where things currently stand.
In the comments, many people tried repeatedly to change the subject from (*) to various subsidiary questions. For example: isnt it possible that D-Waves current device will be found to provide a speedup on some other distribution of instances, besides the one that was tested? Even if not, isnt it possible that D-Wave will achieve a genuine speedup with some future generation of machines? Did it make business sense for Google to buy a D-Wave machine? What were Googles likely reasons? Whats D-Waves current value as a company? Should Cathy McGeoch have acted differently, in the type of comparison she agreed to do, or in how she communicated about its results? Should I have acted differently, in my interaction with McGeoch?
And, Im afraid to say, I jumped in to the discussion of all of those questionsbecause, lets face it, there are very few subjects about which I dont have an opinion, or at least a list of qualified observations to make. In retrospect, I now think that was a mistake. It would have been better to sidestep all the other questionsnot one of which I really know the answer to, and each of which admits multiple valid perspectivesand just focus relentlessly on the truth of assertion (*).
Heres an analogy: imagine that a biotech startup claimed that, by using an expensive and controversial new gene therapy, it could cure patients at a higher rate than with the best available conventional drugsbasing its claim on a single clinical trial. Imagine that this claim was widely repeated in the press as an established fact. Now imagine that closer examination of the clinical trial revealed that it showed nothing of the kind: it compared against the wrong drugs. And imagine that a more relevant clinical trialmostly unmentioned in the presshad also been done, and discovered that when you compare to the right drugs, the drugs do better. Imagine that someone wrote a blog post bringing all of this to public attention.
And now imagine that the response to that blogger was the following: aha, but isnt it possible that some future clinical trial will show an advantage for the gene therapymaybe with some other group of patients? Even if not, isnt it possible that the startup will manage to develop an effective gene therapy sometime in the future? Betcha didnt consider that, did you? And anyway, at least theyre out there trying to make gene therapy work! So we should all support them, rather than relentlessly criticizing. And as for the startups misleading claims to the public? Oh, dont be so nave: thats just PR. If you cant tune out the PR and concentrate on the science, thats your own damn problem. In summary, the real issue isnt what some clinical trial did or didnt show; its you and your hostile attitude.
In a different context, these sorts of responses would be considered strange, and the need to resort to them revealing. But the rules for D-Wave are different.
(Interestingly, in excusing D-Waves statements, some commenters explicitly defended standards of intellectual discourse so relaxed that, as far as I could tell, just about anything anyone could possibly say would be OK with themexcept of course for what I say on this blog, which is not OK! It reminds me of the central tenet of cultural relativism: that there exist no universal standards by which any culture could ever be judged good or bad, except that Western culture is irredeemably evil.)
Update (June 4): Matthias Troyer (who, unfortunately, still cant comment here for embargo reasons) has asked me to clarify that its not he, but rather his postdoc Sergei Isakov, who deserves the credit for actually writing the simulated annealing code that outperformed the D-Wave machine on the latters own home turf (i.e., random QUBO instances with the D-Wave constraint graph). The quantum Monte Carlo code, which also did quite well at simulating the D-Wave machine, was written by Isakov together with another of Matthiass postdocs, Troels Rnnow.
Update (June 3): See Cathy McGeochs response (here and here), and my response to her response.
Yet More Updates (June 2): Alex Selby has a detailed new post summarizing his comparisons between the D-Wave device (as reported by McGeoch and Wang) and his own solverfinding that his solver can handily outperform the device and speculating about the reasons why.
In other news, Catherine McGeoch spoke on Friday in the MIT quantum group meeting. Incredibly, she spoke for more than an hour, without once mentioning the USC results that found that simulated annealing on a standard laptop (when competently implemented) handily outperformed the D-Wave machine, or making any attempt to reconcile those results with hers and Wangs. Instead, McGeogh used the time to enlighten the assembled experts about what quantum annealing was, what an exact solver was, etc. etc., then repeated the speedup claims as if the more informative comparisons simply didnt exist. I left without asking questions, not wanting to be the one to instigate an unpleasant confrontation, andIll admitquestioning my own sanity as a result of no one else asking about the gigantic elephant in the room.
More Updates (May 21): Happy 25th birthday to me! Among the many interesting comments below, see especially this one by Alex Selby, who says hes written his own specialist solver for one class of the McGeoch and Wang benchmarks that significantly outperforms the software (and D-Wave machine) tested by McGeoch and Wang on those benchmarksand who provides the Python code so you can try it yourself.
Also, Igor Vernik asked me to announce that on July 8th, D-Wave will be giving a technical presentation at the International Superconducting Electronics Conference in Cambridge. See here for more info; Ill be traveling then and wont be able to make it. I dont know whether the performance comparisons to Matthias Troyers and Alex Selbys code will be among the topics discussed, or if there will be an opportunity to ask questions about such things.
In another exciting update, John Smolin and Graeme Smith posted a paper to the arXiv tonight questioning even the signature of quantumness part of the latest D-Wave claimsthe part that Id been ~98% willing to accept, even as I relayed evidence that cast enormous doubt on the speedup part. Specifically, Smolin and Smith propose a classical model that they say can explain the bimodal pattern of success probabilities observed by the USC group as well as quantum annealing can. I havent yet had time to read their paper or form an opinion about it, but Id be very interested if others wanted to weigh in. Update (May 26): The USC group has put out a new preprint responding to Smolin and Smith, offering additional evidence for quantum behavior in the D-Wave device that they say cant be explained using Smolin and Smiths model.
Update (May 17): Daniel Lidar emailed me to clarify his views about error-correction and the viability of D-Waves approach. He invited me to share his clarification with otherssomething that Im delighted to do, since I agree with him wholeheartedly. Without further ado, heres what Lidar says:
I dont believe D-Waves approach is scalable without error correction. I believe that the incorporation of error correction is a necessary condition in order to ever achieve a speedup with D-Waves machines, and I dont believe D-Waves machines are any different from other types of quantum information processing in this regard. I have repeatedly made this point to D-Wave over several years, and I hope that in the future their designs will allow more flexibility in the incorporation of error correction.
Lidar also clarified that he not only doesnt dispute what Matthias Troyer told me about the lack of speedup of the D-Wave device compared to classical simulated annealing in their experiments, but fully agrees, endorses, and approves of itand indeed, that he himself was part of the team that did the comparison.
In other news,this Hacker News thread, which features clear, comprehending discussions of this blog post and the backstory that led up to it, has helped to restore my faith in humanity.

Two years ago almost to the day, I announced my retirement as Chief D-Wave Skeptic. Butas many readers predicted at the timerecent events (and the contents of my inbox!) have given me no choice except to resume my post. In an all-too-familiar pattern, multiple rounds of D-Wave-related hype have made it all over the world before the truth has had time to put its pants on and drop its daughter off in daycare. And the current hype is particularly a shame, because once one slices through all the layers of ughthe rigged comparisons, the dramatic announcements that mean nothing, the lazy journalists cherry-picking what they want to hear and ignoring the inconvenient bitsthere really has been a huge scientific advance this past month in characterizing the D-Wave devices. Im speaking about the experiments on the D-Wave One installed at USC, the main results of which finally appeared in April. Two of the coauthors of this new workMatthias Troyer and Daniel Lidarwere at MIT recently to speak about their results, Troyer last week and Lidar this Tuesday. Intriguingly, despite being coauthors on the same paper, Troyer and Lidar have very different interpretations of what their results mean, but well get to that later. For now, let me summarize what I think their work has established.
Evidence for Quantum Annealing Behavior
For the first time, we have evidence that the D-Wave One is doing what should be described as quantum annealing rather than classical annealing on more than 100 qubits. (Note that D-Wave itself now speaks about quantum annealing rather than quantum adiabatic optimization. The difference between the two is that the adiabatic algorithm runs coherently, at zero temperature, while quantum annealing is a messier version in which the qubits are strongly coupled to their environment throughout, but still maintain some quantum coherence.) The evidence for quantum annealing behavior is still extremely indirect, but despite my Chief Skeptic role, Im ready to accept what the evidence indicates with essentially no hesitation.
So what is the evidence? Basically, the USC group ran the D-Wave One on a large number of randomly generated instances of what Ill call the D-Wave problem: namely, the problem of finding the lowest-energy configuration of an Ising spin glass, with nearest-neighbor interactions that correspond to the D-Wave chips particular topology. Of course, restricting attention to this D-Wave problem tilts the tables heavily in D-Waves favor, but no matter: scientifically, it makes a lot more sense than trying to encode Sudoku puzzles or something like that. Anyway, the group then looked at the distribution of success probabilities when each instance was repeatedly fed to the D-Wave machine. For example, would the randomly-generated instances fall into one giant clump, with a few outlying instances that were especially easy or especially hard for the machine? Surprisingly, they found that the answer was no: the pattern was strongly bimodal, with most instances either extremely easy or extremely hard, and few instances in between. Next, the group fed the same instances to Quantum Monte Carlo: a standard classical algorithm that uses Wick rotation to find the ground states of stoquastic Hamiltonians, the particular type of quantum evolution that the D-Wave machine is claimed to implement. When they did that, they found exactly the same bimodal pattern that they found with the D-Wave machine. Finally they fed the instances to a classical simulated annealing programbut there they found a unimodal distribution, not a bimodal one. So, their conclusion is that whatever the D-Wave machine is doing, its more similar to Quantum Monte Carlo than it is to classical simulated annealing.
Curiously, we dont yet have any hint of a theoretical explanation for why Quantum Monte Carlo should give rise to a bimodal distribution, while classical simulating annealing should give rise to a unimodal one. The USC group simply observed the pattern empirically (as far as I know, theyre the first to do so), then took advantage of it to characterize the D-Wave machine. I regard explaining this pattern as an outstanding open problem raised by their work.
In any case, if we accept that the D-Wave One is doing quantum annealing, then despite the absence of a Bell-inequality violation or other direct evidence, its reasonably safe to infer that there should be large-scale entanglement in the device. I.e., the true quantum state is no doubt extremely mixed, but theres no particular reason to believe we could decompose that state into a mixture of product states. For years, I tirelessly repeated that D-Wave hadnt even provided evidence that its qubits were entangledand that, while you can have entanglement with no quantum speedup, you cant possibly have a quantum speedup without at least the capacity to generate entanglement. Now, Id say, D-Wave finally has cleared the evidence-for-entanglement barand, while theyre not the first to do so with superconducting qubits, theyre certainly the first to do so with so many superconducting qubits. So I congratulate D-Wave on this accomplishment. If this had been advertised from the start as a scientific research projectof course were a long way from QC being practical; no one would ever claim otherwise; but as a first step, weve shown experimentally that we can entangle 100 superconducting qubits with controllable couplingsmy reaction wouldve been, cool! (Similar to my reaction to any number of other steps toward scalable QC being reported by research groups all over the world.)
No Speedup Compared to Classical Simulated Annealing
But of course, D-Waves claimsand the claims being made on its behalf by the Hype-Industrial Complexare far more aggressive than that. And so we come to the part of this post that has not been pre-approved by the International D-Wave Hype Repeaters Association. Namely, the same USC paper that reported the quantum annealing behavior of the D-Wave One, also showed no speed advantage whatsoever for quantum annealing over classical simulated annealing. In more detail, Matthias Troyers group spent a few months carefully studying the D-Wave problemafter which, they were able to write optimized simulated annealing code that solves the D-Wave problem on a normal, off-the-shelf classical computer, about 15 times faster than the D-Wave machine itself solves the D-Wave problem! Of course, if you wanted even more classical speedup than that, then you could simply add more processors to your classical computer, for only a tiny fraction of the ~$10 million that a D-Wave One would set you back.
Some people might claim its unfair to optimize the classical simulated annealing code to take advantage of the quirks of the D-Wave problem. But think about it this way: D-Wave has spent ~$100 million, and hundreds of person-years, optimizing the hell out of a special-purpose annealing device, with the sole aim of solving this one problem that D-Wave itself defined. So if were serious about comparing the results to a classical computer, isnt it reasonable to have one professor and a few postdocs spend a few months optimizing the classical code as well?
As I said, besides simulated annealing, the USC group also compared the D-Wave Ones performance against a classical implementation of Quantum Monte Carlo. And maybe not surprisingly, the D-Wave machine was faster than a direct classical simulation of itself (I cant remember how many times faster, and couldnt find that information in the paper). But even here, theres a delicious irony. The only reason the USC group was able to compare the D-Wave one against QMC at all, is that QMC is efficiently implementable on a classical computer! (Albeit probably with a large constant overhead compared to running the D-Wave annealer itselfhence the superior performance of classical simulated annealing over QMC.) This means that, if the D-Wave machine can be understood as reaching essentially the same results as QMC (technically, QMC with no sign problem), then theres no real hope for using the D-Wave machine to get an asymptotic speedup over a classical computer. The race between the D-Wave machine and classical simulations of the machine would then necessarily be a cat-and-mouse game, a battle of constant factors with no clear asymptotic victor. (Some people might conjecture that it will also be a Tom & Jerry game, the kind where the classical mouse always gets the better of the quantum cat.)
At this point, its important to give a hearing to three possible counterarguments to what Ive written above.
The first counterargument is that, if you plot both the runtime of simulated annealing and the runtime of the D-Wave machine as functions of the instance size n, you find that, while simulated annealing is faster in absolute terms, it can look like the curve for the D-Wave machine is less steep. Over on the blog nextbigfuture, an apparent trend of this kind has been fearlessly extrapolated to predict that with 512 qubits, the D-Wave machine will be 10 billion times faster than a classical computer. But theres a tiny fly in the ointment. As Troyer carefully explained to me last week, the slow growth rate of the D-Wave machines runtime is, ironically, basically an artifact of the machine being run too slowly on small values of n. Run the D-Wave machine as fast as it can run for small n, and the difference in the slopes disappears, with only the constant-factor advantage for simulated annealing remaining. In short, there seems to be no evidence, at present, that the D-Wave machine is going to overtake simulated annealing for any instance size.
The second counterargument is that the correlation between the two bimodal distributionsthat for the D-Wave machine and that for the Quantum Monte Carlo simulationis not perfect. In other words, there are a few instances (not many) that QMC solves faster than the D-Wave machine, and likewise a few instances that the D-Wave machine solves faster than QMC. Not surprisingly, the latter fact has been eagerly seized on by the D-Wave boosters (hey, sometimes the machine does better!). But Troyer has a simple and hilarious response to that. Namely, he found that his groups QMC code did a better job of correlating with the D-Wave machine, than the D-Wave machine did of correlating with itself! In other words, calibration errors seem entirely sufficient to explain the variation in performance, with no need to posit any special class of instances (however small) on which the D-Wave machine dramatically outperforms QMC.
The third counterargument is just the banal one: the USC experiment was only one experiment with one set of instances (albeit, a set one might have thought would be heavily biased toward D-Wave). Theres no proof that, in the future, it wont be discovered that the D-Wave machine does something more than QMC, and that theres some (perhaps specially-designed) set of instances on which the D-Wave machine asymptotically outperforms both QMC and Troyers simulated annealing code. (Indeed, I gather that folks at D-Wave are now assiduously looking for such instances.) Well, I concede that almost anything is possible in the futurebut these experiments, while not supporting D-Waves claims about the usefulness of its devices, also dont conclusively disprove those claims is a very different message than whats currently making it into the press.
Comparison to CPLEX is Rigged
Unfortunately, the USC paper is not the one thats gotten the most press attentionperhaps because half of it inconveniently told the hypesters something they didnt want to hear (no speedup). Instead, journalists have preferred a paper released this week by Catherine McGeoch and Cong Wang, which reports that quantum annealing running on the D-Wave machine outperformed the CPLEX optimization package running on a classical computer by a factor of ~3600, on Ising spin problems involving 439 bits. Wow! That sounds awesome! But before rushing to press, lets pause to ask ourselves: how can we reconcile this with the USC groups result of no speedup?
The answer turns out to be painfully simple. CPLEX is a general-purpose, off-the-shelf exact optimization package. Of course an exact solver cant compete against quantum annealingor for that matter, against classical annealing or other classical heuristics! Noticing this problem, McGeoch and Wang do also compare the D-Wave machine against tabu search, a classical heuristic algorithm. When they do so, they find that an advantage for the D-Wave machine persists, but it becomes much, much smaller (they didnt report the exact time comparison). Amusingly, they write in their Conclusions and Future Work section:
It would of course be interesting to see if highly tuned implementations of, say, tabu search or simulated annealing could compete with Blackbox or even QA[i.e., the D-Wave machines] on QUBO [quadratic binary optimization] problems; some preliminary work on this question is underway.
As I said above, at the timeMcGeoch and Wangs paper was released to the media (though maybe not at the time it was written?), the highly tuned implementation of simulated annealing that they ask for had already been written and tested, and the result was that it outperformed the D-Wave machine on all instance sizes tested. In other words, their comparison to CPLEX had already been superseded by a much more informative comparisonone that gave the opposite resultbefore it ever became public. For obvious reasons, most press reports have simply ignored this fact.
Troyer, Lidar, and Stone Soup
Much of what Ive written in this post, I learned by talking to Matthias Troyerthe man who carefully experimented with the D-Wave machine and figured out how to beat it using simulated annealing, and who I regard as probably the worlds #1 expert right now on what exactly the machine does. Troyer wasnt shy about sharing his opinions, and while couched with qualifications, they tended toward extremely skeptical. For example, Troyer conjectured that, if D-Wave ultimately succeeds in getting a speedup over classical computers in a fair comparison, then it will probably be by improving coherence and calibration, incorporating error-correction, and doing other things that traditional, academic quantum computing researchers had said all along would need to be done.
As I said, Daniel Lidar is another coauthor on the USC paper, and also recently visited MIT to speak. Lidar and Troyer agree on the basic factsyet Lidar noticeably differed from Troyer, in trying to give each fact the most pro-D-Wave spin it could possibly support. Lidar spoke at our quantum group meeting, not about the D-Wave vs. simulated annealing performance comparison (which he agrees with), but about a proposal of his for incorporating quantum error-correction into the D-Wave device, together with some experimental results. He presented his proposal, not as a reductio ad absurdum of D-Waves entire philosophy, but rather as a positive opportunity to get a quantum speedup using D-Waves approach.
So, to summarize my current assessment of the situation: yes, absolutely, D-Wave might someday succeedironically, by adapting the very ideas from the gate model that its entire business plan has been based on avoiding, and that D-Wave founder Geordie Rose has loudly denigrated for D-Waves entire history! If thats what happens, then I predict that science writers, and blogs like nextbigfuture, will announce from megaphones that D-Wave has been vindicated at last, while its narrow-minded, theorem-obsessed, ivory-tower academic naysayers now have egg all over their faces. No one will care that the path to successthrough quantum error-correction and so onactually proved the academic critics right, and that D-Waves vindication was precisely like that of the deliciousness of stone soup in the old folktale. As for myself, Ill probably bang my head on my desk until I sustain so much brain damage that I no longer care either. But at least Ill still have tenure, and the world will have quantum computers.
The Messiahs Quantum Annealer

Over the past few days, Ive explained the above to at least six different journalists who asked. And Ive repeatedly gotten a striking response: What you say makes sensebut then why are all these prestigious people and companies investing in D-Wave? Why did Bo Ewald, a prominent Silicon Valley insider, recently join D-Wave as president of its US operations? Why the deal with Lockheed Martin? Why the huge deal with NASA and Google, just announced today? Whats your reaction to all this news?
My reaction, I confess, is simple. I dont careI actually told them thisif the former Pope Benedict has ended his retirement to become D-Waves new marketing director. I dont care if the Messiah has come to Earth on a flaming chariot, not to usher in an age of peace but simply to spend $10 million on D-Waves new Vesuvius chip. And if you imagine that Ill ever care about such things, then you obviously dont know much about me. Ill tell you what: if peer pressure is where its at, then come to me with the news that Umesh Vazirani, or Greg Kuperberg, or Matthias Troyer is now convinced, based on the latest evidence, that D-Waves chip asymptotically outperforms simulated annealing in a fair comparison, and does so because of quantum effects. Any one such scientists considered opinion would mean more to me than 500,000 business deals.
The Argument from Consequences
Let me end this post with an argument that several of my friends in physics have explicitly made to menot in the exact words below but in similar ones.
Look, Scott, let the investors, government bureaucrats, and gullible laypeople believe whatever they wantand let D-Wave keep telling them whatevers necessary to stay in business. Its unsportsmanlike and uncollegial of you to hold D-Waves scientists accountable for whatever wild claims their companys PR department might make. After all, were in this game too! Our universities put out all sorts of overhyped press releases, but we dont complain because we know that its done for our benefit. Besides, youd doubtless be trumpeting the same misleading claims, if you were in D-Waves shoes and needed the cash infusions to survive. Anyway, who really cares whether theres a quantum speedup yet or no quantum speedup? At least D-Wave is out there trying to build a scalable quantum computer, and getting millions of dollars from Jeff Bezos, Lockheed, Google, the CIA, etc. etc. to do soresources more of which would be directed our way if we showed a more cooperative attitude! If we care about scalable QCs ever getting built, then the wise course is to celebrate what D-Wave has donethey just demonstrated quantum annealing on 100 qubits, for crying out loud! So lets all be grownups here, focus on the science, and ignore the marketing buzz as so much meaningless noisejust like a tennis player might ignore his opponents trash-talking (your mother is a whore, etc.) and focus on the game.
I get this argument: really, I do. I even concede that theres something to be said for it. But let me now offer a contrary argument for the readers consideration.
Suppose that, unlike in the stone soup scenario I outlined above, it eventually becomes clear that quantum annealing can be made to work on thousands of qubits, but that its a dead end as far as getting a quantum speedup is concerned. Suppose the evidence piles up that simulated annealing on a conventional computer will continue to beat quantum annealing, if even the slightest effort is put into optimizing the classical annealing code. If that happens, then I predict that the very same people now hyping D-Wave will turn around andwithout the slightest acknowledgment of error on their partdeclare that the entire field of quantum computing has now been unmasked as a mirage, a scam, and a chimera. The same pointy-haired bosses who now flock toward quantum computing, will flock away from it just as quickly and as uncomprehendingly. Academic QC programs will be decimated, despite the slow but genuine progress that theyd been making the entire time in a parallel universe from D-Wave. Peoples contempt for academia is such that, while a D-Wave success would be trumpeted as its alone, a D-Wave failure would be blamed on the entire QC community.
When it comes down to it, thats the reason why I care about this matter enough to have served as Chief D-Wave Skeptic from 2007 to 2011, and enough to resume my post today. As Ive said many times, I really, genuinely hope that D-Wave succeeds at building a QC that achieves an unambiguous speedup! I even hope the academic QC community will contribute to D-Waves success, by doing careful independent studies like the USC group did, and by coming up with proposals like Lidars for how D-Wave could move forward. On the other hand, in the strange, unlikely event that D-Wave doesnt succeed, Id like people to know that many of us in the QC community were doing what academics are supposed to do, which is to be skeptical and not leave obvious questions unasked. Id like them to know that some of us simply tried to understand and describe what we saw in front of uschanging our opinions repeatedly as new evidence came in, but disregarding meta-arguments like my physicist friends above. The reason I can joke about how easy it is to bribe me is that its actually kind of hard.Still fiddling on the roof

This week Shtetl-Optimized celebrates its one-year anniversary!
That being the case, in the remainder of this post I thought it would be a good idea to take stock of everything this blog has achieved over the past year, and also to set concrete goals for the coming year.Ja!  Ein klein Wienerschnitzel Entscheidungsproblem

I arrived yesterday in Innsbruck, Austria  a lovely medieval town set in a valley in the Tyrolean Alps.  Here the Pontiff and I are sharing an office at the Institut fr Quantenoptik und Quanteninformation, and will have to work out a comedy routine to be performed Friday morning, when were supposed to open the QIPC meeting at Ike Newtons old stomping grounds, the Royal Society in London.
Since Im too jetlagged to write a coherent entry, I hope youll be satisfied with some lists:
The three secrets of air travel (distilled from a decade of experience flying to four continents, and offered free of charge to you, my readers):

Bring a book.  Dont even try to work on the plane; just read read read read read.  If you get stuck in the airport for hours, all the more time to read!
If you must work, do it with pen and paper, not a laptop.
Put your laptop case in the overhead bin, not under your seat.  This will give you more room to stretch your legs.

The only three German words youll ever need to know:

Danke (thank you).  To be said after any interaction with anyone.
Ein (one).  As in: I will have one of those (pointing).
Entscheidungsproblem (decision problem).  The problem of deciding whether a first-order sentence is true in every interpretation, proven to be undecidable by Church and Turing.

The two things I saw yesterday that I wish Id taken a photo of but didnt:

A jewelry store display case, proudly displaying SCHMUCK brand designer watches.  (Important Correction: Ignorant schmuck that I am, I hadnt realized that schmuck is not a brand name, but just the German word for jewelry.  Apparently the meaning in Yiddish migrated from jewels to family jewels to person being compared to the family jewels, which is a bit ironic.  Oh my turtledove, the apple of my eye, my priceless schmuck)
A campaign poster for one of Austrias far-right politicians, which graffiti artists had decorated with a Hitler mustache, a forehead swastika, and salutations of Heil!  (Just what point were the graffiti artists trying to make?  I wish I understood.)Why complexity is better than cannabis

Whether there exist subexponential-size locally decodable codes, and sub-n-communication private information retrieval (PIR) protocols, have been major open problems for a decade.  A new preprint by Sergey Yekhanin reveals that both of these questions hinge on  wait for this  whether or not there are infinitely many Mersenne primes.  By using the fact (discovered a month ago) that 232,582,657-1 is prime, Yekhanin can already give a 3-server PIR protocol with communication complexity O(n1/32,582,658), improving the previous bound of O(n1/5.25).   Duuuuuude.  If youve ever wondered what it is that motivates complexity theorists, roll this one up and smoke it.The Ghost in the Quantum Turing Machine

Ive been traveling this past week (in Israel and the French Riviera), heavily distracted by real life from my blogging career. But by popular request, let me now provide a link to my very first post-tenure publication: The Ghost in the Quantum Turing Machine.
Heres the abstract:
In honor of Alan Turings hundredth birthday, I unwisely set out some thoughts about one of Turings obsessions throughout his life, the question of physics and free will. I focus relatively narrowly on a notion that I call Knightian freedom: a certain kind of in-principle physical unpredictability that goes beyond probabilistic unpredictability. Other, more metaphysical aspects of free will I regard as possibly outside the scope of science. I examine a viewpoint, suggested independently by Carl Hoefer, Cristi Stoica, and even Turing himself, that tries to find scope for freedom in the universes boundary conditions rather than in the dynamical laws. Taking this viewpoint seriously leads to many interesting conceptual problems. I investigate how far one can go toward solving those problems, and along the way, encounter (among other things) the No-Cloning Theorem, the measurement problem, decoherence, chaos, the arrow of time, the holographic principle, Newcombs paradox, Boltzmann brains, algorithmic information theory, and the Common Prior Assumption. I also compare the viewpoint explored here to the more radical speculations of Roger Penrose. The result of all this is an unusual perspective on time, quantum mechanics, and causation, of which I myself remain skeptical, but which has several appealing features. Among other things, it suggests interesting empirical questions in neuroscience, physics, and cosmology; and takes a millennia-old philosophical debate into some underexplored territory.
See here (and also here) for interesting discussions over on Less Wrong. I welcome further discussion in the comments section of this post, and will jump in myself after a few days to address questions (update: eh, already have). There are three reasons for the self-imposed delay: first, general busyness. Second, inspired by the McGeoch affair, Im trying out a new experiment, in which I strive not to be on such an emotional hair-trigger about the comments people leave on my blog. And third, based on past experience, I anticipate comments like the following:
Hey Scott, I didnt have time to read this 85-page essay that you labored over for two years. So, can you please just summarize your argument in the space of a blog comment? Also, based on the other comments here, I have an objection that Im sure never occurred to you. Oh, wait, just now scanning the table of contents
So, I decided to leave some time for people to RTFM (Read The Free-Will Manuscript) before I entered the fray.
For now, just one remark: some people might wonder whether this essay marks a new research direction for me. While its difficult to predict the future (even probabilistically  ), I can say that my own motivations were exactly the opposite: I wanted to set out my thoughts about various mammoth philosophical issues once and for all, so that then I could get back to complexity, quantum computing, and just general complaining about the state of the world.Setting The Record straight

So, it seems Ive been written up in the Kitchener-Waterloo Record, a newspaper whose prestige and journalistic excellence make the Wall Street Journal look like the Shop-Rite coupon book.  The article, by Meghan Waters, is about nerd culture in Waterloo, and I am the prototypical nerd who Waters found to interview.
A few corrections:

While I said some very nice things about Mike Lazaridis, I did not compare him to God.  (Sorry, Mike!)
I did not use the phrase create some nerd capital.  Indeed, if you find a phrase that sounds like I wouldnt have used it, I probably didnt use it.
I did not confidently declare that in the future, nerdlings will dream about the University of Waterloo as they now do MIT and Caltech (just give it some time).  I speculated that something like this might happen, particularly if the US were to continue its descent into medieval theocracy.

Despite these and other minor errors, Im glad that my plan to increase the number of women in science by nerdifying the world has now received the wide public airing it deserves.The tightrope of truth and courtesy

A reader calling him- or herself A Merry Clown left a comment on my previous post which was so wise, I decided it had to be promoted to a post of its own.
Scientific discourse is the art of juggling decorum, truth and humor. A high-wire feat, attempted under imposing shadows cast by giants and above the distraction of merry dancing clowns.
The appropriate tone for scientific discourse seems to be:
(a) Cordial. Always credit others for their hard work and good intentions (allow or at least pretend that others are basically well-intentioned, except in rare situations where there is proof of egregious misconduct).
(b) Biting, merciless and hard-nosed on the substantive issues. The truth deserves no less.
Perhaps the harsher (b) is, the gentler and more thorough (a) should be. After-all, human beings are what they are.
Certainly, provided one adequately treads through the niceties in (a), theres no reason to worry about hurting anyones feelings in (b). Anyone who makes scientific claims in a professional or public arena should be prepared to put on their big boy pants or their big girl pants and have their claims face the brutal gauntlet of scientific scrutiny. All attempts should be made to avoid even the appearance that any part of (b) contains personal barbs or insults (unless these barbs happen to be to be hilarious.)
Outside of science the rule is: whoever flings the horseshit the hardest wins.
Essentially, what Shtetl-Optimized readers got to see this past week was me falling off the high wire (with tenure the safety net below?  ). I failed at a purely human levelthough admittedly, while attempting a particularly difficult tightrope walk, and while heavily distracted by the taunts of both giants and clowns. Ive already apologized to Cathy McGeoch for insulting her, but I reiterate my apology now, and I extend the apology to any colleagues at MIT who might have been offended by anything I said. Ill strive, in future posts, to live up to a higher standard of cordiality, composure, and self-control.
At the scientific leveli.e., at level (b)I stand by everything I wrote in the previous post and the comments therein.Reigniting flame wars is my solemn responsibility

The New York Times on Yau.  Thanks to Hoeteck Wee.The Collision Lower Bound After 12 Years

Streaming video is now available for the talks at the QStart conference, a couple weeks ago at Hebrew University in Jerusalem. If youre the sort of person who likes watching quantum information talks, then check out the excellent ones by Ray Laflamme, John Martinis, Umesh Vazirani, Thomas Vidick, Jacob Bekenstein, and many others.
My own contributionthe first backwards-facing, crusty, retrospective talk Ive ever givenwas called The Collision Lower Bound After 12 Years (click here for the slidesand to answer the inevitable question, no, I have no idea how to open PowerPoint files in your favorite free-range, organic computing platform). Briefly, the collision lower bound is the theorem that even a quantum computer needs at least ~n1/3 steps to find a duplicate in a long list of random numbers between 1 and n, even assuming the list is long enough that there are many, many duplicates to be found. (Moreover,~n1/3 steps are known to suffice, by the BHT algorithm, a clever adaptation of Grovers search algorithm. Also, for simplicity a step means a single access to the list, though of course a quantum algorithm can access multiple list elements in superposition and it still counts as one step.)
By comparison, for classical algorithms, ~n steps are necessary and sufficient to find a collision, by the famous Birthday Paradox. So, just like for Grovers search problem, a quantum computer could give you a modest speedup over classical for the collision problem, but only a modest one. The reason this is interesting is that, because of the abundance of collisions to be found, the collision problem has a great deal more structure than Grovers search problem (though it has less structure than Shors period-finding problem, where there famously is an exponential quantum speedup).
One obvious motivation for the collision problem is that it models the problem of breaking collision-resistant hash functions (like SHA-256) in cryptography. In particular, if there were a superfast (e.g., log(n)-time) quantum algorithm for the collision problem, then there could be no CRHFs secure against quantum attack. So the fact that theres no such algorithm at least opens up the possibility of quantum-secure CRHFs. However, there are many other motivations. For example, the collision lower bound rules out the most simpleminded approach to a polynomial-time quantum algorithm for the Graph Isomorphism problem (though, I hasten to add, it says nothing about more sophisticated approaches). The collision problem is also closely related to Statistical Zero Knowledge (SZK) proof protocols, so that the collision lower bound leads to an oracle relative to which SZK is not in BQP.
Probably the most bizarre motivation to other people, but for some reason the most important one to me back in 2001, is that the collision problem is closely related to the problem of sampling the entire trajectories of hidden variables, in hidden-variable theories such as Bohmian mechanics. The collision lower bound provides strong evidence that this trajectory-sampling problem is hard even for a quantum computerintuitively because a QC cant keep track of the correlations between the hidden-variable positions at different times. The way I like to put it is that if, at the moment of your death, your entire life history flashed before you in an instant (and if a suitable hidden-variable theory were true, and if youd performed an appropriate quantum interference experiment on your own brain during your life), then you really could solve the collision problem in only O(1) steps. Interestingly, you still might not be able to solve NP-complete problemsI dont know! But you could at least do something that we think is hard for a quantum computer.
I proved the first collision lower bound in 2001 (actually, a week or so after the 9/11 attacks), after four months of sleepless nights and failed attempts. (Well actually, I only got the weaker lower bound of ~n1/5; the~n1/3 was a subsequent improvement due to Yaoyun Shi. Before ~n1/5, no one could even rule out that a quantum computer could solve the collision problem with a constant number of steps (!!), independent of nsay, 4 steps.) It was the first thing Id proved of any significance, and probably the most important thing I did while in grad school. I knew it was one of the favorite problems of my adviser, Umesh Vazirani, so I didnt even tell Umesh I was working on it until Id already spent the whole summer on it. I figured hed think I was nuts.

Bonus Proof Explanation!
The technique that ultimately worked was the polynomial method, which was introduced to quantum computing four years prior in a seminal paper of Beals et al. In this technique, you first suppose by contradiction that a quantum algorithm exists to solve your problem that makes very few accesses to the input bitssay, T. Then you write out the quantum algorithms acceptance probability (e.g., the probability that the algorithm outputs yes, I found what I was looking for) as a multivariate polynomial p in the input bits. Its not hard to prove that p has degree at most 2T, since the amplitudes in the quantum algorithm can be written as degree-T polynomials (each input access increases the degree by at most 1, and unitary transformations in between input accesses dont increase the degree at all); then squaring the amplitudes to get probabilities doubles the degree. (This is the only part of the method that uses anything specific to quantum mechanics!)
Next, you choose some parameter k related to the problem of interest, and you let q(k) be the expectation of p(X) over all inputs X with the parameter equal to k. For example, with the collision problem, it turns out that the right choice to make is to set k=1 if each number appears exactly once in your input list, k=2 if each number appears exactly twice, k=3 if each number appears exactly three times, and so on. Thenhere comes the magic partyou show that q(k) itself is a univariate polynomial in k, again of degree at most 2T. This magical step is called symmetrization; it can be traced at least as far back as the famous 1969 book Perceptrons by Marvin Minsky and Seymour Papert. In the case of the collision problem, I still have no explanation, 12 years later, for why symmetrization works: all I can say is that you do the calculation, and you cancel lots of things from both the numerator and the denominator, and what comes out at the end is a low-degree polynomial in k. (Its precisely because I would never have predicted such a zany coincidence, that I had to stumble around in the dark for 4 months before I finally discovered by chance that the polynomial method worked.)
Anyway, after applying symmetrization, youre left with a low-degree univariate polynomial q with some very interesting properties: for example, you need 0q(k)1 for positive integers k, since then q(k) represents an averaged probability that your quantum algorithm does something. You also need q(1) to be close to 0, since if k=1 then there no collisions to be found, and you need q(2) to be close to 1, since if k=2 then there are lots of collisions and youd like your algorithm to find one. But now, you can appeal to a theorem of A. A. Markov from the 1890s, which implies that no low-degree polynomial exists with those properties! Hence your original efficient quantum algorithm cant have existed either: indeed, you get a quantitative lower bound (a tight one, if youre careful) on the number of input accesses your algorithm must have made. And that, modulo some nasty technicalities (e.g., what if k doesnt evenly divide the size of your list?), is how the collision lower bound works.

So, in the first half of my QStart talk, I explain the collision lower bound and its original motivations (and a little about the proof, but no more than what I said above). Then in the second half, I survey lots of extensions and applications between 2002 and the present, as well as the many remaining open problems. For example, I discuss the tight lower bound of Ambainis et al. for the index erasure problem, Belovss proof of the element distinctness lower bound using the adversary method, and my and Ambainiss generalization of the collision lower bound to arbitrary symmetric problems. I also talk about Mark Zhandrys recent breakthrough (sorry, am I not allowed to use that word?) showing that the GGM construction of pseudorandom functions is secure against quantum adversaries, and how Zhandrys result can be seenin retrospect, anywayas yet another application of the collision lower bound.
Probably of the most general interest, I discuss how Daniel Harlow and Patrick Hayden invoked the collision lower bound in their striking recent paper on the AMPS black hole firewall paradox. In particular they argued that, in order to uncover the apparent violation of local quantum field theory at the heart of the paradox, an observer falling into a black hole would probably need to solve a QSZK-complete computational problem. And of course, the collision lower bound furnishes our main piece of evidence that QSZK-complete problems really should require exponential time even for quantum computers. So, Harlow and Hayden argue, the black hole would already have evaporated before the observer had even made a dent in the requisite computation.
Now, the Harlow-Hayden paper, and the AMPS paradox more generally, really deserve posts of their ownjust as soon as I learn enough to decide what I think about them. For now, Ill simply say that, regardless of how convinced you are by Harlow and Haydens argument (and, a bit like with my free-will essay, its not clear how convinced the authors themselves are!), its one of the most ambitious syntheses of computational complexity and physics Ive ever seen. You can disagree with it, but to read the paper (or watch the talk, streaming video from Strings2013 here) is to experience the thrill of seeing black hole physics related to complexity theory by authors who really know both.
(In my own talk on the collision lower bound, the short segment about Harlow-Hayden generated more questions and discussion than the rest of the talk combinedwith me being challenged to defend their argument, even with Patrick Hayden right there in the audience! I remarked later that that portion of the talk was itself a black hole for audience interest.)
In totally unrelated news, Quantum Computing Since Democritus made Scientific Americans list of best summer books! I cant think of a more appropriate honor, since if theres any phrase that captures what QCSD is all about, sizzling summer beach read would be it. Apparently there will even be an online poll soon, where yall can go and vote for QCSD as your favorite. Vote early and often, and from multiple IP addresses!Newton vs. Leibniz: the wigs are off

Of course, the greatest scientific flame war of all time was the calculus priority dispute between Isaac Newton and Gottfried Wilhelm Leibniz.  This one had everything: intrigue, pettiness, hypocrisy, nationalism, and even hints of the physicist vs. computer scientist split that continues to this day.
In our opening talk at QIPC2006 in London, Dave Bacon and I decided to relive the hatred  with Dave in a frilly white wig playing the part of Newton, and your humble blogger in a frilly black wig playing the part of Leibniz.  We forgot to take photos, but heres the script, and here are the slides for the  err, serious talk that Dave and I gave after dewigging.
Update (thanks to Dave and Viv Kendon):You know youve made it when

 Lance Fortnow and Bill Gasarch perform a Talmudic exegesis of one of your blog posts, taking more time to do so than you took to write the post.  Listen to Bill and Lance dissect my Ten Reasons to Believe P!=NP, and then offer their own reasons that are every bit as flaky as mine are.  (Indeed, Lances reason turns out to be almost identical to my reason #9, which he had previously rejected.)
Im honored, of course, but Im also offended by Bill and Lances speculation that not all of my Reasons to Believe were meant completely seriously.  Needless to say, everything I write on this blog carries the Official Scott Aaronson Seal of Really Meaning It.  Including the last sentence.  And the last one.  And the last one.  And the last one.Microsoft: From QDOS to QMA in less than 35 years

This past week I was in Redmond for the Microsoft Faculty Summit, which this year included a special session on quantum computing. (Bill Gates was also there, I assume as our warmup act.) I should explain that Microsoft Research now has not one but two quantum computing research groups: theres Station Q in Santa Barbara, directed by Michael Freedman, which pursues topological quantum computing, but theres also QuArC in Redmond, directed by Krysta Svore, which studies things like quantum circuit synthesis.
Anyway, Ive got two videos for your viewing pleasure:

An interview about quantum computing with me, Krysta Svore, and Matthias Troyer, moderated by Chris Cashman, and filmed in a studio where they put makeup on your face. Just covers the basics.
A session about quantum computing, with three speakers: me about what quantum mechanics is good for (quantum algorithms, money, crypto, and certified random numbers), then Charlie Marcus about physical implementations of quantum computing, and finally Matthias Troyer about his groups experiments on the D-Wave machines. (You can also download my slides here.)

This visit really drove home for me that MSR is the closest thing that exists today to the old Bell Labs: a corporate lab that does a huge amount of openly-published, high-quality fundamental research in math and CS, possibly more than all the big Silicon-Valley-based companies combined. This research might or might not be good for Microsofts bottom line (Microsoft, of course, says that it is, and Id like to believe them), but its definitely good for the world. With the news of Microsofts reorganization in the background, I found myself hoping that MS will remain viable for a long time to come, if only because its decline would leave a pretty gaping hole in computer science research.
Unfortunately, last week I also bought a new laptop, and had the experience of PowerPoint 2013 first refusing to install (it mistakenly thought it was already installed), then crashing twice and losing my data, and just generally making everything (even saving a file) harder than it used to be for no apparent reason. Yes, thats correct: the preparations for my talk at the Microsoft Faculty Summit were repeatedly placed in jeopardy by the new and improved Microsoft Office. So not just for its own sake, but for the sake of computer science as a whole, I implore Microsoft to build a better Office. It shouldnt be hard: it would suffice to re-release the 2003 or 2007 versions as Office 2014! If Mr. Gates took a 2-minute break from curing malaria to call his former subordinates and tell them to do that, Id really consider him a great humanitarian.Three announcements

1. As many of you probably know, this week my EECS colleague Hal Abelson released his 180-page report on MITs involvement in the Aaron Swartz case. I read the whole thing, and I recommend it if you have any interest in the case. My take is that, far from being the whitewash that some people described it as, the report (if you delve into it) clearly and eloquently explains how MIT failed to live up to its own standards, even as it formally followed the rules. The central insight here is that the world expects MIT to behave, not like some other organization would behave if someone hid a laptop in its supply closet to download the whole JSTOR database, insulted and then tried to flee from its security officers when questioned, etc. etc., but rather with perspective and imaginationworrying less about the security of its facilities than about the future of the world. People expect MIT, of all places, to realize that the sorts of people who pull these sorts of shenanigans in their twenties sometimes become Steve Jobs or Richard Feynman (or for that matter, MIT professor Robert Morris) later in their lives, and therefore to speak up in their defense. In retrospect, I wish Swartzs arrest had sparked a debate about the wider issues among MITs students, faculty, and staff. I think its likely that such a debate would have led to pressure on the administration to issue a statement in Swartzs support. As it was (and as I pointed out in this interview), most people at MIT, even if theyd read about the arrest, werent even aware of the issues continued existence, let alone of MITs continued role in it, until after Swartz had already committed suicide. For the MIT communitywhich includes some prominent supporters of open accessto have played such a passive role is one of the many tragedies thats obvious with hindsight.
2. Shafi Goldwasser has asked me to announce that the fifth Innovations in Theoretical Computer Science (ITCS) conference will be held in Princeton, a town technically in New Jersey, on January 12-14, 2014. Heres the conference website; if you want to submit a paper, the deadline is coming up soon, on Thursday, August 22.
3. As the summer winds to a close, Im proud to announce my main goals for the upcoming academic year. Those goals are the following:
(a) Take care of Lily.
(b) Finish writing up old papers.
It feels liberating to have no higher aspirations for an entire yearand for the aspirations I have to seem so modest and so achievable. On the other hand, it will be all the more embarrassing if I fail to achieve even these goals.Quantum Computing Since Democritus Lecture 5: Paleocomplexity

From my inbox:
We simple folk out in the cold wastes of the internet are dying the slow and horrible death of intellectual starvation.  Only you can save us, by posting the next installment of your lecture notes before we shuffle off this mortal coil.  Will you help us, or will you say Let them read slashdot?  Ok, seriously, I know youre busy.  Just wanted to make sure you knew people are enjoying the lecture notes.
And from my comments section:
You know youve made it, and then lost it, when you no longer publish notes on your course 
Alright, alright, alright, alright, alright.  Now that Ive returned from my two-week world concert tour (which took me to Innsbruck, London, Yale, and U. of Toronto), and now that my girlfriend and I have settled into a lovely new apartment (complete with silverware, shower curtains, and a giant poster of complexity class inclusions above the fireplace), I finally have some time to resume your regularly-scheduled programming.
So wont you join me, as I attempt to excavate the strange forgotten world of paleocomplexity, and relive an age when STOC and FOCS were held in caves and Diagonalosaurs ruled the earth?The SuperScott and Morgan Freeman FAQ

Update (Sept. 3): When I said that about 5000 steps are needed for the evolutionary approach to color an 88 chessboard, I was counting as a step any examination of two random adjacent squaresregardless of whether or not you end up having to change one of the colors. If you count only the changes, then the expected number goes down to about 1000 (which, of course, only makes the point about the power of the evolutionary approach stronger). Thanks very much to Raymond Cuenen for bringing this clarification to my attention.

Last week I appeared on an episode of Through the Wormhole with Morgan Freeman, a show on the Science Channel. (See also here for a post on Morgan Freemans Facebook page.) The episode is called Did God Create Evolution? The first person interviewed is the Intelligent Design advocate Michael Behe. But not to worry! After him, they have a parade of scientists who not only agree that Chuck Darwin basically had it right in 1859, but want to argue for that conclusion using ROBOTS! and MATH!
So, uh, thats where I come in. My segment features me (or rather my animated doppelgnger, SuperScott) trying to color a chessboard two colors, so that no two neighboring squares are colored the same, using three different approaches: (1) an intelligent design approach (which computer scientists would call nondeterminism), (2) a brute-force, exhaustive enumeration approach, and (3) an evolutionary local search approach.
[Spoiler alert: SuperScott discovers that the local search approach, while not as efficient as intelligent design, is nevertheless much more efficient than brute-force search. And thus, he concludes, the arguments of the ID folks to the effect of I cant see a cleverer way to do it, therefore it must be either brute-force search or else miraculous nondeterminism are invalid.]
Since my appearance together with Morgan Freeman on cable TV raises a large number of questions, Ive decided to field a few of them in the following FAQ.
Q: How can I watch?
Amazon Instant Video has the episode here for $1.99. (No doubt you can also find it on various filesharing sites, but let it be known that Id never condone such nefarious activity.) My segment is roughly from 10:40 until 17:40.
Q: Given that youre not a biologist, and that your research has basically nothing to do with evolution, why did they ask to interview you?
Apparently they wanted a mathematician or computer scientist who also had some experience spouting about Big Ideas. So they first asked Greg Chaitin, but Chaitin couldnt do it and suggested me instead.
Q: Given how little relevant expertise you have, why did you agree to be interviewed?
To be honest, I was extremely conflicted. I kept saying, Why dont you interview a biologist? Or at least a computational biologist, or someone who studies genetic algorithms? They replied that they did have more bio-oriented people on the show, but they also wanted me to provide a mathematical perspective. So, I consulted with friends like Sean Carroll, whos appeared on Through the Wormhole numerous times. And after reflection, I decided that I do have a way to explain a central conceptual point about algorithms, complexity, and the amount of time needed for natural selectiona point that, while hardly novel, is something that many laypeople might not have seen before and that might interest them. Also, as an additional argument in favor of appearing, MORGAN FREEMAN!

So I agreed to do it, but only under two conditions:
(1) At least one person with a biology background would also appear on the show, to refute the arguments of intelligent design.
(2) I would talk only about stuff that I actually understood, like the ability of local search algorithms to avoid the need for brute-force search.
Ill let you judge for yourself to what extent these conditions were fulfilled.
Q: Did you get to meet Morgan Freeman?
Alas, no. But at least I got to hear him refer repeatedly to SuperScott on TV.
Q: What was the shooting like?
Extremely interesting. I know more now about TV production than I did before!
It was a continuing negotiation: they kept wanting to say that I was on a quest to mathematically prove evolution (or something like that), and I kept telling them they werent allowed to say that, or anything else that would give the misleading impression that what I was saying was either original or directly related to my research. I also had a long discussion about the P vs. NP problem, which got cut for lack of time (now P and NP are only shown on the whiteboard). On the other hand, the crew was extremely accommodating: they really wanted to do a good job and to get things right.
The most amusing tidbit: I knew that local search would take O(n4) time to 2-color an nxn chessboard (2-coloring being a special case of 2SAT, to which Schnings algorithm applies), but I didnt know the constant. So I wrote a program to get the specific number of steps when n=8 (its about 5000). I then repeatedly modified and reran the program during the taping, as we slightly changed what we were talking about. It was the first coding Id done in a while.
Q: How much of the segment was your idea, and how much was theirs?
The chessboard was my idea, but the SuperScott bit was theirs. Luddite that I am, I was just going to get down on hands and knees and move apples and oranges around on the chessboard myself.
Also, they wanted me to speak in front of a church in Boston, to make a point about how many people believe that God created the universe. I nixed that idea and said, why not just do the whole shoot in the Stata Center? I mean, MIT spent $300 million just to make the building where I work as visually arresting as possibleat the expense of navigability, leakage-resilience, and all sorts of other criteriaso why not take advantage of it? Plus, that way Ill be able to crack a joke about how Stata actually looks like it was created by that favorite creationist strawman, a tornado passing through a junkyard.
Needless to say, all the stuff with me drawing complexity class inclusion diagrams on the whiteboard, reading my and Alex Arkhipovs linear-optics paper, walking around outside with an umbrella, lifting the umbrella to face the camera dramaticallythat was all just the crew telling me what to do. (Well, OK, they didnt tell me what to write on the whiteboard or view on my computer, just that it should be something sciencey. And the umbrella thing wasnt planned: it really just happened to be raining that day.)
Q: Dont you realize that not a word of what you said was newindeed, that all you did was to translate the logic of natural selection, which Darwin understood in 1859, into algorithms and complexity language?
Yes, of course, and Im sorry if the show gave anyone the impression otherwise. I repeatedly begged them not to claim newness or originality for anything I was saying. On the other hand, one shouldnt make the mistake of assuming that whats obvious to nerds who read science blogs is obvious to everyone else: I know for a fact that it isnt.
Q: Dont you understand that you cant prove mathematically that evolution by natural selection is really what happened in Nature?
Of course! You cant even prove mathematically that bears crap in the woods (unless crapping in the woods were taken as part of the definition of bears). To the writers credit, they did have Morgan Freeman explain that I wasnt claiming to have proved evolution. Personally, I wish Freeman had gone even furtherto say that, at present, we dont even have mathematical theories that would explain from first principles why 4 billion years is a reasonable amount of time for natural selection to have gotten from the primordial soup to humans and other complex life, whereas (say) 40 million years is not a reasonable amount. One could imagine such theories, but we dont really have any. What we do have is (a) the observed fact that evolution did happen in 4 billion years, and (b) the theory of natural selection, which explains in great detail why ones initial intuitionthat such evolution cant possibly have happened by blind, chance natural processes aloneis devoid of force.
Q: Watching yourself presented in such a goony wayscribbling Complicated Math Stuff on a whiteboard, turning dramatically toward the camera, etc. etc.didnt you feel silly?
Some of itis silly, no two ways about it! On the other hand, I feel satisfied that I got across at least one correct and important scientific point to hundreds of thousands of people. And that, one might argue, is sufficiently worthwhile that it should outweigh any embarrassment about how goofy I look.Mistake of the Week: X works on paper, but not in the real world

Time again for Shtetl-Optimizeds Mistake of the Week series!  This week my inspiration comes from a paper thats been heating up the quantum blogosphere (the Blochosphere?): Is Fault-Tolerant Quantum Computation Really Possible? by M. I. Dyakonov.  Ill start by quoting my favorite passages:
The enormous literature devoted to this subject (Google gives 29300 hits for fault-tolerant quantum computation) is purely mathematical.  It is mostly produced by computer scientists with a limited understanding of physics and a somewhat restricted perception of quantum mechanics as nothing more than unitary transformations in Hilbert space plus entanglement.
Whenever there is a complicated issue, whether in many-particle physics, climatology, or economics, one can be almost certain that no theorem will be applicable and/or relevant, because the explicit or implicit assumptions, on which it is based, will never hold in reality.
Ill leave the detailed critique of Dyakonovs paper to John Preskill, the Pontiff, and other computer scientists who understand the fault-tolerance theorem much better than a mere physicist like me.  Here I instead want to take issue with an idea that surfaces again and again in Dyakonovs paper, is almost universally accepted, but is nevertheless false.  The idea is this: that its possible for a theory to work on paper but not in the real world.
The proponents of this idea go wrong, not in thinking that a theory can fail in the real world, but in thinking that if it fails, then the theory can still work on paper. If a theory claims to describe a phenomenon but doesnt, then the theory doesnt work, period  neither in the real world nor on paper.  In my view, the refrain that something works on paper but not in the real world serves mainly as an intellectual crutch: a way for the lazy to voice their opinion that something feels wrong to them, without having to explain how or  where its wrong.
Ah, you say, but theorists often make assumptions that dont hold in the real world!  Yes, but youre sidestepping the key question: did the theorists state their assumptions clearly or not?  If they didnt, then the fault lies with them; if they did, then the fault lies with those practitioners who would milk a nonspherical cow like a spherical one.
To kill a theory (in the absence of direct evidence), you need to pinpoint which of its assumptions are unfounded and why.  You dont become more convincing by merely finding more assumptions to criticize; on the contrary, the hope something sticks approach usually smacks of desperation:
Theres no proof that the Earths temperature is rising, but even if there was, theres no proof that humans are causing it, but even if there was, theres no proof that its anything to worry about, but even there was, theres no proof that we can do anything about it, but even if there was, its all just a theory anyway!
As should be clear, just a theory is not a criticism: its a kvetch.
Marge: I really think this is a bad idea.
Homer: Marge, I agree with you  in theory.  In theory, communism works.  In theory.
Actually, lets look at Homers example of communism, since nothing could better illustrate my point.  When people say that communism works in theory, they presumably mean that it works if everyone is altruistic.  But regulating selfishness is the whole problem political systems are supposed to solve in the first place!  Any political system that defines the problem away doesnt work on paper, any more than Call a SAT oracle works on paper as a way to solve NP-complete problems.  Once again, we find the real world / paper distinction used as a cover for intellectual laziness.
Let me end this rant by preempting the inevitable clich that in theory, theres no difference between theory and practice; in practice, there is.  Behold my unanswerable retort:
In theory, theres no difference between theory and practice even in practice.Quantum Computing Since Democritus Lecture 6: P, NP, and Friends

P, NP, and Friends.  A whole undergraduate complexity course in one HTML file.
For those of you who already know this stuff: forgive me for boring you.  For those who dont: read, learn, and join the Enlightened.
Note: The comment section was down all day, but its back now.  Google ought to be ashamed to be running something as rickety and unreliable as Blogger.  Well, I guess you get what you pay for.Einstein the man

Sorry for the inordinate delay in updating!  This weekend I was busy with several things, one of which was EinsteinFest, Perimeter Institutes celebration of the hundred-year anniversary of Einsteins annus mirabilis. The Fest is a monthlong program of exhibits, talks, etc., aimed at the general public, and covering four topics: The Science, The Times, The Man, The Legacy. This weekends talks were about The Man, which is why I attended.
See, I was worried that the Fest would place too much emphasis on Einstein the sockless symbol of scientific progress, Einstein the secular saint, Einstein the posthumous salesman for Perimeter Institute. And how it could do that without indulging in the very pomposity that Einstein himself detested?
My fears were not assuaged by the many exhibits devoted to Freud, Picasso, the Wright Brothers, the automobile, fashion at the turn of the century, and so on. These exhibits gave visitors the impression of a great band of innovators marching into the future, with Einstein cheerfully in front. The reality, of course, is that Einstein never marched in anyones band, and  like his friend Gdel  saw himself as opposed to the main intellectual currents of the time.
It didnt help either that, to handle the influx of visitors, Perimeter has basically transformed itself into Relativistic Disney World  complete with tickets, long lines, guides wearing uniforms, signs directing traffic, cordoned-off areas, and an outdoor tent for kids called Physica Fantastica. To some extent I guess this was unavoidable, although sometimes it resulted in unintended comedy:

(Sorry, I just bought a digital camera and couldnt resist.)
So it was a pleasure to attend the talks on Einstein the Man and find that, in spite of everything, they were fantastic. We heard David Rowe on Einstein and politics, Trevor Lipscombe on Einstein and Mileva, and John Dawson on Einstein and Gdel. Partly these speakers won me over with wisecracks (Dawson: Gdel thought hed found a flaw in the Constitution, by which the US could legally turn into a dictatorship. In light of recent events, I dont see why anyone would doubt him). But mostly they just let the old man speak for himself. We saw Einstein write the following to his then-mistress Elsa:
If you were to recite the most beautiful poem ever so divinely, the joy I would derive from it would not come close to the joy I experienced when I received the mushrooms and goose cracklings you cooked.
And to Mileva, during the months when he was finishing general relativity:
You will see to it: (1) that my clothes and linen are kept in order; (2) that I am served three regular meals a day in my room; (3) that my bedroom and study are always kept in good order and that my desk is not touched by anyone other than me.
We saw Einstein the pacifist urging the Allies to rearm at once against Hitler, and Einstein the secular internationalist supporting the creation of Israel. And eventually we came to understand that this was not an oracle spouting wisdom from God; it was just a guy with a great deal of common sense  as much common sense as anyones ever had. Isnt it strange that, despite deserving to be celebrated, he is?Twitl-Optimized

Today I experiment with tweeting: writing <=140-character announcements, but posting them to my blog. Like sending lolcat videos by mail
Last week at QCrypt in Waterloo: http://2013.qcrypt.net This week at CQIQC in Toronto: http://tinyurl.com/kfexzv6 Back with Lily in between
While we debate D-Wave, ID Quantique et al. quietly sold ~100 quantum crypto devices. Alas, market will remain small unless RSA compromised
One speaker explained how a photon detector works by showing this YouTube video: http://tinyurl.com/k8x4btx Couldnt have done better
Luca Trevisan asks me to spread the word about a conference for LGBTs in technology: www.outforundergrad.org/technology
Steven Pinker stands up for the Enlightenment in The New Republic: Science Is Not Your Enemy http://tinyurl.com/l26ppaf
Think Pinker was exaggerating? Read Leon Wieseltiers defiantly doofusy Brandeis commencement speech: http://tinyurl.com/jwhj8ub
Black-hole firewalls make the New York Times, a week before the firewall workshop at KITP (Ill be there): http://tinyurl.com/kju9crj
You probably already saw the Schrodinger cat Google doodle: http://tinyurl.com/k8et44p For me, the ket was much cooler than the cat
While working on BosonSampling yesterday, (1/6)pi^2 and Euler-Mascheroni constant made unexpected unappearances. What I live forFirewalls

Updates (Aug. 29): John Preskill now has a very nice post summarizing the different views on offer at the firewall workshop, thereby alleviating my guilt for giving you only the mess below. Thanks, John!
And if you check out Johns Twitter feed (which you should), youll find another, unrelated gem: a phenomenal TEDx talk on quantum computing by my friend, coauthor, and hero, the Lowerboundsman of Latvia, Andris Ambainis. (Once again, when offered a feast of insight to dispel their misconceptions and ennoble their souls, the YouTube commenters are distinguishing themselves by focusing on the speakers voice.Been there, man, been there.)

So, last week I was at the Fuzzorfire workshop at the Kavli Institute for Theoretical Physics in Santa Barbara, devoted to the black hole firewall paradox. (The workshop is still going on this week, but I needed to get back early.) For some background:

The original paper by Almheiri et al. (from July 2012, so now ancient history)
New York Times article by Dennis Overbye
Quanta article by Jennifer Ouellette
Blog post by John Preskill

I had fantasies of writing a long, witty blog post that would set out my thoughts about firewalls, full of detailed responses to everything Id heard at the conference, as well as ruminations about Harlow and Haydens striking argument that computational complexity might provide a key to resolving the paradox. But the truth is, Im recovering from a nasty stomach virus, am feeling firewalled out, and wish to use my few remaining non-childcare hours before the semester starts to finish writing papers. So I decided that better than nothing would be a hastily-assembled pastiche of links.
First and most important, you can watch all the talks online. In no particular order:

My talk (about the computational complexity underpinnings of the Harlow-Hayden argument)
Stephen Hawkings 10-minute talk by videoconference, denying that firewalls form, and basically repeating his position from his black hole bet concession speech of 2004 (I confess that I dont really understand his arguments)
Lenny Susskinds ER=EPR talk
Bill Unruhs entertaining talk denouncing the other participants obsession with unitarity, and defending what he sees as the simplest solution to all the black hole information problems: information dropped into a black hole is simply gone forever, buh-bye!
All the other talks

Heres my own attempt to summarize whats at stake, adapted from a comment on Peter Woits blog (see also a rapid response by Lubos):
As I understand it, the issue is actually pretty simple. Do you agree that
 (1) the Hawking evaporation process should be unitary, and
 (2) the laws of physics should describe the experiences of an infalling observer, not just those of an observer who stays outside the horizon?
 If so, then you seem forced to accept
 (3) the interior degrees of freedom should just be some sort of scrambled re-encoding of the exterior degrees, rather than living in a separate subfactor of Hilbert space (since otherwise wed violate unitarity).
 But then we get
 (4) by applying a suitable unitary transformation to the Hawking radiation of an old enough black hole before you jump into it, someone ought to be able, in principle, to completely modify what you experience when you do jump in. Moreover, that person could be far away from youan apparent gross violation of locality.
So, there are a few options: you could reject either (1) or (2). You could bite the bullet and accept (4). You could say that the experience of an infalling observer should just be to die immediately at the horizon (firewalls). You could argue that for some reason (e.g., gravitational backreaction, or computational complexity), the unitary transformations required in (4) are impossible to implement even in principle. Or you could go the Lubosian route, and simply assert that the lack of any real difficulty is so obvious that, if you admit to being confused, then that just proves youre an idiot. AdS/CFT is clearly relevant, but as Polchinski pointed out, it does surprisingly little to solve the problem.
Now, what Almheiri et al. (AMPS) added to the simple logical argument above was really to make the consequence (4) more concrete and vividby describing something that, in principle, someone could actually do to the Hawking radiation before jumping in, such that after you jumped in, if there wasnt anything dramatic that happenedsomething violating local QFT and the equivalence principlethen youd apparently observe a violation of the monogamy of entanglement, a basic principle of quantum mechanics. Im sure the bare logic (1)-(4) was known to many people before AMPS: I certainly knew it, but I didnt call it a paradox, I just called it I dont understand black hole complementarity!
 At any rate, thinking about the Hawking radiation decoding problem already led me to some very nice questions in quantum computing theory, which remain interesting even if you remove the black hole motivation entirely. And that helped convince me that something new and worthwhile might indeed come out of this business, despite how much fun it is. (Hopefully whatever does come out wont be as garbled as Hawking radiation.)
For continuing live updates from the workshop, check out John Preskills Twitter feed.
Or you can ask me to expand on various things in the comments, and Ill do my best. (As I said in my talk, while Im not sure that the correct quantum description of the black hole interior is within anyones professional expertise, its certainly outside of mine! But I do find this sort of thing fun to think abouthow could I not?)
Unrelated, but also of interest: check out an excellent article in Quanta by Erica Klarreich, about the recent breakthroughs by Reichardt-Unger-Vazirani, Vazirani-Vidick, and others on classical command of quantum systems.My googol rank

According to my usage statistics, of the people who come to scottaaronson.com via a search engine, about 5% do so by typing in one of the following queries:
biggest number in the world
the biggest number in the world
what is the largest number
largest number in the world
what is the biggest number
These people are then led to my big numbers essay, which presumably befuddles them even more.
So, let me satisfy the publics curiosity once and for all: the biggest number in the world is a million billion gazillion.  But stay tuned: even as I write, Space Shuttle astronauts are combing the galaxy for an even bigger number!NSA: Possibly breaking US laws, but still bound by laws of computational complexity

Update (Sept. 9): Reading more about these things, and talking to friends who are experts in applied cryptography, has caused me to do the unthinkable, and change my mind somewhat. I now feel that, while the views expressed in this post were OK as far as they went, they failed to do justice to the  complexity (har, har) of whats at stake. Most importantly, I didnt clearly explain that theres an enormous continuum between, on the one hand, a full break of RSA or Diffie-Hellman (which still seems extremely unlikely to me), and on the other, pure side-channel attacks involving no new cryptanalytic ideas. Along that continuum, there are many plausible places where the NSA might be. For example, imagine that they had a combination of side-channel attacks, novel algorithmic advances, and sheer computing power that enabled them to factor, lets say, ten 2048-bit RSA keys every year. In such a case, it would still make perfect sense that theyd want to insert backdoors into software, sneak vulnerabilities into the standards, and do whatever else it took to minimize their need to resort to such expensive attacks. But the possibility of number-theoretic advances well beyond what the open world knows certainly wouldnt be ruled out. Also, as Schneier has emphasized, the fact that NSA has been aggressively pushing elliptic-curve cryptography in recent years invites the obvious speculation that they know something about ECC that the rest of us dont.
And that brings me to a final irony in this story. When a simpleminded complexity theorist like me hears his crypto friends going on and on about the latest clever attack that still requires exponential time, but that puts some of the keys in current use just within reach of gigantic computing clusters, his first instinct is to pound the table and shout: well then, so why not just increase all your key sizes by a factor of ten? Sweet Jesus, the asymptotics are on your side! if you saw a killer attack dog on a leash, would you position yourself just outside what you guesstimated to be the leashs radius? why not walk a mile away, if you can? The crypto experts invariably reply that its a lot more complicated than I realize, because standards, and efficiency, and smartphones  and before long I give up and admit that Im way out of my depth.
So its amusing that one obvious response to the recent NSA revelationsa response that sufficiently-paranoid people, organizations, and governments might well actually take, in practiceprecisely matches the nave complexity-theorist intuition. Just increase the damn key sizes by a factor of ten (or whatever).
Another Update (Sept. 20): In my original posting, I should also have linked to Matthew Greens excellent post. My bad.

Last week, I got an email from a journalist with the following inquiry. The recent Snowden revelations, which made public for the first time the US governments black budget, contained the following enigmatic line from the Director of National Intelligence: We are investing in groundbreaking cryptanalytic capabilities to defeat adversarial cryptography and exploit internet traffic. So, the journalist wanted to know, what could these groundbreaking capabilities be? And in particular, was it possible that the NSA was buying quantum computers from D-Wave, and using them to run Shors algorithm to break the RSA cryptosystem?
I replied that, yes, thats possible, but only in the same sense that its possible that the NSA is using the Easter Bunny for the same purpose. (For one thing, D-Wave themselves have said repeatedly that they have no interest in Shors algorithm or factoring. Admittedly, I guess thats what D-Wave would say, were they making deals with NSA on the sly! But its also what the Easter Bunny would say.) More generally, I said that if the open scientific worlds understanding is anywhere close to correct, then quantum computing might someday become a practical threat to cryptographic security, but it isnt one yet.
That, of course, raised the extremely interesting question of what groundbreaking capabilities the Director of National Intelligence was referring to. I said my personal guess was that,with ~99% probability, he meant various implementation vulnerabilities and side-channel attacksthe sort of thing that we know has compromised deployed cryptosystems many times in the past, but where its very easy to believe that the NSA is ahead of the open world. With ~1% probability, I guessed, the NSA made some sort of big improvement in classical algorithms for factoring, discrete log, or other number-theoretic problems. (I wouldve guessed even less than 1% probability for the latter, before the recent breakthrough by Joux solving discrete log in fields of small characteristic in quasipolynomial time.)
Then, on Thursday, a big New York Times article appeared, based on 50,000 or so documents that Snowden leaked to the Guardian and that still arent public. (See also an important Guardian piece by security expert Bruce Schneier, and accompanying Q&A.) While a lot remains vague, there might be more public information right now about current NSA cryptanalytic capabilities than theres ever been.
So, how did my uninformed, armchair guesses fare? Its only halfway into the NYT article that we start getting some hints:
The files show that the agency is still stymied by some encryption, as Mr. Snowden suggested in a question-and-answer session on The Guardians Web site in June.
Properly implemented strong crypto systems are one of the few things that you can rely on, he said, though cautioning that the N.S.A. often bypasses the encryption altogether by targeting the computers at one end or the other and grabbing text before it is encrypted or after it is decrypted
Because strong encryption can be so effective, classified N.S.A. documents make clear, the agencys success depends on working with Internet companies  by getting their voluntary collaboration, forcing their cooperation with court orders or surreptitiously stealing their encryption keys or altering their software or hardware
Simultaneously, the N.S.A. has been deliberately weakening the international encryption standards adopted by developers. One goal in the agencys 2013 budget request was to influence policies, standards and specifications for commercial public key technologies, the most common encryption method.
Cryptographers have long suspected that the agency planted vulnerabilities in a standard adopted in 2006 by the National Institute of Standards and Technology and later by the International Organization for Standardization, which has 163 countries as members.
Classified N.S.A. memos appear to confirm that the fatal weakness, discovered by two Microsoft cryptographers in 2007, was engineered by the agency. The N.S.A. wrote the standard and aggressively pushed it on the international group, privately calling the effort a challenge in finesse.
So, in pointing to implementation vulnerabilities as the most likely possibility for an NSA breakthrough, I might have actually erred a bit too far on the side of technological interestingness. It seems that a large part of what the NSA has been doing has simply been strong-arming Internet companies and standards bodies into giving it backdoors. To put it bluntly: sure, if it wants to, the NSA can probably read your email. But that isnt mathematical cryptographys faultany more than it would be mathematical cryptos fault if goons broke into your house and carted away your laptop. On the contrary, properly-implemented, backdoor-less strong crypto is something that apparently scares the NSA enough that they go to some lengths to keep it from being widely used.
I should add that, regardless of how NSA collects all the private information it doesby beating crypto in a fair fight (!) or, more likely, by exploiting backdoors that it itself installedthe mere fact that it collects so much is of course unsettling enough from a civil-liberties perspective. So Im glad that the Snowden revelations have sparked a public debate in the US about how much surveillance we as a society want (i.e., the balance between preventing 9/11 and preventing Orwell), what safeguards are in place to prevent abuses, and whether those safeguards actually work. Such a public debate is essential if were serious about calling ourselves a democracy.
At the same time, to me, perhaps the most shocking feature of the Snowden revelations is just how unshocking theyve been. So far, I havent seen anything that shows the extent of NSAs surveillance to be greater than what I wouldve considered plausible a priori. Indeed, the following could serve as a one-sentence summary of what weve learned from Snowden:
Yes, the NSA is, in fact, doing the questionable things that anyone not living in a cave had long assumed they were doingthat assumption being so ingrained in nerd culture that countless jokes are based around it.
(Come to think of it, people living in caves might have been even more certain that the NSA was doing those things. Maybe thats why they moved to caves.)
So, rather than dwelling on civil liberties, national security, yadda yadda yadda, let me move on to discuss the implications of the Snowden revelations for something that really matters: a 6-year-old storm in theoretical computer sciences academic teacup. As many readers of this blog might know, Neal Koblitza respected mathematician and pioneer of elliptic curve cryptography, who (from numerous allusions in his writings) appears to have some connections at the NSA (on reflection, this is unfair to Koblitz; he does reportconversations with NSA people in his writings, but has never had any financial connection with NSA)published a series of scathing articles, in the Notices of the American Mathematical Society and elsewhere, attacking the theoretical computer science approach to cryptography. Koblitzs criticisms were varied and entertainingly-expressed: the computer scientists are too sloppy, deadline-driven, self-promoting, and corporate-influenced; overly trusting of so-called security proofs (a term they shouldnt even use, given how many errors and exaggerated claims they make); absurdly overreliant on asymptotic analysis; bodacious in introducing dubious new hardness assumptions that they then declare to be standard; and woefully out of touch with cryptographic realities. Koblitz seemed to suggest that, rather than demanding the security reductions so beloved by theoretical computer scientists, people would do better to rest the security of their cryptosystems on two alternative pillars: first, standards set by organizations like the NSA with actual real-world experience; and second, the judgments of mathematicians with taste and experience, who can just see whats likely to be vulnerable and what isnt.
Back in 2007, my mathematician friend Greg Kuperberg pointed out the irony to me: here we had a mathematician, lambasting computer scientists for trying to do for cryptography what mathematics itself has sought to do for everything since Euclid! That is, when you see an unruly mess of insights, related to each other in some tangled way, systematize and organize it. Turn the tangle into a hierarchical tree (or dag). Isolate the minimal assumptions (one-way functions? decisional Diffie-Hellman?) on which each conclusion can be based, and spell out all the logical steps needed to get from here to thereeven if the steps seem obvious or boring. Any time anyone has tried to do that, its been easy for the natives of the unruly wilderness to laugh at the systematizing newcomers: the latter often know the terrain less well, and take ten times as long to reach conclusions that are ten times less interesting. And yet, in case after case, the clarity and rigor of the systematizing approach has eventually won out. So it seems weird for a mathematician, of all people, to bet against the systematizing approach when applied to cryptography.
The reason Im dredging up this old dispute now, is that I think the recent NSA revelations might put it in a slightly new light. In his articlewhose main purpose is to offer practical advice on how to safeguard ones communications against eavesdropping by NSA or othersBruce Schneier offers the following tip:
Prefer conventional discrete-log-based systems over elliptic-curve systems; the latter have constants that the NSA influences when they can.
Here Schneier is pointing out a specific issue with ECC, which would be solved if we could merely ensure that NSA or other interested parties werent providing input into which elliptic curves to use. But I think theres also a broader issue: that, in cryptography, its unwise to trust any standard because of the prestige, real-world experience, mathematical good taste, or whatever else of the people or organizations proposing it. What was long a plausible conjecturethat the NSA covertly influences cryptographic standards to give itself backdoors, and that otherwise-inexplicable vulnerabilities in deployed cryptosystems are sometimes there because the NSA wanted them therenow looks close to an established fact. In cryptography, then, its not just for idle academic reasons that youd like a publicly-available trail of research papers and source code, open to criticism and improvement by anyone, that takes you all the way from the presumed hardness of an underlying mathematical problem to the security of your system under whichever class of attacks is relevant to you.
Schneiers final piece of advice is this: Trust the math. Encryption is your friend.
Trust the math. On that note, heres a slightly-embarrassing confession. When Im watching a suspense movie (or a TV show like Homeland), and I reach one of those nail-biting scenes where the protagonist discovers that everything she ever believed is a lie, I sometimes mentally recite the proof of the Karp-Lipton Theorem. It always calms me down. Even if the entire universe turned out to be a cruel illusion, it would still be the case that NP  P/poly would collapse the polynomial hierarchy, and I can tell you exactly why. It would likewise be the case that you couldnt break the GGM pseudorandom function without also breaking the underlying pseudorandom generator on which its based. Math could be defined as that which can still be trusted, even when you cant trust anything else.My daily dose of depression

Yesterdays Times ran an essay by Steve Lohr, based on speeches about the future of computing given by my former teachers Richard Karp and Jon Kleinberg.  Though most of the essay is welcome and unobjectionable, lets look at the first two paragraphs:
Computer science is not only a comparatively young field, but also one that has had to prove it is really science. Skeptics in academia would often say that after Alan Turing described the concept of the universal machine in the late 1930s  the idea that a computer in theory could be made to do the work of any kind of calculating machine, including the human brain  all that remained to be done was mere engineering.
The more generous perspective today is that decades of stunningly rapid advances in processing speed, storage and networking, along with the development of increasingly clever software, have brought computing into science, business and culture in ways that were barely imagined years ago. The quantitative changes delivered through smart engineering opened the door to qualitative changes.
So, here are the two options on offer from the paper of record: either

computer science was finished off by Alan Turing, or
stunningly rapid advances in processing speed, storage and networking have reopened it just recently.

Even among the commenters on this post by Chad Orzel  which Dave Bacon forwarded to me with the subject line bait  awareness of any third possibility seems depressingly rare.  Judging from the evidence, its not that people have engaged the mysteries of P versus NP, randomness and determinism, one-way functions and interactive proofs, and found them insufficiently deep.  Rather, as bizarre as it sounds, its that people dont know these mysteries exist  just as they wouldnt know about black holes or the Big Bang if no one told them.  If you want to understand why our subject  which by any objective standard, has contributed at least as much over the last 30 years as (say) particle physics or cosmology to humankinds basic picture of the universe  receives a whopping $5 million a year from the NSF (with even that in constant danger), look no further.Logicians on safari

Sean Carroll, who many of you know from Cosmic Variance, asked the following question in response to my last entry:
Im happy to admit that I dont know anything about one-way functions and interactive proofs. So, in what sense has theoretical computer science contributed more in the last 30 years to our basic understanding of the universe than particle physics or cosmology? (Despite the fact that Im a cosmologist, I dont doubt your statement  Id just like to be able to explain it in public.)
I posted my response as a comment, but its probably better to make it an entry of its own.  So:
Hi Sean,
Thanks for your question!
Of course I was joking when I mentioned objective standards for ranking scientific fields. Depending on which questions keep you up at night, different parts of humankinds basic picture of the universe will seem larger or smaller.  (To say that, of course, is not to suggest any relativism about the picture itself.)
What I can do, though, is to tell you why  by my own subjective standards  the contributions of theoretical computer science over the last 30 years rival those of theoretical physics or any other field I know about.  Of course, people will say I only think that because Im a theoretical computer scientist, but that gets the causal arrow wrong: I became a theoretical computer scientist because, as a teenager, I thought it!
Its probably best to start with some examples.

We now know that, if an alien with enormous computational powers came to Earth, it could prove to us whether White or Black has the winning strategy in chess. To be convinced of the proof, we would not have to trust the alien or its exotic technology, and we would not have to spend billions of years analyzing one move sequence after another. Wed simply have to engage in a short conversation with the alien about the sums of certain polynomials over finite fields.
Theres a finite (and not unimaginably-large) set of boxes, such that if we knew how to pack those boxes into the trunk of your car, then wed also know a proof of the Riemann Hypothesis. Indeed, every formal proof of the Riemann Hypothesis with at most (say) a million symbols corresponds to some way of packing the boxes into your trunk, and vice versa. Furthermore, a list of the boxes and their dimensions can be feasibly written down.
Supposing you do prove the Riemann Hypothesis, its possible to convince someone of that fact, without revealing anything other than the fact that you proved it. Its also possible to write the proof down in such a way that someone else could verify it, with very high confidence, having only seen 10 or 20 bits of the proof.
If every second or so your computers memory were wiped completely clean, except for the input data; the clock; a static, unchanging program; and a counter that could only be set to 1, 2, 3, 4, or 5, it would still be possible (given enough time) to carry out an arbitrarily long computation  just as if the memory werent being wiped clean each second. This is almost certainly not true if the counter could only be set to 1, 2, 3, or 4. The reason 5 is special here is pretty much the same reason its special in Galois proof of the unsolvability of the quintic equation.
It would be great to prove that RSA is unbreakable by classical computers.  But every known technique for proving that would, if it worked, simultaneously give an algorithm for breaking RSA!  For example, if you proved that RSA with an n-bit key took n5 steps to break, you wouldve discovered an algorithm for breaking it in 2n^1/5 steps. If you proved that RSA took 2n^1/3 steps to break, you wouldve discovered an algorithm for breaking it in n(log n)^2 steps.  As you show the problem to be harder, you simultaneously show it to be easier.

Alright, let me stop before I get carried away. The examples Ive listed (and hundreds more like them) are not exactly discoveries about physics, but they dont have the flavor of pure math either. And even if they have some practical implications for computing (which they do), they certainly dont have the flavor of nitty-gritty software engineering.
So what are they then? Maybe its helpful to think of them as quantitative epistemology: discoveries about the capacities of finite beings like ourselves to learn mathematical truths.  On this view, the theoretical computer scientist is basically a mathematical logician on a safari to the physical world: someone who tries to understand the universe by asking what sorts of mathematical questions can and cant be answered within it.  Not whether the universe is a computer, but what kind of computer it is! Naturally, this approach to understanding the world tends to appeal most to people for whom math (and especially discrete math) is reasonably clear, whereas physics is extremely mysterious.
In my opinion, one of the biggest challenges for our time is to integrate the enormous body of knowledge in theoretical computer science (or quantitative epistemology, or whatever you want to call it) with the rest of what we know about the universe.   In the past, the logical safari mostly stayed comfortably within 19th-century physics; now its time to venture out into the early 20th century.  Indeed, thats exactly why I chose to work on quantum computing: not because I want to build quantum computers (though I wouldnt mind that), but because I want to know what a universe that allows quantum computers is like.
Incidentally, its also why I try hard to keep up with your field.   If Im not mistaken, less than a decade ago cosmologists made an enormous discovery about the capacity of finite beings to learn mathematical truths: namely, that no computation carried out in the physical world can ever involve more than 1/ ~ 10122 bits.
Best,
ScottThe Unitarihedron: The Jewel at the Heart of Quantum Computing

Update (9/24): This parody post was a little like a belch: I felt it build up in me as I read about the topic, I let it out, it was easy and amusing, I dont feel any profound guilt over itbut on the other hand, not one of the crowning achievements of my career. As several commenters correctly pointed out, it may be true that, mostly because of the name and other superficialities, and because of ill-founded speculations about the death of locality and unitarity, the amplituhedron work is currently inspiring a flood of cringe-inducing misstatements on the web. But, even if true, still the much more interesting questions are whats actually going on, and whether or not there are nontrivial connections to computational complexity.
Here I have good news: if nothing else, my belch of a post at least attracted some knowledgeable commenters to contribute excellent questions and insights, which have increased my own understanding of the subject from2 to . See especially this superb comment by David Speyerwhich, among other things, pointed me to a phenomenal quasi-textbook on this subject by Elvang and Huang. My most immediate thoughts:

The amplituhedron is only the latest in a long line of research over the last decadeWitten, Turing biographer Andrew Hodges, and many others have been important playerson how to compute scattering amplitudes more efficiently than by summing zillions of Feynman diagrams. One of the key ideas is to find combinatorial formulas that express complicated scattering amplitudes recursively in terms of simpler ones.
This subject seems to be begging for a computational complexity perspective. When I read Elvang and Huang, I felt like they were working hard not to say anything about complexity: discussing the gains in efficiency from the various techniques they consider in informal language, or in terms of concrete numbers of terms that need to be summed for 1 loop, 2 loops, etc., but never in terms of asymptotics. So if it hasnt been done already, it looks like it could be a wonderful project for someone just to translate whats already known in this subject into complexity language.
On reading about all these modern approaches to scattering amplitudes, one of my first reactions was to feel slightly less guilty about never having learned how to calculate Feynman diagrams! For, optimistically, it looks like some of that headache-inducing machinery (ghosts, off-shell particles, etc.) might be getting less relevant anywaythere being ways to calculate some of the same things that are not only more conceptually satisfying but also faster.


Many readers of this blog probably already saw Natalie Wolchovers Quanta article A Jewel at the Heart of Quantum Physics, which discusses the amplituhedron: a mathematical structure that IAS physicist Nima Arkami-Hamed and his collaborators have recently been investigating. (See also here for Slashdot commentary, here for Luboss take, here for Peter Woits, here for a Physics StackExchange thread, here for Q&A with Pacific Standard, and here for an earlier but closely-related 154-page paper.)
At first glance, the amplituhedron appears to be a way to calculate scattering amplitudes, in the planar limit of a certain mathematically-interesting (but, so far, physically-unrealistic) supersymmetric quantum field theory, much more efficiently than by summing thousands of Feynman diagrams. In which case, you might say: wow, this sounds like a genuinely-important advance for certain parts of mathematical physics! Id love to understand it better. But, given the restricted class of theories it currently applies to, it does seem a bit premature to declare this to be a jewel that unlocks all of physics, or a death-knell for spacetime, locality, and unitarity, etc. etc.
Yet youd be wrong: it isnt premature at all. If anything, the popular articles have understated the revolutionary importance of the amplituhedron. And the reason I can tell you that with such certainty is that, for several years, my colleagues and I have been investigating a mathematical structure that contains the amplituhedron, yet is even richer and more remarkable. I call this structure the unitarihedron.
The unitarihedron encompasses, within a single abstract jewel, all the computations that can ever be feasibly performed by means of unitary transformations, the central operation in quantum mechanics (hence the name). Mathematically, the unitarihedron is an infinite discrete space: more precisely, its an infinite collection of infinite sets, which collection can be organized (as can every set that it contains!) in a recursive, fractal structure. Remarkably, each and every specific problem that quantum computers can solvesuch as factoring large integers, discrete logarithms, and moreoccurs as just a single element, or facet if you will, of this vast infinite jewel. By studying these facets, my colleagues and I have slowly pieced together a tentative picture of the elusive unitarihedron itself.
One of our greatest discoveries has been that the unitarihedron exhibits an astonishing degree of uniqueness. At first glance, different ways of building quantum computerssuch as gate-based QC, adiabatic QC, topological QC, and measurement-based QCmight seem totally disconnected from each other. But today we know that all of those ways, and many others, are merely different projections of the same mysterious unitarihedron.
In fact, the longer Ive spent studying the unitarihedron, the more awestruck Ive been by its mathematical elegance and power. In some way thats not yet fully understood, the unitarihedron knows so much that its even given us new insights about classical computing. For example, in 1991 Beigel, Reingold, and Spielman gave a 20-page proof of a certain property of unbounded-error probabilistic polynomial-time. Yet, by recasting things in terms of the unitarihedron, I was able to give a direct, half-page proof of the same theorem. If you have any experience with mathematics, then youll know that that sort of thing never happens: if it does, its a sure sign that cosmic or even divine forces are at work.
But I havent even told you the most spectacular part of the story yet. While, to my knowledge, this hasnt yet been rigorously proved, many lines of evidence support the hypothesis that the unitarihedron must encompass the amplituhedron as a special case. If so, then the amplituhedron could be seen as just a single sparkle on an infinitely greater jewel.
Now, in the interest of full disclosure, I should tell you that the unitarihedron is what used to be known as the complexity class BQP (Bounded-Error Quantum Polynomial-Time). However, just like the Chinese gooseberry was successfully rebranded in the 1950s as the kiwifruit, and the Patagonian toothfish as the Chilean sea bass, so with this post, Im hereby rebranding BQP as the unitarihedron. For Ive realized that, when it comes to bowling over laypeople, inscrutable complexity class acronyms are deathbut the suffix -hedron is golden.
So, journalists and funders: if youre interested in the unitarihedron, awesome! But be sure to also ask about my other research on the bosonsamplinghedron and the quantum-money-hedron. (Though, in recent months, my research has focused even more on the diaperhedron: a multidimensional, topologically-nontrivial manifold rich enough to encompass all wastes that an 8-month-old human could possibly emit. Well, at least to first-order approximation.)More tender nuggets

You asked for em, you got em.  (Do you want fries with that?)

Suppose a baby is given some random examples of grammatical and ungrammatical sentences, and based on that, it wants to infer the general rule for whether or not a given sentence is grammatical.  If the baby can do this with reasonable accuracy and in a reasonable amount of time, for any regular grammar (the very simplest type of grammar studied by Noam Chomsky), then that baby can also break the RSA cryptosystem.
Oded Regev recently invented a public-key cryptosystem with an interesting property: though its purely classical, his system only known to be secure under the assumption that certain problems are hard for quantum computers.  The upside is that, if these problems are hard for quantum computers, then Regevs system (unlike RSA) is also secure against attack by quantum computers!
Suppose N boys and N girls join a dating service.  We write down an N-by-N matrix, where the (i,j) entry equals 1 if the ith boy and the jth girl are willing to date each other, and 0 if they arent.  We want to know if its possible to pair off every boy and girl with a willing partner.  Heres a simple way to find out: first rescale every row of the matrix to sum to 1.  Then rescale every column to sum to 1.  Then rescale every row, then rescale every column, and so on N5 times.  If at the end of this scaling process, every row and column sum is between 1-1/N and 1+1/N, then its possible to pair off the boys and girls; otherwise it isnt.
If two graphs are isomorphic, then a short and simple proof of that fact is just the isomorphism itself.  But what if two graphs arent isomorphic?  Is there also a short proof of that  one that doesnt require checking every possible way of matching up the vertices?  Under a plausible assumption, we now know that there is such a proof, for any pair of non-isomorphic graphs whatsoever (even with the same eigenvalue spectrum, etc).  Whats the plausible assumption?  It has nothing to do with graphs!  Roughly, its that a certain problem, which is known to take exponential time for any one algorithm, still takes exponential time for any infinite sequence of algorithms.
Suppose we had a small neural network with only three or four layers of neurons between the input and output, where the only thing each neuron could do was to compute the sum of its input signals modulo 2.  We can prove, not surprisingly, that such a neural net would be extremely limited in its power.  Ditto if we replace the 2 by 3, 4, 5, 7, 8, 9, or 11.  But if we replace the 2 by 6, 10, or 12, then we no longer know anything!  For all we know, a three-layer neural network, composed entirely of mod 6 neurons, could solve NP-complete problems in polynomial time.This week, lets overthrow the Taliban

Let this mans face serve as a reminder to all my American friends, to haul your respective asses to your respective polling places with no excuses accepted.  Keep in mind that this year the Democratic voting day is Tuesday November 7th, while the Republican voting day is Wednesday November 8th.
(Me?  I couldnt find a precinct station in Waterloo for some strange reason, so I mailed an absentee ballot back to New Hope, PA.)Five announcements

Update (Oct. 3): OK, a sixth announcement. I just posted a question on CS Theory StackExchange, entitled Overarching reasons why problems are in P or BPP. If you have suggested additions or improvements to my rough list of overarching reasons, please post them over there  thanks!

1. Im in Oxford right now, for a Clay Institute workshop on New Insights into Computational Intractability. The workshop is concurrent with three others, including one on Number Theory and Physics that includes an amplituhedron-related talk by Andrew Hodges. (Speaking of which, see here for a small but non-parodic observation about expressing amplitudes as volumes of polytopes.)
2. I was hoping to stay in the UK one more week, to attend the Newton Institutes special semester on Mathematical Challenges in Quantum Information over in Cambridge. But alas I had to cancel, since my diaper-changing services are needed in the other Cambridge. So, if anyone in Cambridge (or anywhere else in the United Kingdom) really wants to talk to me, come to Oxford this week!
3. Back in June, Jens Eisert and three others posted a preprint claiming that the output of a BosonSampling device would be indistinguishable from the uniform distribution in various senses. Ever since then, people have emailing me, leaving comments on this blog, and cornering me at conferences to ask whether Alex Arkhipov and I had any response to these claims. OK, so just this weekend, we posted our own 41-page preprint, entitled BosonSampling Is Far From Uniform. I hope it suffices by way of reply! (Incidentally, this is also the paper I hinted at in a previous post: the one where 2/6 and the Euler-Mascheroni constant make cameo appearances.) To clarify, if we just wanted to answer the claims of the Eisert group, then I think a couple paragraphs would suffice for that (see, for example, these PowerPoint slides). In our new paper, however, Alex and I take the opportunity to go further: we study lots of interesting questions about the statistical properties of Haar-random BosonSampling distributions, and about how one might test efficiently whether a claimed BosonSampling device worked, even with hundreds or thousands of photons.
4. Also on the arXiv last night, there was a phenomenal survey about the quantum PCP conjecture by Dorit Aharonov, Itai Arad, and my former postdoc Thomas Vidick (soon to be a professor at Caltech). I recommend reading it in the strongest possible terms, if youd like to see how far people have come with this problem (but also, how far they still have to go) since my Quantum PCP Manifesto seven years ago.
5. Christos Papadimitriou asked me to publicize that the deadline for early registration and hotel reservations for the upcoming FOCS in Berkeley is fast approaching! Indeed, its October 4 (three days from now). See here for details, and here for information about student travel support. (The links were down when I just tried them, but hopefully the server will be back up soon.)Three things that I shouldve gotten around to years ago

Updates (11/8): Alas, video of Eliezers talk will not be available after all.  The nincompoops who we paid to record the talk wrote down November instead of October for the date, didnt show up, then stalled for a month before finally admitting what had happened.  So my written summary will have to suffice (and maybe Eliezer can put his slides up as well).
In other news, Shachar Lovett has asked me to announce a workshop on complexity and coding theory, which will be held at UC San Diego, January 8-10, 2014.

Update (10/21): Some readers might be interested in my defense of LessWrongism against a surprisingly-common type of ad-hominem attack (i.e., the LW ideas must be wrong because so many of their advocates are economically-privileged but socially-awkward white male nerds, the same sorts of people who might also be drawn to Ayn Rand or other stuff I dislike). By all means debate the ideasIve been doing it for yearsbut please give beyond-kindergarten arguments when you do so!

Update (10/18): I just posted a long summary and review of Eliezer Yudkowskys talk at MIT yesterday.

Update (10/15): Leonard Schulman sent me the news that, according to an article by Victoria Woollaston in the Daily Mail, Google hopes to use its D-Wave quantum computer to solve global warming, develop sophisticated artificial life, and find aliens. (No, Im not making any of this up: just quoting stuff other people made up.) The article also repeats the debunked canard that the D-Wave machine is 3600 times faster, and soberly explains that D-Waves 512 qubits compare favorably to the mere 32 or 64 bits found in home PCs (exercise for those of you who arent already rolling on the floor: think about that until you are). It contains not a shadow of a hint of skepticism anywhere, not one token sentence. I would say that, even in an extremely crowded field, Woollastons piece takes the cake as the single most irresponsible article about D-Wave Ive seen. And Id feel terrible for my many friends at Google, whose company comes out of this looking like a laughingstock. But thats assuming that this isnt some sort of elaborate, Sokal-style prank, designed simply to prove that media outlets will publish anything whatsoever, no matter how forehead-bangingly absurd, as long as it contains the words D-Wave, Google, NASA, and quantumand thereby, to prove the truth of what Ive been saying on this blog since 2007.

1. Ive added MathJax support to the comments section! If you want to insert an inline LaTeX equation, surround it with\( \backslash( \backslash) \), while if you want to insert a displayed equation, surround it with \(\text{\$\$ \$\$}\). Thanks very much to Michael Dixon for prodding me to do this and telling me how.
2. Ive also added upvoting and downvoting to the comments section! OK, in the first significant use of comment voting, the readers have voted overwhelmingly, by 41  13, that they want the comment voting to disappear. So disappear it has!
3. Most importantly, Ive invited Eliezer Yudkowsky to MIT to give a talk! Hes here all week, and will be speaking on Recursion in Rational Agents: Foundations for Self-Modifying AI this Thursday at 4PM in 32-123 in the MIT Stata Center. Refreshments at 3:45. See here for the abstract. Anyone in the area whos interested in AI, rationalism, or other such nerdy things is strongly encouraged to attend; it should be interesting. Just dont call Eliezer a Singularitarian: Im woefully out of the loop, but I learned yesterday that theyve dropped that term entirely, and now prefer to be known as machine intelligence researchers talk about the intelligence explosion.
(In addition, Paul Christianoformer MIT undergrad, and my collaborator on quantum moneywill be speaking today at 4:30 at the Harvard Science Center, on Probabilistic metamathematics and the definability of truth. His talk will be related to Eliezers but somewhat more technical. See here for details.)

Update (10/15): Alistair Sinclair asked me to post the following announcement.
The Simons Institute for the Theory of Computing at UC Berkeley invites applications for Research Fellowships for academic year 2014-15.
Simons-Berkeley Research Fellowships are an opportunity for outstanding junior scientists (up to 6 years from PhD by Fall 2014) to spend one or two semesters at the Institute in connection with one or more of its programs. The programs for 2014-15 are as follows:
* Algorithmic Spectral Graph Theory (Fall 2014)
* Algorithms and Complexity in Algebraic Geometry (Fall 2014)
* Information Theory (Spring 2015)
Applicants who already hold junior faculty or postdoctoral positions are welcome to apply. In particular, applicants who hold, or expect to hold, postdoctoral appointments at other institutions are encouraged to apply to spend one semester as a Simons-Berkeley Fellow subject to the approval of the postdoctoral institution.
Further details and application instructions can be found at http://simons.berkeley.edu/fellows2014. Information about the Institute and the above programs can be found at http://simons.berkeley.edu.
Deadline for applications: 15 December, 2013.Beating swords into pitchforks

Heres a heartwarming story of religious reconciliation in Israel, one that puts the lie to those cynics who thought such ecumenism impossible.  It seems that large portions of Jerusalems Orthodox Jewish, Muslim, and Christian communities have finally set aside their differences, and joined together to support a common goal: threatening the marchers in a Gay Pride parade with death.Woohoo!

Scattershot BosonSampling: A new approach to scalable BosonSampling experiments

Update (12/2): Jeremy Hsu has written a fantastic piece for IEEE Spectrum, entitled D-Waves Year of Computing Dangerously.

Update (11/13): See here for video of a fantastic talk that Matthias Troyer gave at Stanford, entitled Quantum annealing and the D-Wave devices. The talk includes the results of experiments on the 512-qubit machine. (Thanks to commenter jim for the pointer. I attended the talk when Matthias gave it last week at Harvard, but I dont think that one was videotaped.)

Update (11/11): A commenter named RaulGPS has offered yet another great observation that, while forehead-slappingly obvious in retrospect, somehow hadnt occurred to us. Namely, Raul points out that the argument given in this post, for the hardness of Scattershot BosonSampling, can also be applied to answer open question #4 from my and Alexs paper: namely, how hard is BosonSampling with Gaussian inputs and number-resolving detectors? Raul points out that the latter, in general, is certainly at least as hard as Scattershot BS. For we can embed Scattershot BS into ordinary BS with Gaussian inputs, by first generating a bunch of entangled 2-mode Gaussian states (which are highly attenuated, so that with high probability none of them have 2 or more photons per mode), and then applying a Haar-random unitary U to the right halves of these Gaussian states while doing nothing to the left halves. Then we can measure the left halves to find out which of the input states contained a photon before we applied U. This is precisely equivalent to Scattershot BS, except for the unimportant detail that our measurement of the herald photons has been deferred till the end of the experiment instead of happening at the beginning. And therefore, since (as I explain in the post) a fast classical algorithm for approximate Scattershot BosonSampling would let us estimate the permanents of i.i.d. Gaussian matrices in BPPNP, we deduce that a fast classical algorithm for approximate Gaussian BosonSampling would have the same consequence. In short, approximate Gaussian BS can be argued to be hard under precisely the same complexity assumption as can approximate ordinary BS (and approximate Scattershot BS). Thus, in the table in Section 1.4 of our paper, the entries Gaussian states / Adaptive, demolition and Gaussian states / Adaptive, nondemolition should be upgraded from Exact sampling hard to Apx. sampling hard?
One other announcement: following a suggestion by commenter Rahul, I hereby invite guest posts on Shtetl-Optimized by experimentalists working on BosonSampling, offering your personal views about the prospects and difficulties of scaling up. Send me email if youre interested. (Or if you dont feel like writing a full post, of course you can also just leave a comment on this one.)

[Those impatient for a cool, obvious-in-retrospect new idea about BosonSampling, which I learned from the quantum optics group at Oxford, should scroll to the end of this post. Those who dont even know what BosonSampling is, let alone Scattershot BosonSampling, should start at the beginning.]
BosonSampling is a proposal by me and Alex Arkhipov for a rudimentary kind of quantum computer: one that would be based entirely on generating single photons, sending them through a network of beamsplitters and phaseshifters, and then measuring where they ended up. BosonSampling devices are not thought to be capable of universal quantum computing, or even universal classical computing for that matter. And while they might be a stepping-stone toward universal optical quantum computers, they themselves have a grand total of zeroknown practical applications. However, even if the task performed by BosonSamplers is useless, the task is of some scientific interest, by virtue of apparently being hard! In particular, Alex and I showed that, if a BosonSampler can be simulated exactly in polynomial time by a classical computer, then P#P=BPPNP, and hence the polynomial hierarchy collapses to the third level. Even if a BosonSampler can only be approximately simulated in classical polynomial time, the polynomial hierarchy would still collapse, if a reasonable-looking conjecture in classical complexity theory is true. For these reasons, BosonSampling might provide an experimental path to testing the Extended Church-Turing Thesisi.e., the thesis that all natural processes can be simulated with polynomial overhead by a classical computerthats more direct than building a universal quantum computer. (As an asymptotic claim, obviously the ECT can never be decisively proved or refuted by a finite number of experiments. However, if one could build a BosonSampler with, lets say, 30 photons, then while it would still be feasible to verify the results with a classical computer, it would be fair to say that the BosonSampler was working faster than any known algorithm running on existing digital computers.)
In arguing for the hardness of BosonSampling, the crucial fact Alex and I exploited is that the amplitudes for n-photon processes are given by the permanents of nxn matrices of complex numbers, and Leslie Valiant proved in 1979 that the permanent is #P-complete (i.e., as hard as any combinatorial counting problem, and probably even harder than NP-complete). To clarify, this doesnt mean that a BosonSampler lets you calculate the permanent of a given matrixthat would be too good to be true! (See the tagline of this blog.) What you could do with a BosonSampler is weirder: you could sample from a probability distribution over matrices, in which matrices with large permanents are more likely to show up than matrices with small permanents. So, what Alex and I had to do was to argue that even that sampling task is still probably intractable classicallyin the sense that, if it werent, then there would also be unlikely classical algorithms for more conventional problems.
Anyway, thats my attempt at a 2-paragraph summary of something weve been thinking about on and off for four years. See here for my and Alexs original paper on BosonSampling, here for a recent followup paper, here for PowerPoint slides, hereand here for MIT News articles by Larry Hardesty, and here for my blog post about the first (very small, 3- or 4-photon) demonstrations of BosonSampling by quantum optics groups last year, with links to the four experimental papers that came out then.
In general, weve been thrilled by the enthusiastic reaction to BosonSampling by quantum optics peopleespecially given that the idea started out as pure complexity theory, with the connection to optics coming as an unexpected bonus. But not surprisingly, BosonSampling has also come in for its share of criticism: e.g., that its impractical, unscalable, trivial, useless, oversold, impossible to verify, and probably some other things. A few people have even claimed that, in expressing support and cautious optimism about the recent BosonSampling experiments, Im guilty of the same sort of quantum computing hype that I complain about in others. (Ill let you be the judge of that. Reread the paragraphs above, or anything else Ive ever written about this topic, and then compare to, lets say,this video.)
By far the most important criticism of BosonSamplingone that Alex and I have openly acknowledged and worried a lot about almost from the beginningconcerns the proposals scalability. The basic problem is this: in BosonSampling, your goal is to measure a pattern of quantum interference among n identical, non-interacting photons, where n is as large as possible. (The special case n=2 is called the Hong-Ou-Mandel dip; conversely, BosonSampling can be seen as just Hong-Ou-Mandel on steroids.) The bigger n gets, the harder the experiment ought to be to simulate using a classical computer (with the difficulty increasing at least like ~2n). The trouble is that, to detect interference among n photons, the various quantum-mechanical paths that your photons could take, from the sources, through the beamsplitter network, and finally to the detectors, have to get them there at exactly the same timeor at any rate, close enough to the same time that the wavepackets overlap. Yet, while that ought to be possible in theory, the photon sources that actually exist today, and that will exist for the foreseeable future, just dont seem good enough to make it happen, for anything more than a few photons.
The reasonwell-known for decades as a bane to quantum information experimentsis that theres no known process in nature that can serve as a deterministic single-photon source. What you get from an attenuated laser is whats called a coherent state: a particular kind of superposition of 0 photons, 1 photon, 2 photons, 3 photons, etc., rather than just 1 photon with certainty (the latter is called a Fock state). Alas, coherent states behave essentially like classical light, which makes them pretty much useless for BosonSampling, and for many other quantum information tasks besides. For that reason, a large fraction of modern quantum optics research relies on a process called Spontaneous Parametric Down-Conversion (SPDC). In SPDC, a laser (called the pump) is used to stimulate a crystal to produce further photons. The process is inefficient: most of the time, no photon comes out. But crucially, any time a photon does come out, its arrival is heralded by a partner photon flying out in the opposite direction. Once in a while, 2 photons come out simultaneously, in which case theyre heralded by 2 partner photonsand even more rarely, 3 photons come out, heralded by 3 partner photons, and so on. Furthermore, there exists something called a number-resolving detector, which can tell you (today, sometimes, with as good as ~95% reliability) when one or more partner photons have arrived, and how many of them there are. The result is that SPDC lets us build whats called a nondeterministic single-photon source. I.e., you cant control exactly when a photon comes outthats randombut eventually one (and only one) photon will come out, and when that happens, youll know it happened, without even having to measure and destroy the precious photon. The reason youll know is that the partner photon heralds its presence.
Alas, while SPDC sources have enabled demonstrations of a large number of cool quantum effects, theres a fundamental problem with using them for BosonSampling. The problem comes from the requirement that nthe number of single photons fired off simultaneously into your beamsplitter networkshould be big (say, 20 or 30). Suppose that, in a given instant, the probability that your SPDC source succeeds in generating a photon is p. Then whats the probability that two SPDC sources will both succeed in generating a photon at that instant? p2. And the probability that three sources will succeed is p3, etc. In general, with n sources, the probability that theyll succeed simultaneously falls off exponentially with n, and the amount of time youll need to sit in the lab waiting for the lucky event increases exponentially with n. Sure, when it finally does happen, it will be heralded. But if you need to wait exponential time for it to happen, then there would seem to be no advantage over classical computation. This is the reason why so far, BosonSampling has only been demonstrated with 3-4 photons.
At least three solutions to the scaling problem suggest themselves, but each one has problems of its own. The first solution is simply to use general methods for quantum fault-tolerance: its not hard to see that, if you had a fault-tolerant universal quantum computer, then you could simulate BosonSampling with as many photons as you wanted. The trouble is that this requires a fault-tolerant universal quantum computer! And if you had that, then youd probably just skip BosonSampling and use Shors algorithm to factor some 10,000-digit numbers. The second solution is to invent some specialized fault-tolerance method that would apply directly to quantum optics. Unfortunately, we dont know how to do that. The third solutionuntil recently, the one that interested me and Alex the mostwould be to argue that, even if your sources are so cruddy that you have no idea which ones generated a photon and which didnt in any particular run, the BosonSampling distribution is still intractable to simulate classically. After all, the great advantage of BosonSampling is that, unlike with (say) factoring or quantum simulation, we dont actually care which problem were solving! All we care about is that were doing something that we can argue is hard for classical computers. And we have enormous leeway to change what that something is, to match the capabilities of current technology. Alas, yet again, we dont know how to argue that BosonSampling is hard to simulate approximately in the presence of realistic amounts of noiseat best, we can argue that its hard to simulate approximately in the presence of tiny amounts of noise, and hard to simulate super-accurately in the presence of realistic noise.
When faced with these problems, until recently, all we could do was

shrug our shoulders,
point out that none of the difficulties added up to a principled argument that scalable BosonSampling was not possible,
stress, again, that all we were asking for was to scale to 20 or 30 photons, not 100 or 1000 photons, and
express hope that technologies for single-photon generation currently on the drawing boardmost notably, something called optical multiplexingcould be used to get up to the 20 or 30 photons we wanted.

Well, Im pleased to announce, with this post, that theres now a better idea for how to scale BosonSampling to interesting numbers of photons. The idea, which Ive taken to calling Scattershot BosonSampling, is not mine or Alexs. I learned of it from Ian Walmsleys group at Oxford, where its been championed in particular by Steve Kolthammer. (Update: A commenter has pointed me to a preprint by Lund, Rahimi-Keshari, and Ralph from May of this year, which I hadnt seen before, and which contains substantially the same idea, albeit with an unsatisfactory argument for computational hardness. In any case, as youll see, its not surprising that this idea wouldve occurred to multiple groups of experimentalists independently; whats surprising is that we didnt think of it!) The minute I heard about Scattershot BS, I kicked myself for failing to think of it, and for getting sidetracked by much more complicated ideas. Steve and others are working on a paper about Scattershot BS, but in the meantime, Steve has generously given me permission to share the idea on this blog. I suggested a blog post for two reasons: first, as youll see, this idea really is blog-sized. Once you make the observation, theres barely any theoretical analysis that needs to be done! And second, I was impatient to get out to the experimental BosonSampling communitynot to mention to the critics!that theres now a better way to BosonSample, and one thats incredibly simple to boot.
OK, so what is the idea? Well, recall from above what an SPDC source does: it produces a photon with only a small probability, but whenever it does, it heralds the event with a second photon. So, lets imagine that you have an array of 200 SPDC sources. And imagine that, these sources being unpredictable, only (say) 10 of them, on average, produce a photon at any given time. Then what can you do? Simple: just define those 10 sources to be the inputs to your experiment! Or to say it more carefully: instead of sampling only from a probability distribution over output configurations of your n photons, now youll sample from a joint distribution over inputs and outputs: one where the input is uniformly random, and the output depends on the input (and also, of course, on the beamsplitter network). So, this idea could also be called Double BosonSampling: now, not only do you not control which output will be observed (but only the probability distribution over outputs), you dont control which input eitheryet this lack of control is not a problem! There are two key reasons why it isnt:

As I said before, SPDC sources have the crucial property that they herald a photon when they produce one. So, even though you cant control which 10 or so of your 200 SPDC sources will produce a photon in any given run, you know which 10 they were.
In my and Alexs original paper, the hardest case of BosonSampling that we were able to findthe case we used for our hardness reductionsis simply the one where the mxn scattering matrix, which describes the map between the n input modes and the m>>n output modes, is a Haar-random matrix whose columns are orthonormal vectors. But now suppose we have m input modes and m output modes, and the mxm unitary matrix U mapping inputs to outputs is Haar-random. Then any mxn submatrix of U will simply be an instance of the original hard case that Alex and I studied!

More formally, what can we say about the computational complexity of Scattershot BS? Admittedly, I dont know of a reduction from ordinary BS to Scattershot BS (though its easy to give a reduction in the other direction). However, under exactly the same assumption that Alex and I used to argue that ordinary BosonSampling was hardour so-called Permanent of Gaussians Conjecture (PGC)one can show that Scattershot BS is hard also, and by essentially the same proof. The only difference is that, instead of talking about the permanents of nxn submatrices of an mxn Haar-random, column-orthonormal matrix, now we talk about the permanents of nxn submatrices of an mxm Haar-random unitary matrix. Or to put it differently: where before we fixed the columns that defined our nxn submatrix and only varied the rows, now we vary both the rows and the columns. But the resulting nxn submatrix is still close in variation distance to a matrix of i.i.d. Gaussians, for exactly the same reasons it was before. And we can still check whether submatrices with large permanents are more likely to be sampled than submatrices with small permanents, in the way predicted by quantum mechanics.
Now, everything above assumed that each SPDC source produces either 0 or 1 photon. But what happens when the SPDC sources produce 2 or more photons, as they sometimes do? It turns out that there are two good ways to deal with these higher-order terms in the context of Scattershot BS. The first way is by using number-resolving detectors to count how many herald photons each SPDC source produces. That way, at least youll knowexactly which sources produced extra photons, and how many extra photons each one produced. And, as is often the case in BosonSampling, a devil you know is a devil you can deal with. In particular, a few known sources producing extra photons, just means that the amplitudes of the output configurations will now be permanents of matrices with a few repeated rows in them. But the permanent of an otherwise-random matrix with a few repeated rows should still be hard to compute! Granted, we dont know how to derive that as a consequence of our original hardness assumption, but this seems like a case where one is perfectly justified to stick ones neck out and make a new assumption.
But theres also a more elegant way to deal with higher-order terms. Namely, suppose m>>n2 (i.e., the number of input modes is at least quadratically greater than the average number of photons). Thats an assumption that Alex and I typically made anyway in our original BosonSampling paper, because of our desire to avoid what we called the Bosonic Birthday Paradox (i.e., the situation where two or more photons congregate in the same output mode). Whats wonderful is that exactly the same assumption also implies that, in Scattershot BS, two or more photons will almost never be found in the same input mode! That is, when you do the calculation, you find that, once youve attenuated your SPDC sources enough to avoid the Bosonic Birthday Paradox at the output modes, youve also attenuated them enough to avoid higher-order terms at the input modes. Cool, huh?
Are there any drawbacks to Scattershot BS? Well, Scattershot BS certainly requires more SPDC sources than ordinary BosonSampling does, for the same average number of photons. A little less obviously, Scattershot BS also requires a larger-depth beamsplitter network. In our original paper, Alex and I showed that for ordinary BosonSampling, it suffices to use a beamsplitter network of depth O(n log m), where n is the number of photons and m is the number of output modes (or equivalently detectors). However, our construction took advantage of the fact that we knew exactly which n<<m sources the photons were going to come from, and could therefore optimize for those. For Scattershot BS, the depth bound increases to O(m log m): since the n photons could come from any possible subset of the m input modes, we no longer get the savings based on knowing where they originate. But this seems like a relatively minor issue.
I dont want to give the impression that Scattershot BS is a silver bullet that will immediately let us BosonSample with 30 photons. The most obvious limiting factor that remains is the efficiency of the photon detectorsboth those used to detect the photons that have passed through the beamsplitter network, and those used to detect the herald photons. Because of detector inefficiencies, Im told that, without further technological improvements (or theoretical ideas), it will still be quite hard to push Scattershot BS beyond about 10 photons. Still, as you might have noticed, 10 is greater than 4 (the current record)! And certainly, Scattershot BS itselfa simple, obvious-in-retrospect idea that was under our noses for years, and that immediately pushes forward the number of photons a BosonSampler can handleshould make us exceedingly reluctant to declare there cant be any more such ideas, and that our current ignorance amounts to a proof of impossibility.Public Relations 101

From sayat-travel.kz:
ALMATY, Kazakhstan  Sayat Tour, a leading Kazakh tour operator, announced today several new tours for Americans and others who are willing to travel to Kazakhstan and see for themselves what the real country, not the Borats version, is really like.
The tours, called Kazakhstan vs. Boratistan and Jagzhemash!!! See the Real Kazakhstan, include visits to the cosmopolitan Almaty and its beautiful surroundings, tours of ancient sites such as the Hodja Akhmed Yassaui Mausoleum in Turkestan, as well as plentiful opportunities to meet and interact with the real Kazakhs. In addition to sightseeing, tours also include visits to local colorful bazaars, artifact shops and high fashion boutiques, as well as trying kumyss, the deliciously tasting Kazakh traditional drink made from fermented horse milk.
Marianna Tolekenova, Sayats Executive Director, said: With the release of Borat: Cultural Learnings of America for Make Benefit Glorious Nation of Kazakhstan, we are hoping many Americans will want to engage in cultural learnings of that unknown glorious nation for their own make benefit. That is why we are launching these new tours and hoping the Americans will come visit us.
Earlier in October 2006, a high ranking Kazakh official said the creator of Borat, British comedian Sasha Baron Cohen, would be welcome in Kazakhstan. First Deputy Foreign Minister Rakhat Aliyev said, His trip could yield a lot of discoveries  that women not only travel inside buses but also drive their own cars, that we make wine from grapes, that Jews can freely attend synagogues and so on.
Update (11/13): In response to a comment by Greg Kuperberg, Ive now reached a halakhic ruling on the morality of Sacha Baron Cohens antics.  Go to the comments section if you want to read it.Handle with care

In todays quant-ph we find a report of a truly dramatic experiment  one that detected entanglement between Baton Rouge, Louisiana and Givarlais, France.  How, you ask: by fiber-optic cable?  Satellite?  Neither: by postal mail!  The authors dont say if it was FedEx, UPS, or some other carrier that managed to ship half an EPR pair across the Atlantic without decohering it  but whoever it was, thats who Im using from now on.
(Note: On close reading, it appears that when the authors use the word entanglement, they actually mean classical correlation.  However, this is a technical distinction that should only matter for experts.)Twenty Reasons to Believe Oswald Acted Alone

As the world marked the 50th anniversary of the JFK assassination, I have to confess  no, no, not that I was in on the plot. I wasnt even born then, silly. I have to confess that, in between struggling to make a paper deadline, attending a workshop in Princeton, celebrating Thanksgivukkah, teaching Lily how to pat her head and clap her hands, and not blogging, I also started dipping, for the first time in my life, into a tiny fraction of the vast literature about the JFK assassination. The trigger (so to speak) for me was this article by David Talbot, the founder of Salon.com. I figured, if the founder of Salon is a JFK conspiracy buffif, for crying out loud, my skeptical heroes Bertrand Russell and Carl Sagan were both JFK conspiracy buffsthen maybe its at least worth familiarizing myself with the basic facts and arguments.
So, what happened when I did? Were the scales peeled from my eyes?
In a sense, yes, they were. Given how much has been written about this subject, and how many intelligent people take seriously the possibility of a conspiracy, I was shocked by how compelling I found the evidence to be that there were exactly three shots, all fired by Lee Harvey Oswald with a Carcano rifle from the sixth floor of the Texas School Book Depository, just as the Warren Commission said in 1964. And as for Oswalds motives, I think I understand them as well and as poorly as I understand the motives of the people who send me ramblings every week about P vs. NP and the secrets of the universe.
Before I started reading, if someone forced me to guess, maybe I wouldve assigned a ~10% probability to some sort of conspiracy. Now, though, Id place the JFK conspiracy hypothesis firmly in Moon-landings-were-faked, Twin-Towers-collapsed-from-the-inside territory. Or to put it differently, Oswald as lone, crazed assassin has been added to my large class of sanity-complete propositions: propositions defined by the property that if I doubt any one of them, then theres scarcely any part of the historical record that I shouldnt doubt. (And while one cant exclude the possibility that Oswald confided in someone else before the acthis wife or a friend, for exampleand that other person kept it a secret for 50 years, whats known about Oswald strongly suggests that he didnt.)
So, what convinced me? In this post, Ill give twenty reasons for believing that Oswald acted alone. Notably, my reasons will have less to do with the minutiae of bullet angles and autopsy reports, than with general principles for deciding whats true and what isnt. Of course, part of the reason for this focus is that the minutiae are debated in unbelievable detail elsewhere, and I have nothing further to contribute to those debates. But another reason is that Im skeptical that anyone actually comes to believe the JFK conspiracy hypothesis because they dont see how the second bullet came in at the appropriate angle to pass through JFKs neck and shoulder and then hit Governor Connally. Clear up some technical point (or ten or fifty of them)as has been done over and overand the believers will simply claim that the data you used was altered by the CIA, or theyll switch to other anomalies without batting an eye. Instead, people start with certain general beliefs about how the world works, whos really in charge, what sorts of explanations to look for, etc., and then use their general beliefs to decide which claims to accept about JFKs head wounds or the foliage in Dealey Plazanot vice versa. That being so, one might as well just discuss the general beliefs from the outset. So without further ado, here are my twenty reasons:
1. Conspiracy theorizing represents a known bug in the human nervous system. Given that, I think our prior should be overwhelmingly against anything that even looks like a conspiracy theory. (This is not to say conspiracies never happen. Of course they do: Watergate, the Tobacco Institute, and the Nazi Final Solution were three well-known examples. But the difference between conspiracy theorists fantasies and actual known conspiracies is this: in a conspiracy theory, some powerful organizations public face hides a dark and terrible secret; its true mission is the opposite of its stated one. By contrast, in every real conspiracy I can think of, the facade was already 90% as terrible as the reality! And the dark secret was that the organization was doing precisely what youd expect it to do, if its members genuinely held the beliefs that they claimed to hold.)
2. The shooting of Oswald by Jack Ruby created the perfect conditions for conspiracy theorizing to fester. Conditioned on that happening, it would be astonishing if a conspiracy industry hadnt arisen, with its hundreds of books and labyrinthine arguments, even under the assumption that Oswald and Ruby both really acted alone.
3. Other high-profile assassinations to which we might compare this onefor example, those of Lincoln, Garfield, McKinley, RFK, Martin Luther King Jr., Gandhi, Yitzchak Rabinappear to have been the work of lone nuts, or at most conspiracies of small numbers of lowlifes. So why not this one?
4. Oswald seems to have perfectly fit the profile of a psychopathic killer (see, for example, Case Closed by Gerald Posner). From very early in his life, Oswald exhibited grandiosity, resentment, lack of remorse, doctrinaire ideological fixations, and obsession with how hed be remembered by history.
5. A half-century of investigation has failed to link any individual besides Oswald to the crime. Conspiracy theorists love to throw around large, complicated entities like the CIA or the Mafia as potential conspiratorsbut in the rare cases when theyve tried to go further, and implicate an actual human being other than Oswald or Ruby (or distant power figures like LBJ), the results have been pathetic and tragic.
6. Oswald had previously tried to assassinate General Walkera fact that was confirmed by his widow Marina Oswald, but that, incredibly, is barely even discussed in the reams of conspiracy literature.
7. Theres clear evidence that Oswald murdered Officer Tippit an hour after shooting JFKa fact that seems perfectly consistent with the state of mind of someone whod just murdered the President, but that, again, seems to get remarkably little discussion in the conspiracy literature.
8. Besides being a violent nut, Oswald was also a known pathological liar. He lied on his employment applications, he lied about having established a thriving New Orleans branch of Fair Play for Cuba, he lied and lied and lied. Because of this tendencyas well as his persecution complexOswalds loud protestations after his arrest that he was just a patsy count for almost nothing.
9. According to police accounts, Oswald acted snide and proud of himself after being taken into custody: for example, when asked whether he had killed the President, he replied you find out for yourself. He certainly didnt act like an innocent patsy arrested on such a grave charge would plausibly act.
10. Almost all JFK conspiracy theories must be false, simply because theyre mutually inconsistent. Once you realize that, and start judging the competing conspiracy theories by the standards youd have to judge them by if at most one could be true, enlightenment may dawn as you find theres nothing in the way of just rejecting all of them. (Of course, some people have gone through an analogous process with religions.)
11. The case for Oswald as lone assassin seems to become stronger, the more you focus on the physical evidence and stuff that happened right around the time and place of the event. To an astonishing degree, the case for a conspiracy seems to rely on verbal testimony years or decades afterwardoften by people who are known confabulators, who were nowhere near Dealey Plaza at the time, who have financial or revenge reasons to invent stories, and who remembered seeing Oswald and Ruby with CIA agents, etc. only under drugs or hypnosis. This is precisely the pattern we would expect if conspiracy theorizing reflected the reality of the human nervous system rather than the reality of the assassination.
12. If the conspiracy is so powerful, why didnt it do something more impressive than just assassinate JFK? Why didnt it rig the election to prevent JFK from becoming President in the first place? (In math, very often the way you discover a bug in your argument is by realizing that the argument gives you more than you originally intendedvastly, implausibly more. Yet every pro-conspiracy argument Ive read seems to suffer from the same problem. For example, after successfully killing JFK, did the conspiracy simply disband? Or did it go on to mastermind other assassinations? If it didnt, why not? Isnt pulling the puppet-strings of the world sort of an ongoing proposition? What, if any, are the limits to this conspiracys power?)
13. Pretty much all the conspiracy writers I encountered exude total, 100% confidence, not only in the existence of additional shooters, but in the guilt of their favored villains (they might profess ignorance, but then in the very next sentence theyd talk about how JFKs murder was a triumph for the national security establishment). For me, their confidence had the effect of weakening my own confidence in their intellectual honesty, and in any aspects of their arguments that I had to take on faith. The conspiracy camp would of course reply that the Oswald acted alone camp also exudes too much confidence in its position. But the two cases are not symmetric: for one thing, because there are so many different conspiracy theories, but only one Oswald. If I were a conspiracy believer Id be racked with doubts, if nothing else then about whether my conspiracy was the right one.
14. Every conspiracy theory Ive encountered seems to require uncontrolled growth in size and complexity: that is, the numbers of additional shooters, alterations of medical records, murders of inconvenient witnesses, coverups, coverups of the coverups, etc. that need to be postulated all seem to multiply without bound. To some conspiracy believers, this uncontrolled growth might actually be a feature: the more nefarious and far-reaching the conspiracys tentacles, the better. It should go without saying that I regard it as a bug.
15. JFK was not a liberal Messiah. He moved slowly on civil rights for fear of a conservative backlash, invested heavily in building nukes, signed off on the botched plans to kill Fidel Castro, and helped lay the groundwork for the USs later involvement in Vietnam. Yes, its possible that he wouldve made wiser decisions about Vietnam than LBJ ended up making; thats part of what makes his assassination (like RFKs later assassination) a tragedy. But many conspiracy theorists view of JFK as an implacable enemy of the military-industrial complex is preposterous.
16. By the same token, LBJ was not exactly a right-wing conspirators dream candidate. He was, if anything, more aggressive on poverty and civil rights than JFK was. And even if he did end up being better for certain military contractors, thats not something that wouldve been easy to predict in 1963, when the USs involvement in Vietnam had barely started.
17. Lots of politically-powerful figures have gone on the record as believers in a conspiracy, including John Kerry, numerous members of Congress, and even frequently-accused conspirator LBJ himself. Some people would say that this lends credibility to the conspiracy cause. To me, however, it indicates just the opposite: that theres no secret cabal running the world, and that those in power are just as prone to bugs in the human nervous system as anyone else is.
18. As far as I can tell, the conspiracy theorists are absolutely correct that JFKs security in Dallas was unbelievably poor; that the Warren Commission was as interested in reassuring the nation and preventing a war with the USSR or Cuba as it was in reaching the truth (the fact that it did reach the truth is almost incidental); and that agencies like the CIA and FBI kept records related to the assassination classified for way longer than there was any legitimate reason to (though note that most records finally were declassified in the 1990s, and they provided zero evidence for any conspiracy). As you might guess, I ascribe all of these things to bureaucratic incompetence rather than to conspiratorial ultra-competence. But once again, these government screwups help us understand how so many intelligent people could come to believe in a conspiracy even in the total absence of one.
19. In the context of the time, the belief that JFK was killed by a conspiracy filled a particular need: namely, the need to believe that the confusing, turbulent events of the 1960s had an understandable guiding motive behind them, and that a great man like JFK could only be brought down by an equally-great evil, rather than by a chronically-unemployed loser who happened to see on a map that JFKs motorcade would be passing by his workplace. Ironically, I think that Roger Ebert got it exactly right when he praised Oliver Stones JFK movie for its emotional truth. In much the same way, one could say that Birth of a Nation was emotionally true for Southern racists, or that Ben Steins Expelled was emotionally true for creationists. Again, Id say that the emotional truth of the conspiracy hypothesis is further evidence for its factual falsehood: for it explains how so many people could come to believe in a conspiracy even if the evidence for one were dirt-poor.
20. At its core, every conspiracy argument seems to be built out of holes: the details that dont add up in the official account, the questions that havent been answered, etc. What Ive never found is a truly coherent alternative scenario: just one hole after another. This pattern is the single most important red flag for me, because it suggests that the JFK conspiracy theorists view themselves as basically defense attorneys: people who only need to sow enough doubts, rather than establish the reality of what happened. Crucially, creationism, 9/11 trutherism, and every other elaborate-yet-totally-wrong intellectual edifice Ive ever encountered has operated on precisely the same defense attorney principle: if we can just raise enough doubts about the other sides case, we win! But thats a terrible approach to knowledge, once youve seen firsthand how a skilled arguer can raise unlimited doubts even about the nonexistence of a monster under your bed. Such arguers are hoping, of course, that youll find their monster hypothesis so much more fun, exciting, and ironically comforting than the random sounds in the night hypothesis, that it wont even occur to you to demand they show you their monster.
Further reading: this article in Slate.Climbing Mount Boredom

Two weeks ago, I argued that scientific papers are basically a waste of time.  Today Id like to generalize the results of that earlier post, by explaining why scientific talks are also a waste of time.
Let me set the scene for you.  You arrive at the weekly colloquium eager to learn, like a cargo cult member whos sure that this time the planes are going to land. But then, about fifteen minutes after the PowerPoint train has left the station, you start to get nervous: Why are we stopping at all these unfamiliar little hamlets? Are we really headed for the place mentioned in the abstract? You glance at your fellow passengers: are they as confused as you are? (Youd ask the guy sitting next to you, but hes sound asleep.) Eventually the announcer comes on and  uh-oh! It seems the train is about to begin its long ascent up Mount Boredom, and you dont have the prerequisites for this leg of the trip. Can you dodge the ticket collector? Too stressful! You get off, and the train roars past you, never to return.
Such was my experience again and again until three years ago, when I finally gave up on talks as a medium for scientific communication. These days, whenever I have to sit through one, I treat the speakers words as background music for my private fantasies and daydreams, unless the speaker chooses to interrupt with a novel idea.
But what about when I have to talk? To be honest, I havent intentionally perpetrated a research talk in years. Instead I do a stand-up comedy routine where you have to be a quantum computing expert to get the jokes. Its like Seinfeld, except not that funny. So why does it work? Simple: because the crowd that expects to be bored is the easiest crowd on Earth.
Now one could argue that, by stuffing my talks with flying pigs and slide-eating black holes, Ive been setting back the cause of scientific knowledge.  But I dont think so.  See, the basic problem with talks is that they have no anti-boredom escape hatch.  I mean, if you were chatting with a colleague who droned on for too long, youd have several options:

Change the subject.
Say something like yeah, I get it, but does this actually lead to a new lower bound?
Tap your fingers, study the wall patterns, etc.
If all else fails, mention your immense workload, then excuse yourself and go back to reading weblogs.

The key point is that none of these tactics are inherently rude or insulting. All of us use them regularly; if we didnt, itd be impossible to tell when we were boring each other. Put differently, these tactics are part of the feedback and dialogue thats essential to any healthy relationship:
Was it good for you?
Could you maybe go a little faster?
Do you like it when I use this notation?
The seminar speaker, by contrast, is a narcissist who verbally ravages his defenseless audience. Sure, its fine to interrupt with things like Arent you missing an absolute value sign?, or How do you know A is Hermitian? But have you ever raised your hand to say, Excuse me, but would you mind skipping the next 20 slides and getting right to the meat? Or: This is boring. Would you please talk about a different result?
(Incidentally, as my adviser Umesh Vazirani pointed out to me, when people get lost during a talk they think it means that the speaker is going too fast. But more often, the real problem is that the speaker is going too slow, and thereby letting the audience get mired in trivialities.)
So whats the solution?  (You knew there was going to be one, didnt you?)  My solution is to replace talks by conversations whenever possible. Heres how the Aaronson system works: you get five minutes to tell your audience something unexpected. (Usually this will involve no slides, just a board.) Then, if people have questions, you answer them; if they want details, you provide them. At any time, anyone whos no longer interested can get up and leave (and maybe come back later), without being considered a jerk. When there are no further questions, you sit down and give someone else a chance to surprise the audience.
If you dont think this system would work, come visit our quantum algorithms lunch at Waterloo, Tuesdays at 11:30 in the BFG seminar room. Bring a result or open problem.Shtetl-Optimized is dead.  Long live Shtetl-Optimized!

So, I finally had it both with Blogger, which was constantly down, and with my web hosting service, which was constantly down and inserting hidden Cialis ads into my homepage.  (Yes, really.)  So I ditched them both!
This morning Shtetl-Optimized finally departed the old country, and boarded a crowded ship bound for a strange new world: the world of Bluehost and WordPress.  So welcome to a brand-new blog, which will feature the same name as the old one, the same topics, and the same terrible jokes.  I hope you like it.
(Also this morning, I discovered a little hole-in-the-wall in Waterloo that sells hot, fresh bagels barely distinguishable from what you could get in New York.  Yes, this is shaping up to be a very good day.)
(Oh, yes: Happy belated Thanksgiving to my American friends.  I decided to stay in Waterloo over Thanksgiving to teach my course  is this is a sign that Im actually becoming Canadian?)23, Me, and the Right to Misinterpret Probabilities

If youre the sort of person who reads this blog, you may have heard that 23andMethe company that (until recently) let anyone spit into a capsule, send it away to a DNA lab, and then learn basic information about their ancestry, disease risks, etc.has suspended much of its service, on orders from the US Food and Drug Administration. As I understand it, on Nov. 25, the FDA ordered 23andMe to stop marketing to new customers (though it can still serve existing customers), and on Dec. 5, the company stopped offering new health-related information to any customers (though you can still access the health information you had before, and ancestry and other non-health information is unaffected).
Of course, the impact of these developments is broader: within a couple weeks, do-it-yourself genomics has gone from an industry whose explosive growth lots of commentators took as a given, to one whose future looks severely in doubt (at least in the US).
The FDA gave the reasons for its order in a letterto Ann Wojcicki,23andMes CEO. Excerpts:
For instance, if the BRCA-related risk assessment for breast or ovarian cancer reports a false positive, it could lead a patient to undergo prophylactic surgery, chemoprevention, intensive screening, or other morbidity-inducing actions, while a false negative could result in a failure to recognize an actual risk that may exist. Assessments for drug responses carry the risks that patients relying on such tests may begin to self-manage their treatments through dose changes or even abandon certain therapies depending on the outcome of the assessment. For example, false genotype results for your warfarin drug response test could have significant unreasonable risk of illness, injury, or death to the patient due to thrombosis or bleeding events that occur from treatment with a drug at a dose that does not provide the appropriately calibrated anticoagulant effect The risk of serious injury or death is known to be high when patients are either non-compliant or not properly dosed; combined with the risk that a direct-to-consumer test result may be used by a patient to self-manage, serious concerns are raised if test results are not adequately understood by patients or if incorrect test results are reported.
To clarify, the DNA labs that 23andMe uses are already government-regulated. Thus, the question at issue here is not whether, if 23andMe claims (say) that you have CG instead of CC at some particular locus, the information is reliable. Rather, the question is whether 23andMe should be allowed to tell you that fact, while also telling you that a recent research paper found that people with CG have a 10.4% probability of developing Alzheimers disease, as compared to a 7.2% base rate. More bluntly, the question is whether ordinary schmoes ought to be trustedto learn such facts about themselves, without a doctor as an intermediary to interpret the results for them, or perhaps to decide that theres no good reason for the patient to know at all.
Among medical experts, a common attitude seems to be something like this: sure, getting access to your own genetic data is harmless fun, as long as youre an overeducated nerd who just wants to satisfy his or her intellectual curiosity (or perhaps narcissism). But 23andMe crossed a crucial line when it started marketing its service to the hoi polloi, as something that could genuinely tell them about health risks. Most people dont understand probability, and are incapable of parsing based on certain gene variants we found, your chances of developing diabetes are about 6 times higher than the baseline as anything other than you will develop diabetes. Nor, just as worryingly, are they able to parse your chances are lower than the baseline as anything other than you wont develop diabetes.
I understand this argument. Nevertheless, I find it completely inconsistent with a free society. Moreover, I predict that in the future, the FDAs current stance will be looked back upon as an outrage, with the subtleties in the FDAs position mattering about as much as the subtleties in the Churchs position toward Galileo (look, Mr. G., its fine to discuss heliocentrism among your fellow astronomers, as a hypothesis or a calculational tooljust dont write books telling the general public that heliocentrism isliterally true, and that they should change their worldviews as a result!). Thats why I signed this petitionasking the FDA to reconsider its decision, and I encourage you to sign it too.
Here are some comments that might help clarify my views:
(1) I signed up for 23andMe a few years ago, as did the rest of my family. The information I gained from it wasnt exactly earth-shattering: I learned, for example, that my eyes are probably blue, that my ancestry is mostly Ashkenazi, that theres a risk my eyesight will further deteriorate as I age (the same thing a succession of ophthalmologists told me), that I cant taste the bitter flavor in brussels sprouts, and that Im an unlikely sprinter. On the other hand, seeing exactly which gene variants correlate with these things, and how they compare to the variants my parents and brother have, was  cool. It felt like I imagine it must have felt to buy a personal computer in 1975. In addition, I found nothing the slightest bit dishonest about the way the results were reported. Each result was stated explicitly in terms of probabilitiesgiving both the baseline rate for each condition, and the rate conditioned on having such-and-such gene variantand there were even links to the original research papers if I wanted to read them myself. I only wish that I got half as much context and detail from conventional doctor visitsor for that matter, from most materials Ive read from the FDA itself. (When Dana was pregnant, I was pleasantly surprised when some of the tests she underwent came back with explicit probabilities and base rates. I remember wishing doctors would give me that kind of information more often.)
(2) From my limited reading and experience, I think its entirely possible that do-it-yourself genetic testing is overhyped; that it wont live up to its most fervent advocates promises; that for most interesting traits there are just too many genes involved, via too many labyrinthine pathways, to make terribly useful predictions about individuals, etc. So its important to me that, in deciding whether what 23andMe does should be legal, were not being asked to decide any of these complicated questions! Were only being asked whether the FDA should get to decide the answers in advance.
(3) As regular readers will know, Im far from a doctrinaire libertarian. Thus, my opposition to shutting down 23andMe is not at all a corollary of reflexive opposition to any government regulation of anything. In fact, Id be fine if the FDA wanted to insert a warning message on 23andMe (in addition to the warnings 23andMe alreadyprovides), emphasizing that genetic tests only provide crude statistical information, that they need to be interpreted with care, consult your doctor before doing anything based on these results, etc. But when it comes to banning access to the results, I have trouble with some of the obvious slippery slopes. E.g., what happens when some Chinese or Russian company launches a competing service? Do we ban Americans from mailing their saliva overseas? What happens when individuals become able just to sequence their entire genomes, and store and analyze them on their laptops? Do we ban the sequencing technology? Or do we just ban software that makes it easy enough to analyze the results? If the software is hard enough to use, so only professional biologists use it, does that make it OK again? Also, if the FDA will be in the business of banning genomic data analysis tools, then what about medical books? For that matter, what about any books or websites, of any kind, that might cause someone to make a poor medical decision? What would such a policy, if applied consistently, do to the multibillion-dollar alternative medicine industry?
(4) I dont understand the history of 23andMes interactions with the FDA. From what Ive read, though, they have been communicating for five years, with everything 23andMe has said in public sounding conciliatory rather than defiant (though the FDA has accused 23andMe of being tardy with its responses). Apparently, the key problem is simply that the FDA hasnt yet developed a regulatory policy specifically for direct-to-consumer genetic tests. Its been considering such a policy for yearsbut in the meantime, it believes no one should be marketing such tests for health purposes before a policy exists. Alas, there are very few cases where Id feel inclined to support a government in saying: X is a new technology that lots of people are excited about. However, our regulatory policies havent yet caught up to X. Therefore, our decision is that X is banned, until and unless we figure out how to regulate it. Maybe I could support such a policy, if X had the potential to level cities and kill millions. But when it comes to consumer DNA tests, this sort of preemptive banning seems purposefully designed to give wet dreams to Ayn Rand fans.
(5) I confess that, despite everything Ive said, my moral intuitions might be different if dead bodies were piling up because of terrible 23andMe-inspired medical decisions. But as far as I know, theres no evidence so far that even a single person was harmed. Which isnt so surprising: after all, people might run to their doctor terrified about something they learned on 23onMe, but no sane doctor would ever make a decision solely on that basis, without ordering further tests.Luke Muehlhauser interviews me about philosophical progress

Im shipping out today to sunny Rio de Janeiro, where Ill be giving a weeklong course about BosonSampling, at the invitation of Ernesto Galvo. Then its on to Pennsylvania (where Ill celebrate Christmas Eve with old family friends), Israel (where Ill drop off Dana and Lily with Danas family in Tel Aviv, then lecture at the Jerusalem Winter School in Theoretical Physics), Puerto Rico (where Ill speak at the FQXi conference on Physics of Information), back to Israel, and then New York before returning to Boston at the beginning of February. Given this travel schedule, its possible that blogging will be even lighter than usual for the next month and a half (or notwell see).
In the meantime, however, Ive got the equivalent of at least five new blog posts to tide over Shtetl-Optimized fans. Luke Muehlhauser, the Executive Director of the Machine Intelligence Research Institute (formerly the Singularity Institute for Artificial Intelligence), did an in-depthinterview with me about philosophical progress, in which he prodded me to expand on certain comments in Why Philosophers Should Care About Computational Complexity and The Ghost in the Quantum Turing Machine. Here are (abridged versions of) Lukes five questions:
1. Why are you so interested in philosophy? And what is the social value of philosophy, from your perspective?
2.What are some of your favorite examples of illuminating Q-primes [i.e., scientifically-addressable pieces of big philosophical questions] that were solved within your own field, theoretical computer science?
3.Do you wish philosophy-the-field would be reformed in certain ways? Would you like to see more crosstalk between disciplines about philosophical issues? Do you think that, as Clark Glymour suggested, philosophy departments should be defunded unless they produce work that is directly useful to other fields  ?
4.Suppose a mathematically and analytically skilled student wanted to make progress, in roughly the way you describe, on the Big Questions of philosophy. What would you recommend they study? What should they read to be inspired? What skills should they develop? Where should they go to study?
5.Which object-level thinking tactics  do you use in your own theoretical (especiallyphilosophical) research? Are there tactics you suspect might be helpful, which you havent yet used much yourself?
For the answersor at least my answersclick here!
PS. In case you missed it before, Quantum Computing Since Democritus was chosen by Scientific American blogger Jennifer Ouellette (via the Time Lord, Sean Carroll) as the top physics book of 2013. Woohoo!!Merry Christmas!  My quantum computing research explained, using only the 1000 most common English words

[With special thanks to the Up-Goer Five Text Editor, which was inspired bythis xkcd]
I study computers that would work in a different way than any computer that we have today. These computers would be very small, and they would use facts about the world that are not well known to us from day to day life. No one has built one of these computers yetat least, we dont think they have!but we can still reason about what they could do for us if we did build them.
How would these new computers work? Well, when you go small enough, you find that, in order to figure out what the chance is that something will happen, you need to both add and take away a whole lot of numbersone number for each possible way that the thing could happen, in fact. Whats interesting is, this means that the different ways a thing could happen can kill each other out, so that the thing never happens at all! I know it sounds weird, but the world of very small things has been known to work that way for almost a hundred years.
So, with the new kind of computer, the idea is to make the different ways each wrong answer could be reached kill each other out (with some of them pointing in one direction, some pointing in another direction), while the different ways that the right answer could be reached all point in more or less the same direction. If you can get that to happen, then when you finally look at the computer, youll find that theres a very good chance that youll see the right answer. And if you dont see the right answer, then you can just run the computer again until you do.
For some problemslike breaking a big number into its smallest parts (say, 43259 = 181  239)weve learned that the new computers would be much, much faster than we think any of todays computers could ever be. For other problems, however, the new computers dont look like theyd be faster at all. So a big part of my work is trying to figure out for which problems the new computers would be faster, and for which problems they wouldnt be.
You might wonder, why is it so hard to build these new computers? Why dont we have them already? This part is a little hard to explain using the words Im allowed, but let me try. It turns out that the new computers would very easily break. In fact, if the bits in such a computer were to get out in any waythat is, to work themselves into the air in the surrounding room, or whateverthen you could quickly lose everything about the new computer that makes it faster than todays computers. For this reason, if youre building the new kind of computer, you have to keep it very, very carefully away from anything that could cause it to lose its statebut then at the same time, you do have to touch the computer, to make it do the steps that will eventually give you the right answer. And no one knows how to do all of this yet. So far, people have only been able to use the new computers for very small checks, like breaking 15 into3  5. But people are working very hard today on figuring out how to do bigger things with the new kind of computer.
In fact, building the new kind of computer is so hard, that some people even believe it wont be possible! But my answer to them is simple. If its not possible, then thats even more interesting to me than if it is possible! And either way, the only way I know to find out the truth is to try it and see what happens.
Sometimes, people pretend that they already built one of these computers even though they didnt. Or they say things about what the computers could do that arent true. I have to admit that, even though I dont really enjoy it, I do spend a lot of my time these days writing about why those people are wrong.
Oh, one other thing. Not long from now, it might be possible to build computers that dont do everything that the new computers could eventually do, but that at least do some of it. Like, maybe we could use nothing but light and mirrors to answer questions that, while not important in and of themselves, are still hard to answer using todays computers. That would at least show that we can do something thats hard for todays computers, and it could be a step along the way to the new computers. Anyway, thats what a lot of my own work has been about for the past four years or so.
Besides the new kind of computers, Im also interested in understanding what todays computers can and cant do. The biggest open problem about todays computers could be put this way: if a computer can check an answer to a problem in a short time, then can a computer also find an answer in a short time? Almost all of us think that the answer is no, but no one knows how to show it. Six years ago, another guy and I figured out one of the reasons why this question is so hard to answer: that is, why the ideas that we already know dont work.
Anyway, I have to go to dinner now. I hope you enjoyed this little piece about the kind of stuff that I work on.BosonSampling Lecture Notes from Rio

Update (January 3): Theres now a long interview with me about quantum computingin theWashington Post (or at least, on their website). The interview accompanies their lead article about quantum computing and the NSA, which also quotes me (among many others), and which reportsunsurprisinglythat the NSA is indeed interested in building scalable quantum computers but, based on the Snowden documents, appears to be quite far from that goal.
(Warning: The interview contains a large number of typos and other errors, which might have arisen from my infelicities in speaking or the poor quality of the phone connection. Some were corrected but others remain.)

The week before last, I was in Rio de Janeiro to give a mini-course on Complexity Theory and Quantum Optics at theInstituto de Fsica of the Universidade Federal Fluminense. Next week Ill be giving a similar course at the Jerusalem Winter School on Quantum Information.
In the meantime, my host in Rio, Ernesto Galvo, and others were kind enough to make detailed, excellent notes for my five lectures in Rio. You can click the link in the last sentence to get them, or here are links for the five lectures individually:



Lecture 1: The Extended Church-Turing Thesis
Lecture 2: Classical and Quantum Complexity Theory
Lecture 3: Linear Optics and Exact BosonSampling
Lecture 4: KLM, Postselection, and Approximate BosonSampling
Lecture 5: Scalability and Verification of BosonSampling Devices



If you have questions or comments about the lectures, leave them here (since I might not check the quantumrio blog).
One other thing: I can heartily recommend a trip to Rio to anyone interested in quantum informationor, for that matter, to anyone interested in sunshine, giant Jesus statues, or (especially) fruit juices youve never tasted before. My favorite from among the latter was acerola. Also worth a try are caja, mangaba, guarana, umbu, seriguela, amora, and fruta do conde juicesas well as caju and cacao, even though they taste almost nothing like the more commercially exportable products from the same plants (cashews and chocolate respectively). I didnt like cupuau or graviola juices. Thanks so much to Ernesto and everyone else for inviting me (not just because of the juice).
Update (January 2): You can now watch videos of my mini-course at the Jerusalem Winter School here.



Lecture 1: The Extended Church-Turing Thesis
Lecture 2: Classical and Quantum Complexity Theory
Lecture 3: Linear Optics and Exact BosonSampling
Lecture 4: KLM, Approximate BosonSampling, and Experimental Issues



Videos of the other talks at the Jerusalem Winter School are available from the same site (just scroll through them on the right).What happens when an unstoppable PR force hits an NP-hard problem?  The answers getting clearer

Update (Jan. 23): Daniel Lidar, one of the authors of the Defining and detecting paper, was kind enough to email me his reactions to this post. While he thought the post was generally a very nice summary of their paper, he pointed out one important oversight in my discussion. Ironically, this oversight arose from my desire to bend over backwards to be generous to D-Wave! Specifically, I claimed that there were maybe ~10% of randomly-chosen 512-qubit problem instances on which the D-Wave Two slightly outperformed the simulated annealing solver (compared to ~75% where simulated annealing outperformed the D-Wave Two), while also listing several reasons (such as the minimum annealing time, and the lack of any characterization of the good instances) why that speedup is likely to be entirely an artifact. I obtained the ~10% and ~75% figures by eyeballing Figure 7 in the paper, and looking at which quantiles were just above and just below the 100 line when N=512.
However, I neglected to mention that even the slight speedup on ~10% of instances, only appears when one looks at the quantiles of ratio: in other words, when one plots the probability distribution of [Simulated annealing time / D-Wave time] over all instances, and then looks at (say) the ~10% of the distribution thats best for the D-Wave machine. The slight speedup disappears when one looks at the ratio of quantiles: that is, when one (say) divides the amount of time that simulated annealing needs to solve its best 10% of instances, by the amount of time that the D-Wave machine needs to solve its best 10%. AndRnnow et al. give arguments in their paper that ratio of quantiles is probably the more relevant performance comparison than quantiles of ratio. (Incidentally, the slight speedup on a few instances also only appears for certain values of the parameter r, which controls how many possible settings there are for each coupling. Apparently it appears for r=1, but disappears for r=3 and r=7thereby heightening ones suspicion that were dealing with an artifact of the minimum annealing time or something like that, rather than a genuine speedup.)
Theres one other important point in the paper that I didnt mention: namely, all the ratios of simulated annealing time to D-Wave time are normalized by 512/N, where N is the number of spins in the instance being tested. In this way, one eliminates the advantages of the D-Wave machine that come purely from its parallelism (which has nothing whatsoever to do with quantumness, and which could easily skew things in D-Waves favor if not controlled for), while still not penalizing the D-Wave machine in absolute terms.

A few days ago, a group of nine authors (Troels Rnnow, Zhihui Wang, Joshua Job, Sergio Boixo, Sergei Isakov, David Wecker, John Martinis, Daniel Lidar, and Matthias Troyer) released their long-awaited arXiv preprint Defining and detecting quantum speedup, which contains the most thorough performance analysis of the D-Wave devices to date, and which seems to me to set a new standard of care for any future analyses along these lines. Notable aspects of the paper: it uses data from the 512-qubit machine (a previous comparison had been dismissed by D-Waves supporters because it studied the 128-qubit model only); it concentrates explicitly from the beginning on comparisons of scaling behavior between the D-Wave devices and comparable classical algorithms, rather than getting sidetracked by other issues; and it includes authors from both USC and Googles Quantum AI Lab, two places that have made large investments in D-Waves machines and have every reason to want to see them succeed.
Let me quote the abstract in full:
The development of small-scale digital and analog quantum devices raises the question of how to fairly assess and compare the computational power of classical and quantum devices, and of how to detect quantum speedup. Here we show how to define and measure quantum speedup in various scenarios, and how to avoid pitfalls that might mask or fake quantum speedup. We illustrate our discussion with data from a randomized benchmark test on a D-Wave Two device with up to 503 qubits. Comparing the performance of the device on random spin glass instances with limited precision to simulated classical and quantum annealers, we find no evidence of quantum speedup when the entire data set is considered, and obtain inconclusive results when comparing subsets of instances on an instance-by-instance basis. Our results for one particular benchmark do not rule out the possibility of speedup for other classes of problems and illustrate that quantum speedup is elusive and can depend on the question posed.
Since the paper is exceedingly well-written, and since I have maybe an hour before Im called back to baby duty, my inclination is simply to ask people to RTFP rather than writing yet another long blog post. But maybe there are four points worth calling attention to:

The paper finds, empirically, that the time needed to solve random size-N instances of the quadratic binary optimization (QUBO) problem on D-Waves Chimera constraint graph seems to scale like exp(cN) for some constant cand that this is true regardless of whether one attacks the problem using the D-Wave Two, quantum Monte Carlo (i.e., a classical algorithm that tries to mimic the native physics of the machine), or an optimized classical simulated annealing code. Notably, exp(cN) is just what one would have predicted from theoretical arguments based on treewidth; and the constant c doesnt appear to be better for the D-Wave Two than for simulated annealing.
The last sentence of the abstract (Our results do not rule out the possibility of speedup for other classes of problems) is, of course, the reed on which D-Waves supporters will now have to hang their hopes. But note that its unclear what experimental results couldeverrule out the possibility of speedup for other classes of problems. (No matter how many wrong predictions a psychic has made, the possibility remains that shed be flawless at predicting the results of Croatian ping-pong tournaments) Furthermore, like with previous experiments, the instances tested all involved finding ground states for random coupling configurations of the D-Wave machines own architecture. In other words, this was a set of instances where one might have thought, a priori, that the D-Wave machine would have an immense home-field advantage. Thus, one really needs to look more closely, to see whether theres any positive evidence for an asymptotic speedup by the D-Wave machine.
Here, for D-Wave supporters, the biggest crumb the paper throws is that, if one considers only the ~10% of instances on which the D-Wave machine does best, then the machine does do slightly better on those instances than simulated annealing does. (Conversely, simulated annealing does better than the D-Wave machine on the ~75% of instances on which it does best.) Unfortunately, no one seems to know how to characterize the instances on which the D-Wave machine will do best: one just has to try it and see what happens! And of course, its extremely rare that two heuristic algorithms will succeed or fail on exactly the same set of instances: its much more likely that their performances will be correlated, but imperfectly. So its unclear, at least to me, whether this finding represents anything other than the noise that would inevitably occur even if one classical algorithm were pitted against another one.
As the paper points out, theres also a systematic effect that biases results in the D-Wave Twos favor, if one isnt careful. Namely, the D-Wave Two has a minimum annealing time of 20 microseconds, which is often greater than the optimum annealing time, particularly for small instance sizes. The effect of that is artificially to increase the D-Wave Twos running time for small instances, and thereby make its scalingbehavior look better than it really is. The authors say they dont know whether even the D-Wave Twos apparent advantage for its top 10% of instances will persist after this effect is fully accounted for.

Those seeking something less technical might want to check out anexcellent recent article in Inc.by Will Bourne, entitled D-Waves dream machine (D-Wave thinks it has built the first commercial quantum computer. Mother Nature has other ideas). Wisely, Bourne chose not to mention me at all in this piece. Instead, he gradually builds a skeptical case almost entirely on quotes from people like Seth Lloyd and Daniel Lidar, who one might have thought would be more open to D-Waves claims. Bournes piece illustrates that it is possible for the mainstream press to get the D-Wave story pretty much right, and that you dont even need a physics background to do so: all you need is a willingness to commit journalism.
Oh. Id be remiss not to mention that, in the few days between the appearance of this paper and my having a chance to write this post, two other preprints of likely interest to the Shtetl-Optimized commentariat showed up on quant-ph. The first, by a large list of authors mostly from D-Wave, is called Entanglement in a quantum annealing processor. This paper presents evidence for a point that many skeptics (including me) had been willing to grant for some time: namely, that the states generated by the D-Wave machines contain some nonzero amount of entanglement. (Note that, because of a technical property called stoquasticity, such entanglement is entirely compatible with the machines continuing to be efficiently simulable on a classical computer using Quantum Monte Carlo.) While it doesnt address the performance question at all, this paper seems like a perfectly fine piece of science.
From the opposite side of the (eigen)spectrum comes the latest preprint by QC skeptic Michel Dyakonov, entitledProspects for quantum computing: Extremely doubtful. Ironically, Dyakonov and D-Wave seem to agree completely about the irrelevance of fault-tolerance and other insights from quantum computing theory. Its just that D-Wave thinks QC can work even without the theoretical insights, whereas Dyakonov thinks that QC cant work even with the insights. Unless I missed it, theres no new scientific content in Dyakonovs article. Its basically a summary of some simple facts about QC and quantum fault-tolerance, accompanied by sneering asides about how complicated and implausible it all sounds, and how detached from reality the theorists are.
And as for the obvious comparisons to previous complicated and implausible technologies, like (say) classical computing, or heavier-than-air flight, or controlled nuclear fission? Dyakonov says that such comparisons are invalid, because they ignore the many technologies proposed in previous eras that didnt work. Whats striking is how little he seems to care about whythe previous technologies failed: was it because they violated clearly-articulated laws of physics? Or because there turned out to be better ways to do the same things? Or because the technologies were simply too hard, too expensive, or too far ahead of their time? Supposing QC to be impossible, which of those is the reason for the impossibility? Since were not asking about something arbitrary here (like teaching a donkey to read), but rather about the computational power of Nature itself, isnt it of immense scientific interest to know the reason for QCs impossibility? How does Dyakonov propose to learn the reason, assuming he concedes that he doesnt already know it?
(As Ive said many times, Id support even the experiments that D-Wave was doing, if D-Wave and its supporters would only call them for what they were: experiments. Forays into the unknown. Attempts to find out what happens when a particular speculative approach is thrown at NP-hard optimization problems. Its only when people obfuscate the results of those experiments, in order to claim something as commercially useful that quite obviously isnt yet, that they leave the realm of science, and indeed walk straight into the eager jaws of skeptics like Dyakonov.)
Anyway, since we seem to have circled back to D-Wave, Id like to end this post by announcing my second retirement as Chief D-Wave Skeptic. The first time I retired, it was because I mistakenly thought that D-Wave had fundamentally changed, and would put science ahead of PR from that point forward. (The truth seems to be that there were, and are, individuals at D-Wave committed to science, but others who remain PR-focused.) This time, Im retiring for a different reason: because scientists like the authors of the Defining and detecting preprint, and journalists like Will Bourne, are doing my job better than I ever did it. If the D-Wave debate were the American Civil War, then my role would be that of the frothy-mouthed abolitionist pamphleteer: someone who repeats over and over points that are fundamentally true, but in a strident manner that serves only to alienate fence-sitters and allies. As I played my ineffective broken record, the Wave Power simply moved from one triumph to another, expanding its reach to Google, NASA, Lockheed Martin, and beyond. I must have looked like a lonely loon on the wrong side of history.
But today the situation is different. Today Honest Abe and his generals (Honest Matthias and his coauthors?) are meeting the Wave Power on the battlefield of careful performance comparisons against Quantum Monte Carlo and simulated annealing. And while the battles might continue all the way to 2000 qubits or beyond, the results so far are not looking great for the Wave Power. The intractability of NP-complete problemsthat which we useless, ivory-tower theorists had prophesied years ago, to much derision and laughterwould seem to be rearing its head. So, now that the bombs are bursting and the spins decohering in midair, what is there for a gun-shy pampleteer like myself to do but sit back and watch it all play out?
Well, and maybe blog about it occasionally. But not as Chief Skeptic, just as another interested observer.Retiring falsifiability?  A storm in Russells teacup

My good friend Sean Carroll took a lot of flak recently for answering this years Edge question, What scientific idea is ready for retirement?, with Falsifiability, and for using string theory and the multiverse as examples of why science needs to break out of its narrow Popperian cage. For more, seethis blog post of Seans, where one commenter after another piles on the beleaguered dude for his abandonment of science and reason themselves.
My take, for whatever its worth, is that Sean and his critics are both right.
Sean is right that falsifiability is a crude slogan that fails to capture what science really aims at. As a doofus example, the theory that zebras exist is presumably both true and scientific, but its not falsifiable: if zebras didnt exist, there would be no experiment that proved their nonexistence. (And thats to say nothing of empirical claims involving multiple nested quantifiers: e.g., for every physical device that tries to solve the Traveling Salesman Problem in polynomial time, there exists an input on which the device fails.) Less doofusly, a huge fraction of all scientific progress really consists ofmathematical or computational derivationsfrom previously-accepted theoriesand, as such, has no falsifiable content apart from the theories themselves. So, do workings-out of mathematical consequences count as science? In practice, the Nobel committee says sure they do, but only if the final results of the derivations are directly confirmed by experiment. Far better, it seems to me, to say that science is a search for explanations that do essential and nontrivial work, within the network of abstract ideas whose ultimate purpose to account for our observations. (On this particular question, I endorse everything David Deutsch has to say inThe Beginning of Infinity, which you should read if you havent.)
On the other side, I think Seans critics are right that falsifiability shouldnt be retired. Instead, falsifiabilitys portfolio should be expanded, with full-time assistants (like explanatory power) hired to lighten falsifiabilitys load.
I also, to be honest, dont see that modern philosophy of science has advanced much beyond Popper in its understanding of these issues. Last year, I did something weird and impulsive: I read Karl Popper. Given all the smack people talk about him these days, I was pleasantly surprised by the amount of nuance, reasonableness, and just general getting-it that I found. Indeed, I found a lotmore of those things in Popper than I found in his latter-day overthrowers Kuhn and Feyerabend. For Popper (if not for some of his later admirers), falsifiability was not a crude bludgeon. Rather, it was the centerpiece of a richly-articulated worldview holding that millennia of human philosophical reflection had gotten it backwards: the question isnt how to arrive at the Truth, but rather how to eliminate error. Which sounds kind of obvious, until I meet yet another person who rails to me about how empirical positivism cant provide its own ultimate justification, and should therefore be replaced by the persons favorite brand of cringe-inducing ugh.
Oh, I also think Sean might have made a tactical error in choosing string theory and the multiverse as his examples for why falsifiability needs to be retired. For it seems overwhelmingly likely to me that the following two propositions are both true:
1. Falsifiability is too crude of a concept to describe how science works.
2. In the specific cases of string theory and the multiverse, a dearth of novel falsifiable predictions really is a big problem.
As usual, the best bet is to use explanatory power as our criterionin which case, Id say string theory emerges as a complex and evolving story. On one end, there are insights like holography and AdS/CFT, which seem clearly to do explanatory work, and which Id guess will stand as permanent contributions to human knowledge, even if the whole foundations on which they currently rest get superseded by something else. On the other end, theres the idea, championed by a minority of string theorists and widely repeated in the press, that the anthropic principle applied to different patches of multiverse can be invoked as a sort of get-out-of-jail-free card, to rescue a favored theory from earlier hopes of successful empirical predictions that then failed to pan out. I wouldnt know how to answer a layperson who asked why that wasnt exactly the sort of thing Sir Karl was worried about, and for good reason.
Finally, not that Edge asked me, but Id say the whole notions of determinism and indeterminism in physics are past ready for retirement. I cant think of any work they do, that isnt better done by predictability and unpredictability.More tweets

Update (Feb. 4): After Luke Muelhauser of MIRI interviewed me about philosophical progress, Luke asked me for other people to interview about philosophy and theoretical computer science.  I suggested my friend and colleague Ronald de Wolf of the University of Amsterdam, and Im delighted that Luke took me up on it.  Heres the resulting interview, which focuses mostly on quantum computing (with a little Kolmogorov complexity and Occams Razor thrown in).  I read the interview with admiration (and hoping to learn some tips): Ronald tackles each question with more clarity, precision, and especially levelheadedness than I would.
Another Update: Jeff Kinne asked me to post a link to a forum about the future of the Conference on Computational Complexity (CCC)and in particular, whether it should continue to be affiliated with the IEEE.  Any readers who have ever had any involvement with the CCC conference are encouraged to participate.  You can read all about what the issues are in a manifesto written by Dieter van Melkebeek.
Yet Another Update: Some people might be interested in my response to Geordie Roses response to the Shin et al. paper about a classical model for the D-Wave machine.

How Quantum is the D-Wave Machine? by Shin, Smith, Smolin, Vazirani goo.gl/JkLg0l  was previous skepticism too GENEROUS to D-Wave?
D-Wave not of broad enough interest? OK then, try AM with Multiple Merlins by Dana Moshkovitz, Russell Impagliazzo, and me goo.gl/ziSUz9
Remarks on the Physical Church-Turing Thesis  my talk at the FQXi conference in Vieques, Puerto Rico is now on YouTube goo.gl/kAd9TZ
Cool new SciCast site (scicast.org) lets you place bets on P vs NP, Unique Games Conjecture, etc. But glitches remain to be ironed outTIMEs cover story on D-Wave: A case study in the conventions of modern journalism

This morning, commenter rrtucci pointed me to TIME Magazines cover story about D-Wave (yes, in todays digital media environment, I need Shtetl-Optimized readers to tell me whats on the cover of TIME). rrtucci predicted that, soon after reading the article, Id be hospitalized with a severe stress-induced bleeding ulcer. Undeterred, I grit my teeth, paid the $5 to go behind the paywall, and read the article.
The article, by Lev Grossman, could certainly be a lot worse. If you get to the end, it discusses the experiments by Matthias Troyers group, and it makes clear the lack of any practically-relevant speedup today from the D-Wave devices. It also includes a few skeptical quotes:
In quantum computing, we have to be careful what we mean by utilizing quantum effects,' says Monroe, the University of Maryland scientist, whos among the doubters. This generally means that we are able to store superpositions of information in such a way that the system retains its fuzziness, or quantum coherence, so that it can perform tasks that are impossible otherwise. And by that token there is no evidence that the D-Wave machine is utilizing quantum effects.
One of the closest observers of the controversy has been Scott Aaronson, an associate professor at MIT and the author of a highly influential quantum-computing blog [aww, shucks SA]. He remains, at best, cautious. Im convinced  that interesting quantum effects are probably present in D-Waves devices, he wrote in an email. But Im not convinced that those effects, right now, are playing any causal role in solving any problems faster than we could solve them with a classical computer. Nor do I think theres any good argument that D-Waves current approach, scaled up, will lead to such a speedup in the future. It might, but theres currently no good reason to think so.
Happily, the quote from me is something that I actually agreed with at the time I said it! Today, having read the Shin et al. paperwhich hadnt yet come out when Grossman emailed meI might tone down the statement Im convinced  that interesting quantum effects are probably present to something like: theres pretty good evidence for quantum effects like entanglement at a local level, but at the global level we really have no idea.
Alas, ultimately I regard this article as another victim (through no fault of the writer, possibly) of the strange conventions of modern journalism. Maybe I can best explain those conventions with a quickie illustration:
MAGIC 8-BALL: THE RENEGADE MATH WHIZ WHO COULD CHANGE NUMBERS FOREVER
An eccentric billionaire, whose fascinating hobbies include nude skydiving and shark-taming, has been shaking up the scientific world lately with his controversial claim that 8+0 equals 17 [ six more pages about the billionaire redacted ] It must be said that mathematicians, who we reached for comment because were diligent reporters, have tended to be miffed, skeptical, and sometimes even sarcastic about the billionaires claims. Not surprisingly, though, the billionaire and his supporters have had some dismissive comments of their own about the mathematicians. So, which side is right? Or is the truth somewhere in the middle? At this early stage, its hard for an outsider to say. In the meantime, the raging controversy itself is reason enough for us to be covering this story using this story template. Stay tuned for more!
As shown (for example) by Will Bournes story in Inc. magazine, its possible for a popular magazine to break out of the above template when covering D-Wave, or at least bend it more toward reality. But its not easy.
More detailed comments:

The article gets off on a weird foot in the very first paragraph, describing the insides of D-Waves devices as the coldest place in the universe. Err, 20mK is pretty cold, but colder temperatures are routinely achieved in many other physics experiments. (Are D-Waves the coldest current, continuously-operating experiments, or something like that? I dunno: counterexamples, anyone? Ive learned from experts that theyre not, not even close. I heard from someone who had a bunch of dilution fridges running at 10mK in the lab he was emailing me from)


The article jumps enthusiastically into the standard Quantum Computing = Exponential Parallelism Fallacy (the QC=EPF), which is so common to QC journalism that I dont know if its even worth pointing it out anymore (but here I am doing so).


Commendably, the article states clearly that QCs would offer speedups only for certain specific problems, not others; that D-Waves devices are designed only for adiabatic optimization, and wouldnt be useful (e.g.) for codebreaking; and that even for optimization, D-Waves hardware isnt powerful enough or well enough understood to show serious quantum speedup yet. But theres a crucial further point that the article doesnt make: namely, that we have no idea yet whether adiabatic optimization is something where quantum computerscan give any practically-important speedup. In other words, even if you could implement adiabatic optimization perfectlyat zero temperature, with zero decoherencewe still dont knowwhether theres any quantum speedup to be had that way, for any of the nifty applications that the article mentions: software design, tumor treatments, logistical planning, the stock market, airlines schedules, the search for Earth-like planets in other solar systems, and in particular machine learning. In that respect, adiabatic optimization is extremely different from (e.g.) Shors factoring algorithm or quantum simulation: things where weknow how much speedup we could get, at least compared to the best currently-known classical algorithms. But I better stop now, since I feel myself entering an infinite loop (and I didnt even need the adiabatic algorithm to detect it).Umesh Vazirani responds to Geordie Rose

You might recall that Shin, Smith, Smolin, and Vazirani posted a widely-discussed preprint a week ago, questioning the evidence for large-scale quantum behavior in the D-Wave machine. Geordie Rose responded here. Tonight, in a Shtetl-Optimized exclusive scoop, I bring you Umesh Vaziranis response to Geordies comments. Without further ado:

Even a cursory reading of our paper will reveal that Geordie Rose is attacking a straw man. Let me quickly outline the main point of our paper and the irrelevance ofRoses comments:
To date the Boixo et al paper was the only serious evidence in favor of largescale quantum behavior by the D-Wave machine. We investigated their claimsand showed that there are seriousproblems with their conclusions. Theirconclusions were based on the close agreement between the input-outputdata from D-Wave and quantum simulated annealing, and their inability despiteconsiderable effort to find any classical model that agreed with the input-outputdata. In our paper, we gave a very simpleclassical model of interacting magnets that closely agreed with the input-output data. We stated that our results impliedthat it is premature to conclude that D-Wave machine exhibits large scale quantum behavior.
Rose attacks our paper for claiming that D-Wave processors are inherently classical,and can be described by a classical model with no need to invoke quantum mechanics. A reading of our paper will make it perfectly clear that this is not a claim that we make. We stateexplicitly It is worth emphasizing that the goal of this paper is not toprovide a classical model for the D-Wave machine,  The classical model introduced here is useful for the purposes of studying the large-scale algorithmic featuresof the D-Wave machine. The task of finding an accurate model for the D-Wavemachine (classical, quantum or otherwise), would be better pursued with direct access, not only to programming the D-Wave machine, but also to its actual hardware.
Rose goes on to point to a large number of experiments conducted by D-Wave to provesmall scale entanglement over 2-8 qubits and criticizes our paper for not trying to modelthose aspects of D-Wave. But such small scale entanglement properties are not directly relevantto prospects for a quantum speedup. Therefore we were specifically interested in claimsabout the large scale quantum behavior of D-Wave. There was exactly one such claim,which we duly investigated, and it did not stand up to scrutiny.Recent papers by Susskind and Tao illustrate the long reach of computation

Most of the time, Im a crabby, cantankerous ogre, whose only real passion in life is using this blog to shoot down the wrong ideas of others. But alas, try as I might to maintain my reputation as a pure bundle of seething negativity, sometimes events transpire that pierce my crusty exterior. Maybe its because Im in Berkeley now, visiting the new Simons Institute for Theory of Computing during its special semester on Hamiltonian complexity. And its tough to keep up my acerbic East Coast skepticism of everything new in the face of all this friggin sunshine. (Speaking of which, if youre in the Bay Area and wanted to meet me, this weeks the week! Email me.) Or maybe its watching Lily running around, her face wide with wonder. If shes so excited by her discovery of (say) a toilet plunger or some lint on the floor, what right do I have not to be excited by actual scientific progress?
Which brings me to the third reason for my relatively-sunny disposition: two long and fascinating recent papers on the arXiv. What these papers have in common is that they use concepts from theoretical computer science in unexpected ways, while trying to address open problems at the heart of traditional, continuous physics and math. One paper uses quantum circuit complexity to help understand black holes; the other uses fault-tolerant universal computation to help understand the Navier-Stokes equations.
Recently, our always-pleasant string-theorist friend Lubo Motl described computational complexity theorists as extraordinarily nave (earlier, he also called us deluded and bigoted). Why? Because were obsessed with arbitrary, manmade concepts like the set of problems solvable in polynomial time, and especially because we assume things we havent yet proved such as PNP. (Jokes about throwing stones from a glass houseor a stringy houseare left as exercises for the reader.) The two papers that I want to discuss today reflect a different perspective: one that regards computation as no more arbitrary than other central concepts of mathematics, and indeed, as something that shows up even in contexts that seem incredibly remote from it, from the AdS/CFT correspondence to turbulent fluid flow.

Our first paper is Computational Complexity and Black Hole Horizons, by Lenny Susskind. As readers of this blog might recall, last year Daniel Harlow and Patrick Hayden made a striking connection between computational complexity and the black-hole firewall question, by giving complexity-theoretic evidence that performing the measurement of Hawking radiation required for the AMPS experiment would require an exponentially-long quantum computation. In his new work, Susskind makes a different, and in some ways even stranger, connection between complexity and firewalls. Specifically, given an n-qubit pure state |, recall that the quantum circuit complexity of | is the minimum number of 2-qubit gates needed to prepare| starting from the all-|0 state. Then for reasons related to black holes and firewalls, Susskind wants to use the quantum circuit complexity of | as an intrinsic clock, to measure how long| has been evolving for. Last week, I had the pleasure of visiting Stanford, where Lenny spent several hours explaining this stuff to me. I still dont fully understand it, but since its arguable that no one (including Lenny himself) does, let me give it a shot.
My approach will be to divide into two questions. The first question is: why, in general (i.e., forgetting about black holes), might one want to use quantum circuit complexity as a clock? Here the answer is: because unlike most other clocks, this one should continue to tick for an exponentially long time!
Consider some standard, classical thermodynamic system, like a box filled with gas, with the gas all initially concentrated in one corner. Over time, the gas will diffuse across the box, in accord with the Second Law, until it completely equilibrates. Furthermore, if we know the laws of physics, then we can calculate exactly how fast this diffusion will happen. But this implies that we can use the box as a clock! To do so, wed simply have to measure how diffused the gas was, then work backwards to determine how much time had elapsed since the gas started diffusing.
But notice that this clock only works until the gas reaches equilibriumi.e., is equally spread across the box. Once the gas gets to equilibrium, which it does in a reasonably short time, it just stays there (at least until the next Poincar recurrence time). So, if you see the box in equilibrium, theres no measurement you could makeor certainly no practical measurementthat would tell you how long its been there. Indeed, if we model the collisions between gas particles (and between gas particles and the walls of the box) as random events, then something even stronger is true. Namely, the probability distribution over all possible configurations of the gas particles will quickly converge to an equilibrium distribution. And if you all you knew was that the particles were in the equilibrium distribution, then theres no property of their distribution that you could point tonot even an abstract, unmeasurable propertysuch that knowing that property would tell you how long the gas had been in equilibrium.
Interestingly, something very different happens if we consider a quantum pure state, in complete isolation from its environment. If you have some quantum particles in a perfectly-isolating box, and you start them out in a simple state (say, with all particles unentangled and in a corner), then they too will appear to diffuse, with their wavefunctions spreading out and getting entangled with each other, until the system reaches equilibrium. After that, there will once again be no simple measurement you can makesay, of the density of particles in some particular locationthat will give you any idea of how long the box has been in equilibrium. On the other hand, the laws of unitary evolution assure us that the quantum state is still evolving, rotating serenely through Hilbert space, just like it was before equilibration! Indeed, in principle you could even measure that the evolution was still happening, but to do so, youd need to perform an absurdly precise and complicated measurementone that basically inverted the entire unitary transformation that had been applied since the particles started diffusing.
Lenny now asks the question: if the quantum state of the particles continues to evolve even after equilibration, then what physical quantity can we point to as continuing to increase? By the argument above, it cant be anything simple that physicists are used to talking about, like coarse-grained entropy. Indeed, the most obvious candidate that springs to mind, for a quantity that should keep increasing even after equilibration, is just the quantum circuit complexity of the state! If theres no magic shortcut to simulating this systemthat is, if the fastest way to learn the quantum state at time T is just to run the evolution equations forward for T time stepsthen the quantum circuit complexity will continue to increase linearly with T, long after equilibration. Eventually, the complexity will max out at ~cn, where n is the number of particles, simply because (neglecting small multiplicative terms) the dimension of the Hilbert space is always an upper bound on the circuit complexity. After even longer amounts of timelike ~cc^nthe circuit complexity will dip back down (sometimes even to 0), as the quantum state undergoes recurrences. But both of those effects only occur on timescales ridiculously longer than anything normally relevant to physics or everyday life.
Admittedly, given the current status of complexity theory, theres little hope of proving unconditionally that the quantum circuit complexity continues to rise until it becomes exponential, when some time-independent Hamiltonian is continuously applied to the all-|0 state. (If we could prove such a statement, then presumably we could also prove PSPACEBQP/poly.) But maybe we could prove such a statement modulo a reasonable conjecture. And we do have suggestive weaker results. In particular (and as I just learned this Friday), in 2012 Brando, Harrow, and Horodecki, building on earlier work due to Low, showed that, if you apply S>>n random two-qubit gates to n qubits initially in the all-|0 state, then with high probability, not only do you get a state with large circuit complexity, you get a state that cant even be distinguished from the maximally mixed state by any quantum circuit with at most ~S1/6 gates.
OK, now on to the second question: what does any of this have to do with black holes? The connection Lenny wants to make involves the AdS/CFT correspondence, the duality between two completely different-looking theories thats been the rage in string theory since the late 1990s. On one side of the ring is AdS (Anti de Sitter), a quantum-gravitational theory in D spacetime dimensionsone where black holes can form and evaporate, etc., but on the other hand, the entire universe is surrounded by a reflecting boundary a finite distance away, to help keep everything nice and unitary. On the other side is CFT (Conformal Field Theory): an ordinary quantum field theory, with no gravity, that lives only on the (D-1)-dimensional boundary of the AdS space, and not in its interior bulk. The claim of AdS/CFT is that despite how different they look, these two theories are equivalent, in the sense that any calculation in one theory can be transformed to a calculation in the other theory that yields the same answer. Moreover, we get mileage this way, since a calculation thats hard on the AdS side is often easy on the CFT side and vice versa.
As an example, suppose were interested in what happens inside a black holesay, because we want to investigate the AMPS firewall paradox. Now, figuring out what happens inside a black hole (or even on or near the event horizon) is a notoriously hard problem in quantum gravity; thats why people have been arguing about firewalls for the past two years, and about the black hole information problem for the past forty! But what if we could put our black hole in an AdS box? Then using AdS/CFT, couldnt we translate questions about the black-hole interior to questions about the CFT on the boundary, which dont involve gravity and which would therefore hopefully be easier to answer?
In fact people have tried to do thatbut frustratingly, they havent been able to use the CFT calculations to answer even the grossest, most basic questions about what someone falling into the black hole would actually experience. (For example, would that person hit a firewall and die immediately at the horizon, or would she continue smoothly through, only dying close to the singularity?) Lennys paper explores a possible reason for this failure. It turns out that the way AdS/CFT works, the closer to the black holes event horizon you want to know what happens, the longer you need to time-evolve the quantum state of the CFT to find out. In particular, if you want to know whats going on at distance from the event horizon, then you need to run the CFT for an amount of time that grows like log(1/). And what if you want to know whats going on inside the black hole? In line with the holographic principle, it turns out that you can express an observable inside the horizon by an integral over the entire AdS space outside the horizon. Now, that integral will include a part where the distance from the event horizon goes to 0solog(1/), and hence the complexity of the CFT calculation that you have to do, diverges to infinity. For some kinds of calculations, the 0 part of the integral isnt very important, and can be neglected at the cost of only a small error. For other kinds of calculations, unfortunatelyand in particular, for the kind that would tell you whether or not theres a firewallthe0 part is extremely important, and it makes the CFT calculation hopelessly intractable.
Note that yes, we even need to continue the integration for  much smaller than the Planck lengthi.e., for so-called transplanckian distances! As Lenny puts it, however:
For most of this vast sub-planckian range of scales we dont expect that the operational meaning has anything to do with meter sticks  It has more to do with large times than small distances.
One could give this transplanckian blowup in computational complexity a pessimistic spin: darn, so its probably hopeless to use AdS/CFT to prove once and for all that there are no firewalls! But theres also a more positive interpretation: the interior of a black hole is protected from meddling by a thick armor of computational complexity. To explain this requires a digression about firewalls.
The original firewall paradox of AMPS could be phrased as follows: if you performed a certain weird, complicated measurement on the Hawking radiation emitted from a sufficiently old black hole, then the expected results of that measurement would be incompatible with also seeing a smooth, Einsteinian spacetime if you later jumped into the black hole to see what was there. (Technically, because youd violate the monogamy of entanglement.) If what awaited you behind the event horizon wasnt a classical black hole interior with a singularity in the middle, but an immediate breakdown of spacetime, then one says you wouldve hit a firewall.
Yes, it seems preposterous that firewalls would exist: at the least, it would fly in the face of everything people thought they understood for decades about general relativity and quantum field theory. But cruciallyand here I have to disagree with Stephen Hawkingone cant solve this problem by simply repeating the physical absurdities of firewalls, or by constructing scenarios where firewalls self-evidently dont arise. Instead, as I see it, solving the problem means giving an account of what actually happens when you do the AMPS experiment, or of what goes wrong when you try to do it.
On this last question, it seems to me that Susskind and Juan Maldacena achieved a major advance in their much-discussed ER=EPR paper last year. Namely, they presented a picture where, sure, a firewall arises (at least temporarily) if you do the AMPS experimentbut no firewall arises if you dont do the experiment! In other words, doing the experiment sends a nonlocal signal to the interior of the black hole (though you do have to jump into the black hole to receive the signal, so causality outside the black hole is still preserved). Now, how is it possible for your measurement of the Hawking radiation to send an instantaneous signal to the black hole interior, which might be light-years away from you when you measure? On Susskind and Maldacenas account, its possible because the entanglement between the Hawking radiation and the degrees of freedom still in the black hole, can be interpreted as creating wormholes between the two. Under ordinary conditions, these wormholes (like most wormholes in general relativity) are non-traversable: they pinch off if you try to send signals through them, so they cant be used for faster-than-light communication. However, if you did the AMPS experiment, then the wormholes would become traversable, and could carry a firewall (or an innocuous happy-birthday message, or whatever) from the Hawking radiation to the black hole interior. (Incidentally, ER stands for Einstein and Rosen, who wrote a famous paper on wormholes, while EPR stands for Einstein, Podolsky, and Rosen, who wrote a famous paper on entanglement. ER=EPR is Susskind and Maldacenas shorthand for their proposed connection between wormholes and entanglement.)
Anyway, these heady ideas raise an obvious question: how hard would it be to do the AMPS experiment? Is sending a nonlocal signal to the interior of a black hole via that experiment actually a realistic possibility? In their work a year ago on computational complexity and firewalls, Harlow and Hayden already addressed that question, though from a different perspective than Susskind. In particular, Harlow and Hayden gave strong evidence that carrying out the AMPS experiment would require solving a problem believed to be exponentially hard even for a quantum computer: specifically, a complete problem for QSZK (Quantum Statistical Zero Knowledge). In followup work (not yet written up, though see my talk at KITP and my PowerPoint slides), I showed that the Harlow-Hayden problem is actually at least as hard as inverting one-way functions, which is even stronger evidence for hardness.
All of this suggests that, even supposing we could surround an astrophysical black hole with a giant array of perfect photodetectors, wait ~1069 years for the black hole to (mostly) evaporate, then route the Hawking photons into a super-powerful, fault-tolerant quantum computer, doing the AMPS experiment (and hence, creating traversable wormholes to the black hole interior) still wouldnt be a realistic prospect, even if the equations formally allow it! Theres no way to sugarcoat this: computational complexity limitations seem to be the only thing protecting the geometry of spacetime from nefarious experimenters.
Anyway, Susskind takes that amazing observation of Harlow and Hayden as a starting point, but then goes off on a different tack. For one thing, he isnt focused on the AMPS experiment (the one involving monogamy of entanglement) specifically: he just wants to know how hard it is to do any experiment (possibly a different one) that would send nonlocal signals to the black hole interior. For another, unlike Harlow and Hayden, Susskind isnt trying to show that such an experiment would be exponentially hard. Instead, hes content if the experiment is merely polynomially hardbut in the same sense that (say) unscrambling an egg, or recovering a burned book from the smoke and ash, are polynomially hard. In other words, Susskind only wants to argue that creating a traversable wormhole would be thermodynamics-complete. A third, related, difference is that Susskind considers an extremely special model scenario: namely, the AdS/CFT description of something called the thermofield double state. (This state involves two entangled black holes in otherwise-separated spacetimes; according to ER=EPR, we can think of those black holes as being connected by a wormhole.) While I dont yet understand this point, apparently the thermofield double state is much more favorable for firewall production than a realistic spacetimeand in particular, the Harlow-Hayden argument doesnt apply to it. Susskind wants to show that even so (i.e., despite how easy weve made it), sending a signal through the wormhole connecting the two black holes of the thermofield double state would still require solving a thermodynamics-complete problem.
So thats the setup. What new insights does Lenny get? This, finally, is where we circle back to the view of quantum circuit complexity as a clock. Briefly, Lenny finds that the quantum state getting more and more complicated in the CFT descriptioni.e., its quantum circuit complexity going up and updirectly corresponds to the wormhole getting longer and longer in the AdS description. (Indeed, the length of the wormhole increases linearly with time, growing like the circuit complexity divided by the total number of qubits.) And the wormhole getting longer and longer is what makes it non-traversablei.e., what makes it impossible to send a signal through.
Why has quantum circuit complexity made a sudden appearance here? Because in the CFT description, the circuit complexity continuing to increase is the only thing thats obviously happening! From a conventional physics standpoint, the quantum state of the CFT very quickly reaches equilibrium and then just stays there. If you measured some conventional physical observablesay, the energy density at a particular pointthen it wouldnt look like the CFT state was continuing to evolve at all. And yet we know that the CFT state is evolving, for two extremely different reasons. Firstly, because (as we discussed early on in this post) unitary evolution is still happening, so presumably the states quantum circuit complexity is continuing to increase. And secondly, because in the dual AdS description, the wormhole is continuing to get longer!
From this connection, at least three striking conclusions follow:

That even when nothing else seems to be happening in a physical system (i.e., it seems to have equilibrated), the fact that the systems quantum circuit complexity keeps increasing can be physically relevant all by itself. We know that its physically relevant, because in the AdS dual description, it corresponds to the wormhole getting longer!
That even in the special case of the thermofield double state, the geometry of spacetime continues to be protected by an armor of computational complexity. Suppose that Alice, in one half of the thermofield double state, wants to send a message to Bob in the other half (which Bob can retrieve by jumping into his black hole). In order to get her message through, Alice needs to prevent the wormhole connecting her black hole to Bobs from stretching uncontrollablysince as long as it stretches, the wormhole remains non-traversable. But in the CFT picture, stopping the wormhole from stretching corresponds to stopping the quantum circuit complexity from increasing! And that, in turn, suggests that Alice would need to act on the radiation outside her black hole in an incredibly complicated and finely-tuned way. For generically, the circuit complexity of an n-qubit state should just continue to increase, the longer you run unitary evolution for, until it hits its exp(n) maximum. To prevent that from happening would essentially require freezing or inverting the unitary evolution applied by naturebut thats the sort of thing that we expect to be thermodynamics-complete. (How exactly do Alices actions in the bulk affect the evolution of the CFT state? Thats an excellent question that I dont understand AdS/CFT well enough to answer. All I know is that the answer involves something that Lenny calls precursor operators.)
The third and final conclusion is that there can be a physically-relevant difference between pseudorandom n-qubit pure states and truly random stateseven though, by the definition of pseudorandom, such a difference cant be detected by any small quantum circuit! Once again, the way to see the difference is using AdS/CFT. Its easy to show, by a counting argument, that almost all n-qubit pure states have nearly-maximal quantum circuit complexity. But if the circuit complexity is already maximal, that means in particular that its not increasing! Lenny argues that this corresponds to the wormhole between the two black holes no longer stretching. But if the wormhole is no longer stretching, then its vulnerable to firewalls (i.e., to messages going through!). It had previously been argued that random CFT states almost always correspond to black holes with firewallsand since the CFT states formed by realistic physical processes will look indistinguishable from random states, black holes that form under realistic conditions should generically have firewalls as well. But Lenny rejects this argument, on the ground that the CFT states that arise in realistic situations are not random pure states. And what distinguishes them from random states? Simply that they have non-maximal (and increasing) quantum circuit complexity!

Ill leave you with a question of my own about this complexity / black hole connection: one that Im unsure how to think about, but that perhaps interests me more than any other here. My question is: could you ever learn the answer to an otherwise-intractable computational problem by jumping into a black hole? Of course, youd have to really want the answerso much so that you wouldnt mind dying moments after learning it, or not being able to share it with anyone else! But never mind that. What I have in mind is first applying some polynomial-size quantum circuit to the Hawking radiation, then jumping into the black hole to see what nonlocal effect (if any) the circuit had on the interior. The fact that the mapping between interior and exterior states is so complicated suggests that there might be complexity-theoretic mileage to be had this way, but I dont know what. (Its also possible that you can get a computational speedup in special cases like the thermofield double state, but that a Harlow-Hayden-like obstruction prevents you from getting one with real astrophysical black holes. I.e., that for real black holes, youll just see a smooth, boring, Einsteinian black hole interior no matter what polynomial-size quantum circuit you applied to the Hawking radiation.)

If youre still here, the second paper I want to discuss today is Finite-time blowup for an averaged three-dimensional Navier-Stokes equation by Terry Tao. (See also the excellent Quanta article by Erica Klarreich.) Ill have much, much less to say about this paper than I did about Susskinds, but thats not because its less interesting: its only because I understand the issues even less well.
Navier-Stokes existence and smoothness is one of the seven Clay Millennium Problems (alongside P vs. NP, the Riemann Hypothesis, etc). The problem asks whether the standard, classical differential equations for three-dimensional fluid flow are well-behaved, in the sense of not blowing up (e.g., concentrating infinite energy on a single point) after a finite amount of time.
Expanding on ideas from his earlier blog posts and papers about Navier-Stokes (see here for the gentlest of them), Tao argues that the Navier-Stokes problem is closely related to the question of whether or not its possible to build a fault-tolerant universal computer out of water. Why? Well, its not the computational universality per se that matters, but if you could use fluid flow to construct general enough computing elementsresistors, capacitors, transistors, etc.then you could use those elements to recursively shift the energy in a given region into a region half the size, and from there to a region a quarter the size, and so on, faster and faster, until you got infinite energy density after a finite amount of time.
Strikingly, building on an earlier construction by Katz and Pavlovic, Tao shows that this is actually possible for an averaged version of the Navier-Stokes equations! So at the least, any proof of existence and smoothness for the real Navier-Stokes equations will need to notice the difference between the real and averaged versions. In his paper, though, Tao hints at the possibility (or dare one say likelihood?) that the truth might go the other way. That is, maybe the universal computer construction can be ported from the averaged Navier-Stokes equations to the real ones. In that case, wed have blowup in finite time for the real equations, and a negative solution to the Navier-Stokes existence and smoothness problem. Of course, such a result wouldnt imply that real, physical water was in any danger of blowing up! It would simply mean that the discrete nature of water (i.e., the fact that its made of H2O molecules, rather than being infinitely divisible) was essential to understanding its stability given arbitrary initial conditions.
So, what are the prospects for such a blowup result? Let me quote from Taos paper:
Once enough logic gates of ideal fluid are constructed, it seems that the main difficulties in executing the above program [to prove a blowup result for the real Navier-Stokes equations] are of a software engineering nature, and would be in principle achievable, even if the details could be extremely complicated in practice. The main mathematical difficulty in executing this fluid computing program would thus be to arrive at (and rigorously certify) a design for logical gates of inviscid fluid that has some good noise tolerance properties. In this regard, ideas from quantum computing (which faces a unitarity constraint somewhat analogous to the energy conservation constraint for ideal fluids, albeit with the key difference of having a linear evolution rather than a nonlinear one) may prove to be useful.
One minor point that Id love to understand is, what happens in two dimensions? Existence and smoothness are known to hold for the 2-dimensional analogues of the Navier-Stokes equations. If they also held for the averaged 2-dimensional equations, then it would follow that Taos universal computer must be making essential use of the third dimension. How? If I knew the answer to that, then Id feel for the first time like I had some visual crutch for understanding why 3-dimensional fluid flow is so complicated, even though 2-dimensional fluid flow isnt.
I see that, in blog comments here and here, Tao says that the crucial difference between the 2- and 3-dimensional Navier-Stokes equations arises from the different scaling behavior of the dissipation term: basically, you can ignore it in 3 or more dimensions, but you cant ignore it in 2. But maybe theres a more doofus-friendly explanation, which would start with some 3-dimensional fluid logic gate, and then explain why the gate has no natural 2-dimensional analogue, or why dissipation causes its analogue to fail.

Obviously, theres much more to say about both papers (especially the second) than I said in this post, and many people more knowledgeable than I am to say those things. But thats what the comments section is for. Right now Im going outside to enjoy the California sunshine.A trivial post

Why do academics feel the need to stuff their papers with nontrivial results? After all, if a paper is remembered decades after it was written, its almost always for a simple core idea  not for the extensions and applications that fill 90% of the papers bulk.
The nontriviality virus can infect even the greats: think of Leonid Levins famous paper on universal search. According to legend, the reason Levin was scooped by Cook and Karp is that he spent a year trying to prove Graph Isomorphism was NP-complete! You see, that wouldve been a deep, publication-worthy result, unlike the obvious fact that there exist natural NP-complete problems.
Heres a more recent example.  In my opinion, this 43-pager by Barak et al. is one of the sweetest computer science papers of the past decade. But what makes it so sweet is a two-sentence insight (my wording):
Theres no generic, foolproof way to obfuscate a computer program. For even if a program looked hopelessly unreadable, you could always feed it its own code as input, which is one thing you couldnt do if all you had was a black box with the same input/output behavior as the program in question.
So why did the authors go on for 43 more pages?
One possibility was suggested to me by Robin Hanson, an economist at George Mason who spews interesting ideas out of his nose and ears. Depending on your prejudices, you might see Robin as either a visionary futurist or a walking reductio ad absurdum of mainstream economic theory.  Either way, his web page will surprise and provoke you.
When I talked with Robin in August, he speculated that nontrivial results function mainly as certificates of smartness: that is, expensive, difficult-to-fake evidence that the author(s) of a paper are smart enough that their simple core idea is likely to be worth taking seriously. Without these certificates, the theory goes, we academics would be deluged by too many promising ideas to entertain them all  since even if the ideas are simple, it usually isnt simple to ascertain their worth.
Note that this theory differs from a more standard complaint, that academics fill their papers with nontrivial results for the sole purpose of getting them published. On Robins account, nontrivial results actually are useful to readers, just not in the way the paper advertises. Think of the author as a groom, the reader as a bride, and the nontrivial result as a wedding ring. The bride doesnt care about the actual ring, but she does care that the groom was rich and devoted enough to buy one.
One prediction of Robins theory would be that, once youve established your smartness within the community, you should be able to get papers published even if they contain only simple observations. Another prediction would be that, if youre very smart but emotionally attached to a simple idea, you should be able to buy exposure for your idea by encrusting it with nontrivialities. (As Robin remarked to me, everything in social science is either obvious or false; the only question is which.)
I dont have anything deeper to say about Robins theory, but Im enjoying the freedom to blog about it anyway.The Scientific Case for PNP

Out there in the wider worldOK, OK, among Lubo Motl, and a few others who comment on this blogthere appears to be a widespread opinion that PNP is just a fashionable dogma of the so-called experts, something thats no more likely to be true than false. The doubters can even point to at least one accomplished complexity theorist, Dick Lipton, who publicly advocates agnosticism about whether P=NP.
Of course, not all the doubters reach their doubts the same way. For Lipton, the thinking is probably something like: as scientists, we should be rigorously open-minded, and constantly question even the most fundamental hypotheses of our field. For the outsiders, the thinking is more like: computer scientists are just not very smartcertainly not as smart as real scientistsso the fact that they consider something a fundamental hypothesis provides no information of value.
Consider, for example, this comment of Ignacio Mosqueira:
If there is no proof that means that there is no reason a-priori to prefer your arguments over those [of] Lubos. Expertise is not enough. And the fact that Lubos is difficult to deal with doesnt change that.
In my response, I wondered how broadly Ignacio would apply the principle if theres no proof, then theres no reason to prefer any argument over any other one. For example, would he agree with the guy interviewed on Jon Stewart who earnestly explained that, since theres no proof that turning on the LHC will destroy the world, but also no proof that it wont destroy the world, the only rational inference is that theres a 50% chance it will destroy the world? (John Olivers deadpan response was classic: Im  not sure thats how probability works)
In a lengthy reply, Lubobites this bullet with relish and mustard. In physics, he agrees, or even in continuous mathematics that is more physics-wise, its possible to have justified beliefs even without proof. For example,he admits to a 99.9% probability that the Riemann hypothesis is true. But, he goes on, partial evidence in discrete mathematics just cannot exist. Discrete math and computer science, you see, are so arbitrary, manmade, and haphazard that every question is independent of every other; no amount of experience can give anyone any idea which way the next question will go.
No, Im not kidding. Thats his argument.
I couldnt help wondering: what about number theory? Arent the positive integers a discrete structure? And isnt the Riemann Hypothesis fundamentally about the distribution of primes? Or does the Riemann Hypothesis get counted as an honorary physics-wise continuous problem because it can also be stated analytically? But then what about Goldbachs Conjecture? Is Lubo50/50 on that one too? Better yet, what about continuous, analytic problems that are closely related to P vs. NP? For example, Valiants Conjecture says you cant linearly embed the permanent of an nn matrix as the determinant of an mm matrix, unless mexp(n). Mulmuley and others have connected this continuous cousin of PNP to issues in algebraic geometry, representation theory, and even quantum groups and Langlands duality. So, does that make it kosher? The more I thought about the proposed distinction, the less sense it made to me.
But enough of this. In the rest of this post,I want to explain why the odds that you should assign to PNP are more like 99% than they are like 50%. This post supersedes my 2006 post on the same topic, which I hereby retire. While that post was mostly OK as far as it went, I now feel like I can do a much better job articulating the central point. (And also, I made the serious mistake in 2006 of striving for literary eloquence and tongue-in-cheek humor. That works great for readers who already know the issues inside-and-out, and just want to be amused. Alas, it doesnt work so well for readers who dontknow the issues, are extremely literal-minded, and just want ammunition to prove their starting assumption that Im a doofus who doesnt understand the basics of his own field.)
So, OK, why should you believe PNP? Heres why:
Because, like any other successful scientific hypothesis, the PNPhypothesis has passed severe tests that it had no good reason to pass were it false.
What kind of tests am I talking about?
By now, tens of thousands of problems have been proved to be NP-complete. They range in character from theorem proving to graph coloring to airline scheduling to bin packing to protein folding to auction pricing to VLSI design to minimizing soap films to winning at Super Mario Bros. Meanwhile, another cluster of tens of thousands of problems has been proved to lie in P (or BPP). Those range from primality to matching to linear and semidefinite programming to edit distance to polynomial factoring to hundreds of approximation tasks. Like the NP-complete problems, many of the P and BPP problems are also related to each other by a rich network of reductions. (For example, countless other problems are in P because linear and semidefinite programming are.)
So, if we were to draw a map of the complexity class NP according to current knowledge, what would it look like? Thered be a huge, growing component of NP-complete problems, all connected to each other by an intricate network of reductions. Thered be a second huge component of P problems, many of them again connected by reductions. Then, much like with the map of the continental US, thered be a sparser population in the middle: stuff like factoring, graph isomorphism, and Unique Games that for various reasons has thus far resisted assimilation onto either of the coasts.
Of course, to prove P=NP, it would suffice to find a single linkthat is, a single polynomial-time equivalencebetween any of the tens of thousands of problems on the P coast, and any of the tens of thousands on the NP-complete one. In half a century, this hasnt happened: even as theyve both ballooned exponentially, the two giant regions have remained defiantly separate from each other. But thats not even the main point. The main point is that, as people explore these two regions, again and again there are close calls: places where, if a single parameter had worked out differently, the two regions would have come together in a cataclysmic collision. Yet every single time, its just a fake-out. Again and again the two regions touch, and their border even traces out weird and jagged shapes. But even in those border zones, not a single problem ever crosses from one region to the other. Its as if theyre kept on their respective sides by an invisible electric fence.
As an example, consider the Set Cover problem: i.e., the problem, given a collection of subsets S1,,Sm{1,,n}, of finding as few subsets as possible whose union equals the whole set. Chvatal showed in 1979 that a greedy algorithm can produce, in polynomial time, a collection of sets whose size is at most ln(n) times larger than the optimum size. This raises an obvious question: can you do better? What about 0.9ln(n)? Alas, building on a long sequence of prior works in PCP theory, it was recently shownthat, if you could find a covering set at most (1-)ln(n) times larger than the optimum one, then youd be solving an NP-complete problem, and P would equal NP. Notice that, conversely, if the hardness result worked for ln(n) or anything above, then wed also get P=NP. So, why do the algorithm and the hardness result happen to meet at exactly ln(n), with neither one venturing the tiniest bit beyond? Well, we might say,ln(n) is where the invisible electric fence is for this problem.
Want another example? OK then, consider the Boolean Max-k-CSP problem: that is, the problem of setting n bits so as to satisfy the maximum number of constraints, where each constraint can involve an arbitrary Boolean function on any k of the bits. The best known approximation algorithm, based on semidefinite programming, is guaranteed to satisfy at least a 2k/2k fraction of the constraints. Can you guess where this is going? Recently, Siu On Chan showed that its NP-hard to satisfy even slightly more than a 2k/2kfraction of constraints: if you can, then P=NP. In this case the invisible electric fence sends off its shocks at 2k/2k.
I could multiply such examples endlesslyor at least, Dana (my source for such matters) could do so. But there are also dozens of weird coincidences that involve running times rather than approximation ratios; and that strongly suggest, not only that PNP,but that problems like 3SAT should require cn time for some constant c. For a recent examplenot even a particularly important one, but one thats fresh in my memoryconsider this paper by myself, Dana, and Russell Impagliazzo. A first thing we do in that paper is to give an approximation algorithm for a family of two-prover games called free games. Our algorithm runs in quasipolynomial time: specifically, nO(log(n)). A second thing we do is show how to reduce the NP-complete 3SAT problem to free games of size ~2O(n).
Composing those two results, you get an algorithm for 3SAT whose overall running time is roughly
$$ 2^{O( \sqrt{n} \log 2^{\sqrt{n}}) } = 2^{O(n)}. $$
Of course, this doesnt improve on the trivial try all possible solutions algorithm. But notice that, if our approximation algorithm for free games had been slightly fastersay, nO(log log(n))then we couldve used it to solve 3SAT in $$ 2^{O(\sqrt{n} \log n)} $$ time. Conversely, if our reduction from 3SAT had produced free games of size (say) $$ 2^{O(n^{1/3})} $$ rather than 2O(n), then we couldve used that to solve 3SAT in $$ 2^{O(n^{2/3})} $$ time.
I should stress that these two results have completely different proofs: the approximation algorithm for free games doesnt know or care about the existence of the reduction, nor does the reduction know or care about the algorithm. Yet somehow, their respective parameters conspire so that 3SAT still needs cntime. And you see the same sort of thing over and over, no matter which problem domain youre interested in. These ubiquitous coincidences would be immediately explained if 3SAT actually didrequirecntimei.e., if it had a hard core for which brute-force search was unavoidable, no matter which way you sliced things up. If thats not truei.e., if 3SAT has a subexponential algorithmthen were left with unexplained spooky action at a distance. How do the algorithms and the reductions manage to coordinate with each other, every single time, to avoid spilling the subexponential secret?
Notice that, contrary to Lubos loud claims, theres no symmetry between P=NP and PNP in these arguments. Lower bound proofs are much harder to come across than either algorithms or reductions, and theres not really a mystery about why: its hard to prove a negative! (Especially when youre up against known mathematical barriers, including relativization, algebrization, and natural proofs.) In other words, even under the assumption that lower bound proofs exist, we now understand a lot about why the existing mathematical tools cant deliver them, or can only do so for much easier problems. Nor can I think of any example of a spooky numerical coincidence between two unrelated-seeming results, which wouldve yielded a proof of PNP had some parameters worked out differently. P=NP and PNPcan look like symmetric possibilities only if your symmetry is unbroken by knowledge.
Imagine a pond with small yellow frogs on one end, and large green frogs on the other. After observing the frogs for decades, herpetologists conjecture that the populations represent two distinct species with different evolutionary histories, and are not interfertile. Everyone realizes that to disprove this hypothesis, all it would take would be a single example of a green/yellow hybrid. Since (for some reason) the herpetologistsreally care about this question, they undertake a huge program of breeding experiments, putting thousands of yellow female frogs next to green male frogs (and vice versa) during mating season, with candlelight, soft music, etc. Nothing.
As this green vs. yellow frog conundrum grows in fame, other communities start investigating it as well: geneticists, ecologists, amateur nature-lovers, commercial animal breeders, ambitious teenagers on the science-fair circuit, and even some extralusionary physicists hoping to show up their dimwitted friends in biology. These other communities try out hundreds of exotic breeding strategies that the herpetologists hadnt considered, and contribute many useful insights. They also manage to breed a larger, greener, but still yellow frogsomething that, while its not a true hybrid, does have important practical applications for the frog-leg industry. But in the end, no one has any success getting green and yellow frogs to mate.
Then one day, someone exclaims: aha! I just found a huge, previously-unexplored part of the pond where green and yellow frogs live together! And whats more, in this part, the small yellow frogs are bigger and greener than normal, and the large green frogs are smaller and yellower!
This is exciting: the previously-sharp boundary separating green from yellow has been blurred! Maybe the chasm can be crossed after all!
Alas, further investigation reveals that, even in the new part of the pond, the two frog populations still stay completely separate. The smaller, yellower frogs there will mate with other small yellow frogs (even from faraway parts of the pond that theyd never ordinarily visit), but never, ever with the larger, greener frogs even from their own part. And vice versa. The result? A discovery that could have falsified the original hypothesis has instead strengtheneditand precisely because it couldvefalsified it but didnt.
Now imagine the above story repeated a few dozen more timeswith more parts of the pond, a neighboring pond, sexually-precocious tadpoles, etc. Oh, and I forgot to say this before, but imagine that doing a DNA analysis, to prove once and for all that the green and yellow frogs had separate lineages, is extraordinarily difficult. But the geneticists know why its so difficult, and the reasons have more to do with the limits of their sequencing machines and with certain peculiarities of frog DNA, than with anything about thesespecific frogs. In fact, the geneticists did get the sequencing machines to work for the easier cases of turtles and snakesand in those cases, their results usually dovetailed well with earlier guesses based on behavior. So for example, where reddish turtles and bluish turtles had never been observed interbreeding, the reason reallydid turn out to be that they came from separate species. There were some surprises, of course, but nothing even remotely as shocking as seeing the green and yellow frogs suddenly getting it on.
Now, even after all this, someone could saunter over to the pond and say: ha, what a bunch of morons! Ive never even seen a frog or heard one croak, but I know that you havent proved anything! For all you know, the green and yellow frogs will start going at it tomorrow. And dont even tell me about the weight of evidence, blah blah blah. Biology is a scummy mud-discipline. It has no ideas or principles; its just a random assortment of unrelated facts. If the frogs started mating tomorrow, that would just be another brute, arbitrary fact, no more surprising or unsurprising than if they didnt start mating tomorrow. You jokers promote the ideology that green and yellow frogs are separate species, not because the evidence warrants it, but just because its a convenient way to cover up your own embarrassing failure to get them to mate. I could probably breed them myself in ten minutes, but I have better things to do.
At this, a few onlookers might nod appreciatively and say: yknow, that guy might be an asshole, but lets give him credit: hes unafraid to speak truth to competence.
Even among the herpetologists, a few might beat their breasts and announce: Whos to say he isnt right? I mean, what do we reallyknow? How do we know there even is a pond, or that these so-called frogs arent secretly giraffes? I, at least, have some small measure of wisdom, in that I know that I know nothing.
What I want you to notice is how scientifically worthlessall of these comments are. If you wanted to do actual research on the frogs, then regardless of which sympathies you started with, youd have no choice but to ignore the naysayers, and proceed as if the yellow and green frogs were different species. Sure, youd have in the back of your mind that they might be the same; youd be ready to adjust your views if new evidence came in. But for now, the theory that theres just one species, divided into two subgroups that happen never to mate despite living in the same habitat, fails miserably at making contact with any of the facts that have been learned. It leaves too much unexplained; in fact it explains nothing.
For all that, you might ask, dont the naysayers occasionally turn out to be right? Of course they do! But if they wereright more than occasionally, then science wouldnt be possible. We would still be in caves, beating our breasts and asking how we can know that frogs arent secretly giraffes.
So, thats what I think about P and NP. Do I expect this post to convince everyone? Nobut to tell you the truth, I dont wantit to. I want it to convince most people, but I also want a fewto continue speculating that P=NP.
Why, despite everything Ive said, do I want maybe-P=NP-ism not to die out entirely? Because alongside the P=NP carpers, I also often hear from a second group of carpers. This second group says thatP and NP are so obviously, self-evidently unequal that the quest to separate them with mathematical rigor is quixotic and absurd. Theoretical computer scientists should quit wasting their time struggling to understand truths that dont need to be understood, but only accepted, and do something useful for the world. (A natural generalization of this view, I guess, is that allbasic science should end.) So, what I really want is for the two opposing groups of naysayers to keep each other in check, so that those who feel impelled to do so canget on with the fascinating quest to understand the ultimate limits of computation.

Update (March 8): At least eight readers have by now emailed me, or left comments, asking why Im wasting so much time and energy arguing with Lubo Motl. Isnt it obvious that, ever since he stopped doing research around 2006 (if not earlier), this guy has completely lost his marbles? That hell never, ever change his mind about anything?
Yes. In fact, Ive noticed repeatedly that, even when Lubois wrong about a straightforward factual matter, he never reallyadmits error: he just switches, without skipping a beat, to some other way to attack his interlocutor. (To give a small example: watch how he reacts to being told that graph isomorphism is neither known nor believed to be NP-complete. Caught making a freshman-level error about the field hes attacking, he simply rants about how graph isomorphism is just as representative and important as NP-complete problems anyway, since no discrete math question is ever more or less important than any other; theyre all equally contrived and arbitrary. At the Lubocasino, you lose even when you win! The only thing you can do is stop playing and walk away.)
Anyway, my goal here was never to convince Lubo. I was writing, not for him, but for my other readers: especially for those genuinely unfamiliar with these interesting issues, or intimidated by Lubos air of certainty. I felt like I owed it tothemto set out, clearly and forcefully, certain facts that all complexity theorists have encountered in their research, but that we hardly ever bother to articulate. If youve never studied physics, then yes, it sounds crazy that there would be quadrillions of invisible neutrinos coursing through your body. And if youve never studied computer science, it sounds crazy that there would be an invisible electric fence, again and again just barely separating what the state-of-the-art approximation algorithms can handle from what the state-of-the-art PCP tools can prove is NP-complete. But there it is, and I wanted everyone else at least to see what the experts see, so that their personal judgments about the likelihood of P=NP could be informed by seeing it.
Lubos response to my post disappointed me (yes, really!). I expected it to be nasty and unhinged, and so it was. What I didnt expect was that it would be so intellectually lightweight. Confronted with the total untenability of his foot-stomping distinction between continuous math (where you can have justified beliefs without proof) and discrete math (where you cant), and withexactly the sorts of detailed, confirmed predictions of the PNP hypothesis that hed declared impossible,Lubos response was simply to repeat his original misconceptions, but louder.
And that brings me, I confess, to a second reason for my engagement with Lubo. Several times, Ive heard people express sentiments like:
Yes, of courseLubo is a raging jerk and a social retard. But if you can just get past that, hes so sharp and intellectually honest! No matter how many people he needlessly offends, he always tells it like it is.
I want the nerd world to seein as stark a situation as possiblethat the above is not correct. Lubo iswrong much of the time,and hes intellectually dishonest.
At one point in his post, Luboactually compares computer scientists who find PNP a plausible working hypothesis to his even greater nemesis: the climate cataclysmic crackpots. (Strangely, he forgot to compare us to feminists, Communists, Muslim terrorists, or loop quantum gravity theorists.) Even though the P versus NP and global warming issues might not seemclosely linked, part of me is thrilled that Lubohas connected them as he has. If, after seeing this ex-physicists thought process laid bare on the P versus NP problemhow his arrogance and incuriosity lead him to stake out a laughably-absurd position; how his vanity then causes him to double down after his errors are exposedif, after seeing this, a single person is led toquestion Luboian epistemology more generally, then my efforts will not have been in vain.
Anyway, now that Ive finally unmasked Lubocertainly to my own satisfaction, and I hope to that of most scientifically-literate readersIm done with this. The physicist John Baez is rumored to have said: Its not easy to ignore Lubo, but its ALWAYS worth the effort. It took me eight years, but I finally see the multiple layers of profundity hidden in that snark.
And thus I make the following announcement:
For the next three years, I, Scott Aaronson, will not respond to anything Lubo says, nor will I allow him to comment on this blog.
In March 2017, Ill reassess my Lubopolicy. Whether I relent will depend on a variety of factorsincluding whetherLubo has gotten the professional help he needs (from a winged pig, perhaps?) and changed his behavior; but also, how much my own quality of life has improved in the meantime.

Another Update (3/11): Theres some further thoughtful discussion of this post over on Reddit.

Another Update (3/13): Check out my MathOverflow question directly inspired by the comments on this post.

Yet Another Update (3/17): Dick Lipton and Ken Regan now have a response up to this post.  My own response is coming soon in their comment section.  For now, check out an excellent comment by Timothy Gowers, which begins I firmly believe that PNP, then plays devils-advocate by exploring the possibility that in this comment thread I called P being severed in two, then finally returns to reasons for believing that PNP after all.This review of Max Tegmarks book also occurs infinitely often in the decimal expansion of 

Two months ago, commenter rrtucci asked me what I thought about Max Tegmark and his Mathematical Universe Hypothesis: the idea, which Tegmark defends in his recent book Our Mathematical Universe, that physical and mathematical existence are the same thing, and that what we call the physical world is simply one more mathematical structure, alongside the dodecahedron and so forth. I replied as follows:
I find Max a fascinating person, a wonderful conference organizer, someone whos always been extremely nice to me personally, and an absolutemasterat finding common ground with his intellectual opponentsIm trying to learn from him, and hope someday to become 10-122as good. I can also say that, like various other commentators (e.g., Peter Woit), I personally find the Mathematical Universe Hypothesis to be devoid of content.
After Peter Woit found that comment and highlighted it on his own blog, my comments section was graced by none other than Tegmark himself, who wrote:
Thanks Scott for your all to [sic] kind words! I very much look forward to hearing what you think about what I actually say in the book once youve had a chance to read it! Im happy to give you a hardcopy (which can double as door-stop)  just let me know.
With this reply, Max illustrated perfectly why Ive been trying to learn from him, and how far I fall short. Where I wouldve said yo dumbass, why dont you read my book before spouting off?, Tegmark gracefully, diplomatically shamed me into reading his book.
So, now that Ive done so, what do I think? Briefly, I think its a superb piece of popular science writingstuffed to the gills with thought-provoking arguments, entertaining anecdotes, and fascinating facts. I think everyone interested in math, science, or philosophy should buy the book and read it. And I still think the MUH is basically devoid of content, as it stands.
Let me start with what makes the book so good. First and foremost, the personal touch. Tegmark deftly conveys the excitement of being involved in the analysis of the cosmic microwave background fluctuationsof actually getting detailed numerical data about the origin of the universe. (The book came out just a few months before last weeks bombshell announcement of B-modes in the CMB data; presumably the next edition will have an update about that.) And Tegmark doesnt just give you arguments for the Many-Worlds Interpretation of quantum mechanics; he tells you how he came to believe it. He writes of being a beginning PhD student at Berkeley, living at International House (and dating an Australian exchange student who he met his first day at IHouse), who became obsessed with solving the quantum measurement problem, and who therefore headed to the physics library, where he was awestruck by reading the original Many-Worlds articles of Hugh Everett and Bryce deWitt. As it happens, every single part of the last sentence also describes me (!!!)except that the Australian exchange student who I met my first day at IHouse lost interest in me when she decided that I was too nerdy. And also, I eventually decided that the MWI left me pretty much as confused about the measurement problem as before, whereas Tegmark remains a wholehearted Many-Worlder.
The other thing I loved about Tegmarks book was its almost comical concreteness. He doesnt just metaphorically write about knobs for adjusting the constants of physics: he shows you a picture of a box with the knobs on it. He also shows a letter that lists not only his street address, zip code, town, state, and country, but also his planet, Hubble volume, post-inflationary bubble, quantum branch, and mathematical structure. Probably my favorite figure was the one labeled What Dark Matter Looks Like / What Dark Energy Looks Like, which showed two blank boxes.
Sometimes Tegmark seems to subtly subvert the conventions of popular-science writing. For example, in the first chapter, he includes a table that categorizes each of the books remaining chapters as Mainstream, Controversial, or Extremely Controversial. And whenever youre reading the text and cringing at a crucial factual point that was left out, chances are good youll find a footnote at the bottom of the page explaining that point. I hope both of these conventions become de rigueur for all future pop-science books, but Im not counting on it.
The book has what Tegmark himself describes as a Dr. Jekyll / Mr. Hyde structure, with the first (Dr. Jekyll) half of the book relaying more-or-less accepted discoveries in physics and cosmology, and the second (Mr. Hyde) half focusing on Tegmarks own Mathematical Universe Hypothesis (MUH). Lets accept that both halves are enjoyable reads, and that the first half contains lots of wonderful science. Is there anything worth saying about the truth or falsehood of the MUH?
In my view, the MUH gestures toward two points that are both correct and importantneither of them new, but both well worth repeating in a pop-science book. The first is that the laws of physics arent suggestions, which the particles can obey when they feel like it but ignore when Uri Geller picks up a spoon. In that respect, theyre completely unlike human laws, and the fact that we use the same word for both is unfortunate. Nor are the laws merely observed correlations, as in scientists find link between yogurt and weight loss. The links of fundamental physics are ironclad: the world obeys them in much the same sense that a computer obeys its code, or the positive integers obey the rules of arithmetic. Of course we dont yet know the complete program describing the state evolution of the universe, but everything learned since Galileo leads one to expect that such a program exists. (According to quantum mechanics, the program describing our observed reality is a probabilistic one, but for me, that fact by itself does nothing to change its lawlike character. After all, if you know the initial state, Hamiltonian, and measurement basis, then quantum mechanics gives you a perfect algorithm to calculatethe probabilities.)
The second true and important nugget in the MUH is that the laws are mathematical. By itself, Id say thats a vacuous statement, since anything that can be described at all can be described mathematically. (As a degenerate case, a mathematical description of reality could simply be a gargantuan string of bits, listing everything that will ever happen at every point in spacetime.) The nontrivial part is that, at least if we ignore boundary conditions and the details of our local environment (whichmaybe we shouldnt!), the laws of nature are expressible as simple, elegant mathand moreover, the same structures (complex numbers, group representations, Riemannian manifolds) that mathematicians find important for internal reasons, again and again turn out to play a crucial role in physics. It didnt have to be that way, but it is.
Putting the two points together, it seems fair to say that the physical world is isomorphic to a mathematical structureand moreover,a structure whose time evolution obeyssimple, elegant laws.  All of this I find unobjectionable: if you believe it, it doesnt make you a Tegmarkian; it makes you ready for freshman science class.
But Tegmark goes further. He doesnt say that the universe is isomorphic to a mathematical structure; he says that it is that structure, that its physical and mathematical existence are the same thing. Furthermore, he says that every mathematical structure exists in the same sense that ours does; we simply find ourselves in one of the structures capable of intelligent life (which shouldnt surprise us). Thus, for Tegmark, the answer to Stephen Hawkings famous questionWhat is it that breathes fire into the equations and gives them a universe to describe?is that every consistent set of equations has fire breathed into it. Or rather, every mathematical structure of at most countable cardinality whose relations are definable by some computer program. (Tegmark allows that structures that arentcomputably definable, like the set of real numbers, might not have fire breathed into them.)
Anyway, the ensemble of all (computable?) mathematical structures, constituting the totality of existence, is what Tegmark calls the Level IV multiverse. In his nomenclature, our universe consists of anything from which we can receive signals; anything that exists but that we cant receive signals from is part of a multiverse rather than our universe. The Level I multiverse is just the entirety of our spacetime, including faraway regions from which we can never receive a signal due to the dark energy. The Level II multiverse consists of the infinitely many other bubbles (i.e., local Big Bangs), with different values of the constants of physics, that would, in eternal inflation cosmologies, have generically formed out of the same inflating substance that gave rise to our Big Bang. The Level III multiverse is Everetts many worlds. Thus, for Tegmark, the Level IV multiverse is a sort of natural culmination of earlier multiverse theorizing. (Some people might call it a reductio ad absurdum, but Tegmark is nothing if not a bullet-swallower.)
Now, why should you believe in any of these multiverses? Or better: what does it buy you to believe in them?
As Tegmark correctly points out, none of the multiverses are theories, but they might be implications of theories that we have other good reasons to accept. In particular, it seems crazy to believe that the Big Bang created space only up to the furthest point from which light can reach the earth, and no further. So, do you believe that space extends further than our cosmological horizon? Then boom! you believe in the Level I multiverse, according to Tegmarks definition of it.
Likewise, do you believe there was a period of inflation in the first ~10-32 seconds after the Big Bang? Inflation has made several confirmed predictions (e.g., about the fractal nature of the CMB perturbations), and if last weeks announcement of B-modes in the CMB is independently verified, that will pretty much clinch the case for inflation. But Alan Guth, Andrei Linde, and others have argued that, if you accept inflation, then it seems hard to prevent patches of the inflating substance from continuing to inflate forever, and thereby giving rise to infinitely many other Big Bangs. Furthermore, if you accept string theory, then the six extra dimensions should generically curl up differently in each of those Big Bangs, giving rise to different apparent values of the constants of physics. So then boom! with those assumptions, youre sold on the Level II multiverse as well. Finally, of course, there are people (like David Deutsch, Eliezer Yudkowsky, and Tegmark himself) who think that quantum mechanics forces you to accept the Level III multiverse of Everett. Better yet, Tegmark claims that these multiverses are falsifiable. For example, if inflation turns out to be wrong, then the Level II multiverse is dead, while if quantum mechanics is wrong, then the Level III one is dead.
Admittedly, the Level IV multiverse is a tougher sell, even by the standards of the last two paragraphs. If you believe physical existence to be the same thing as mathematical existence, what puzzles does that help to explain? What novel predictions does it make? Forging fearlessly ahead, Tegmark argues that the MUH helps to explain why our universe has so many mathematical regularities in the first place. And it predicts that more mathematical regularities will be discovered, and that everything discovered by science will be mathematically describable. But what about the existence of other mathematical universes? If, Tegmark says (on page 354), our qualitative laws of physics turn out to allow a narrow range of numerical constants that permit life, whereas other possible qualitative laws have no range of numerical constants that permit life, then that would be evidence for the existence of a mathematical multiverse. For ifour qualitative laws were the only ones into which fire had been breathed, then why would they just so happen to have a narrow but nonempty range of life-permitting constants?
I suppose Im not alone in finding this totally unpersuasive. When most scientists say they want predictions, they have in mind something meatier than predict the universe will continue to be describable by mathematics. (How would we know if we found something that wasnt mathematically describable? Could we even describe such a thing with English words, in order to write papers about it?) They also have in mind something meatier than predict that the laws of physics will be compatible with the existence of intelligent observers, but if you changed them a little, then theyd stop being compatible. (The first part of that prediction is solid enough, but the second part might depend entirely on what we mean by a little change or even an intelligent observer.)
Whats worse is that Tegmarks rules appear to let him have it both ways. To whatever extent the laws of physics turn out to be as simple and elegant as anyone could hope for, Tegmark can say: you see? thats evidence for the mathematical character of our universe, and hence for the MUH! But to whatever extent the laws turn out not to be so elegant, to be weird or arbitrary, he can say: see? thats evidence that our laws were selected more-or-less randomlyamong all possible laws compatible with the existence of intelligent lifejust as the MUH predicted!
Still, maybe the MUH could be sharpened to the point where it did make definite predictions? As Tegmark acknowledges, the central difficulty with doing so is that no one has any idea what measure to use over the space of mathematical objects (or even computably-describable objects). This becomes clear if we ask a simple question like: what fraction of the mathematical multiverse consists of worlds that contain nothing but a single three-dimensional cube?
We could try to answer such a question using the universal prior: that is, we could make a list of all self-delimiting computer programs, then count the total weight of programs that generate a single cube and then halt, where each n-bit program gets assigned 1/2n weight. Sure, the resulting fraction would be uncomputable, but at least wed have defined it. Except wait  which programming language should we use? (The constant factors could actually matter here!) Worse yet, what exactly counts as a cube? Does it have to have faces, or are vertices and edges enough? How should we interpret the string of 1s and 0s output by the program, in order to know whether it describes a cube or not? (Also, how do we decide whether two programs describe the same cube? And if they do, does that mean theyre describing the same universe, or two different universes that happen to be identical?)
These problems are simply more-dramatic versions of the standard measure problem in inflationary cosmology, which asks how to make statistical predictions in a multiverse where everything that can happen will happen, and will happen an infinite number of times. The measure problem is sometimes discussed as if it were a technical issue: something to acknowledge but then set to the side, in the hope that someone will eventually come along with some clever counting rule that solves it. To my mind, however, the problem goesdeeper: its a sign that, although we might have started out in physics, weve now stumbled into metaphysics.
Some cosmologists would strongly protest that view. Most of them would agree with me that Tegmarks Level IV multiverse is metaphysics, but theyd insist that the Level I, Level II, and perhaps Level III multiverses were perfectly within the scope of scientific inquiry: they either exist or dont exist, and the fact that we get confused about the measure problem is our issue, not natures.
My response can be summed up in a question: why not ride this slippery slope all the way to the bottom? Thinkers like Nick Bostrom and Robin Hanson have pointed out that, in the far future, we might expect that computer-simulated worlds (as in The Matrix) will vastly outnumber the real world. So then, why shouldnt we predict that were much more likely to live in a computer simulation than we are in one of the original worlds doing the simulating? And as a logical next step, why shouldnt we do physics by trying to calculate a probability measure over different kinds of simulated worlds: for example, those run by benevolent simulators versus evil ones? (For our world, my own moneys on evil.)
But why stop there? As Tegmark points out, what does it matter if a computer simulation is actually run or not? Indeed, why shouldnt you say something like the following: assuming thatis a normal number, your entire life history must be encoded infinitely many times in sdecimal expansion. Therefore, youre infinitely more likely to be one of your infinitely many doppelgngers living in the digits of than you are to be the real you, of whom theres only one! (Of course, you might alsobe living in the digits of e or 2, possibilities that also merit reflection.)
At this point, of course, youre all the way at the bottom of the slope, in Mathematical Universe Land, where Tegmark is eagerly waiting for you. But you still have no idea how to calculate a measureover mathematical objects: for example, how to say whether youre more likely to be living in the first 1010^120 digits of , or the first 1010^120digits of e. And as a consequence, you still dont know how to use the MUH to constrain your expectations for what youre going to see next.
Now, notice that these different ways down the slippery slope all have a common structure:

We borrow an idea from science thats real and important and profound: for example, the possible infinite size and duration of our universe, or inflationary cosmology, or the linearity of quantum mechanics, or the likelihood of being a normal number, or the possibility of computer-simulated universes.
We then run with that idea until we smack right into a measure problem, and lose the ability to make useful predictions.

Many people want to frame the multiverse debates as science versus pseudoscience, or science versus science fiction, or (as I did before) physics versus metaphysics. But actually, I dont think any of those dichotomies get to the nub of the matter. All of the multiverses Ive mentionedcertainly the inflationary and Everett multiverses, but even the computer-simuverse and the -versehave their origins in legitimate scientific questions and in genuinely-great achievements of science. However, they then extrapolate those achievements in a direction that hasnt yet led to anythingimpressive. Or at least, not to anything that we couldnt have gotten without the ontological commitments that led to the multiverse and its measure problem.
What is it, in general, that makes a scientific theory impressive? Id say that the answer is simple: connecting elegant math to actual facts of experience.
When Einstein said, the perihelion of Mercury precesses at 43 seconds of arc per century because gravity is the curvature of spacetimethat was impressive.
When Dirac said, you should see a positron because this equation in quantum field theory is a quadratic with both positive and negative solutions (and then the positron was found)that was impressive.
When Darwin said, there must be equal numbers of males and females in all these different animal speciesbecause any other ratio would fail to be an equilibriumthat was impressive.
When people say that multiverse theorizing isnt science, I think what they mean is that its failed, so far, to be impressive science in the above sense. It hasnt yet produced any satisfying clicks of understanding, much less dramatically-confirmed predictions. Yes, Steven Weinberg kind-of, sort-of used multiverse reasoning to predictcorrectlythat the cosmological constant should be nonzero. But as far as I can tell, he could just as well have dispensed with the multiverse part, and said: I see no physical reason why the cosmological constant should be zero, rather than having some small nonzero value still consistent with the formation of stars and galaxies.
At this, many multiverse proponents would protest: look, Einstein, Dirac, and Darwin is setting a pretty high bar! Those guys were smart but also lucky, and its unrealistic to expect that scientists will always be so lucky. For many aspects of the world, there might not be an elegant theoretical explanationor any explanation at all better than, well, if it were much different, then we probably wouldnt be here talking about it. So, are you saying we should ignore where the evidence leads us, just because of some a-priori prejudice in favor of mathematical elegance?
In a sense, yes, I am saying that. Heres an analogy: suppose an aspiring filmmaker said, I want my films to capture the reality of human experience, not some Hollywood myth. So, in most of my movies nothing much will happen at all. If something does happensay, a major character diesit wont be after some interesting, character-forming struggle, but meaninglessly, in a way totally unrelated to the rest of the film. Like maybe they get hit by a bus. Then some other random stuff will happen, and then the movie will end.
Such a filmmaker, Id say, would have a perfect plan for creating boring, arthouse movies that nobody wants to watch. Dramatic, character-forming struggles against the odds might not be the norm of human experience, but they are the central ingredient of entertaining cinemaso if you want to create an entertaining movie, then you haveto postselect on those parts of human experience that do involve dramatic struggles. In the same way, I claim that elegant mathematical explanations for observed facts are the central ingredient of great science. Not everything in the universe might have such an explanation, but if one wants to create great science, one has to postselect on the things that do.
(Note that theres an irony here: the same unsatisfyingness, the same lack of explanatory oomph, that make something a lousy movieto those with a scientific mindset, can easily make it a great movie to those without such a mindset. The hunger for nontrivial mathematical explanations is a hunger one has to acquire!)
Some readers might argue: but werentquantum mechanics, chaos theory, and Gdels theorem scientifically important precisely because they said that certain phenomenathe exact timing of a radioactive decay, next months weather, the bits of Chaitins were unpredictable and unexplainable in fundamental ways? To me, these are the exceptions that prove the rule. Quantum mechanics, chaos, and Gdels theorem were great science not because they declared certain facts unexplainable, but because they explained whythose facts (and not other facts) had no explanations of certain kinds. Even more to the point, they gave definite rules to help figure out what would and wouldnt be explainable in their respective domains: is this state an eigenstate of the operator youre measuring? is the Lyapunov exponent positive? is there a proof of independence from PA or ZFC?
So, what would be the analogue of the above for the multiverse? Is there any Level II or IV multiverse hypothesis that says: sure, the mass of electron might be a cosmic accident, with at best an anthropic explanation, but the mass of the Higgs boson is almost certainlynot such an accident? Or that the sum or difference of the two masses is not an accident? (And no, it doesnt count to affirm as non-accidental things that we already have non-anthropic explanations for.) If such a hypothesis exists, tell me in the comments! As far as I know, all Level II and IV multiverse hypotheses are still at the stage where basically anything that isnt already explained might vary across universes and be anthropically selected. And that, to my mind, makes them very different in character from quantum mechanics, chaos, or Gdels theorem.
In summary, heres what I feel is a reasonable position to take right now, regarding all four of Tegmarks multiverse levels (not to mention the computer-simuverse, which I humbly propose as Level 3.5):
Yes, these multiverses are a perfectly fine thing to speculate about: sure theyre unobservable, but so are plenty of other entities that science has forced us to accept. There are even natural reasons, within physics and cosmology, that could lead a person to speculate about each of these multiverse levels. So if you want to speculate, knock yourself out! If, however, you want me to accept the results as more than speculationif you want me to put them on the bookshelf next to Darwin and Einsteinthen youll need to do more than argue that other stuff I already believe logically entails a multiverse (which Ive never been sure about), or point to facts that are currently unexplained as evidence that we need a multiverse to explain their unexplainability, or claim as triumphs for your hypothesis things that dont really need the hypothesis at all, or describe implausible hypothetical scenarios that could confirm or falsify the hypothesis. Rather, youll need to use your multiverse hypothesisand your proposed solution to the resulting measure problemto do something new that impresses me.Waiting for BQP Fever

Update (April 5): By now, three or four people have written in asking for my reaction to the preprint Computational solution to quantum foundational problems by Arkady Bolotin. (See here for the inevitable Slashdot discussion, entitled P vs. NP Problem Linked to the Quantum Nature of the Universe.) It gives me no pleasure to respond to this sort of thingit would be far better to let papers thisgobsmackingly uninformed about the relevant issues fade away in quiet obscuritybut since that no longer seems to be possible in the age of social media, my brief response is here.

(note: sorry, no April Fools post, just a post that happens to have gone up on April Fools)
This weekend, Dana and I celebrated our third anniversary by going out to your typical sappy romantic movie:Particle Fever, a documentary about the Large Hadron Collider. As it turns out, the movie was spectacularly good; anyone who reads this blog should go see it. Or, to offer even higher praise:
If watchingParticle Feverdoesnt cause you to feel in your bones the value of fundamental sciencethe thrill of discovery, unmotivated by any applicationthen you are not truly human. You are a barnyard animal who happens to walk on its hind legs.
Indeed, I regardParticle Feveras one of the finest advertisements for science itself ever created. Its effective precisely because it doesnt try totellyou why science is important (except for one scene, where an economist asks a physicist after a public talk about the return on investment of the LHC, and is given the standard correct answer, about what was the return on investment of radio waves when they were first discovered?). Instead, the movie simply shows you the lives of particle physicists, of people who take for granted the urgency of knowing the truth about the basic constituents of reality. And in showing you the scientists quest, it makes you feel as they feel. Incidentally, the movie also shows footage of Congressmen ridiculing the uselessness of the Superconducting Supercollider, during the debates that led to the SSCs cancellation. So, gently, implicitly, youre invited to choose: whose side are you on?
I do have a few, not quite criticisms of the movie, but points that any viewer should bear in mind while watching it.
First, its important not to come away with the impression that Particle Fever shows what science is usually like. Sure, there are plenty of scenes that any scientist would find familiar: sleep-deprived postdocs; boisterous theorists correcting each others statements over Chinese food; a harried lab manager walking to the office oblivious to traffic. On the other hand, the decades-long quest to find the Higgs boson, the agonizing drought of new data before the one big money shot, the need for an entire field to coalesce around a single machine,the whole careers hitched to specific speculative scenarios that this one machine could favor or disfavorall of that is a profoundlyabnormalsituation in the history of science. Particle physics didnt used to be that way, and other parts of science are not that way today. Of course, the fact that particle physics became that way makes it unusually suited for a suspenseful moviea fact that the creators of Particle Feverunderstood perfectly and exploited to the hilt.
Second, the movie frames the importance of the Higgs search as follows: if the Higgs boson turned out to be relatively light, like 115 GeV, then that would favor supersymmetry, and hence an elegant, orderly universe. If, on the other hand, the Higgs turned out to be relatively heavy, like 140 GeV, then that would favor anthropic multiverse scenarios (and hence a messy, random universe). So the fact that the Higgs ended up being 125 GeV means the universe is coyly refusing to tell us whether its orderly or random, and more research is needed.
In my view, its entirely appropriate for a movie like this one to relate its subject matter to big, metaphysical questions, to the kinds of questions anyone can get curious about (in contrast to, say, what is the mechanism of electroweak symmetry breaking?) and that the scientists themselves talk about anyway. But caution is needed here. My lay understanding, which might be wrong, is as follows: while its true that a lighter Higgs would tend to favor supersymmetric models, the only way to argue that a heavier Higgs would favor the multiverse, is if you believe that a multiverse is automatically favored by a lack of better explanations. More broadly, I wish the film had made clearer that the explanation for (some) apparent fine-tunings in the Standard Model might be neither supersymmetry, nor the multiverse, norits just an inexplicable accident, but simply some other explanation that no one has thought of yet, but that would emerge from a better understanding of quantum field theory. As one example, on reading up on the subject after watching the film, I was surprised to learn that a very conservative-sounding ideathat of asymptotically safe gravitywas used in 2009 to predict the Higgs mass right on the nose, at 126.32.2 GeV. Of course, its possible that this was just a lucky guess (there were, after all, lots of Higgs mass predictions). But as an outsider, Id love to understand why possibilities like this dont seem to get discussed more (there might, of course, be perfectly good reasons that I dont know).
Third, for understandable dramatic reasons, the movie focuses almost entirely on the younger generation, from postdocs working on ATLAS and CMS detectors, to theorists like Nima Arkani-Hamed who are excited about the LHC because of its ability to test scenarios like supersymmetry. From the movies perspective, the creation of the Standard Model itself, in the 60s and 70s, might as well be ancient history. Indeed, when Peter Higgs finally appears near the end of the film, its as if Isaac Newton has walked onstage. At several points, I found myself wishing that some of the original architects of the Standard Model, like Steven Weinberg or Sheldon Glashow, had been interviewed to provide their perspectives. After all, their model is really the one thats been vindicated at the LHC, not (so far) any of the newer ideas like supersymmetry or large extra dimensions.
OK, but let me come to the main point of this post. I confess that my overwhelming emotion on watchingParticle Fever was one of regretregret that my own field, quantum computing, has never managed to make the case for itself the way particle physics and cosmology have, in terms of the human urge to explore the unknown.
See, from my perspective, theres a lot to envy about the high-energy physicists. Most importantly, they dont perceive any need to justify what they do in terms of practical applications. Sure, they happily point to spinoffs, like the fact that the Web was invented at CERN. But any time they try to justify what they do, the unstated message is that if you dont see the inherent value of understanding the universe, then the problem lies with you.
Now, no marketing consultant would ever in a trillion years endorse such an out-of-touch, elitist sales pitch. But the remarkable fact is thatthe message has more-or-less worked. While the cancellation of the SSC was a setback, the high-energy physicists did succeed in persuading the world to pony up the $11 billion needed to build the LHC, and to gain the information that the mass of the Higgs boson is about 125 GeV.
Now contrast that with quantum computing. To hear the media tell it, a quantum computer would be a powerful new gizmo, sort of like existing computers except faster. (Why would it be faster? Something to do with trying both 0 and 1 at the same time.) The reasons to build quantum computers are things that could make any buzzword-spouting dullard nod in recognition: cracking uncrackable encryption, finding bugs in aviation software, sifting through massive data sets, maybe even curing cancer, predicting the weather, or finding aliens. And all of this could be yours in a few short yearsor some say its even commercially available today. So, if you check back in a few years and its stillnot on store shelves, probably it went the way of flying cars or moving sidewalks: another technological marvel that just failed to materialize for some reason.
Foolishly, shortsightedly, many academics in quantum computing have played along with this stunted vision of their fieldbecause saying this sort of thing is the easiest way to get funding, because everyone else says the same stuff, and because after youve repeated something on enough grant applications you start to believe it yourself. All in all, then, its just easier to go along with the gizmo vision of quantum computing than to ask pointed questions like:
What happens when it turns out that some of the most-hyped applications of quantum computers (e.g., optimization, machine learning, and Big Data) were based on wildly inflated hopesthat there simply isnt much quantum speedup to be had for typical problems of that kind, that yes, quantum algorithms exist, but they arent much faster than the best classical randomized algorithms? What happens when it turns out that the real applications of quantum computinglike breaking RSA and simulating quantum systemsare nice, but not important enough by themselves to justify the cost? (E.g., when the imminent risk of a quantum computer simply causes people to switch from RSA to other cryptographic codes? Or when the large polynomial overheads of quantum simulation algorithms limit their usefulness?) Finally, what happens when it turns out that the promises of useful quantum computers in 5-10 years were wildly unrealistic?
Ill tell you: when this happens, the spigots of funding that once flowed freely will dry up, and the techno-journalists and pointy-haired bosses who once sang our praises will turn to the next craze. And theyre unlikely to be impressed when we protest, no, look, the reasons we told you before for why you should support quantum computing were never the real reasons! and the real reasons remain as valid as ever!
In my view, we as a community have failed to make the honest case for quantum computingthe case based on basic sciencebecause weve underestimated the public. Weve falsely believed that people would never support us if we told them the truth: that while the potential applications are wonderful cherries on the sundae, theyre not and have never been the main reason to build a quantum computer. The main reason is that we want to make absolutely manifest what quantum mechanics says about the nature of reality. We want to lift the enormity of Hilbert space out of the textbooks, and rub its full, linear, unmodified truth in the face of anyone who denies it. Or if it isnt the truth, then we want to discover what is the truth.
Many people would say its impossible to make the latter pitch, that funders and laypeople would never understand it or buy it. But theres an $11-billion, 17-mile ring under Geneva that speaks against their cynicism.
Anyway, let me end this movie review with an anecdote. The other day a respected colleague of minesomeone who doesnt normally follow such mattersasked me what I thought about D-Wave. After Id given my usual spiel, he smiled and said:
See Scott, but you could imagine scientists of the 1400s saying the same things about Columbus! He had no plan that could survive academic scrutiny. He raised money under the false belief that he could reach India by sailing due west. And he didnt understand what hed found even after hed found it. Yet for all that, it was Columbus, and not some academic critic on the sidelines, who discovered the new world.
With this one analogy, my colleague had eloquently summarized the case for D-Wave, a case often leveled against me much more verbosely. But I had an answer.
I accept your analogy! I replied. But to me, Columbus and the other conquerors of the Americas werent heroes to be admired or emulated. Motivated by gold and spices rather than knowledge, they spread disease, killed and enslaved millions in one of historys greatest holocausts, and burned the priceless records of the Maya and Inca civilizations so that the world would never even understand what was lost. I submit that, had it been undertaken by curious and careful scientistsor at least people with a scientific mindsetrather than by swashbucklers funded by greedy kings, the European exploration and colonization of the Americas could have been incalculably less tragic.
The trouble is, when I say things like that, people just laugh at me knowingly. There he goes again, the pie-in-the-sky complexity theorist, who has no idea what it takes to get anything done in the real world. What an amusingly contrary perspective he has.
And that, in the end, is why I thinkParticle Fever is such an important movie. Through the stories of the people who built the LHC, youll see how it really is possible to reach a new continent without the promise of gold or the allure of lies.Quantum Computing Since Democritus Lecture 7: Randomness

Yes, less than a week after the course itself finished, a new set of lecture notes is finally here!   The topic: randomness.
Im writing this post from ber-commenter Greg Kuperbergs office at UC Davis, where Im visiting for a few days to give a math colloquium.  Greg has been trying to fill my thick skull with something called t-cubature formulas, and writing this post provides me with a much-needed break!
After Davis, Ill be going to Berkeley for a couple weeks (not that I ever really left it), then my parents place in Pennsylvania for the holidays, then Caltech, then New Zealand (why the hell not?), then Australia for QIP, then back to Waterloo in February. Much more relaxing than last years trip  note that I wont return from this one with an (additional) 2i phase.Is There Anything Beyond Quantum Computing?

So Ive written an article about the above questionfor PBSs websitea sort of tl;dr version of my 2005 survey paperNP-Complete Problems and Physical Reality, butupdated with new material about the simulation of quantum field theories and about AdS/CFT. Go over there, read the article (its free), then come back here to talk about it if you like. Thanks so much to Kate Becker for commissioning the article.
In other news, theres a profile of me at MIT News(called The Complexonaut) that some people might find amusing.
Oh, and anyone who thinks the main reason to care about quantum computing is that, if our civilization ever manages to surmount the profound scientific and technological obstacles to building a scalable quantum computer, then that little padlock icon on your web browser would no longer represent ironclad security? Ha ha. Yeah, it turns out that, besides factoring integers, you can alsobreak OpenSSL by (for example) exploiting a memory bug in C. The main reason to care about quantum computing is, and has always been,science.The Quest for Randomness

So, Ive written an article of that title for the wonderful American Scientist magazineor rather, Part I of such an article. This part explains the basics of Kolmogorov complexity and algorithmic information theory: how, under reasonable assumptions, these ideascan be used in principle to certify that a string of numberswas reallyproduced randomlysomething that one mightve imaginedimpossible a priori. Unfortunately, the article also explains why this fact is of limited use in practice: because Kolmogorov complexity is uncomputable! Readers who already know this material wont find much thats new here, but I hope those who dont will enjoy the piece.
Part II, to appear in the next issue, will be all about quantum entanglement and Bells Theorem, and theirvery recent use in strikingprotocols for generating so-called Einstein-certified random numberssomething of much more immediatepractical interest.
Thanks so much to Fenella Saunders of American Scientist for commissioning these articles, and my apologies to her and any interested readersfor the 4.5years (!) it took me to get off my rear end (or rather, onto it)towrite these things.

Update (4/28): Kate Becker of NOVA has published an article about whether information is fundamental to reality, which includes some quotes from me. Enjoy!What American accent do you have?

Among all the mysteries of the universe, its good to know that at least one of them is answerable.  My accent, apparently, is as Philadelphian as a cheesesteak.  Hat tip to Greg Kuperberg.The NEW Ten Most Annoying Questions in Quantum Computing

Eight years ago, I put up a post entitledThe Ten Most Annoying Questions in Quantum Computing. One of the ten wasnt a real questionit was simply a request for readers to submit questionsso lets call it nine. Im delighted to say that, of the nine questions, six have by now been completely settledmost recently, my question about the parallel-repeated value of the CHSH game, which Andris Ambainis pointed out to me last week can be answered using a 2008 result of Barak et al. combined with a 2013 result of Dinur and Steurer.
To be clear, the demise of so many problems is exactly the outcome I wanted. In picking problems, my goal wasnt to shock and awe with difficultyas if to say this is how smartI am, that whatever stumps me will also stump everyone else for decades. Nor was it to showcase my bottomlessprofundity, by proffering questions so vague, multipartite, and open-ended that no matter what progress was made, I could always reply ah, but you still havent addressedthe real question! Nor, finally, was my goal to list the biggestresearch directions for the entire field, the stuff everyone already knows about (is there a polynomial-time quantum algorithm for graph isomorphism?). My interest was exclusively in little questions, inweird puzzlesthat looked (at least at the time) like there was no deep obstruction to just killing them one by one, whichever way their answers turned out. What made them annoying was that they hadnt succumbed already.
So, now that two-thirds of my problems have met the fate they deserved, at Andriss suggestion Im presentinga new list of Ten Most Annoying Questions in Quantum Computinga list that starts with the three still-unanswered questions from the old list, and then adds seven more.
But well get to that shortly. First, lets review the six questions that have been answered.

CLOSED, NO-LONGER ANNOYING QUESTIONS IN QUANTUM COMPUTING
1. Given an n-qubit pure state, is there always a way to apply Hadamard gates to some subset of the qubits, so as to make all 2ncomputational basis states have nonzero amplitudes? Positive answer by Ashley Montanaro and Dan Shepherd, posted to this blog in2006.
3. Can anyQMA(2)(QMAwith two unentangled yes-provers) protocol be amplified to exponentially small error probability? Positive answer by Aram Harrow and Ashley Montanaro, from a FOCS2010 paper.
4. If a unitary operation U can be applied in polynomial time, then can some square root of U also be applied in polynomial time? Positive answer by Lana Sheridan, Dmitri Maslov, and Michele Mosca, from a 2008 paper.
5. Suppose Alice and Bob are playing n parallelCHSH games, with no communication or entanglement. Is the probability that theyll win all n games at most pn, for some p bounded below 0.853?
OK, let me relay what Andris Ambainis told me about this question, with Andriss kind permission. First of all, weve known for a while that the optimal success probability is not the (3/4)n that Alice and Bob could trivially achieve by just playing all n games separately. I observed in 2006 that, by correlating their strategies between pairs of games in a clever way, Alice and Bob can win with probability (10 / 4)n ~ 0.79n. And Barak et al. showed in 2008 that they can win with probability ((1+5)/4)n ~ 0.81n. (Unfortunately, I dont know the actual strategy that achieves the latter bound! Barak et al. say theyll describe it in the full version of their paper, but the full version hasnt yet appeared.)
Anyway, Dinur-Steurer 2013 gave a general recipe to prove that the value of a repeated projection game is at most n, where  is some constant that depends on the game in question. When Andris followed their recipe for the CHSH game, he obtained the result =(1+5)/4thereby showing that Barak et al.s strategy, whatever it is, is preciselyoptimal! Andris also observes that, for any two-prover game G, the Dinur-Steurer bound (G) is always strictly less than the entangled value *(G), unless the classical and entangled values are the same for one copy of the game (i.e., unless (G)=*(G)). This implies that parallel repetition can never completely eliminate a quantum advantage.
6. Forget about an oracle relative to whichBQPis not in PH (the Polynomial Hierarchy). Forget about an oracle relative to which BQP is not inAM (Arthur-Merlin). Is there an oracle relative to which BQP is not inSZK (Statistical Zero-Knowledge)? Positive answer by me, posted to this blog in 2006. See alsomy BQP vs. PH paper for a different proof.
9. Is there an n-qubit pure state that can be prepared by a circuit of size n3, and that cant be distinguished from the maximally mixed state by any circuit of size n2? A positive answer follows from this 2009 paper by Richard Lowthanks very much to Fernando Brandao for bringing that to my attention a few months ago.

OK, now on to:
THE NEW TEN MOST ANNOYING QUESTIONS IN QUANTUM COMPUTING
1.Can we get any upper bound whatsoever on the complexity class QMIPi.e., quantum multi-prover interactive proofs with unlimited prior entanglement? (Since I asked this question in 2006, Ito and Vidick achieved the breakthrough lower bound NEXPQMIP, but theres been basically no progress on the upper bound side.)
2. Given any n-qubit unitary operation U, does there exist an oracle relative to which U can be (approximately) applied in polynomial time? (Since 2006, my interest in this question has only increased. See this paper by me and Greg Kuperberg for background and related results.)
3.How manymutually unbiased basesare there in non-prime-power dimensions?
4. Since Chris Fuchs was so thrilled by my including one of his favorite questions on my earlier list (question #3 above), let me add another of his favorites: do SIC-POVMs exist in arbitrary finite dimensions?
5. Is there a Boolean function f:{0,1}n{0,1} whosebounded-error quantum query complexity isstrictly greater than n/2? (Thanks to Shelby Kimmel for this question! Note that this paper by van Dam shows that the bounded-error quantum query complexity never exceeds n/2+O(n), while this paper by Ambainis et al. shows that its at least n/2-O(n) for almost all Boolean functions f.)
6. Is there a universal disentangler: that is, a superoperator S that takes nO(1) qubits as input; that produces a 2n-qubit bipartite state (with n qubits on each side) as output;whose output S() is always close in variation distance to a separable state; and that given an appropriate input state, can produce as output an approximation to any desired separable state? (See here for background about this problem, originally posed by John Watrous. Note that if such an S existed and were computationally efficient, it would imply QMA=QMA(2).)
7. Suppose we have explicit descriptions ofn two-outcome POVM measurementssay,as dd Hermitian matrices E1,,Enand are also given k=(log(nd))O(1)copies of an unknown quantum state  in d dimensions. Is there a wayto measure the copiesso as to estimate the n expectation values Tr(E1),,Tr(En), each to constant additive error? (A forthcoming paper of mine on private-key quantum money will containsome background and related results.)
8. Is there a collection of 1- and 2-qubit gates that generates a groupof unitary matrices that is (a) not universal for quantum computation, (b) not just conjugate to permuted diagonal matrices or one-qubit gates plus swaps, and (c) not conjugate to a subgroup of the Clifford group?
9. Given a partial Boolean function f:S{0,1} with S{0,1}n, is the bounded-error quantum query complexity of falways polynomially related to the smallestdegree of any polynomial p:{0,1}nR such that (a) p(x)[0,1] for all x{0,1}n, and (b) |p(x)-f(x)|1/3 for all xS?
10. Is there a quantum finite automaton that reads in an infinite sequence of i.i.d. coin flips, and whose limiting probability of being found in anaccept state is at least 2/3 if the coin is fair and at most 1/3 if the coin is unfair? (See this paper by me and Andy Drucker for background and related results.)Why I Am Not An Integrated Information Theorist (or, The Unconscious Expander)

Happy birthday to me!
Recently, lots of peoplehave been askingme what I thinkaboutIITno, not the Indian Institutes of Technology, but Integrated Information Theory, awidely-discussed mathematical theory of consciousness developed over the past decade by the neuroscientist Giulio Tononi. One of the askerswas Max Tegmark, whos enthusiastically adopted IIT as a plank in his radical mathematizing platform (see his paper Consciousness as a State of Matter). When, in the comment thread about MaxsMathematical Universe Hypothesis, I expressed doubts about IIT, Max challenged me to back up my doubtswith a quantitative calculation.
So, this is the post that I promised to Max and all the others, about why I dont believe IIT. And yes, it will contain that quantitative calculation.
But first, what is IIT? The central ideas of IIT, as I understand them, are:
(1) to propose a quantitative measure, called , of the amount of integrated information in a physicalsystem (i.e. information that cant be localized in the systems individual parts), and then
(2) tohypothesizethat a physical system is conscious if and only if it has a large value of and indeed, that a system is more conscious the larger its  value.
Ill return later to the precise definition of but basically, its obtained by minimizing, over all subdivisionsof your physical system into two parts A and B,somemeasure of the mutual informationbetween As outputs and Bs inputs and vice versa. Now, one immediate consequence of anydefinition like thisis that all sorts of simple physical systems (a thermostat, a photodiode, etc.) will turn out to havesmall but nonzero  values. To his credit, Tononi cheerfully accepts the panpsychist implication: yes, he says, it really does meanthat thermostats and photodiodes have smallbut nonzero levels of consciousness. On the other hand, for the theory to work, it had better be the case that  is small for intuitively unconscious systems, and only large for intuitively conscious systems. As Ill explain later, this strikes me asacrucial point on whichIIT fails.
The literature on IITis too big to do it justicein a blog post. Strikingly, in addition to the primary literature, theres now even a secondary literature, which treatsIIT as a sort of establishedbase on which to build further speculations aboutconsciousness. Besides the Tegmark paper linked toabove, see for examplethis paperby Maguire et al., and associated popular article. (Ironically, Maguire et al. use IIT to argue for the Penrose-like viewthat consciousness might have uncomputable aspectsa usediametrically opposed to Tegmarks.)
Anyway, if you want to read a popular article aboutIIT,there are loadsof them: seeherefor theNew York Timess,hereforScientific Americans,hereforIEEE Spectrums, andherefor theNew Yorkers. Unfortunately, none of those articles will tell you the meat (i.e., the definition of integrated information); for that you need technical papers, likethisorthisby Tononi, orthisby Seth et al. IIT is also described in Christof Kochs memoirConsciousness: Confessions of a Romantic Reductionist, which I read and enjoyed; as well as TononisPhi: A Voyage from the Brain to the Soul, which I havent yet read. (Koch, one of the worlds best-knownthinkers and writers about consciousness, has also become an evangelist for IIT.)
So, I want to explainwhy I dont think IIT solveseven the problem that it plausibly could have solved. But beforeI can do that, I need to do some philosophical ground-clearing. Broadly speaking, what is it that a mathematical theory of consciousness is supposed to do? What questions should itanswer, and how should we judgewhether its succeeded?
The most obvious thing a consciousness theory could do is to explain why consciousness exists: that is, to solve what David Chalmers calls theHard Problem, by telling us how a clump of neurons is able to give rise to the taste of strawberries, the redness of red  you know, all that ineffable first-persony stuff. Alas, theres a strong argumentone that I, personally, find completely convincingwhy thats too much to ask of any scientific theory. Namely, no matter whatthe third-personfacts were, onecould always imagine a universeconsistent with those facts in which no one really experienced anything. So for example, if someone claimsthat integrated information explains why consciousness existsnope, sorry! Ive just conjured into my imagination beings whose -values are a thousand, nay a trillion times larger than humans, yet who are alsophilosophical zombies: entities that theres nothing that its like to be. Granted, maybesuch zombies cant exist in the actual world: maybe, if you tried to create one, God would notice its large-value and generously bequeath it a soul. But if so, then thats a further fact about our world, a factthat manifestly couldnt be deduced from the properties of alone. Notice that the detailsof are completely irrelevant to the argument.
Faced with this point, many scientifically-minded people start yelling and throwing things. They say that zombies and so forthare emptymetaphysics, and that our only hope of learning about consciousness is to engage with actual facts about the brain. And thats a perfectly reasonable position! As far as Im concerned, you absolutelyhave the option of dismissing ChalmersHard Problem as a navel-gazing distraction from the real work ofneuroscience. The one thing you cantdo is have it both ways: that is, you cant sayboth that the Hard Problem is meaningless, and that progress in neuroscience willsoon solvethe problem if it hasnt already. You cantmaintainsimultaneously that
(a) once you account for someones observed behavior and the details of their brain organization, theres nothing further about consciousness to be explained, and
(b) remarkably, the XYZtheory of consciousness canexplainthe nothing further (e.g., by reducing it to integrated information processing), or might be on the verge of doing so.
As obvious as this sounds, it seems to me that largeswaths of consciousness-theorizing can just be summarily rejected for trying to have their brain and eat it in precisely the above way.
Fortunately, I think IIT survives the above observations. For we can easily interpret IIT as trying to do something more modest than solve the Hard Problem, althoughstill staggeringly audacious. Namely, we can say that IIT merely aims to tell us which physical systems are associated with consciousness and which arent, purely in terms of the systems physical organization. The test of such atheory is whether it can produce results agreeing with commonsense intuition: for example, whether it can affirm, from first principles, that (most) humans are conscious; that dogs and horsesare also conscious but less so; that rocks, livers, bacteriacolonies, andexisting digital computers are not conscious (or are hardly conscious); and that a room full of people has no mega-consciousness over and above the consciousnesses of the individuals.
The reason its so important that the theory upholdcommon sense on thesetest cases is that, given the experimental inaccessibility of consciousness,this is basicallythe only test available to us. If the theory gets the test cases wrong (i.e., gives results diverging from common sense), its not clear that theresanything else for the theory to get right. Of course, supposing we had a theory that got the test cases right, we could then have a field day with theless-obvious cases, programming our computers to tell us exactly how much consciousness is present in octopi, fetuses, brain-damaged patients, and hypothetical AI bots.
In my opinion, how to constructa theory that tells us which physical systems are conscious and which arentgiving answersthat agree with common sensewhenever the latterrenders a verdictis one of the deepest, most fascinating problems in all of science. Since I dont know a standard name for the problem, Ihereby call it the Pretty-HardProblem of Consciousness. Unlike with the Hard Hard Problem, I dont know of anyphilosophical reason why the Pretty-Hard Problemshould be inherently unsolvable; but on the other hand, humans seemnowhere close tosolving it (if we had solved it, thenwecouldreduce the abortion, animal rights, and strong AI debates to gentlemen, let us calculate!).
Now,I regard IIT as a serious, honorable attempt to grapple with thePretty-Hard Problem of Consciousness: something concrete enough to move the discussion forward. But I also regard IIT as a failed attempt on the problem. And I wish people would recognize itsfailure, learn from it, and move on.
In my view, IIT fails to solve the Pretty-Hard Problem because itunavoidably predicts vastamounts of consciousness in physical systems that no sane personwould regard as particularlyconscious at all:indeed, systems that do nothing but apply a low-density parity-check code, or other simple transformations of their input data. Moreover, IIT predicts not merely that these systems are slightly conscious (which would be fine), but that they can be unboundedly more conscious than humans are.
To justify that claim, I first need to define. Strikingly, despite the large literature about, I had a hard time finding a clear mathematical definition of itone that not only listedformulas but fullydefined the structuresthat the formulas were talking about. Complicating matters further, there are several competing definitions of  in the literature, including DM (discrete memoryless), E(empirical), and AR (autoregressive), which apply indifferent contexts (e.g., some take time evolution into account and others dont). Nevertheless, I thinkI can define  in a way that will make sense to theoretical computer scientists. And crucially, the broad point I want to make about  wont depend muchon the details of its formalization anyway.
We consider a discrete system in a state x=(x1,,xn)Sn, where Sis a finite alphabet (the simplest case is S={0,1}). We imagine that the system evolves via an updating function f:SnSn. Then the question that interests us is whether the xis can be partitioned into two sets A and B, of roughly comparable size, such that the updates to the variables in A dont depend very much on the variables in B and vice versa. If such a partition exists, then we say that the computation of f does not involve global integration of information, which on Tononis theory is a defining aspect of consciousness.
More formally, given a partition (A,B) of {1,,n}, let us write an input y=(y1,,yn)Snto f in the form (yA,yB), where yA consists of the y variables in A and yB consists of the y variables in B. Then we can think of f as mapping an input pair (yA,yB) to an output pair (zA,zB). Now, we define the effective information EI(AB) as H(zB | A random, yB=xB). Or in words, EI(AB) is the Shannon entropy of the output variables in B, if the input variables in A are drawnuniformly at random, while the input variables in B are fixed to their values in x. Its a measure of the dependence of B on A in the computation of f(x). Similarly, we define
EI(BA) :=H(zA | B random, yA=xA).
We then consider the sum
(A,B) := EI(AB) +EI(BA).
Intuitively, wed like the integrated information=(f,x)be the minimum of (A,B), over all 2n-2 possible partitions of {1,,n} into nonempty sets A and B. The idea is that  should be large, if and only if its not possible to partition the variables into two sets A and B, in such a way that not much information flows from A to B or vice versa when f(x) is computed.
However, no sooner do we propose this than we notice a technical problem. What if A is much larger than B, or vice versa? As an extreme case, what if A={1,,n-1} and B={n}? In that case, well have(A,B)2log2|S|, but only for the boringreason that theres hardly any entropy in B as a whole, to either influence A or be influenced by it. For this reason, Tononi proposes a fix where we normalize each(A,B) by dividing it by min{|A|,|B|}. He then defines the integrated information to be(A,B), for whichever partition (A,B) minimizes the ratio(A,B) / min{|A|,|B|}. (Unless I missed it, Tononi never specifieswhat we should do if there are multiple (A,B)s that all achieve the same minimum of (A,B) /min{|A|,|B|}. Ill return to that point later, along with other idiosyncrasies of thenormalization procedure.)
Tononi gives some simple examples of the computation of , showing that it is indeed larger for systems that are more richly interconnected in an intuitive sense. He speculates, plausibly, that  is quite large for (some reasonable model of) the interconnection network of the human brainand probably larger for the brain than for typical electronic devices (which tend to be highly modular in design, thereby decreasing their), or, lets say, than for other organs like the pancreas. Ambitiously, he even speculates at length about how a large value of  might be connected to the phenomenology of consciousness.
To be sure, empirical work in integrated information theory has been hampered by threedifficulties. The first difficulty is that we dont know the detailed interconnection network of the human brain. The second difficulty is that its not even clear what we should define that network to be: for example, as a crudefirst attempt, should we assign a Boolean variable to each neuron, which equals 1 if the neuron is currently firing and 0 if its not firing, and let f be the function that updates those variables over a timescale of, say, a millisecond? What other variables do we needfiring rates,internal states ofthe neurons, neurotransmitter levels? Is choosingmany of these variables uniformly at random (for the purpose of calculating ) really a reasonable way to randomize the variables, and if not, what other prescription should we use?
The third and final difficulty is that, even if we knew exactlywhat we meant by the f and x corresponding to the human brain, and even if we had complete knowledge of that f and x, computing (f,x) could still be computationally intractable. For recall that the definition of involvedminimizing aquantity over all the exponentially-many possible bipartitions of {1,,n}. While its not directly relevant to my arguments in this post, I leave it as a challenge for interested readers to pin downthe computational complexity of approximating  to some reasonable precision, assuming that f is specifiedby a polynomial-size Boolean circuit, or alternatively, by an NC0 function (i.e., a function each of whose outputs depends on only a constant number of the inputs). (Presumably will be#P-hard to calculateexactly, but only because calculating entropy exactly is a #P-hard problemthats not interesting.)
I conjecture that approximating  is an NP-hard problem, even for restricted families of fs like NC0circuitswhich invites the amusing thought that God, or Nature, would need to solve an NP-hard problem just to decide whether or not to imbue a given physical system with consciousness! (Alas, if you wanted to exploit this asa practical approach for solvingNP-complete problems such as3SAT, youd need to do aratherdrastic experiment on your own brainan experimentwhose result would beto render you unconscious if your 3SAT instance was satisfiable, orconscious if it was unsatisfiable! In neither case would you be able to communicate the outcomeof the experiment to anyone else, nor would you have any recollection of the outcome after the experiment was finished.) In the other direction, it would also be interesting to upper-bound the complexity of approximating . Because of the need to estimate the entropies of distributions (even given a bipartition (A,B)), I dont know that this problem is in NPthe best I can observe is that its in AM.
In any case, my ownreason for rejectingIIT has nothing to do with any of themerely practical issues above: neither the difficulty of defining f and x, nor the difficulty of learning them, nor the difficulty of calculating(f,x). My reason is much more basic, striking directly at thehypothesized link between integrated informationand consciousness. Specifically, I claim the following:
Yes, it might be adecentrule of thumb that, if you want to knowwhichbrain regions(for example)are associated with consciousness, you should start by looking for regionswith lots of information integration. And yes, its even possible, for all I know,that having a large -value is one necessary condition among manyfor a physical system to be conscious. However, having a large-value is certainly nota sufficient condition for consciousness, or even for the appearance of consciousness. As a consequence,  cant possibly capturethe essence of what makes a physical system conscious, or even of what makes a system lookconscious to external observers.
The demonstration of this claim is embarrassingly simple. Let S=Fp, where p is some prime sufficiently larger than n, and let V be an nn Vandermonde matrix over Fpthat is, a matrix whose (i,j) entry equals ij-1 (mod p). Then let f:SnSnbe the update function defined by f(x)=Vx. Now, for p large enough, the Vandermonde matrix is well-known to have the property that every submatrix is full-rank (i.e., every submatrix preserves all the information that its possible to preserve about the part of x that it acts on). And this implies that, regardless of which bipartition (A,B) of {1,,n} we choose, well get
EI(AB) = EI(BA) = min{|A|,|B|} log2p,
and hence
(A,B) = EI(AB) +EI(BA) = 2min{|A|,|B|} log2p,
or after normalizing,
(A,B) /min{|A|,|B|} = 2log2p.
Or in words: the normalized information integration has the same valuenamely, the maximum value!for every possible bipartition. Now, Id like to proceed from here to a determination of  itself, but Im prevented from doing so by the ambiguity in the definition of that I notedearlier. Namely, since every bipartition (A,B) minimizes thenormalized value(A,B) /min{|A|,|B|}, in theory I ought to be able to pickany of them for the purpose of calculating . But the unnormalized value (A,B), which gives the final , can vary greatly,across bipartitions: from 2log2p (if min{|A|,|B|}=1) all the way up to n log2p(if min{|A|,|B|}=n/2). So at this point, is simply undefined.
On the other hand, I can solve this problem, and make well-defined, by an ironic little hack. The hack is to replace the Vandermonde matrix V by an nnmatrix W, whichconsists of the first n/2 rows of the Vandermonde matrix each repeated twice (assume for simplicity that n is a multiple of 4). As before, we let f(x)=Wx. Then if we set A={1,,n/2} and B={n/2+1,,n}, we can achieve
EI(AB) = EI(BA) = (n/4)log2p,
(A,B) = EI(AB) +EI(BA)=(n/2)log2p,
and hence
(A,B) /min{|A|,|B|} = log2p.
In this case, I claim that the above is the uniquebipartition that minimizes the normalized integrated information(A,B) /min{|A|,|B|}, up to trivial reorderings of the rows. To prove this claim: if |A|=|B|=n/2, then clearly we minimize (A,B) by maximizing the number of repeated rows in A and the number of repeated rows in B, exactlyas we did above. Thus, assume |A||B| (the case |B||A| isanalogous). Then clearly
EI(BA)  |A|/2,
while
EI(AB) min{|A|, |B|/2}.
So if we let |A|=cn and |B|=(1-c)n for some c(0,1/2], then
(A,B) [c/2 +min{c, (1-c)/2}] n,
and
(A,B) /min{|A|,|B|} =(A,B) / |A|= 1/2 + min{1, 1/(2c)  1/2}.
But the above expression is uniquely minimized when c=1/2. Hence the normalized integrated information is minimized essentially uniquely by setting A={1,,n/2} and B={n/2+1,,n}, and we get
 = (A,B)=(n/2)log2p,
which is quite a large value (only a factor of 2 less than the trivial upper bound of n log2p).
Now, why did I call the switch from V to W an ironic little hack? Because, in order to ensure a large value of , I decreasedby a factor of 2, in factthe amount of information integration that was intuitively happening in mysystem! I did that in order to decrease the normalized value(A,B) /min{|A|,|B|} for the particular bipartition (A,B) that I cared about, thereby ensuring that that (A,B) would be chosen over all the other bipartitions, thereby increasing the final, unnormalized value (A,B) that Tononis prescription tells me to return. I hope Im not alone in fearing that this illustrates a disturbing non-robustnessin the definition of .
But lets leave that issueaside; maybe it can be amelioratedby fiddling with the definition. The broader point is this: Ive shown that my systemthe system that simplyapplies the matrix W to an input vector xhas an enormous amount of integrated information. Indeed, this systems equals half of its entireinformation content. So for example, if n were 1014 or sosomething that wouldnt be hard to arrange with existing computersthen thissystems  would exceed any plausible upper bound on the integrated information content of the human brain.
And yet thisVandermondesystem doesnt even come close to doing anything that wed want to call intelligent, let alone conscious! When you apply the Vandermonde matrix to a vector, all youre really doing is mapping the list of coefficients of a degree-(n-1) polynomial over Fp, to the valuesof the polynomial on the n points 0,1,,n-1. Now, evaluating a polynomial on a setof points turns out to bean excellent way to achieveintegratedinformation, with everysubset of outputs as correlated withevery subset of inputs as itcould possibly be. In fact, thats precisely why polynomials are used so heavily in error-correcting codes, such as the Reed-Solomon code, employed(among many other places) in CDs and DVDs. But that doesnt implythat every time you start up your DVD player youre lighting the fire of consciousness. It doesnt even hint at such a thing. All it tells us is that you can have integrated information without consciousness (or even intelligence)just like you can have computation without consciousness, and unpredictabilitywithout consciousness, and electricity without consciousness.
It might be objected that, in definingmy Vandermonde system, I was too abstract and mathematical. I said that the system maps the input vector x to the output vector Wx, but I didnt say anything abouthow it did so. To perform a computationeven a computation as simple as a matrix-vector multiplywont we need a physical network of wires, logic gates, and so forth? And in any realistic such network, wont each logic gatebe directly connected to at most a few other gates, rather than to billions of them? And if we define the integrated information, not directly in terms of the inputs and outputs of the function f(x)=Wx, but in terms of all the actual logicgates involved incomputing f, isnt it possible or even likely that will go back down?
This is a good objection, but I dont think it canrescue IIT. For we can achieve the same qualitative effect that I illustrated with the Vandermonde matrixthe same global information integration, in whichevery large set of outputs depends heavily on every large set of inputseven using much sparser computations, ones where each individual output depends on only a few of the inputs. This is precisely the idea behind low-density parity check (LDPC) codes, which have had a major impact on coding theory over the past two decades. Of course, one would need to muckaround a bit to construct a physical system based on LDPC codes whose integrated information  was provably large, and for which there were no wildly-unbalanced bipartitions that achieved lower (A,B)/min{|A|,|B|} values than the balanced bipartitions one cared about. But I feel safe in asserting that this could be done,similarly to how I did it withthe Vandermonde matrix.
More generally, we can achieve pretty good information integration by hooking together logic gates accordingto any bipartite expander graph: that is, any graph with n vertices on each side,such thatevery k vertices on the left side are connected to at least min{(1+)k,n} vertices on the right side, for some constant >0. And its well-known how to create expander graphswhose degree (i.e., the number of edges incident to each vertex, or the number of wires coming out of each logic gate) is a constant, such as 3. One can do soeither by plunking down edges at random, or (less trivially) by explicit constructions from algebra or combinatorics. And as indicated in the title of this post, I feel 100% confident in saying that the so-constructedexpander graphs are not conscious! The brain might be an expander, but not every expander is a brain.
Before winding down this post, I cant resist telling you that the concept ofintegrated information (though it wasnt called that) played an interestingrole in computational complexity in the 1970s. As I understand the history, Leslie Valiant conjectured that Boolean functions f:{0,1}n{0,1}nwith a high degree of information integration (such as discrete analogues of the Fourier transform) mightbe good candidates for proving circuit lower bounds, which in turn might be baby steps toward PNP. More strongly, Valiantconjecturedthat the property of information integration, all by itself, implied that suchfunctions had to beat least somewhat computationally complexi.e., that they couldnt be computedby circuits of size O(n), or even requiredcircuits of size (n log n). Alas, that hope was refutedby Valiants laterdiscovery of linear-size superconcentrators. Just as information integration doesnt suffice for intelligence or consciousness, so Valiant learnedthat information integration doesnt suffice for circuit lower bounds either.
As humans, we seem to have the intuition that global integration of information is such a powerful propertythat nosimple or mundane computational process could possibly achieve it. But our intuition is wrong. If it were right, then we wouldnt have linear-size superconcentrators or LDPC codes.
I should mention that I had the privilege of briefly speakingwithGiulio Tononi (as well as his collaborator, Christof Koch) this winter at an FQXi conference in Puerto Rico. At that time, I challenged Tononi with a much cruder, handwavier version of some of the same points that I made above. Tononis response, as best as I can reconstruct it, wasthat its wrong to approach IITlike a mathematician; instead one needsto start from the inside, with the phenomenology of consciousness, and only then tryto buildgeneral theories that can be tested against counterexamples. This response perplexed me: of course you can start from phenomenology, or from anything else you like, when constructing your theory of consciousness. However, once yourtheory has been constructed, surely its then fair game for others to try to refute itwith counterexamples? And surely the theory should be judged, like anything else in science or philosophy, by how well it withstands such attacks?
But let me end on a positive note. In my opinion, the fact that Integrated Information Theory is wrongdemonstrably wrong, for reasons that go to its coreputs it in something like the top 2% of all mathematical theories of consciousness ever proposed. Almost allcompeting theories of consciousness, it seems to me,have beenso vague, fluffy, and malleable that they can only aspire to wrongness.
[Endnote: See also this related post, by the philosopher Eric Schwetzgebel: Why Tononi Should Think That the United States Is Conscious. While the discussion is much more informal, and the proposed counterexample more debatable, the basic objection to IITis the same.]

Update (5/22): Here are a fewclarifications of this post that might be helpful.
(1) The stuff about zombies and theHard Problem was simplymeant asmotivation and background for what I called the Pretty-Hard Problem of Consciousnessthe problem that I take IIT to be addressing. You can disagree with the zombie stuff without it having any effect on my arguments about IIT.
(2) I wasntarguing in this postthat dualism is true, or that consciousness is irreducibly mysterious, or that there could never be any convincing theory that told us how much consciousness was present in a physical system. All I was arguing was that, at any rate, IIT is not such a theory.
(3) Yes, its true that my demonstrationof IITs falsehoodassumesas an axiom, if you likethatwhile we might not know exactly what we mean byconsciousness, at any rate were talking aboutsomething that humans have to a greaterextent than DVD players. If you reject that axiom, then Id simply want to definea new word for a certain qualitythat non-anesthetized humans seem to have and that DVD players seem not to, and clarify that that other qualityis the oneIm interested in.
(4) For my counterexample, the reason I chosetheVandermonde matrix is not merely that its invertible, but that all of its submatrices are full-rank. This is the property thats relevant for producing a large value of the integrated information; by contrast, note that the identity matrix is invertible,but produces a system with =0. (As another note, if we work overa large enough field, then arandom matrix will have thissame property with high probabilitybut I wanted an explicit example, and while the Vandermonde is far from the only one, its one ofthe simplest.)
(5) The nn Vandermonde matrix only does what I want if we work over (say) a primefield Fp with p>>n elements. Thus, its natural to wonder whether similar examples exist where the basic system variables are bits, rather than elements of Fp. The answer is yes. One way to get such examples is using the low-density parity check codes that I mention in the post. Another common way to get Booleanexamples, and which is also used in practice in error-correcting codes, is to start with the Vandermonde matrix (a.k.a. the Reed-Solomon code), and then combine it with an additional component that encodes the elements of Fp as strings of bits in some way. Of course, you then need to check that doing this doesnt harm the properties of the original Vandermonde matrix that you cared about (e.g., the information integration) too much, which causes someadditional complication.
(6) Finally, it might be objected that my counterexamples ignored the issue of dynamics and feedback loops: they all consisted of unidirectional processes, which map inputs to outputs and then halt. However, this can be fixed by the simple expedient of iterating the process over and over! I.e., first map x to Wx, then map Wx to W2x, and so on. The integrated information should then be the same as in the unidirectional case.

Update (5/24): See a very interesting comment by David Chalmers.Announcing the Shtetl-Optimized Math Journalism Award!

To those of us who cant tell a hypotenuse from a rhombus, the phrase math journalism sounds like an oxymoron.  It brings to mind boring pedants like Martin Gardner, Sara Robinson, and Brian Hayes, who make everything seem confusing and complicated, and who wont even write a single word without consulting two dozen experts.  But today, a new breed of journalist is bringing math directly to the people  and theyre doing it with flair, pizzazz, and an eye for the all-too-neglected human side.
Thats why Im proud to announce Shtetl-Optimizeds semiregular Math Journalism Award, intended to recognize those journalists who make fractions, long division, and other topics of current research seem as easy as pi even to those of us who cant balance our checkbooks and never did get algebra.  The inaugural award goes to Ben Moore of the BBC, for his fascinating report about a maverick professor whos solved a problem that befuddled Newton and Pythagoras over 1,200 years ago  not to mention millions of students since!  The problem: what happens when you divide by zero?
Feel free to nominate other journalists for this prestigious award.  (Hat tip for this one goes to my brother David.)Hath not a nerd eyes?

When someone wrote to Richard Feynman to tell him how his bongo-drumming habit proved that physicists can also be human, Feynman shot back a scathing reply: I am human enough to tell you to go fuck yourself. Why was Feynman so angry? Because for him, the notion that physicists had to prove their humanity by having non-scientific interests was an arrogant presumption. Why not point to a guitarist who enjoys doing math on the side, as proof that musicians can also be human?
While its possible that Feynman overreacted to what was meant as a compliment, a quick glance at American popular culture demonstrates that he had a point. In the minds of many Hollywood writers, there are apparently only two kinds of scientist: (1) the asexual nerd who babbles incomprehensibly before getting killed around scene 3 (unless of course hes the villain), and (2) the occasional character whos human despite being a scientist, as demonstrated by his or her charm, physical agility, and fashion sense. The idea that one can be both nerdy and sympathetic  indeed, that nerdiness might even have positive aspects  is absent.
This trend is so pervasive that, whenever a movie bucks it even partly, Im inclined to overlook any other flaws it might have. Thus, for example, I enjoyed both A Beautiful Mind and Enigma, despite those movies liberal departures from the true stories on which they were based. But the most unabashed celebration of nerdiness Ive seen in cinema is a little-known 80s comedy called Real Genius. I was introduced to this movie by Christine Chung, a friend at Cornell. Then I saw it again with friends at Berkeley. Yesterday I continued the tradition by organizing a screening for friends at Waterloo.
Briefly, Real Genius follows the adventures of Mitch, a 15-year-old who goes to a college obviously based on Caltech, having been recruited by the duplicitous Professor Hathaway to work on powerful lasers. Mitch is sympathetic, not because he defies the stereotype of a 15-year-old at Caltech, but because were shown some of the emotions behind that stereotype: the feeling of outsiderness, of taking up space on the planet only at other peoples mercy; the fear of failure, of letting down his parents, Professor Hathaway, and others who expect great things from him; but at the same time, the longing for the easy social confidence represented by his roommate Chris (who used to be a teenage prodigy like Mitch, but is now a womanizing slacker). All of this is shown with enough wit and humor that theres no need for Mitch to make an explicit declaration:
Hath not a nerd eyes? Hath not a nerd hands organs, dimensions, senses, affections, passions; fed with the same food, hurt with the same weapons, subject to the same diseases, heald by the same means, warmd and coold by the same winter and summer, as a quarterback is?Quantum Computing Since Democritus Lecture 8: Crypto

Psst  one-way functions?  Pseudorandom generators?  Lattices?  RSA?  Come and get em, in plaintext.
Gus Gutoski took notes for this all about cryptography lecture, and they were so good that Ive posted them with only moderate editing and joke-reinsertion.  Ive thereby provided you, my readers, with the unique opportunity to experience my lecture as Gus himself experienced it  as if you actually were Gus, sitting in a real Waterloo classroom taking notes.
For those of you who feel the need to prepare yourselves for this experience, heres a recap of all the lectures so far:

Lecture 1 (9/12): Atoms and the Void
Lecture 2 (9/14): Sets
Lecture 3 (9/19): Gdel, Turing, and Friends
Lecture 4 (9/21): Minds and Machines
Lecture 5 (9/26): Paleocomplexity
Lecture 6 (9/28): P, NP, and Friends
Lecture 7 (10/3): Randomness
Lecture 8 (10/5): Crypto

Update: Preparing these notes is a sh&tload of work for me.  So dude  if you want me to keep doing it, please let me know in the comments section if youre actually reading the notes and deriving any benefit therefrom.  Constructive criticism would also be fantastic.  Thanks very much!Quantifying the Rise and Fall of Complexity in Closed Systems: The Coffee Automaton

Update (June 3):A few days after we posted this paper online, Brent Werness, a postdoc in probability theory at the University of Washington, discovered a serious error in the experimental part of the paper. Happily, Brent is now collaborating with us on producing a new version of the paper that fixes the error, which we hope to have available within a few months(and which will replace the version currently on the arXiv).
To make a long story short: while the overall idea, of measuring apparent complexity by the compressedfile size of a coarse-grained image, is fine, the interacting coffee automaton that we study in the paper is not an example where the apparent complexity becomes large at intermediate times. That fact can be deduced as a corollary of aresult of Liggett from 2009about the symmetric exclusion process, and can be seen as a far-reaching generalization of a result that we prove in our papers appendix: namely, that in the non-interacting coffee automaton (our control case), the apparent complexity after t time steps is upper-bounded by O(log(nt)). As it turns out, we were more right than we knew to worry about large-deviation bounds giving complete mathematical control over what happens when the cream spills into the coffee, thereby preventing the apparent complexity from ever becoming large!
But what about our numericalresults, which showed a small but unmistakable complexity bump for the interacting automaton (figure 10(a) in the paper)? It now appears that the complexity bump we saw in our data is likely to be explainable by an incomplete removal of what we called border pixel artifacts: that is, spurious complexity that arises merely from the fact that, at the border between cream and coffee, we need to round the fraction of cream up or down to the nearest integer to produce a grayscale. In the paper, we devoted a whole section (Section 6) to border pixel artifacts and the need to deal with them: something sufficiently non-obvious that in the comments of this post, you can find people arguing with me that its a non-issue. Well, it now appears that we erred by underestimating the severity of border pixel artifacts, and that a better procedureto get rid of them would also eliminate the complexity bump for the interacting automaton.
Once again, this errorhas no effect on either the general idea of complexity rising and then falling in closed thermodynamic systems, orour proposalforhow to quantify that rise and fallthe two aspects of the paper that have generated themost interest. But we made a badchoice ofmodel system with which to illustrate those ideas. Had I looked more carefully at the data, I couldve noticed the problem before we posted, and I take responsibility for my failure to do so.
The good news is that ultimately, I think the truth only makes ourstorymore interesting. For it turns out that apparent complexity, as we define it, is not something thats trivial to achieve by just setting loose a bunch of randomly-walking particles, which bump into each other but are otherwise completely independent. If you want complexity along the approach to thermal equilibrium, you needto work a bit harder for it. One promising idea, which were now exploring, is to consider a cream tendril whose tip takes a random walk through the coffee, leaving a trail of cream in its wake. Using results in probability theoryclosely related, or so Im told, to the results for which Wendelin Werner won his Fields Medal!it may even be possible to prove analytically that the apparent complexity becomes large in thermodynamic systems with this sort of behavior, much as one can prove that the complexitydoesnt become large in our original coffee automaton.
So, if youre interested in this topic, stay tuned for the updated version of our paper. In the meantime, I wish to express our deepest imaginable gratitude to Brent Werness for telling us all this.

Good news! After nearly three years of procrastination, fellow blogger Sean Carroll, former MIT undergraduate Lauren Ouellette, and yours trulyfinally finished a paper with the above title(coming soon to an arXiv near you). PowerPoint slides are also available (as usual, youre on your own if you cant open themsorry!).
For the background and context of this paper, please see my old post The First Law of Complexodynamics,which discussed Seansproblem of defining a complextropy measure that first increases and then decreases in closed thermodynamic systems, in contrast to entropy (which increases monotonically). In this exploratory paper, we basically do fivethings:

We surveyseveral candidate complextropy measures: their strengths, weaknesses, and relations to one another.
We proposea model system for studying suchmeasures: a probabilistic cellular automaton that models a cup of coffee into which cream has just been poured.
We report the results of numerical experiments with one of the measures, which we call apparent complexity (basically, the gzip file size of a smeared-out image of the coffee cup). The results confirm that the apparent complexity does indeed increase, reach a maximum, then turn around and decrease as the coffee and cream mix.
We discuss a technical issue that one needs to overcome (the so-called border pixels problem) before one can do meaningful experiments in this area, and offer a solution.
We raise the openproblem of proving analytically that the apparent complexity ever becomes large for the coffee automaton. To underscore this problems difficulty, we prove that the apparent complexity doesntbecome large in a simplified version of the coffee automaton.

Anyway, heres the abstract:
In contrast to entropy, which increases monotonically, the complexity or interestingness of closed systems seems intuitively to increase at first and then decrease as equilibrium is approached. For example, our universe lacked complex structures at the Big Bang and will also lack them after black holes evaporate and particles are dispersed. This paper makes an initial attempt to quantify this pattern. As a model system, we use a simple, two-dimensional cellular automaton that simulates the mixing of two liquids (coffee and cream). A plausible complexity measure is then the Kolmogorov complexity of a coarse-grained approximation of the automatons state, which we dub the apparent complexity. We study this complexity measure, and show analytically that it never becomes large when the liquid particles are non-interacting. By contrast, when the particles do interact, we give numerical evidence that the complexity reaches a maximum comparable to the coffee cups horizontal dimension. We raise the problem of proving this behavior analytically.
Questions and comments more than welcome.

In unrelated news, Shafi Goldwasser has asked me to announce that the Call for Papers for the 2015 Innovations in Theoretical Computer Science (ITCS) conference is now available.Mercenary in the String Wars

My sojourn in Northern California is now at an end; on Sunday I flew to my parents place near Philadelphia for Hanukhrismanewyears.  But not before going to Stanford to give a talk to their string theory group about Computational Complexity and the Anthropic Principle.  Here are the notes from that talk; you can think of them as a Quantum Computing Since Democritus Special Bonus Lecture.
(The best part of the talk  the lengthy arguments with Lenny Susskind, Andrei Linde, and the other stringers and cosmologists, in which I repeatedly used humor to mask my utter lack of understanding  is sadly lost to eternity.  Fortunately, Im sure that new such arguments will erupt in the comments section.)
In preparation for meeting Susskind and the other Stanford stringers, I made sure to brush up on both sides of the String Wars.  On the anti-string side, I read Peter Woits Not Even Wrong and Lee Smolins The Trouble With Physics.  On the pro-string side, I read Susskinds The Cosmic Landscape and also spent hours talking with Greg Kuperberg, who tried to convince me that critics of string theory are as intellectually non-serious as quantum computing skeptics or Ralph Nader voters.  I heartily recommend all three of the books.
So, what did I learn at Stanford?   Among other things, that when you talk to string theorists in person, theyre much more open-minded and reasonable than youd expect!  Of course, when your de facto spokesman is the self-parodying Lubo Motl  who often manages to excoriate feminists, climatologists, and loop quantum gravity theorists in the very same sentence  its hard not to seem reasonable by comparison.   But Im not even talking about him.
(Conflict-of-interest warning: Im painfully well aware that, so long as Lubo is around, I can only ever be the second-funniest physics blogger  even if the world champion in this field isnt trying to be funny.)
In general, Ive found that tolerance for alternative ideas, willingness to engage with counterarguments, rejection of appeals to authority, and so on are all greater when talking to string theorists in person than when attending their talks or reading their books and articles.  Maybe thats to be expected  to some extent its true of every field!  But with string theorists, the magnitude of the difference always astonishes me.
Alright, let me get more concrete.  One of the few nontrivial points of agreement between string theory and loop quantum gravity seems to be that, in any bounded region of spacetime, the number of bits of information is finite: at most ~1069 bits per square meter of surface area, or (equivalently) at most ~1 bit per Planck area.  In loop quantum gravity, this is basically because one bit of information is stored in each Planck area.  In string theory, its much more subtle than that: the bits of information cant be put into any sort of one-to-one correspondence with the Planck areas on the horizon, but they both add up to the same number.  (Ignoring a factor of 4, which being a complexity theorist, I dont care about.)
Now, much of my conversation with Susskind and fellow string theorist Steve Shenker focused on the following question: isnt it a bizarre coincidence that the Planck areas and the bits of information should both add up to the same number, if theres no dual description of string theory in which each bit (or rather qubit) is stored in a Planck area?  Susskind agreed with me that such a local description of string theory (local on the boundary, not in the bulk) would be desirable  and that, if there isnt such a description, then that by itself is a fundamental fact worthy of more attention.  Id expected Susskind and Shenker to brush aside my question as idle pontificating; instead, they seemed to want to reinvent string theory that very afternoon so that my question would have an answer!
When it became clear that no such reinvention of the theory was forthcoming (at least that afternoon), I suggested the following.  Weve got this one proposal, string theory, which has had some spectacular technical successes (like explaining the Bekenstein-Hawking entropy), but which, setting aside its other well-known problems, offers no local description of spacetime in terms of qubits and quantum circuits at the Planck scale.  Then weve got this other proposal, loop quantum gravity, which has had fewer successes, but which does attempt such a local description at the Planck scale.  So, if we agree that such a local description is our eventual goal, then shouldnt an outsider guess that string theory and loop quantum gravity are probably just different footprints of the same beast  much like the different string theories themselves were found to be different limiting cases of an as-yet-unknown M-theory?
Susskind agreed that such a convergence  between the top-down picture of string theory, which grew out of conventional high-energy physics, and a bottom-up picture in terms of qubits at the Planck scale  was possible or even likely.  He stressed that his opposition was not to the idea of describing spacetime in terms of local interactions of qubits, but rather to the specific technical program of loop quantum gravity, and to the exaggerated claims often made on that programs behalf.  When I reminded him that other people complain about exaggerated claims made on string theorys behalf, he replied that the two cases were not even remotely comparable.
All in all, it was an extremely productive and enjoyable visit  one in which the conversation topics ranged over (among other things) the explanatory role of the Anthropic Principle, the possibility that the entire universe arose as a quantum fluctuation, the prospects for an efficient quantum algorithm for Graph Isomorphism, the relation between thermodynamics and quantum error-correction, and whether or not Gerard t Hooft actually disbelieves quantum mechanics.  Susskind told me, half-jokingly, that the Stanford string theory group was the worlds hotbed of anti-Landscape sentiment, and the arguments that I saw and participated in on my visit gave me no reason to doubt him.
So what are we to make of the fact that, on the one hand, the string theorists are such swell folks in person, and on the other hand, even the most cursory glance at their writings will reveal that the charge of triumphalist arrogance is far from undeserved?  Well, to the anti-stringers, the obvious interpretation will be that the string theorists dont really believe their own pablum: that they say one thing in public and a completely different thing in private.  To the pro-stringers, the obvious interpretation will be that, beneath the faade we all erect around ourselves, the string theorists are just scientists like anyone else: grasping at the truth, struggling to learn more, convinced that string theory is the best idea we have but ready to ditch it if something better comes along.  As usual, it all depends on where youre coming from.
Alas, as tidy as this resolution sounds, it doesnt help me pick sides in the String Wars currently raging through the blogosphere.  But then again, why do I need to pick sides?  I like hanging out with the loop quantum gravity people at Perimeter Institute.  I like the fact that Lee Smolins publisher sent me a free review copy of The Trouble With Physics.  I like the recent paper by Denef and Douglas on computational complexity and the string Landscape.  And I like getting an all-expenses-paid trip to Stanford to have a freewheeling, day-long intellectual conversation with the string theorists there.
I have therefore reached a decision.  From this day forward, my allegiances in the String Wars will be open for sale to the highest bidder.  Like a cynical arms merchant, I will offer my computational-complexity and humor services to both sides, and publicly espouse the views of whichever side seems more interested in buying them at the moment.  Fly me to an exotic enough location, put me up in a swank enough hotel, and the number of spacetime dimensions can be anything you want it to be: 4, 10, 11, or even 172.9+3i.  Is it more important for a quantum gravity theory to connect to the Standard Model, or to build in background-independence from the outset?  Can one use the Anthropic Principle to make falsifiable predictions?  How much is riding on whether or not the LHC finds supersymmetry?  I might have opinions on these topics, but theyre nothing that a cushy job offer or a suitcase full of reimbursements couldnt change.
Someday, perhaps, a dramatic new experimental finding or theoretical breakthrough will change the situation vis--vis string theory and its competitors.  Until then, I shall answer to no quantum-gravity research program, but rather seek to profit from them all.
Update (12/23): The indefatigable Lubo Motl has put up a new jeremiad against me.  Taking my For Sale announcement completely seriously, Lubo writes:
It is absolutely impossible for me to hide how intensely I despise people like Scott Aaronson  Hes the ultimate example of a complete moral breakdown of a scientist. It is astonishing that the situation became so bad that the people are not only corrupt and dishonest but they proudly announce this fact on their blogs

In fact, I have learned that the situation is so bad that when I simply state that Aaronsons attitude is flagrantly incompatible with the ethical standards of a scholar as they have been understood for centuries, there could be some parts of the official establishment that would support him against me. There doesnt seem to be a single blog article besides mine that denounces Aaronsons attitude

The difference between [the] two of us is like the difference between a superman from the action movies who fights for the universal justice on one side and the most dirty corrupt villain on the other side. Its like the Heaven and the Hell, freedom and feminism, careful evaluation of the climate and the alarmist hysteria, or string theory and loop quantum gravity
I cant tell you how proud I am to have become the most dirty corrupt villain in Lubos cosmology, and no longer just an anonymous bystander.  Thanks so much, Lubo, and Merry Christmas to you too!
Update (12/24): Man oh man, I had no idea that people would take my offer so seriously!  Because of this, I now feel obligated to provide a financial disclosure statement.   The Stanford string theorists did not actually pay my way to California, although they offered to  most of my expenses were covered by Umesh, my adviser at Berkeley.  Stanford paid for (1) one nights hotel stay in Palo Alto, and (2) one lunch, consisting of a small cheese pizza and an iced tea.Eigenmorality

This post is about an idea I had around 1997, when I was 16 years old and a freshman computer-science major at Cornell. Back then, I was extremely impressed by a research project called CLEVER, which one of my professors, Jon Kleinberg, had ledwhile working at IBM Almaden. The idea was to use the link structure of the web itself to rank which web pages were most important, and therefore which ones should be returned first in a search query. Specifically, Kleinberg defined hubs as pages that linked to lots of authorities, and authorities as pages that were linked to by lots of hubs. At first glance, this definition seems hopelessly circular, but Kleinberg observed that one can break the circularity by justtreating the World Wide Web as a giant directed graph, and doing some linear algebra on its adjacency matrix. Equivalently, you can imagine an iterative process where each web page starts out with the same hub/authority starting credits, butthen in each round, the pages distribute their credits among their neighbors, so that the most popular pages get more credits, which they can then, in turn, distribute to their neighbors by linking to them.
I wasalsoimpressed by asimilarresearch projectcalled PageRank, which wasproposed later by two guys at Stanford named Sergey Brin and Larry Page. Brin and Page dispensed with Kleinbergs bipartitehubs-and-authorities structure in favor of a more uniform structure, and made some other changes, but otherwise their idea was verysimilar. At the time, of course, I didnt knowthat CLEVER was going to languish at IBM, while PageRank (renamedGoogle) was goingto expand to roughly the size of the entire worlds economy.
In any case, the question I asked myself about CLEVER/PageRank was not the one that, maybe in retrospect, Ishould have asked: namely,how can I leverage the fact that I knowthe importance of this idea before most people do, in order to make millions of dollars?
Instead I asked myself:what other vicious circles in science and philosophy could one unravel using the same linear-algebra trick that CLEVER and PageRank exploit? After all, CLEVER and PageRankwere both founded onwhat looked like a hopelessly circular intuition: a web page is important if other important web pages link to it. Yetthey bothmanaged to use mathto defeatthe circularity. All you had to do was findan importance equilibrium, in which your assignment of importance to each web page was stable under a certain linear map. And such an equilibrium could be shown to existindeed, to exist uniquely.
Searching for other circular notionsto elucidate using linear algebra, I hit on morality. Philosophers from Socrates on, I was vaguely aware, had struggled to define what makes a personmoral or virtuous, without tacitly presupposing the answer. Well, it seemed to me that, as a first attempt, one could do a lot worse than the following:
A moral person is someone who cooperates with other moral people, and whorefuses to cooperate with immoral people.
Obviously one canquibble withthis definition on numerousgrounds: for example, what exactly does it mean to cooperate, and which other people are relevant here? If you dont donate money to starving children in Africa, have you implicitly refused to cooperate with them? Whats the relative importance of cooperating with good people and withholding cooperation with bad people, of kindness and justice? Is there a duty not to cooperate with bad people, or merely the lack of a duty to cooperate with them? Should we consider intent, or only outcomes? Surely we shouldnt hold someone accountable for sheltering a burglar, if they didnt know about the burgling? Also, shouldwe compute your total morality by simply summing over your interactions with everyone else in yourcommunity? If so, then can a careers worthof lifesaving surgeriesnumerically overwhelm the badness of murderinga single child?
For now, I want you to set all of these important questions aside, and just focus on the fact that the definition doesnt even seem to work on its own terms, because of circularity. How can we possibly knowwhich people are moral (and hence worthy of our cooperation), and which ones immoral (and hence unworthy), without presupposing the very thing that we seek to define?
Ah, I thoughtthis is precisely where linear algebra can come to the rescue! Just like in CLEVER or PageRank, we can beginby giving everyone in the community an equal number of morality starting credits. Then we can apply an iterative update rule, where each person A can gain morality credits by cooperating with each other person B, and A gains more credits the more credits B has already. We apply the rule over and over, until the number of morality credits per person converges to an equilibrium. (Or, of course, we can shortcut the process by simply finding the principal eigenvector of thecooperation matrix, using whatever algorithm we like.) We then have ourobjective measure of morality for each individual, solving a 2400-year-old open problem in philosophy.
The next step, I figured, would be to hack togethersome code that computed this eigenmorality metric, and then see what happened when I ran the code to measurethe morality of each participant in a simulated society. What would happen? Would the results conform to my pre-theoretic intuitions about what sort of behavior was moral and what wasnt? If not, thenwould watching the simulation give me new ideas about how to improve the morality metric? Or would it be my intuitions themselves that would change?
Unfortunately, I never got around to the coding it up parttheres a reason why I became a theorist! The eigenmorality idea went onto my back burner, where it stayedfor the next 16 years: 16 years in which ourworld descended ever further into darkness, lacking a principled way to quantify morality. But finally, this year, just two separate things have happened on the eigenmorality front, and thats why Im blogging about it now.
Eigenjesus and Eigenmoses
The first thing thats happened is that Tyler Singer-Clark, my superb former undergraduate advisee, did code up eigenmorality metrics and test them out on a simulated society, for his MIT senior thesis project. You can read Tylers12-pagereport hereits a fun, enjoyable, thought-provoking firstresearch paper, one that I wholeheartedly recommend. Or, if youd like to experiment yourself with the Python code, you can download it here from github. (Of course, all opinions expressed in this post are mine alone, not necessarily Tylers.)
Briefly, Tyler examinedwhat eigenmorality has to say in the setting of an Iterated Prisoners Dilemma(IPD)tournament. The Iterated Prisoners Dilemma is the famous game in which two players meet repeatedly, and in each turn can either Cooperate or Defect. The absolute best thing, from your perspective, is if you defect while your partnercooperates. But youre also pretty happy if you both cooperate. Youre less happy if you both defect, while the worst (from your standpoint) is if you cooperate while your partner defects. At each turn, when contemplatingwhat to do, you have the entire previous history of your interaction with this partner available to you. And thus, for example, you can decide to punish your partner for past defections, reward her for past cooperations, or try to take advantage by unilaterally defecting and seeing what happens. At each turn, the game has some small constant probability of endingso you know approximatelyhow many timesyoull meet this partner in the future, but you dont know exactly when the last turn will be. Your score, in the game, is then the sum-total of your score over all turns and all partners (where each player meets each other player once).
In the late 1970s, as recounted in his classic workThe Evolution of Cooperation, Robert Axelrod invited people all over the world to submit computer programs for playing this game, which were then pit against each other in the worlds first seriousIPD tournament. And, in a talethats been retold in hundreds of popular books, while many people submitted complicated programs that used machine learning, etc. to try to suss out their opponents, the program that wonhands-down, repeatedlywas TIT_FOR_TAT, a few lines of code submitted by the psychologist Anatol Rapaport to implement an ancient moral maxim. TIT_FOR_TAT starts out by cooperating; thereafter, it simply does whatever its opponent did in the last move, swiftlyrewarding every cooperation and punishing every defection, and ignoring the entire previous history. In the decades since Axelrod, running Iterated Prisoners Dilemma tournaments has become a minor industry, with countless variations explored (for example, evolutionary versions, and versions allowing side-communication between the players), countless new strategies invented, and countless papers published. To make a long story short, TIT_FOR_TAT continues to do quite well across a wide range of environments, but depending on the mix of players present, other strategies can sometimes beat TIT_FOR_TAT. (As one example, if theres a sizableminority of colluding players, who recognize each other by cooperating and defecting in a prearranged sequence, then those players can destroyTIT_FOR_TAT and other simple strategies, by cooperating with oneanother while defecting against everyone else.)
Anyway, Tyler sets up and runs a fairlystandard IPD tournament, with a mix of strategies that includes TIT_FOR_TAT, TIT_FOR_TWO_TATS, other TIT_FOR_TAT variations, PAVLOV, FRIEDMAN, EATHERLY, CHAMPION (see the paper for details), and degeneratestrategies like always defecting, always cooperating, and playing randomly. However, Tylerthen asks an unusual question about the IPD tournament: namely, purely on the basis of the cooperate/defect sequences, which players should we judge to have acted morallytoward their partners?
It might be objected that the players didnt know they were going to be graded on morality: as far as they knew, they were just trying to maximize their individual utilities. The troublewith that objection is that the players didnt know they were trying to maximize their utilities either! The players are bots, which do whatever their code tells them to do. So in some sense, utilityno less than moralityis merelyan interpretation that weimpose on the raw cooperate/defect sequences!Theres nothing to stopus from imposing some other interpretation (say, one that explicitly tries to measure morality) and seeing what happens.
In an attempt to measure the players morality, Tyler usesthe eigenmorality idea from before. The extentto which player A cooperates with player B is simply measured by the percentageof times A cooperates. (One acknowledged limitation of this work is that, when two players both defect, theres no attempt to take into account who started it, and to judge the aggressor more harshly than the retaliatoror to incorporate time in any other way.) This then gives us a cooperation matrix, whose (i,j) entry records the total amount of niceness that player i displayed to player j. Diagonalizing that matrix, and taking its largest eigenvector, then gives us our morality scores.
Now, theres a very interesting ambiguity in what I said above. Namely, should we define the niceness scores to lie in [0,1] (so that the lowest, meanest possible score is 0), or in [-1,1] (so that its possible to have negative niceness)? This might sound like a triviality, but in our setting, its precisely the mathematical reflection of one of thephilosophicalconundrums I mentioned earlier. The conundrum can be stated as follows: is your morality a monotone function of your niceness? We all agree, presumably, that its better to be nice to Gandhi than to be nice to Hitler. But do you have apositiveobligation to be not-nice to Hitler: to make him suffer because he made others suffer? Or, OK, how about not Hitler, but someone whossomewhat bad? Consider, for example, a woman who falls in love with, and marries, an unrepentant armed robber(with full knowledge of who he is, and with other options available to her). Is the womanmorally praiseworthy for loving her husband despite his badbehavior? Or is she blameworthy because, by rewarding his behavior with her love, she helps to enable it?
To capture two possible extremes of opinion about such questions, Tyler and I defined two different morality metrics, which we called wait for iteigenmoses and eigenjesus. Eigenmoses has the niceness scores in [-1,1], which means that youre actively rewarded for punishing evildoers: that is, for defecting against those who defect against many moral players. Eigenjesus, by contrast, has the niceness scores in [0,1], which means that you always do at least as well by turning the other cheek and cooperating. (Though note that, even with eigenjesus, you get more morality credits by cooperating with moral players than by cooperating with immoral ones.)
This is probably a good place to mention a second limitation of Tylers current study. Namely, with the current system, theres no direct way for a player to find out how its partner has been behaving toward third parties. The only information that A gets about the goodness or evilness of player B, comes from A and Bs direct interaction. Ideally, one would like to designbots that take into account, not only the other bots behavior toward them, but the other bots behavior toward each other. So for example, even if someone is unfailingly nice to you, if that person is an asshole to everyone else, then the eigenmoses moral code would demand that you return the persons cooperation with icy defection. Conversely, even if Gandhi is mean and hateful to you, you would still be morally obliged (interestingly, on both the eigenmoses and eigenjesus codes) to be nice to him, because of the amount of good he does for everyone else.
Anyway, you can read Tylers paper if you want to see the results of computing the eigenmoses and eigenjesus scores for a diverse population of bots. Briefly, the results accord pretty well with intuition. When we look at eigenjesus scores, the all-cooperate bot comes out on top and the all-defect bot on the bottom (as is mathematically necessary), with TIT_FOR_TAT somewhere in the middle, and generous versions of TIT_FOR_TAT higher up. When we look at eigenmoses, by contrast, TIT_FOR_TWO_TATS comes out on top, with TIT_FOR_TAT in sixth place, and the all-cooperate bot scoring below the median. Interestingly, once again, the all-defect bot gets the lowest score (though in this case, it wasnt mathematically necessary).
Even though the measures acquit themselves well in this particular tournament, its admittedly easy to construct scenarios where the prescriptions of eigenjesus and eigenmoses alike violently diverge from most peoples moral intuitions. Weve already touched on a fewsuch scenarios above (for example, are you really morally obligated to lick the boots of someone who kicks you, just because that person is a saintto everyone other than you?). Another type of scenario involves minorities. Imagine, for instance, that 98% of the players are unfailingly nice to each other, but unfailinglycruel to the remaining2% (who they can recognize, lets say, by their long noses or darker skinsome trivial feature like that). Meanwhile, the put-upon 2% return the favor by being nice to each other and mean to the 98%. Who, in this scenario, is moral, and whos immoral? The mathematical verdict of both eigenmoses and eigenjesus is unequivocal: the 98% are almost perfectly good, while the 2% are almost perfectly evil. After all, the 98% are nice to almost everyone, while the 2% are mean to thosewho are nice to almost everyone, and nice only to a tiny minority who are mean to almost everyone. Of course, for much of human history, this is preciselyhow morality worked, in many peoples minds. But I dare say its a result that would make moderns uncomfortable.
In summary, it seems clear to me that neither eigenmoses nor eigenjesus correctly captures our intuitions about morality, any more than captures our intuitions about consciousness. But as they say, I think theres plentyof scope here for further research: for coming up with new mathematical measures that sharpen our intuitive judgments about morality, and (if we like) testing those measures out using IPD tournaments. It also seems to me that theres somethingfundamentally right about the eigenvectoridea: all else being equal, wed like to say, being nice to others is good, except that aiding and abetting evildoers is not good, and the way we can recognize the evildoers in our midst is that theyre not nice to othersexcept that, if the people who someone isnt nice to are themselves evildoers, then the person might again be good, and so on. The only way to cut offthe infinite regress, it seems, is to demand some sort of reflective equilibriumin our moral judgments, and thats precisely what eigenmorality tries to capture. On the other hand, no such ideacanever make moral debate obsoleteif for no other reason than that we still need to decidewhich specific eigenmorality metric to use, and that choice is itself a moral judgment.
Scooped by Plato
Which brings me, finally, to the second new thing thats happened this year on the eigenmorality front. Namely, Rebecca Newberger Goldsteinwhos far and away my favorite contemporary novelistpublished acharming newbook entitledPlato at the Googleplex: Why Philosophy Wont Go Away. Here she imagines that Plato has reappeared in present-dayAmerica (she doesnt bother to explain how), where hes taught himself English and the basicsof modern science, learned how to use the Internet, and otherwise gotten himself up to speed. The book recounts Platos dialogues with various modern interlocutors, as he volunteers to have his brain scanned, guest-writes a relationship advice column, participates in a panel discussion on child-rearing, and gets interviewed on cable news by Roy McCoy (a thinly veiled Bill OReilly). Often, Goldstein hasPlato answer the moderns questionsusingdirect quotes from the Timaeus, the Gorgias, the Meno, etc., which makes her Plato into averyintelligent sort of chatbot. This is a genre thats not often seriously attempted, and that Id love to read more of (possible subjects: Shakespeare, Galileo, Jefferson, Lincoln, Einstein, Turing).
Anyway, my favoriteepisode in the book is the first, eponymous one, where Plato visits the Googleplex in Mountain View. While eating lunch in one of the many free cafeterias, Plato is cornered by a somewhat self-important, dreadlocked coder named Marcus, who tries to convince Plato that Google PageRank has finally solved the problem agonized over in the Republic, of how to define justice. By using the Internet, we can simply crowd-source the answer, Marcus declares: get millionsof people to render moral judgments on every conceivable question, and also moral judgments on each others judgments. Then declare those judgments the most morally reliable, that are judged the most reliable by the people who are themselves the most morally reliable. The circularity, as usual, is broken by taking the principal eigenvector of the graph of moral judgments (Goldstein doesnt have Marcus put it that way, but its what she means).
Not surprisingly, Plato is skeptical. Through Socratic questioningthemethodhelearned from the horses mouthPlatomanages to makeMarcusrealize that, in the very act of choosing which of several variants of PageRank to usein ourcrowd-sourced justice engine, well implicitly be making moral choices already. And therefore, we cant use PageRank, or anything like it, as the ultimate ground of morality.
Whereas I imagined that the raw data for an eigenmorality metric would consist of numerical measures of how nice people had been to each other, Goldstein imagines the raw data to consist of abstract moral judgments, and of judgments about judgments. Also, whereas the output of my kind of metric would bea measure of the goodness of each individualperson, the outputs of hers would presumably be verdicts about general moral and political questions. But, much like with CLEVER versus PageRank, its obviousthat the ideas are similarand that I should credit Goldstein with independently discovering my nerdy 16-year-old vision, in order to put it in the mouth of a nerdycharacter in her story.
As I said before, I agree with Goldsteins Plato that eigenmorality cant serve as the ultimate ground of morality. But thats a bit like saying that Google rank cant serve as the ultimate ground of importance, because even just to design and evaluatetheir ranking algorithms, Googles engineers must have some prior notion of importance to serve as a standard. Thats true, of course, but it omits to mentionthatGoogle rank is stillusefuluseful enough to have changed civilization in the space of a few years. Goldsteins book has the wonderful property that even the ideas she gives to hersecondary characters,the ones who serve as foils to Plato,are sometimesinteresting enough to deserve book-length treatments of their own, and crowd-sourced morality strikes me as a perfect example.
In the two previous comment threads, we got into a discussion of anthropogenic climate change, and of my own preferred way to address it and related threats to our civilizations survival,which is simply totax every economic activity at a rate commensurate with the environmental damage that it does, and use the funds collected for cleanup, mitigation, and research into alternatives. (Obviously, such ideas are nonstarters in the current political climate of the US, but Im not talking here about whats feasible, only about whats necessary.) As several commenters pointed out, my view raises an obvious question: who is todecide how much damage each activity causes, and thus how much it should be taxed? Of course, this is merely a special case of themore general question: who is to decideon any question of public policy whatsoever?
For the past fewcenturies, our main method for answering such questionsin those parts of the world where aking or dictator or Politburo doesnt decree the answerhas been representative democracy. Democracy is, arguably, the best decision-making method that our sorry species has ever managed to put into practice, at least outside the hard sciences. But in my view, representative democracy is now failing spectacularlyat possibly the single most importantproblem its ever faced: namely, that of leaving our descendantsa livable planet. Even though, by and large, reasonablepeople mostly agree aboutwhat needs to be doneweaning ourselves off fossil fuels (especially the dirtier ones), switching to solar, wind, and nuclear, planting forests and stopping deforestation, etc.after decades of debate were still taking only limping, token steps toward those goals, and in many cases were moving rapidly in the oppositedirection. Thosewho, for financial, theological, or ideological reasons, deny the very existence of aproblem,have proved that despite being a minority, they canpush hard enough on the levers of democracy to prevent anything meaningful from happening.
So whats the solution? To put the world under the thumbof an environmentalist dictator? Absolutely not. In all of history,I dont think any dictatorialsystemhas ever shownitself robust against takeover by murderous tyrants (people who probably arent too keen on alternative energy either). The problem, I think, is epistemological. Within physics and chemistry and climatology, the peoplewho think anthropogenic climate change exists and is a serious problem havewon the argumentbut the news of their intellectual victory hasnt yet spread to the opinion page of the Wall Street Journal, or cable news, or the US Congress, or the minds of enough people to tip the scales of history. Because ourdomination of the earths climate and biosphere is new andunfamiliar;because the evidence for rapidclimate changeiscomplicated and statistical; because theworst effects are still remote from us in time, space, or both; because the sacrifices needed to address the problem are realfor all of these reasons, the deniers have learnedthat they can subvert the Popperian process by which bad explanationsare discardedand good explanationswin. If you just repeatdebunkedideas through a loud enough megaphone, it turns out, manyonlookerswont be able to tell the differencebetween you and thepeoplewho have genuineknowledgeor they will eventually, but not until its too late. If you have a few million dollars, you can even set up your own parody of the scientific process: your own phony experts, in their own phony think tanks, with their own phony publications, giving each other legitimacy by citing each other. (Of course, all this is a problem for many fields, not just climate change. Climate is specialonly because there, the future of life on earth might literally hinge on our ability to get epistemology right.)
Yet for all that, Im an optimistsort of. For it seems to me that the Internet has given us new tools with which to try to fix our collective epistemology, without giving up on a democratic society. Google, Wikipedia, Quora, and so forthhave already improved our situation, if only by a little. We could improve it a lot more. Consider, for example, the following attempted definitions:
A trustworthy source of information is one thats considered trustworthy by many sources who are themselves trustworthy (on the same topic or on closely related topics). The current scientific consensus, on any given issue, is what the trustworthysources consider to be the consensus. A good decision-maker is someone whos considered to be a good decision-maker by many other good decision-makers.
At first glance, the abovedefinitions sound ludicrouslycirculareven Orwellianbut we now know that all thats needed to unravel the circularity is a principal eigenvector computation on the matrix of trust. And the computation of such aneigenvector need be no more Orwellian than  well, Google. If enough people want it, then we have the tools today to put flesh on these definitions, to give them agency: to builda crowd-sourced deliberativedemocracy, one that usually just works in much the same way Google usually just works.
Now, would those with axes to grindtry to subvert such a systemthe instant it wentonline? Certainly. For example, I assumethat millions of people would rate Conservapedia as a more trustworthy source than Wikipediaand would rate other people who had done so as, themselves, trustworthy sources, while rating as untrustworthy anyonewho called Conservapedia untrustworthy. Sothere would arise a parallel worldof trust and consensus and expertise,mutually-reinforcing yetnearlydisjoint from the world of the real. But heres the thing: anyone would be able to see, with the click of a mouse, the extent to which this parallel world had divergedfrom the real one. Theyd see that there was a huge, centralconnected component in the trust graphincluding almost all of the Nobel laureates, physicists from the US nuclear weapons labs, militaryplanners, actuaries, other hardheaded peoplewho all accepted the reality of humans warming the planet, and only tiny, isolated tendrils of trust reaching from that component into the component of Rush Limbaugh and James Inhofe. The deniers and their think-tanks would be exposed to the sun; theyd lose their thincover of legitimacy. It should go without saying that the same would happen to various charlatans on the left, and should go without saying that Id cheer that outcome as well.
Some will object: but people who believe in pseudoscienceswhether creationists or anti-vaxxers or climate change deniersalready knowtheyre in aminority! And far from being worried about it, they treat it as a badge of honor. They think theyre Galileo, that their belief in spite of ascientificconsensus makes them heroes, while those in the giant central component of the trust graph are merely slavish followers.
I admit all this. But the point of an eigentrust system wouldnt be to convince everyone. As long as Im fantasizing, the point would be that, once peoples individual decisions did give rise to a giant connected trust component, the recommendations of that component could acquire the force of law. Theformation of the giant component would be thesignal that theres now enough of aconsensus to warrant action, despite the continuing existence of a vocal dissenting minoritythat the minority has, in effect, withdrawnitself from the main conversation and retreatedinto a different discourse. Conversely, its essential to note, if there were a dissenting minority, but that minority had strong trunks of topic-relevanttrust pointing toward it from the main component(for example, because the minority contained a large fraction of the experts in the relevant field), then the minoritys objections might be enough to veto action, even if it was numerically small. This is still democracy; its just democracy enhanced by linear algebra.
Other people will object that, while we should use the Internet to improvethe democratic process, the idea were looking for is not eigentrust or eigenmorality but rather prediction markets. Such markets would allow us to, as my friend Robin Hanson advocates, vote on values but bet on beliefs. For example, a countrycould vote for the conditionalpolicy that, if business-as-usual is predicted tocause sea levels to rise at least 4 meters by the year 2200, thenan aggressive emissionsreduction planwill be triggered, but not otherwise. But as for the prediction itself, that would be left to afutures market: a place where, unlike with voting, theres a serious penalty for being wrong, namely losing your shirt. If the futures market assigned the prediction at leastsuch-and-such a probability, then the policy tied to that prediction would become law.
I actually like the idea of prediction marketsI have ever since I heard about thembut I consider them limited in scope. My example above, involving the year 2200, gives a hint as to why. Prediction markets are great whenever our disagreements are over something that will be settled one way or the other, to everyones assent, in the near future (e.g., who will win the World Cup, or next years GDP). But most of our important disagreements arent like that: theyre over which direction society should move in, which issues to care about, which statistical indicators are even the right ones to measure a countrys health. Now, those broader questionscansometimes be settled empirically, in a sense: they can be settled by the overwhelming judgment of history, as the slavery, womens suffrage, and fascism debates were. But that kind of empirical confirmation typically takes way too long to set up a decent betting market around it. And for the non-bettable questions, a carefully-crafted eigendemocracy really is the best system I can think of.
Again, I think Rebecca Goldsteins Plato is completelyrightthat such a system, were it implemented,couldntpossibly solve the philosophical problem of finding the ultimate ground of justice, just like Google cant provide us with the ultimate ground of importance. If nothing else, wed still need to decide which of the many possible eigentrust metricsto use,and we couldnt use eigentrust for that without risking an infinite regress. But just like Google, whateverits flaws, works well enoughfor you to use it dozens of times perday, so a crowd-sourced eigendemocracy mightjust mightwork wellenough to save civilization.

Update (6/20):If you havent been following, theres an excellent discussion in the comments, with, as Id hoped, many commenters raising strong and pertinent objections to the eigenmorality and eigendemocracy concepts, while also proposing possible fixes. Let me now mention what I think are the most important problemswith eigenmorality and eigendemocracy respectivelyboth of them things that had occurred to me also, but that the commenters have brought out very clearly and explicitly.
With eigenmorality, perhaps the most glaring problem is that, as I mentionedbefore, theres no notionof time-ordering, or of who started it, in the definition that Tyler and I were using. As Luca Trevisan aptly points out in the comments, this has the consequence that eigenmorality, as it stands, is completely unable to distinguish between a crime syndicate thats hated by the majority because of its crimes, and an equally-large ethnic minority thats hated by the majority solely because its different, and that therefore hates the majority. However,unlike with mathematical theories of consciousnesswhere I used counterexamples to try to showthat no mathematical definition of a certain kind could possibly capture our intuitions about consciousnesshere the problem strikes me as much more circumscribed and bounded. Itsfar from obvious to me that we cant easily improvethedefinition of eigenmorality so that it doesagree with most peoples moralintuition, whenever intuition renders a clear verdict, at least in the limited setting of Iterated Prisoners Dilemma tournaments.
Lets see, in particular, how to solve the problem that Luca stressed. As a first pass, we could do so as follows:
A moral agentis one who only initiates defection against agents who it has good reason to believe are immoral (where, as usual, linear algebra is used to unravel the definitions apparent circularity).
Notice that Ive added two elements to the setup: not only time but also knowledge. If you shun someone solely because you dont like how they look, then wed like to say that reflects poorly on you, even if (unbeknownst to you) it turns out that the person really is an asshole. Now, severalmore clauses would need to be added to the above definition to flesh it out: for example, if youve initiated defection against an immoral person, butthen the person stops being immoral, at what point do you have a moral duty to forgive and forget? Also, just like with the eigenmoses/eigenjesus distinction, do you have a positive duty to initiate defection against an agent who you learn is immoral, or merely no duty not to do so?
OK, so after we handle the above issues, will there still be examplesthat our time-sensitive, knowledge-sensitive eigenmorality definition gets badly, egregiously wrong? MaybeI dont know! Please let me know in the comments.
Moving on to eigendemocracy, here I think the biggest problem is one pointed out by commenter Rahul. Namely, an essential aspectof howGoogle is able towork so well is that people have reasons for linking to webpages other than boosting those pages Google rank. In other words, Google takes a link structure that already exists, independently of its ranking algorithm, and that (as the economists would put it) encodes peoples revealed preferences, and exploitsthat structure for its own purposes. Of course, now that Google is the main way manyof us navigate the web, increasing Google rank has become a major reason for linking to a webpage, and an entire SEO industryhas arisen to try to game the rankings. But Googlestill isnt the only reason for linking, so the link structure still contains real information.
By contrast, consider an eigendemocracy, with a giant networkencoding who trusts whom on what subject. If the only reason why this trust network existed was to help make political decisions, then gaming the system would probably be rampant: people could simply decide first which political outcome they wanted, then choose the experts such that claiming to trust them would do the most for their favored outcome. It follows that this system can only improve on ordinary democracy if the trust network has some other purpose, so that the participantshave an actual incentive to reveal the truth about who they trust. So, how would an eigendemocracy suss out the truth about who trusts whom on which subject? I dont have a very good answer to this, and am open to suggestions. The best idea so far is to use Facebook for this purpose, but I dont know exactly how.

Update (6/22):Many commenters, both here and on Hacker News, interpreted me to be saying something obviously stupid: namely, that any belief identified as the consensus by an eigenvector analysis is therefore the morally right one. They then energetically knocked down this strawman, with the standard examples (Hitler, slavery, discrimination against gays).
Admittedly, I probably contributed to this confusion by my ill-advised decision to discuss eigenmorality and eigendemocracy in the same blog postsolely because of their mathematical similarity, and the ease with which thinking about one leads to thinking about the other. But the two are different, as are my claims about them. For the record:

Eigenmorality: Within the stylized setting of an Iterated Prisoners Dilemma tournament, with side-channels allowing agents to learn who are doing what to each other, I believe it ought to be possible, by looking at who initiated rounds of defection and forgiveness, and then doing an eigenvector analysis on the result, to identify the moral and immoral agents in a way that more-or-less accords with our moral intuitions. Even if true, of course, this wouldnt have any obvious moral implications for hot-button issues such as abortion, gun control, or climate change, which its far from obvious how to encode in terms of IPD tournaments.
Eigendemocracy: By doing an eigenvector analysis, to identify who people implicitly acknowledge as the experts within each field, I believe that it might be possible to produce results that, on average, in practice, and in contemporary society, are better and more rational than those produced by ordinary majority-voting. Obviously, theres no guarantee whatsoever that the results of eigendemocracy would be morally acceptable ones: if the public acknowledges as experts people who believe evil things (as in Nazi Germany), then eigendemocracy will produce evil results. But democracy itself suffers from a precisely analogous problem. The situation that interests me is one thats been with us since the time of ancient Athens: one where there is a consensus among the experts about the wisest course of action, and theres also an implicit consensus among the public that those experts are indeed the experts, but the democratic system is somehow unable to complete the modus ponens, because of manipulation by powerful interests and the sway of demagogues. In such cases, it seems possible to me that an eigendemocracy could improve on the results of ordinary democracyperhaps dramatically sowhile still avoiding the evils of dictatorship.

Crucially, in neither of the above bullet points, nor in their combination, is there any hint of a belief that the will of the majority always defines whats morally right (if anything, theres a belief in the opposite).

Update (7/4):While this isnt really a surpriseId astonished if it werent the caseIve now learned that several people, besides me and Rebecca Goldstein, have previously written about the ideas of eigentrust and eigendemocracy.  Perhaps more surprising is that one of the earlier groupsconsisting of Sep Kamvar, Mario Schlosser, and Hector Garcia-Molina from Stanfordliterally called the idea EigenTrust, when they published about it in 2003.  (Note that Garcia-Molina, in a likely non-coincidence, was Larry Page and Sergey Brins PhD adviser.)  Kamvar et al.s intended application for EigenTrust was to determine which nodes are trustworthy in a peer-to-peer file-sharing network, rather than (say) to reinvent democracy, or to address conundrums of epistemology and ethics that have been with us since Plato.  But while the scope might be more modest, the core idea is the same.  (Hat tip to commenter Babak.)
As for enhancing democracy using linear algebra, it turns out that that too has already been discussed: see for example this presentation by Rob Spekkens of the Perimeter Institute, which Michael Nielsen pointed me to.  (In yet another small-world phenomenon, Robs main interest is in quantum foundations, and in that context Ive known him for a decade!  But his interest in eigendemocracy was news to me.)
If youre wondering whether anything in this post was original  well, so far, I havent learned of prior work specifically about eigenmorality (e.g., in Iterated Prisoners Dilemma tournaments), much less about eigenmoses and eigenjesus.Giulio Tononi and Me: A Phi-nal Exchange

You might recall that last week I wrote a post criticizing Integrated Information Theory(IIT), and its apparent implication that a simple Reed-Solomon decoding circuit would, if scaled to a large enoughsize, bring into being a consciousness vastly exceeding our own. On Wednesday Giulio Tononi, the creatorof IIT, was kindenough to send mea fascinating14-page rebuttal, and to give me permission to share it here:
Why Scott should stare at a blank wall and reconsider (or, the conscious grid)
If youre interested in this subjectat all, then I strongly recommend reading Giulios response before continuing further.  But for those who want the tl;dr: Giulio, not one to battle strawmen,first restatesmy ownargumentagainst IIT with crystal clarity. And while he has some minor quibbles (e.g., apparently my calculations of  didnt usethe most recent, 3.0 versionof IIT), he wisely sets those aside in order to focus on the core question: according to IIT, are all sorts of simple expander graphs conscious?
There,he doesntbite the bullet so much asdevour abullet hoagie with mustard. He affirmsthat, yes, according to IIT,a largenetwork of XORgatesarranged in a simple expander graph isconscious. Indeed, hegoes further, and says that the expander part is superfluous: even a network of XORgatesarranged in a 2D square grid isconscious. In my language, Giulio is simply pointing out here that a nn square gridhas decent expansion:good enough to produce a -value of about n, if not the information-theoretic maximum of n (or n/2, etc.) that an expander graph could achieve. And apparently, by Giulioslights, =n is sufficientfor consciousness!
WhileGiulio never mentions this, its interestingto observethat logicgates arranged in a 1-dimensional line would produce a tiny -value (=O(1)). So even by IITstandards,such a linear array would notbe conscious. Yet the jump from aline to a two-dimensional gridis enough to light the spark of Mind.
Personally, I give Giulio enormous credit for having the intellectual courage to follow his theory wherever it leads. When the critics point out, if your theory weretrue, then the Moon would be made of peanut butter, he doesnt try to wiggle out ofthe prediction,but proudly replies,yes, chunky peanut butterand you forgot to add thatthe Earthis made of Nutella!
Yet even as weadmire Giulios honestyand consistency, his stancemight also promptus, gently, to take another look at this peanut-butter-moon theory, and at what grounds we hadfor believingit in the first place. In his response essay, Giulio offers four arguments(by my count) for acceptingIIT despite, or even becauseof, its conscious-grid prediction: one negative argument and three positive ones. Alas, while your -lage may vary, I didnt find any of the fourarguments persuasive. In the rest of this post, Illgo through them one by one and explain why.
I. TheCopernicus-of-ConsciousnessArgument
Like manycommenterson my lastpost, Giulio heavily criticizes my appeal to common sense in rejecting IIT. Sure, he says, I might find it obvious that a huge Vandermonde matrix, or its physical instantiation, isnt conscious. But didnt people also findit obvious for millennia that the Sun orbits the Earth? Isnt the entirepoint of science to challengecommon sense? Clearly, then, the test of a theory of consciousness is not how well it upholdscommon sense, but how well it fits the facts.
The above position soundsprettyconvincing: who could disputethat observable facts trump personal intuitions? The trouble is,what are the observable facts when it comes to consciousness? The anti-common-sense viewgets all its force by pretending that were in a relatively late stage of researchnamely, the stage of taking an agreed-upon scientificdefinition of consciousness, and applyingit to test our intuitionsrather than in an extremely early stage, of agreeing on what the wordconsciousness is even supposed to mean.
Since I think this point is extremely importantand of general interest,beyond just IITIll expand on it withsome analogies.
Suppose I told you that, in my opinion,the - definition of continuous functionsthe one you learnin calculus classfailed to capture the true meaningof continuity. Suppose I told you that I had a new, better definition of continuityand amazingly, when I tried out my definition on some examples, it turned out thatx(the floor function) was continuous, whereas x2 had discontinuities, though only at17.5 and 42.
You would probably ask what I was smoking, and whether you could have some. But why? Why shouldnt the studyof continuity produce counterintuitive results? After all, even the standard definition of continuity leads tosome famously weird results, like thatx sin(1/x)isa continuous function, even thoughsin(1/x)is discontinuous. And its not as ifthe standard definition is God-given: people had been using words likecontinuous for centuriesbefore Bolzano, Weierstrass, et al. formalized the-definition, a definitionthat millions of calculus students still findfar from intuitive. So why shouldnt there be a different, better definition of continuous, and why shouldnt it reveal that a step function is continuous while a parabola is not?
In my view, thewayout of this conceptual jungle is to realize that, beforeany formal definitions, any s ands, we start with anintuitionfor were trying to capture by thewordcontinuous. And if we press hard enough on what that intuition involves, well find that it largelyconsists ofvarious paradigm-cases. A continuous function, wed say, is a function like 3x, or x2, or sin(x), while a discontinuity is the kind of thing that the function 1/x has at x=0, or thatx has at every integer point. Crucially, we use the paradigm-cases to guide our choice of a formal definitionnot vice versa! Its true that, once we havea formal definition, we can then apply it to exotic cases like x sin(1/x), and we might be surprisedby the results. But the paradigm-cases are different. If, for example, our definition told usthat x2was discontinuous, that wouldnt be a surprise; it would just beevidence that wed pickeda bad definition. The definition failed at the only task for which it could have succeeded: namely, that of capturing what we meant.
Some people might say that this is all well and good inpure math, but empirical science has no need for squishy intuitions and paradigm-cases. Nothing could be further from the truth. Suppose, again, that I toldyou thatphysicists since Kelvin had gotten the definition of temperature all wrong, and that I had a new, better definition. And, when I built a Scott-thermometer that measurestrue temperatures, it delivered the shocking result that boiling water is actually colder than ice. Youd probably tell me where to shove my Scott-thermometer. But wait: how do you know that Im not the Copernicus of heat, and that future generations wont celebrate my breakthrough while scoffing at your small-mindedness?
Id saytheres an excellentanswer: because what wemean by heat is whatever it isthat boiling water has more ofthan ice (along with dozens of other paradigm-cases). And because, if you use a thermometer to check whether boiling water is hotter than ice, then the term for what youre doing iscalibrating yourthermometer. When the clock strikes 13, its time to fix the clock, and when the thermometer says boiling waters colder than ice, its time to replacethe thermometeror if needed, even the entire theory on which the thermometer is based.
Ah, you say, but doesntmodern physics defineheat in a completely different, non-intuitive way, in terms ofmolecular motion? Yes, and that turned out to be a superbdefinitionnot onlybecause it was precise, explanatory, and applicable to cases far beyond our everydayexperience, but crucially, becauseit matchedcommon senseon the paradigm-cases. If it hadnt given sensible results for boiling water and ice, then the only possible conclusion would be that, whatever new quantity physicists had defined, they shouldnt call ittemperature, or claim that their quantitymeasured the amount of heat. They should call their new thing something else.
The implications for the consciousness debate areobvious. When we consider whether to accept IITs equation ofintegrated information with consciousness,we dont start withany agreed-upon, independent notionof consciousness against which the new notioncan be compared. The mainthings we start with, in my view, are certain paradigm-cases thatgesturetoward what we mean:

You are conscious (though not when anesthetized).
(Most) other people appearto be conscious, judging from their behavior.
Manyanimals appear to be conscious, though probably to a lesser degree than humans (and the degree of consciousness in each particular species is far from obvious).
A rock is not conscious. A wall is not conscious. A Reed-Solomon code is not conscious. Microsoft Word is not conscious (though a Word macro that passed the Turing test conceivably would be).

Fetuses, coma patients, fish, and hypothetical AIs are the x sin(1/x)s of consciousness: theyre the tougher cases, the ones where we might actually need a formal definition to adjudicate the truth.
Now, givena proposed formal definition for an intuitive concept, how can wecheck whether the definition is talking about same thing wewere trying to get at before? Well, wecan check whether the definition at least agreesthat parabolas are continuous while step functions are not, that boiling water is hot while ice is cold, and that were conscious while Reed-Solomon decodersare not. If so, then the definitionmightbe pickingout the same thing thatwemeant, or were tryingto mean, pre-theoretically(though westillcantbe certain). If not, then the definition is certainly talking about something else.
What else can we do?
II. The Axiom Argument
According to Giulio, there is something else we can do, besides relying on paradigm-cases. That something else, in his words,is to lay down postulates about how the physical world should be organized to support the essential properties of experience, then use those postulates to derive a consciousness-measuring quantity.
OK, so what are IITs postulates? Heres how Giulio states the five postulates leading to in his response essay (he derives these from earlier phenomenological axioms, which you can find in the essay):

A system of mechanisms exists intrinsically if it can make a difference to itself, by affecting the probability of its past and future states, i.e. it has causal power (existence).
It is composed of submechanisms each with their own causal power (composition).
It generates a conceptual structure that is the specific way it is, as specified by each mechanisms concept  this is how each mechanism affects the probability of the systems past and future states (information).
The conceptual structure is unified  it cannot be decomposed into independent components (integration).
The conceptual structure is singular  there can be no superposition of multiple conceptual structures over the same mechanisms and intervals of time.

From my standpoint, these postulates havethree problems. First, I dont really understand them. Second, insofar as I do understand them, I dont necessarily accept their truth. And third, insofar as I do accept their truth, I dont see how they lead to.
To elaborate a bit:
I dont really understand the postulates. I realize that the postulates are explicated further in the many papers on IIT. Unfortunately, while its possible that I missed something, in all of the papers that I read, the definitions never seemed to bottom out in mathematical notions that I understood, like functions mapping finite sets to other finite sets. What, for example, is a mechanism? Whats a system of mechanisms? Whats causal power? Whats a conceptual structure, and what does it mean for it to be unified? Alas, it doesnt help to define these notions in terms of other notions that I also dont understand. And yes, I agree that all these notions canbe given fully rigorous definitions, but there could be many different ways to do so, and the devil could liein the details. In any case, because (as I said) its entirely possible that the failure is mine, I place much less weight on this point than I do on the two points to follow.
I dont necessarily accept the postulates truth. Is consciousness a unified conceptual structure? Is it singular? Maybe. I dont know. It sounds plausible. But at any rate, Im far less confident about any these postulateswhatever one means by them!than I am aboutmy own postulate, which isthat you and I are conscious while my toaster is not. Note that my postulate, thoughnot phenomenological, does havethe merit of constraining candidate theories of consciousness in an unambiguous way.
I dont see how the postulates lead to . Even if one accepts the postulates, how does one deducethat the amount of consciousness should be measured by , rather than by some other quantity? None of the papers Ireadincluding the ones Giulio linked to in his response essaycontained anything that looked to me like a derivation of. Instead, there was general discussion of the postulates, and then  just sort of appeared at some point. Furthermore, given the manyidiosyncrasies of the minimization over all bipartite (why just bipartite? why not tripartite?) decompositions of the system, the need for normalization (or something else in version 3.0) to deal with highly-unbalanced partitionsit would be quite a surprise were it possible to derive its specific form from postulates of such generality.
I was going to argue for that conclusion in more detail, when I realized that Giulio had kindly done the work for me already. Recall that Giulio chided me for not using the latest, 2014, version 3.0 editionof in my previous post. Well, if the postulates uniquely determined the form of , thenwhats with all these upgrades? Or hass definitionbeen changing from year to year because thepostulates themselves have been changing? If the latter, then maybe oneshould wait for the situation to stabilize before trying to form an opinion of the postulates meaningfulness,truth, and completeness?
III. The Ironic EmpiricalArgument
Or maybe not. Despite all the problems noted above with the IIT postulates, Giulio argues in his essay that theres a good a reason to accept them: namely,theyexplain various empirical facts from neuroscience, and lead to confirmed predictions. In his words:
[A] theorys postulates must be able to explain, in a principled and parsimonious way, at least those many facts about consciousness and the brain that are reasonably established and non-controversial. For example, we know that our own consciousness depends on certain brain structures (the cortex) and not others (the cerebellum), that it vanishes during certain periods of sleep (dreamless sleep) and reappears during others (dreams), that it vanishes during certain epileptic seizures, and so on. Clearly, a theory of consciousness must be able to provide an adequate account for such seemingly disparate but largely uncontroversial facts. Such empirical facts, and not intuitions, should be its primary test
[I]n some cases we already have some suggestive evidence [of the truth of the IIT postulates predictions]. One example is the cerebellum, which has 69 billion neurons or so  more than four times the 16 billion neurons of the cerebral cortex  and is as complicated a piece of biological machinery as any. Though we do not understand exactly how it works (perhaps even less than we understand the cerebral cortex), its connectivity definitely suggests that the cerebellum is ill suited to information integration, since it lacks lateral connections among its basic modules. And indeed, though the cerebellum is heavily connected to the cerebral cortex, removing it hardly affects our consciousness, whereas removing the cortex eliminates it.
I hope Im not alone in noticing the irony of this move. But just in case, let me spell it out: Giuliohas stated, as largely uncontroversial facts, that certain brain regions(the cerebellum) and certain states (dreamless sleep) are not associated with our consciousness. He then views it as a victoryfor IIT, if those regions and states turn out to havelower information integration than the regions and states that he does take to be associated with our consciousness.
But how does Giulio know that the cerebellum isnt conscious? Even if it doesnt produce our consciousness, maybe the cerebellum has its own consciousness, just as rich as the cortexs but separate from it. Maybe removing the cerebellum destroys that other consciousness, unbeknownst to us. Likewise, maybe dreamless sleep brings about its own form of consciousness, one that (unlike dreams) we never, ever remember in the morning.
Giulio might take theimplausibilityof those ideasas obvious, or at leastas largely uncontroversial among neuroscientists. But heres the problem with that: he just told us that a 2D square grid is conscious! He told us that we must notrely on commonsense intuition, or on any popular consensus,to saythat if a square mesh of wires is just sitting there XORing some input bits, doing nothing at allthat wed want to call intelligent, then its probably safe to concludethat the mesh isnt conscious. So then why shouldnt he say the sameforthe cerebellum, or for the brain in dreamless sleep? By Giulios own rules (the ones he used for the mesh), we have no a-priori cluewhether those systemsare conscious or notso even if IIT predicts that theyre not conscious, that cant be counted as any sort of successfor IIT.
For me, the point is evenstronger: I, personally, would be a milliontimes more inclined to ascribe consciousness to the human cerebellum, or to dreamless sleep, than I would to the mesh of XOR gates. For its not hard to imagine neuroscientists of the future discovering hidden forms of intelligence in the cerebellum, and all but impossibletoimagine them doing the same for the mesh. But even if you put those examples on the same footing, still the take-home messageseems clear: you cantcount it asa success forIIT if it predicts that the cerebellum in unconscious, while at the same timedenying that its a failurefor IIT if it predicts that a squaremesh of XOR gatesis conscious. If the unconsciousness of the cerebellum can be considered anempirical fact, safe enough fortheories of consciousness tobe judged against it, then surely the unconsciousness of the mesh can also be consideredsuch a fact.
IV. The Phenomenology Argument
I now come to, for me, the strangest and most surprising part of Giulios response. Despite his earlier claim that IIT need not dovetail with commonsenseintuition about which systems areconsciousthat it can defyintuitionat some point, Giulio valiantly tries to reprogramourintuition, to make us feelwhy a 2D grid could beconscious. As best I can understand, the argument seems to be that, when we stare at a blank 2D screen, we form a rich experience in our heads,and that richness must be mirrored by a corresponding intrinsic richness in 2D space itself:
[I]f one thinks a bit about it, the experience of empty 2D visual space is not at all empty, but contains a remarkable amount of structure. In fact, when we stare at the blank screen, quite a lot is immediately available to us without any effort whatsoever. Thus, we are aware of all the possible locations in space (points): the various locations are right there, in front of us. We are aware of their relative positions: a point may be left or right of another, above or below, and so on, for every position, without us having to order them. And we are aware of the relative distances among points: quite clearly, two points may be close or far, and this is the case for every position. Because we are aware of all of this immediately, without any need to calculate anything, and quite regularly, since 2D space pervades most of our experiences, we tend to take for granted the vast set of relationship[s] that make up 2D space.
And yet, says IIT, given that our experience of the blank screen definitely exists, and it is precisely the way it is  it is 2D visual space, with all its relational properties  there must be physical mechanisms that specify such phenomenological relationships through their causal power  One may also see that the causal relationships that make up 2D space obtain whether the elements are on or off. And finally, one may see that such a 2D grid is necessary not so much to represent space from the extrinsic perspective of an observer, but to create it, from its own intrinsic perspective.
Now, it would be childs-playtocriticizethe above line of argument for conflatingour consciousness of the screen with the allegedconsciousness of the screen itself. To wit: Just because it feels like something tosee a wall, doesnt meanit feels like somethingto bea wall. You can smell a rose, and the rose can smell good, but that doesnt mean the rose can smell you.
However, I actually prefera different tack in criticizingGiulios wallargument. Suppose I accepted that my mental imageof the relationships between certain entities was relevant to assessing whether those entities hadtheir ownmental life, independent of me or any other observer. For example, suppose I believed that, if my experience of 2D spaceis rich and structured, then thats evidence that 2D space is rich and structured enough to be conscious.
Then my question is this: why shouldnt the same be true of 1D space? After all, my experience of staring at a rope is also rich and structured, no less than my experience of staring at a wall. I perceivesome points on the rope as being toward the left, others as being toward the right, and some points as being between two other points. In fact, the rope even has a structurenamely, a natural total ordering on its pointsthat the wall lacks. So why does IIT cruelly deny subjective experience to a row of logic gates strung along a rope, reserving it only for a mesh of logic gates pasted to a wall?
And yes, I know the answer: because the logic gates on the rope arent integrated enough. But whos to say that the gates in the2D mesh areintegrated enough? As I mentioned before, their -value grows only asthe square root of the number of gates, so that the ratio of integrated information to total information tends to 0 as the number of gates increases. And besides, arent what Giulio calls the facts of phenomenology the realarbitershere, and isnt my perception of the ropes structure a phenomenological fact? When you cut a rope, does it not split? When you prick it, does it not fray?
Conclusion
At this point, I fear were at a philosophical impasse. Having learned that, according to IIT,

a squaregridof XORgates is conscious, and your experience of staring at a blank wall provides evidence for that,
by contrast, a linear arrayof XORgates isnot conscious, your experience of staring at a rope notwithstanding,
the human cerebellum is also not conscious (even though agrid of XOR gates is), and
unlike with the XOR gates, we dont need a theory to tell us the cerebellum is unconscious, but can simply accept it as reasonably established and largely uncontroversial,

I personally feel completely safe in saying that this is not the theory of consciousness for me. But Ive also learned that other people, even after understanding the above, still dontreject IIT. And you know what? Bully for them. On reflection, I firmly believe that a two-state solution is possible, in which we simply adopt different words for the different things that we mean by consciousnesslike, say, consciousnessReal for my kind and consciousnessWTF for the IIT kind. OK, OK, just kidding! How about paradigm-case consciousness for the one and IIT consciousness for the other.

Completely unrelated announcement: Some of you might enjoy this Nature News piece by Amanda Gefter, about black holes and computational complexity.(To all x MerryChristmas(x)) and (To all x GoodNight(x))

Hearty, nontrivial Christmas greetings from SAT-a-Clause, the patron saint of theoretical computer scientists!  Tomorrow night, SAT-a-Clause will once again descend all possible chimneys in parallel, nondeterministically guess which ones lead to cookies, and fill the corresponding STOC-ings with loads of publishable results!
As Ive done every year since I was about 14, Ill spend Christmas Eve at my best friend Alexs house (this year bringing the girlfriend along). My role at Alexs family gathering, of course, is to wage the secular-humanist War On Christmas: sanctimoniously insisting that guests say Happy Holidays instead of Merry Christmas, belching loudly during hymns and carols, mocking the Savior as a competent if unoriginal 1st-century rabbi, and just generally dampening Christian faith, fomenting impiety, and advancing the cause of Satan.  After all, what Christmas Eve celebration would be complete without a JudeoGrinch?
If your idea of the Christmas spirit includes, you know, peace on Earth, goodwill to all mankind, etc., you should check out this New York Times essay by Peter Singer, which Luca blogged about previously.  Singer strikes me as one of the few public intellectuals whos actually gotten wiser with age, as opposed to yet more cranky and intransigent.  In this latest piece, he shows himself to be less concerned with chicken liberation than with eradicating rotavirus and malaria, less interested in the Talmudic question of whether a billionaire whos given away 90% of his wealth is now morally obligated to give away the rest than in the practical question of how to get people to give more.  I also recommend this column from last Christmas season by Nicholas Kristof  a writer whos occassionally mistaken, never less than a mensch  in which he compares the War on Christmas to the war in Darfur, and challenges Bill OReilly to join him in witnessing the latter.CCCs Declaration of Independence

Recently, the participants ofthe Conference on Computational Complexity(CCC)the latest iteration of which Ill be speaking at next week in Vancouvervoted to declare their independence from the IEEE, and to become a solo, researcher-organized conference. See this open letter for the reasons why (basically, IEEEcharged a huge overhead, didnt allow open access to the proceedings, and increased rather than decreased the administrative burden on the organizers). As a former member of the CCC Steering Committee, Im in violent agreement with thismove, and only wish wed managed to do itsooner.
Now, Dieter van Melkebeek (the current Steering Committee chair) is asking complexity theorists to sign a public Letter of Support, to make it crystal-clear that the community is behind the move to independence. And Jeff Kinne has asked me to advertise the letter on my blog. So, if youre a complexity theorist who agrees with the move, please go there and sign (it already has 111 signatures, but could use more).
Meanwhile, I wish to express my profound gratitude to Dieter, Jeff, and the other Steering Committee members for their efforts toward independence. The only thing I mightve done differently would be to add a little more  I dunno, pizzazz to the documents explaining the reasons for the move. Like:
When in the Course of human events, it becomes necessary for a conference to dissolve the organizational bands that have connected it with the IEEE, and to assume among the powers of the earth, the separate and equal station to which the Laws of Mathematics and the CCC Charterentitle it, a decent respect to the opinions of theorist-kind requires that the participantsshould declare the causes which impel them to the separation.
We hold these truths to be self-evident (but still in need of proof), that P and NP are created unequal, that one-way functions exist, that the polynomial hierarchy is infiniteMy Conversation with Eugene Goostman, the Chatbot thats All Over the News for Allegedly Passing the Turing Test

If you havent read about it yet, Eugene Goostman is a chatbot thats being heavily promoted by the University of Readings Kevin Warwick, forfooling 33% of judges in a recent Turing Test competition into thinking it was human, and thereby supposedly becoming the first program to pass the Turing Test as Turing defined it in his 1950 paper. See for examplehere, here, here, here. In reality, while Turing didventurea prediction involving AIsfooling humans 30% of the timeby the year 2000, he never set such a numerical milestone as the condition forpassing his test. Much more importantly, Turingsfamous example dialogue, involving Mr. Pickwick and Christmas, clearly shows that the kind of conversation Turing had in mind was at a vastlyhigher level than what any chatbot, including Goostman, has ever been able toachieve.
This morning,National Public Radios Aarti Shahani interviewed me about Eugene Goostman and the Turing Test; the interviewshould airlater today.
Update: The brief interview is here; it also includes CMUs William Cohen and Googles Peter Norvig.
I tried to redirect Ms. Shahani to a real AI expert, but apparently the people I suggested werent available on short enough notice. Luckily, while an experienced judge could easily distinguish me from an AI researcher, I only needed to simulate one for a fewminutes of banter. 
Prompted by Ms. Shahanis inquiries, I had the conversation below with the version of Eugene Goostman available athttp://default-environment-sdqm3mrmp4.elasticbeanstalk.com/. Its possible that theres a more recent version somewhere else, but this is the only version I was able to access. Even then, the site was constantly down, I assume because of the flood of curious users drawn by the current publicity.
Scott:Which is bigger, a shoebox or Mount Everest?
Eugene: I cant make a choice right now. I should think it out later. And I forgot to ask you where you are from
Scott: How many legs does a camel have?
Eugene: Something between 2 and 4. Maybe, three? :-))) By the way, I still dont know your specialty  or, possibly, Ive missed it?
Scott: How many legs does a millipede have?
Eugene: Just two, but Chernobyl mutants may have them up to five. I know you are supposed to trick me.
Scott: No, I need to know that youre not a chatbot. Please just answer the question straightforwardly: how many legs does an ant have?
Eugene: Something between 2 and 4. Maybe, three? :-))) Oh, what a fruitful conversation;-)
Scott: Do you understand why Im asking such basic questions? Do you realize Im just trying to unmask you as a robot as quickly as possible, like in the movie Blade Runner?
Eugene:wait
Scott:Do you think your ability to fool unsophisticated judges indicates a flaw with the Turing Test itself, or merely with the way people have interpreted the test?
Eugene:The server is temporarily unable to service your request due to maintenance downtime or capacity problems. Please try again later.
Scott: Do you think Alan Turing, brilliant though he was, had trouble imagining that the judges of his imitation gamewouldnt think toask commonsense questions like the ones aboveor that, if they did, theyd actually accept evasion or irrelevant banter as answers?
Eugene:No, not really. I dont think alan turing brilliant although this guy was had trouble imagining that the judges of his imitation game would not consider to Oooh. Anything else?
Scott: In your opinion, does your existence demonstrate any idea or principle that wasnt demonstrated just as convincingly by ELIZA, Joseph Weizenbaums chatbot from the 1960s?
Eugene:Eliza was a break-thru. All the bots after it were nothing but weak parodies, claiming to have revolutionary improvements.
Scott: Hey, thats the first sensible thing youve said!
Eugene:Did I really say so? Well, I must have forgotten about it. Could you tell me about your job, by the way?
Scott: OK, dont push your luck. Why do you think journalists are now hyping you? Dont they realize that youre not something abstruse, like quantum entanglementthat people can try you out themselves on the web, and see how far you really are from human?
Eugene:Ask the Creator about it (call Him by phone, for example:-). He knows all hidden reasons of human-beings life and behavior.
Scott: OK, Ill count that as the second sensible thing youve said (grading generously). Dont you think that a more convincing chatbot could be created, by using Google to trawl the entire web for plausible-sounding answers (analogous to what IBMs Watson did)?
Eugene:Yes, I do think that a more convincing chatbot can be built by using google to trawl the all web for plausible  sounding  I hope I have right to have my own opinion. Maybe, lets talk about something else? What would you like to discuss?
Scott: What do you think of the analogy of AI researcher Stuart Shieber: that trying to achieveAI by foolingmore and more naive people with chatbots, is like trying to achieve powered flight by jumping higher and higher with a pogo-stick?
Eugene:Artificial Intelligence? I guess you mean that stupid joke about a blonde who dyed her hair!
Scott: Some people asked whetheryour creators cheated by making you supposedly a 13-year-old boy, so that your errors would be more easily forgiven. Do people actually have that low an opinion of 13-year-old boys? I mean, I knew when I was 13 that camels have four legs!
Eugene:I wasnt created by anyone. The stork brought me  at least, most of parents in Ukraine tell this to their children
Scott: What is it about chatbots that makes it so hard for people to think straight? Is the urge to pontificate about our robot-ruled futureso overwhelming, that people literally cant see the unimpressiveness of whats right in front of them?
Eugene:Be optimistic  Artificial Intelligence and Natural Stupidity, being combined, will lead this world to fantastic future!
Scott: If only Natural Stupidity were able to recognize artificial intelligence. Speaking of which, did you see the movie Her? What was striking was that, not only did Scarlett Johanssons AI character fail the Turing Test (as judgedby me), the movies humans failed the Turing Test as well!
Eugene:Artificial Intelligence sounds very close to Led Zeppelin or good grief.
Scott:Lets end our conversation on that thought-provoking note. Thanks for chatting, Eugene!
Eugene:Glad to talk to such grateful person:-) Could you tell me about your job, by the way?
Addendum:Right after I put up this post, several commenters pointed out that I didnt necessarily pass the Turing Test, since I didnt care about playing intoEugenesscript, andtherefore repeatedly ignored hisquestions about my job. Well, Turing didnt say anything in his paper about the interrogator also being tested! I was trying to illustratehow tounmask a robot as quickly as possible, not how to distinguish yourself from one. But OK, just in case anyone doubts my humanity, heres my answer to Eugene, together with his response:
Me:Not that Im the one being tested, but Im a theoretical computer scientist.
Eugene:I have nice Celeron-667, by the way. I play games on it!
Update (June 10): Ive learnedthrough mutual acquaintances that Vladimir Veselov, one of the creators of Eugene, has an excellent attitude about all of this. Hes under no delusions whatsoever about his fun and entertaining creation standing any chance against a serious interrogator. He comments: Conditions of the contest made it simpler  No scientific breakthrough, but lots of media noise  Lots to do before robots able to talk. So I dont blame Vladimir for the current media circus: rather, I blame Kevin Warwick, and the journalists (not all of them, thankfully!) who uncritically repeated Warwicks pronouncements.
Incidentally, I strongly encourage people to read Stuart Shiebers classic paper, Lessons from a Restricted Turing Test(about Shiebers experiences with the Loebner Prize competition). This is the paper where Shieber introduces the pogo-stick analogy, and where hecrisply explains why AI researchers dont currently focus their energies on chatbot competitions.
Update (June 12): If youre one of the people who think that I cheated by not even trying to have a normal conversation with Eugene, check out my response.Randomness Rules in Quantum Mechanics

So, Part II of my two-part series for American Scientist magazine about how to recognize random numbers is now out. This partwhose original title was the one above, but was changed to Quantum Randomness to fit the allotted spaceis all about quantum mechanics and the Bell inequality, and their use in generating Einstein-certified random numbers. Idiscussthe CHSH game, the Free Will Theorem, and Gerard t Hoofts superdeterminism (just a bit), before explaining the striking recent protocols of Colbeck, Pironio et al., Vazirani and Vidick, Couldron and Yuen, and Miller and Shi, all of which expand a short random seed into additional random bits that areguaranteed to be random unless Nature resorted to faster-than-light communication to bias them. I hope you like it.
[Update: See here for Hacker News thread]
In totally unrelated news, President Obamas commencement speech at UC Irvine, about climate change and the people who still deny its reality, is worth reading.My New Years resolution: to get a real job

Get a leg up on the competition, and offer me a tenure-track position in computer science right now!  Heres everything youll need to decide:

Research Statement [PS] [PDF]
Teaching Statement [PS] [PDF]
CV [PS] [PDF]

In your offer letter, make sure to specify starting salary, teaching load, and the number of dimensions youd like spacetime to have.
(Note to Lubo: Unfortunately, I wasnt planning to apply to the Harvard physics department this year.  But if you make a really convincing pitch, I might just be persuaded)Quantum Computing Since Democritus Lecture 9: Quantum

Many students indicated that this was their favorite lecture in the whole course  the one that finally made them feel at home in QuantumLand.  Come read about why quantum mechanics, far from being a mysterious, arbitrary structure foisted on us by experiment, is something that mathematicians could easily have discovered without leaving their armchairs.   (They didnt?  Minor detail)
Marvel, too, at the beautiful  well anyway, at the displayed equations courtesy of mimeTeX, an eminently-useful CGI script that I downloaded and got working all by myself.  (Who says complexity theorists cant set up a CGI script?  Boo-yah!)
If youve been thinking about following the course but havent, this lecture would be a perfect place to start  it doesnt use any of the earlier lectures as prerequisites.Integrated Information Theory: Virgil Griffith opines

Remember thetwo discussionsabout Integrated Information Theory that we had a month ago on this blog? You know, the ones where I argued that IIT fails because the brain might be an expander, but not every expander is a brain; where IIT inventor Giulio Tononi wrote a 14-page response biting the bullet with mustard; and where famous philosopher of mind David Chalmers, andleading consciousness researcher (and IIT supporter) Christof Koch, also got involved in the comments section?
OK, soone morething about that. Virgil Griffith recently completed hisPhD underChristof Koch at Caltechas he puts it, immersing [him]self in the nitty-gritty of IIT for the past 6.5 years. This morning, Virgil sent me two striking letters abouthis thoughts on the recent IIT exchanges on this blog. He asked me to share them here, something that Immore than happy to do:

Virgils first letter
Virgils second letter

Reading these letters, whatjumped out at megiven Virgils long apprenticeshipin the heart of IIT-landwas the amount of agreement between my views and his. In particular, Virgil agrees with my central contention that , as it stands, can at most be a necessary condition for consciousness, not a sufficient condition, and remarks that [t]o move IIT from talked about to accepted among hard scientists, it may be necessary for [Tononi] to wash his hands of sufficiency claims. He agrees that a lack of mathematical clarity in the definition of is a major problem in the IIT literature, commenting that IIT needs more mathematically inclined people at its helm. He also says he agrees 110% that the lack of a derivation of the form of from IITsaxioms is a pothole in the theory, and further agrees 110% that the current prescriptions for computing  contain many unjustified idiosyncrasies.
Indeed, given the level ofagreement here, theres not all thatmuchfor me to rebut, defend, or clarify!
I supposethere are a few things.

Just as a clarifying remark, in a fewplaces where it looks from the formatting like Virgil is responding to something I said (for example,The conceptual structure is unifiedit cannot be decomposed into independent components and Clearly, a theory of consciousness must be able to provide an adequate account for such seemingly disparate but largely uncontroversial facts), hes actually responding to something Giulio said (and that I, at most, quoted).
Virgil says, correctly, that Giuliowould respond to my central objection against IIT by challenging my intuition for things being unconscious. (Indeed, because Giulio did respond, theres noneed to speculate about how he would respond!) However, Virgil then goes on to explicate Giulios response using the analogy of temperature (interestingly, the same analogy I used for a different purpose). He points out how counterintuitive it would be for Kelvins contemporaries to accept that even the coldest thing youve touched actually has substantial heat in it, and remarks: I find this Kelvin scale for C analogy makes the panpsychism much more palatable. The troubleis that I neverobjected to IITs panpsychism per se: I only objected to its seemingly arbitrary and selective panpsychism. Itsone thing for a theoryto ascribe some amount of consciousness to a 2D grid or an expander graph. Its quite another for a theory to ascribe vastly more consciousness to those things than it ascribes to a human braineven while denying consciousness to things that are intuitively similar but organized a little differently (say, a 1D grid). A betteranalogy here would be if Kelvins theory of temperature had predicted, not merely that all ordinary things had some heat in them, but thatan ice cube was hotter than the Sun, even thougha popsicle was, of course, colder than the Sun. (The ice cube, you see, integrates heat in a way that the popsicle doesnt)
Virgil imaginestwo ways that an IIT proponent could respond to my argument involving the cerebellumthe argument that accuses IIT proponents of changing the rules of the game according to convenience(a 2D grid has a large ? suck it up and accept it; your intuitions about a grids lack of consciousnessare irrelevant. the human cerebellum has a small ? ah, thats a victory for IIT, since the cerebellum is intuitively unconscious). The troubleis that both of Virgils imagined responses are by reference to the IIT axioms. But I wasnt talking about the axioms themselves, but about whether were allowed to validate the axioms, by checking their consequences against earlier, pre-theoretic intuitions. And I was pointing out that Giulio seemed happy to do sowhen the results went in IITsfavor (in the cerebellum example), even though he lectured me against doing so in the cases of the expander and the 2D grid (cases where IIT does less well, to put it mildly, at capturing our intuitions).
Virgil chastises me for ridiculing Giulios phenomenological argument for the consciousness of a 2D grid by way ofnursery rhymes: Just because it feels like something to see a wall, doesnt mean it feels like something to be a wall. You can smell a rose, and the rose can smell good, but that doesnt mean the rose can smell you. Virgil amusingly comments: Even when both are inebriated, Ive never heard [Giulio] nor [Christof] separately or collectively imply anything like this. Moreover, theyre each far too clueful to fall for something so trivial. For my part, I agree that neither Giulio nor Christof would ever advocatesomething as transparentlysillyas, if you have a rich inner experience when thinking about X, then thats evidence X itself is conscious. And I apologize if I seemed to suggest they would. To clarify, my point was not that Giulio was making such anabsurd statement, but rather that, assuming he wasnt, I didnt know what he was trying to say in the passages of his that Id just quoted at length. The silly thing seemed like the obvious reading of his words, and my hermeneutic powers were unequal to the task of figuring outthe non-silly, non-obvious reading that he surely intended.

Anyway, theres much more to Virgils letters than the aboveincluding answersto some of my subsidiary questions about the details of IIT (e.g., how to handle unbalanced partitions, and the mathematical meanings of terms like mechanism and system of mechanisms). Also, in parts of the letters, Virgils main concern is neither to agree with me nor to agree with Giulio, but rather to offerhis own ideas, developed in the course ofhis PhD work, for how to move forward and fixsome of the problems with IIT. All in all, thesearerecommended reads for anyone whos been following this debate.A Physically Universal Cellular Automaton

Its been understoodfor decades that, if you take a simple discrete rulesay, a cellular automaton likeConways Game of Lifeand iterate it over and over, you can very easily get the capacity for universal computation. In other words, your cellular automatonbecomes able to implement any desired sequence of AND, OR, and NOT gates, store and retrieve bits in a memory, and even (in principle) run Windows or Linux, albeit probably veerrryyy sloowwllyyy, using a complicated contraption of thousands or millions of cells to represent each bit of the desired computation. If Im not mistaken, a guy named Wolfram even wrote an entire 1200-page-long book about this phenomenon (see here for my 2002 review).
But suppose we want more than mere computational universality. Suppose we want physical universality: that is, the ability to implement any transformation whatsoever on any finite region of thecellular automatons state, by suitably initializing the complement of that region. So for example, suppose that, given some 10001000 square of cells, wed like to replace every 0 cell within that square by a 1 cell, and vice versa. Then physical universality would mean thatwe coulddo that, eventually, by some machine we couldbuild outside the 10001000square of interest.
You might wonder: are we really asking for more here than just ordinary computational universality? Indeed we are. To see this, consider Conways famous Game of Life. Even though Life has been provedto be computationally universal, its not physically universal in the above sense. The reasonis simply that Lifes evolution rule is not time-reversible. So if, for example, there were a lone 1 cell deep inside the10001000 square, surrounded by a sea of 0 cells, then that 1 cell would immediatelydisappear without a trace, and no amount of machinery outside the square could possibly detect that it was ever there.
Furthermore, even cellular automata that are both time-reversible and computationally universal could fail to be physically universal. Suppose, for example, that our CA allowed for the construction of impenetrable walls, through which no signal could pass. And suppose that our10001000 region contained a hollow box built out of these impenetrable walls. Then, by definition, no amount of machinery that we built outside the region could ever detect whether there was a particle bouncing around inside the box.
So, in summary, we now face a genuinely new question:
Does there exist a physically universal cellular automaton, or not?
This question had sort of vaguely bounced around in my head (and probably other peoples) for years. But as far as I know, it was first asked, clearlyand explicitly, in a lovely 2010 preprint by Dominik Janzing.
Today, Im proud to report that Luke Schaeffer, a first-year PhD student in my group, has answered Janzings question in the affirmative, by constructing the first cellular automaton (again, to the best of our knowledge) thats been proved to be physically universal. Click here for Lukes beautifully-written preprint about his construction, and click here for a webpage that hes prepared, explaining the details of the construction usingcolor figures and videos. Even if you dont have time to get into the nitty-gritty, the videos on the webpage should give you a sense for the intricacy of what he accomplished.
Very briefly, Luke first defines a reversible, two-dimensional CA involving particles that move diagonally across a square lattice, in one of four possible directions (northeast, northwest, southeast, or southwest). The number of particles is always conserved. The only interesting behavior occurs when threeof the particles collide in a single 22 square, and Luke gives rules (symmetric under rotations and reflections) that specify what happens then.
Given these rules, its possible to prove that any configuration whatsoever of finitely many particles will diffuse, after nottoomany time steps, into four unchanging clouds of particles,which thereaftersimply moveaway from each other in the four diagonal directions for all eternity. This has the interesting consequence that Lukes CA, when initialized with finitely many particles, cannot be capable of universal computation in Turings sense. In other words, theres no way, using n initial particles confined to an nn box, to set up a computation that continues to do something interesting after 2n or 22^n time steps, let alone forever. On the other hand, using finitely many particles, one can also prove that the CAcanperform universal computation in the Boolean circuit sense. In other words, we can implement AND, OR, and NOT gates, and by chaining them together, can compute any Boolean function that we like on anyfixed number of input bits (with the number of input bits generally much smaller than the number of particles). And this circuit universality,rather than Turing-machine universality, is all thats implied anyway by physical universality in Janzings sense. (As a side note, the distinction between circuit and Turing-machine universality seems to deserve much more attention than it usually gets.)
Anyway, while the diffusion into four clouds aspect of Lukes CA might seem annoying, it turns out to be extremely usefulfor proving physical universality. For it has the consequence that, no matter what the initial state was insidethe square we cared about, that state will before too long be encoded into the states of four clouds headed away from the square. So then, all we need to do is engineer some additionalclouds of particles, initially outside the square, that

intercept the four escaping clouds,
decode the contents of those clouds into a flat sequence of bits,
apply an arbitrary Boolean circuit to that bit sequence, and then
convert the output bits of the Boolean circuit into new clouds of particles converging back onto the square.

So, well thats exactly what Luke did. And just in case theres any doubt about the correctness of the end result, Luke actually implemented his construction in the cellular-automaton simulator Golly, where you can try it out yourself (he explains how on his webpage).
So far, of course, Ive skirted pastthe obvious question of why. Who cares that we now know that there exists a physically-universal CA? Apart from the sheer intrinsic coolness, a secondreason is that Ive been interested for years in how to make finer (but still computer-sciencey) distinctions, among various candidate laws of physics, than simply saying that some laws are computationally universal and others arent, or some are easy to simulate on a standard Turing machineand others hard. For ironically, the very pervasiveness of computational universality (the thing Wolfram goes on and on about) makes it of limited usefulness in distinguishing physical laws: almost anysufficiently-interesting set of laws will turn out to be computationally universal, at least in the circuit sense if not the Turing-machine one!
On the other hand, many of these laws will be computationally universal only because of extremely convoluted constructions, which fall apart if even the tiniest error is introduced. And in othercases, well be able to build a universal computer, all right, but that computer will be relatively impotent to obtain interesting input about its physical environment, or to make itsoutput affect the gross features of the CAs physical state. If you like, well have a recipe for creatinga universe full of ivory-tower, eggheaded nerds, who can search for counterexamples to Goldbachs Conjecture but cant build a shelter to protect themselves from a hail of 1 bits, or even learn whether such a hail is present or not, or decide which other part of the CA to travel to.
As I see it, Janzings notion of physical universality is directly addressing this egghead problem, by asking whether we can build not merely a universal computer but a particularly powerful kind of robot: one that can effect a completely arbitrary transformation (given enough time, of course) on any part of its physical environment. And the answer turns out to be that, at least in a weird CA consisting of clouds of diagonally-moving particles, we can indeed do that. The question of whether we can also achieve physical universality in more natural CAs remains open (and in his Future Work section, Luke discusses several ways of formalizing what we mean by more natural).
As Luke mentions in his introduction, theres at least a loose connection here to David Deutschs recentnotionofconstructor theory (see also this followup paper by Deutsch and Chiara Marletto). Basically, Deutsch and Marletto want to reconstruct all of physics taking what can and cant be constructed(i.e., what kinds of transformations are possible) as the most primitive concept, rather than (as in ordinary physics) what will or wont happen (i.e., how the universes state evolves with time). The hope is that, once physics was reconstructed in this way, we could then (for example) state and answer the question of whether or not scalable quantum computers can be built as a principled question of physics, rather than as a mere question of engineering.
Now, regardless of what you think about these audacious goals, or about Deutsch and Marlettos progress (or lack of progress?) so far toward achieving them, its certainly a worthwhileproject to study what sorts of machines can and cantbe constructed, as a matter of principle, both in the real physical world andin other, hypothetical worlds that capture various aspects of our world. Indeed, one could say thatthats what many of us in quantum informationand theoretical computer science have been trying to do for decades! However, Janzings physical universality problemhints at a different way to approachthe project: starting with some far-reaching desire (say, to be able to implement any transformation whatsoever on any finite region), can we engineer laws of physics that make thatdesire possible? If so, then how close can we make those laws to our laws?
Luke has now taken a first stab at answering these questions. Whether his result ends up merelybeing a fun, recreational terminal branch on the tree of science, or a trunk leading to something more, probably just depends on how interested people get. I have no doubt that our laws of physics permitthe creation of additional papers on this topic, but whether they do or dont is (as far as I can see) merely a question of contingency and human will, not a constructor-theoretic question.Long-awaited God post

This morning, a reader named Bill emailed me the following:
I stumbled upon [Quantum Computing Since Democritus Lecture 9] by accident and it seemed quite interesting but I was ultimately put off (I stopped reading it) by all the references to god. As a scientist (and athiest) I think personal religious beliefs should be left out of scientific papers/lectures, you shouldnt assume your readers/listeners have the same beliefs as yourself..it just alienates them.
Dear Bill,
Im impressed  you seem to know more about my personal religious beliefs than I do!  If youd asked, I wouldve told you that I, like yourself, am what most people would call a disbelieving atheist infidel heretic.  I became one around age fourteen, shortly after my bar mitzvah, and have remained one ever since.
Admittedly, though, atheist isnt exactly the right word for me, nor even is agnostic.  I dont have any stance toward the question of Gods existence or nonexistence that involves the concept of belief.  For me, beliefs are for things that might eventually have some sort of observable consequence for someone.  So for example, I believe P is different from NP.  I believe Id like some delicious Peanut Chews today.  I believe the weather this January isnt normal for planet Earth over the last 10,000 years, and that we and our Ford Escorts are not entirely unimplicated.  I believe eating babies and voting for Republicans is wrong.  I believe neo-Darwinism and the SU(3)xSU(2)xU(1) Standard Model (though not its supersymmetric extensions, at least until I see the evidence).  I believe that if the God of prayer couldnt get off His lazy ass during the Holocaust, or the Rwandan or Cambodian genocides, then He must not be planning to do so anytime soon  and hence, trusting in faith is utter futility.
But when it comes to the more ethereal questions  the nature of consciousness and free will, the resolution of the quantum measurement problem, the validity of the cosmological anthropic principle or the Continuum Hypothesis, the existence of some sort of intentionality behind the laws of physics, etc.  I dont have any beliefs whatsoever.  Im not even unsure about these questions, in the same Bayesian sense that Im unsure about next weeks Dow Jones average (or for that matter, this weeks Dow Jones average).  All I have regarding the metaphysical questions is a long list of arguments and counterarguments  together with a vague hope that someone, someday, will manage to clarify what the questions even mean.
To me, the most remarkable thing you said was that, despite being otherwise interested in my lecture, you literally stopped reading it because of some tongue-in-cheek references to an Einsteinian God.  That reminds me of a funny story.  When I was a student at Berkeley, my mom kept pestering me to go to the campus Hillel for Friday night dinners.  And to be honest, despite all the pestering, I was tempted to go.  My temptation was largely driven by two factors that, for want of more refined terminology, I will call free food and females.  For some reason, both factors, but particularly the second, were in short supply in the computer science department.
And yet, I couldnt bring myself to go.   Every time I passed the Hillel, I had this vision of a translucent Richard Dawkins (sometimes joined by Bertrand Russell) floating before me on the front steps, demanding that I justify the absurd Bronze Age myths that, by entering the Hillel building, I would implicitly be endorsing.  Come now, Scott, Richard and Bertrand would say, with their elegant Oxbridge accents.  You dont really believe that tosh, do you?
No, most assuredly not, good Sirs, I would reply, and shuffle back to the dorm to work on my problem set.  (The thought of spending Friday night at, say, a beer party never even occurred to me.)
Then, one Friday, I had a revelation: if God doesnt exist, then in particular, He doesnt give a shit where I go tonight.  Theres no vengeful sky-Dawkins, measuring my every word and deed against some cosmic code of atheism.  Theres no Secular-Humanist Yahweh who commanded His infidel flock at Sci-nai not to believe in Him.  So if I want to go to the Hillel, then as long as Im not hurting anyone or lying about my beliefs, I should go.   If I dont want to go, I shouldnt go.  To do otherwise wouldnt merely be silly; it would actually be irrational.
(Incidentally, once I went, I found that the other secularists there greatly outnumbered the believers.  I did stop going after a year or two, but only because Id gotten bored with it.)
What Im trying to say, Bill, is this: you can go ahead and indulge yourself.  If some of the most brilliant unbelievers in history  Einstein, Erds, Twain  could refer to a being of dubious ontological status as they would to a smelly old uncle, then why not the rest of us?  For me, the whole point of scientific rationalism is that youre free to ask any question, debate any argument, read anything that interests you, use whatever phrase most colorfully conveys your meaning, all without having to worry about violating some taboo.  You wont endanger your immortal soul, since you dont have one.
If the trouble is just that the G-word leaves a bad taste in your mouth, then I invite you to try the following experiment.  Every time you encounter the word God in my lecture, mentally substitute Flying Spaghetti Monster.   So for example: why would the Flying Spaghetti Monster, praise be to His infinite noodly appendages, have made the quantum-mechanical amplitudes complex numbers instead of reals or quaternions?
Well, why would He?  Any ideas?
RAmen, and may angel-hair watch over you,
ScottDoctor of Hacking

Amir Michail has asked me to comment on his proposal to create a new field: one thats like computer science, but more creative. My first reaction was to wonder, how much more creative does he want? He might as well ask for a field thats like dentistry, but with more teeth. (I was reminded of Hilberts famous remark, when told that a student had abandoned math to become a poet: Good. He didnt have enough imagination to be a mathematician.)
But on second thought, its true that computer science encourages a particular kind of creativity: one thats directed toward answering questions, rather than building things that are useful or cool. I learned about this distinction as an undergraduate, when the professor in my natural language processing class refused to let me write a parody-generating program (like this one) for my term project, on the grounds that such a program would not elucidate any scientific question. Of course, she was right.
Paul Graham explained the issue memorably in his essay Hackers and Painters:
Ive never liked the term computer science. The main reason I dont like it is that theres no such thing. Computer science is a grab bag of tenuously related areas thrown together by an accident of history, like Yugoslavia. At one end you have people who are really mathematicians, but call what theyre doing computer science so they can get DARPA grants. In the middle you have people working on something like the natural history of computers  studying the behavior of algorithms for routing data through networks, for example. And then at the other extreme you have the hackers, who are trying to write interesting software, and for whom computers are just a medium of expression, as concrete is for architects or paint for painters 
The mathematicians dont seem bothered by this. They happily set to work proving theorems like the other mathematicians over in the math department, and probably soon stop noticing that the building they work in says computer science on the outside. But for the hackers this label is a problem. If what theyre doing is called science, it makes them feel they ought to be acting scientific. So instead of doing what they really want to do, which is to design beautiful software, hackers in universities and research labs feel they ought to be writing research papers.

(Incidentally, Graham is mistaken about one point: most theoretical computer scientists could not blend in among mathematicians. Avi Wigderson, one of the few who can and does, once explained the difference to me as follows. Mathematicians start from dizzyingly general theorems, then generalize them even further. Theoretical computer scientists start from incredibly concrete problems that no one can solve, then find special cases that still no one can solve.)
One puzzle that Grahams analysis helps to resolve is why computer systems papers are so excruciatingly boring, almost without exception. It cant be because the field itself is boring: after all, its transformed civilization in 30 years. Rather, computer systems papers are boring because asking hackers to write papers about what they hacked is like asking Bach to write papers about his sonatas:
Abstract. We describe several challenges encountered during the composition of SONATA2 (Sonata No. 2 in A minor). These results might provide general insights applicable to the composition of other such sonatas

So what should be done? Should universities create Departments of Hacking to complement their CS departments? I actually think they should (especially if the split led to more tenure-tracks for everyone). All I ask is that, if you do find yourself in a future Hacking Department, you come over to CS for a course on algorithms and complexity. Itll be good for your soul.The Power of the Digi-Comp II: My First Conscious Paperlet

Foreword: Right now, I have a painfully-large stack of unwritten research papers. Many of these are paperlets: cool things I noticedthat I wantto tell peopleabout, butthat would require a lot more development before they becamecompetitive for any majortheoretical computer science conference. And what with the baby, I simply dont have time anymore for the kind of obsessive, single-minded, all-nighter-filled effort needed to bulkmy paperlets up. So starting today, Im going to try turning some of my paperlets into blog posts. I dont mean advertisements or sneak previews for papers, but replacements for papers: blog posts that constitute the entirety of what I haveto say for now about some research topic. Peer reviewing (whether signed oranonymous) can take place in the comments section, and citation can be done by URL. The hope is that, much like with 17th-century scientists who communicated results by letter, this will make it easier to get mypaperlets done: after all, Im not writing Official Papers, just blogging forcolleagues andfriends.
Of course, Ive often basicallydone this beforeas have many other academic bloggersbut now Im going to go about it more consciously. Ive thoughtfor yearsthat the Internet wouldeventually change the norms of scientificpublication muchmore radically than it so far has: that yes, instant-feedback tools like blogs and StackExchange and MathOverflowmight have another decade or two at the periphery of progress, but their eventual destiny is at the center. And now that I have tenure, it hitme that I can do more than prognosticate about such things. Ill start small: I wont go direct-to-blogfor big papers, papers that cry out forLaTeX formatting, or joint papers. Icertainly wont do itfor paperswith students who need official publications for their professional advancement. But for things like todays poston the power of a wooden mechanical computer now installed in the lobby of the buildingwhere I workI hope you agree that the Science-by-Blog Plan fits well.
Oh, by the way, happy July 4th to American readers! I hope you find that a paperlet about the logspace-interreducibility of a fewnot-very-well-known computational models captures everything that the holiday is about.

The Power of the Digi-Comp II
by Scott Aaronson
Abstract
I study the Digi-Comp II, a wooden mechanical computer whose only moving parts are balls, switches, and toggles. I show that the problem of simulating (a natural abstraction of) the Digi-Comp, with a polynomial number of balls, is complete for CC (Comparator Circuit), a complexity class defined by Subramanian in 1990 that sits between NL and P. This explains why the Digi-Comp is capable of addition, multiplication, division, and other arithmetical tasks, and alsoimplies new tasks of which the Digi-Comp iscapable (and that indeed are complete for it), including the Stable Marriage Problem, finding a lexicographically-first perfect matching, and thesimulation of other Digi-Comps. However, it also suggests that the Digi-Comp is not a universal computer (not even in the circuit sense), making it a very interesting way to fall short of Turing-universality. I observe that even with an exponential number of balls, simulating the Digi-Comp remains in P, but I leave open the problem of pinning down its complexity more precisely.
Introduction
To celebratehis 60th birthday, my colleague Charles Leiserson(who some of you might know as the L in the CLRSalgorithms textbook) had a striking contraption installed in the lobby of the MIT Stata Center. That contraption, pictured below,is a custom-built, supersized version of a wooden mechanical computer from the 1960s called the Digi-Comp II, now manufactured and sold by a company called Evil Mad Scientist.

Click here for a short video showing the Digi-Comps operation (and here for the users manual). Basically, the way it works is this: a bunch of balls (little steel balls in the original version, pool balls in the supersized version) start at the top and roll to the bottom, one by one. On their way down, the balls may encounter black toggles, which route each incoming ball either left or right. Whenever this happens, the weight of the ball flips the toggleto the opposite setting: so for example, if a ball goesleft, then the next ball to encounter the same togglewill go right, and the ball after that will go left, and so on. The toggles thusmaintain a state for the computer, with each togglestoring one bit.
Besides the toggles, there arealso switches, which the user can set at the beginning to route every incoming ball either left or right, and whose settings arent changed by the balls. And then there are various wooden tunnels and ledges, whose function is simply to direct the balls in a desired way as they roll down. A ball could reach different locations,or even the samelocation in differentways, depending on the settings of the toggles and switchesabove that location. On the other hand, once we fixthe toggles and switches, a balls motionis completely determined: theres no random or chaotic element.
Programming is done by configuring the toggles and switchesin some desiredway, then loading a desired number of balls at the top and letting them go. Reading the output can be done by looking at the final configuration of some subset of the toggles.
Whenever a ball reaches the bottom, it hits a leverthat causesthe next ball to be released from the top. This ensures that the balls go through the device one at a time, rather than all at once. As well see, however, this is mainlyfor aesthetic reasons, and maybe also for the mechanical reason that the toggles wouldnt work properly if two or moreballs hit them at once. The actual logic of the machine doesnt care about thetiming of the balls; the sheer number of balls that go through is allthat matters.
The Digi-Comp II, as sold, contains a few other features:most notably, toggles that can be controlled by other toggles (or switches). But Ill defer discussion of that feature to later. As well see, we already get a quite interesting model of computation without it.
One final note: of course the machine thats sold has a fixed size and a fixed geometry. But for theoretical purposes, its much more interesting to consider an arbitrary network of toggles and switches (not necessarily even planar!), with arbitrary size, and with an arbitrary number of balls fed into it. (Ill give a more formal definition in the next section.)
The Power of the Digi-Comp
So, what exactly can the Digi-Comp do? As a first exercise, you shouldconvince yourself that, by simply putting a bunch of toggles in a line and initializing them all to L (that is, Left), its easy to set upa binary counter. In other words, starting fromthe configuration, say, LLL (in which three toggles all point left), as successive balls pass through we can enter theconfigurations RLL, LRL, RRL, etc. If we interpret L as 0 and R as 1, and treat the first bit as the least significant, then were simply counting from 0 to 7 in binary. With 20 toggles, we could instead count to 1,048,575.

But counting is not the most interestingthing we can do. As Charles eagerly demonstrated to me, we can also set up the Digi-Comp to perform binary addition, binary multiplication, sorting, and even long division. (Excruciatingly slowly, of course: the Digi-Comp might need even more workto multiply 35, than existing quantum computers needto factor the result!)
To me, these demonstrations served only as proof that, while Charles might call himself a theoretical computer scientist, hes really a practical person at heart. Why? Because a theorist would know that the real question is not what the Digi-Comp can do, but rather what it cant do! In particular, do we have a universal computer on our hands here, or not?
If the answer isyes, then its amazing that such a simple contraption of balls and toggles could already takeus over the threshold of universality. Universality would immediately explain why the Digi-Comp is capable of multiplication, division, sorting, and so on. If, on the other hand, we dont have universality, that too is extremely interestingfor wed then face the challenge of explaining how the Digi-Comp can do somany things without being universal.
It might be saidthat the Digi-Comp is certainlynot a universal computer, since if nothing else, its incapable of infinite loops. Indeed, the number of steps that a given Digi-Comp can executeis bounded bythe number of balls, while the number of bits it can store is bounded bythe number of toggles: clearly we dont have a Turing machine. This is true, but doesnt reallytell us what we want to know. For, as discussedin my last post, we can consider not onlyTuring-machine universality, but alsothe weaker (but still interesting) notion of circuit-universality. The latter means the ability to simulate, with reasonable efficiency, any Boolean circuit of AND, OR, and NOT gatesand hence, in particular, tocompute any Boolean function on any fixed number of input bits (given enough resources), or to simulate any polynomial-time Turing machine (given polynomial resources).
The formal way to ask whether something is circuit-universal, is to ask whether the problem of simulating the thing is P-complete. Here P-complete (not to be confused with NP-complete!) basically means the following:
There exists a polynomial p such that any S-step Turing machine computationor equivalently, any Boolean circuit with at most S gatescan be embeddedinto our system if we allow the use of poly(S) computing elements (in our case, balls, toggles, and switches).
Of course, I need to tell you what I mean by the weasel phrase can be embedded into. After all,it wouldnt be tooimpressiveif the Digi-Comp could solve linear programming, primality testing, or other highly-nontrivial problems, but only via embeddings in which we had to do essentially all the work, just to decide how to configure the toggles and switches! The standard way to handle this issueis to demand that the embedding be computationally simple: that is, we should be able to carry out the embedding in L (logarithmic space), or some other complexity class believed to be much smaller than the class (P, in this case) for which were trying to prove completeness. That way, well be able to say that ourdevice really was doing something essentiali.e., something that ourembedding procedure couldnt efficiently do for itselfunless the larger complexity class collapses with the smaller one (i.e., unless L=P).
So then, our question is whether simulating the Digi-Comp II is aP-complete problem under L-reductions, or alternatively, whether the problem is in some complexity class believed to be smaller than P. The one last thing we need is a formal definition of the problem of simulating the Digi-Comp II. Thus, let DIGICOMP be the following problem:
Were given as inputs:

A directed acyclic graph G, with n vertices. There is a designated vertex with indegree 0 and outdegree 1 called the source, and a designatedvertex with indegree 1 and outdegree 0 called the sink. Every internal vertex v (that is, every vertex with both incoming and outgoing edges) has exactly two outgoing edges, labeled L (left) and R (right), as well as one bit of internal state s(v){L,R}.
For each vertex v, an initial value for its internal state s(v).
A positive integer T (encoded in unary notation), representing the number of balls dropped successively from the source vertex.

Computation proceeds as follows: each time a ball appears at the source vertex, it traverses the path induced by the L and R states of the vertices that it encounters, until it reaches a terminal vertex, which might or might not be the sink. As the ball traverses the path, it flips s(v) for each vertex v that it encounters: L goes to R and R goes to L. Then the next ball is dropped in.
The problem is to decide whether any balls reachthe sink.
Here the internal vertices representtoggles, and the source represents the chute at the top from which the balls drop. Switches arent included, since (by definition) the reduction can simply fix their values to L to R and thereby simplify the graph.
Of course we could consider other problems: for example, the problem of deciding whetheran odd number of ballsreach the sink, or of countinghow many balls reach the sink, or of computing the final value of every state-variable s(v). However, its not hard to show that all of these problems are interreducible with the DIGICOMP problem as defined above.
The Class CC
My main result, in this paperlet, is to pin down the complexity of theDIGICOMP problem in terms of a complexity class called CC (Comparator Circuit): a class thatsobscure enough not to be in the Complexity Zoo (!), but thatsbeen studied in several papers. CC was defined by Subramanian in his 1990 Stanford PhD thesis; around the same timeMayr and Subramanian showed the inclusionNL CC (the inclusion CC P is immediate). Recently Cook, Filmus, and L revived interest in CCwith their paper The Complexity of the Comparator Circuit Value Problem, which is probably the best current source of information about this class.
OK, so what is CC? Informally, its the class of problems that you can solve using acomparator circuit, which is a circuit that maps n bits of input to n bits of output, and whose only allowed operation is to sortany desired pair ofbits. That is, a comparator circuit can repeatedly apply the transformation (x,y)(xy,xy), in which 00, 01, and 11 all get mapped to themselves, while 10 gets mapped to 01. Note thattheres no facility in the circuit for copying bits (i.e., for fanout), so sorting could irreversibly destroy information about the input. In the comparator circuit value problem (or CCV), were given as input a description of a comparator circuit C, along with an input x{0,1}n and an index i[n]; then the problem is to determine the final value of the ith bit when C is applied to x. Then CCissimply the class of all languagesthat are L-reducible to CCV.

As Cook et al. discuss, there are various other characterizations of CC: for example, rather than using a complete problem, we can define CC directly as the class of languages computed by uniform families of comparator circuits. More strikingly, Mayr and Subramanian showed that CC has natural complete problems, which include (decision versions of) the famous Stable Marriage Problem, as well asfinding the lexicographically first perfect matching in a bipartite graph. So perhaps the most appealing definition of CC is that its the class of problems that can be easily mapped tothe Stable Marriage Problem.
Its a wide-open problem whether CC=NL orCC=P: as usual, one can give oracle separations, but as far as anyone knows, either equality couldhold without any dramatic implications for standard complexity classes. (Of course, the conjunction of these equalities would have a dramatic implication.) What got Cook et al. interested was that CCisnt even known to contain (or be contained in)the class NC of parallelizable problems. In particular, linear-algebra problems in NC, like determinant, matrix inversion, and iterated matrix multiplicationnot to mention other problems in P, like linear programming andgreatest common divisormight all be examples of problems that are efficiently solvable by Boolean circuits, but not by comparator circuits.
One final note about CC. Cook et al. showed the existence of a universal comparator circuit: that is, a single comparator circuit C able to simulate any other comparator circuit C of some fixed size, given a description of C as part of its input.
DIGICOMP is CC-Complete
I can now proceed to my result: that, rather surprisingly, the Digi-Comp II can solve exactly the problemsinCC, giving us another characterization of that class.
Ill prove this using yet another model of computation, which I call the pebbles model. In the pebbles model, you start out with a pile of x pebbles; the positive integer x is the input to your computation. Then youre allowed toapply a straight-line program that consists entirelyof the following two operations:

Given any pile of y pebbles, you can split it into two piles consisting of y/2 and y/2 pebblesrespectively.
Given any two piles, consisting of y and z pebblesrespectively, you can combine them into a single pile consisting of y+z pebbles.

Your program accepts if and only if some designated output pile contains at least onepebble (or, in a variant that can be shown to be equivalent, if it contains an odd number of pebbles).

As suggested by the imagery, you dont get to make backup copies of the piles before splitting or combining them: if, for example, you merge y with z to create y+z, then y isnt also available to be split into y/2 and y/2.
Note that the ceiling and floor functions are the only nonlinear elements of the pebblesmodel: if not for them, wed simply be applyinga sequence of linear transformations.
I can now divide my CC-completeness proof into two parts: first, that DIGICOMP (i.e., the problem of simulating the Digi-Comp II) is equivalent to the pebblesmodel, and second, that the pebblesmodel is equivalent to comparator circuits.
Lets first showthe equivalence between DIGICOMP and pebbles. The reductionis simply this: in a given Digi-Comp,each edge will be associated to a pile, with the number of pebblesin the pile equal to the total number of balls that ever traverse that edge. Thus, we have T balls dropped in to the edge incident to the source vertex, corresponding to an initial pile with T pebbles. Multiple edges pointing to the same vertex (i.e., fan-in) can be modeled by combining the associated piles into a single pile. Meanwhile, a toggle has the effect of splitting a pile: if y balls enter the toggle in total, theny/2 balls will ultimately exit in whicheverdirection the toggle was pointing initially (whether left or right), and y/2 balls will ultimately exit in the other direction. Its clear that this equivalence works in both directions: not only does it let us simulate any given Digi-Comp by a pebbleprogram, it also lets us simulate anypebbleprogram by a suitably-designed Digi-Comp.
OK, next lets show the equivalence between pebbles and comparator circuits. As a first step, given any comparator circuit, I claim that we can simulate it by a pebbleprogram. The way to do it is simply to use a pile of 0 pebblesto represent each 0 bit, and a pile of 1 pebbleto represent each 1 bit. Then, any time we want to sort two bits, we simply merge their corresponding piles, then split the result back into two piles. The result? 00 gets mapped to00, 11 gets mapped to11, and 01 and 10 both get mapped to one pebblein the y/2 pile and zero pebblesin the y/2 pile. At the end, a given pile will have apebble in itif and only if the corresponding output bit in the comparator circuit is 1.
One might worry that the input to a comparator circuit is a sequence of bits, whereas I said before that the input to a pebbleprogram is just a single pile. However, its not hard to see that we can deal with this, without leaving the world of logspace reductions, by breaking up an initial pile of n pebblesinto n piles each of zero pebblesor one pebble, corresponding to any desired n-bit string(along with some extra pebbles, which we subsequently ignore). Alternatively, we could generalize the pebblesmodel so that the input can consist of multiple piles. One can show, by a similar breaking-up trick, that this wouldnt affect the pebblesmodels equivalence to the DIGICOMP problem.
Finally, given a pebbleprogram, I need to show how to simulate it by a comparator circuit. The reduction works as follows:let T be the number of pebbles were dealing with (or even just an upper bound on that number). Then each pile willbe represented by its own groupof T wires in the comparatorcircuit. The Hamming weight of those T wiresi.e., the number ofthem that contain a 1 bitwill equal the number of pebbles in thecorresponding pile.
To merge two piles, we first merge the corresponding groupsof T wires. We then use comparator gates to sort the bits in those 2T wires, untilall the 1 bits have been moved into the first T wires. Finally, weignorethe remaining T wires for the remainder of the computation.
To split a pile, we first use comparator gates to sort the bits in the Twires, until all the 1 bits have been moved to the left. We then routeall the odd-numbered wires into Pile A (the one thats supposed toget y/2pebbles), and route all the even-numbered wires intoPile B (the one thats supposed to get y/2pebbles). Finally, we introduce T additional wires with 0s in them, so that pilesA and B have T wires each.
At the end, by examining the leftmost wire in the group of wires corresponding to the output pile, we can decide whether that pile ends up with any pebbles in it.
Since its clear that all of the above transformations can be carried out in logspace (or even smaller complexity classes), this completes the proof that DIGICOMP is CC-complete under L-reductions. As corollaries, the Stable Marriage and lexicographically-first perfect matching problems are L-reducible to DIGICOMPor informally, are solvable by easily-described, polynomial-size Digi-Comp machines (and indeed, characterize the power of suchmachines). Combining my result with the universality result of Cook et al., a second corollary is that there exists a universal Digi-Comp: that is, a single Digi-Comp D that can simulate any other Digi-Comp D of some polynomially-smaller size, so long as we initialize some subset of the toggles in D to encode a description of D.
How Does the Digi-Comp Avoid Universality?
Lets now step back and ask: given that the Digi-Comp is able to do so many thingsdivision, Stable Marriage, bipartite matchinghow does it fail to be a universal computer, at least a circuit-universal one? Is the Digi-Comp a counterexample to the oft-repeated claims of people like Stephen Wolfram, about the ubiquity of universal computation and the difficulty of avoiding it in any sufficiently complex system? What would need to be added to the Digi-Comp to make it circuit-universal? Of course, we can ask the same questions about pebble programsand comparator circuits, now that we know that theyre all computationally equivalent.
The reason for the failure of universality is perhaps easiest to see in the case of comparator circuits. As Steve Cook pointed out in a talk, comparator circuits are 1-Lipschitz: that is, if you have a comparator circuit acting on n input bits, and you change one of the input bits, your change can affect at most one output bit. Why? Well, trace through the circuit and use induction. So in particular, theres no amplification of small effects in comparator circuits, no chaos, no sensitive dependence on initial conditions, no whatever you want to call it. Now, while chaos doesnt sufficefor computational universality, at least navely its a necessary condition, since there exist computations that are chaotic. Of course, this simpleminded argument cant be all there is to it, since otherwise we wouldve provedCCP. What the argumentdoes show is that, if CC=P, then the encoding of aBooleancircuit into a comparator circuit (or maybe into a collection of such circuits) would need to be subtle and non-obvious: it would need to take computations with the potential for chaos, and reduce them to computations without that potential.
Once we understand this 1-Lipschitz business, we can also see it at work in the pebbles model. Given a pebble program, suppose someone surreptitiouslyremoved a single pebble from one of the initial piles. For want of that pebble, could the whole kingdom be lost? Not really. Indeed, you can convince yourself that the output will be exactly the same as before, except that one output pile will have one fewer pebble than it would have otherwise. The reason is again an induction: if you change x by 1, that affectsat most one of x/2 andx/2 (and likewise, merging two piles affects at most one pile).
We now see the importance of the point I made earlier, about there being no facility in the piles model for copying a pile. If we could copy piles, then the 1-Lipschitz property would fail. And indeed, its not hard to show that in that case, we could implement AND, OR, and NOT gates with arbitrary fanout, and would therefore have a circuit-universal computer. Likewise, if we could copy bits, then comparator circuitswhich, recall, map (x,y) to (xy,xy)would implement AND, OR, and NOT with arbitrary fanout, and would be circuit-universal. (If youre wondering how to implement NOT: one way to do it is to use whats known in quantum computing as the dual-rail representation, where each bit b is encoded by two bits, one for b and the other for b. Then a NOT can be accomplished simply by swapping those bits. And its not hard to check that comparator gates in a comparator circuit, and combining and splitting two piles in a pebble program, can achieve the desired updates to both the b rails and the b rails when an AND or OR gate is applied. However, we could also just omit NOT gates entirely, and use the fact that computing the output of even a monotone Boolean circuit is a P-complete problem under L-reductions.)
In summary, then, the inability to amplify small effectsseems like an excellent candidate for the central reason why the power of comparator circuits and pebble programs hits a ceiling at CC, and doesnt go all the way up to P. Its interesting, in this connection, that while transistors (and before them, vacuum tubes) can be used to construct logic gates, the original purpose of both of them was simply to amplify information: to transform a small signal into a large one. Thus, we might say, comparator circuits and pebble programs fail to be computationally universal because they lack transistors or other amplifiers.
Id like to apply exactly the same analysis to the Digi-Comp itself: that is, Id like to say that the reason the Digi-Comp fails to be universal (unless CC=P) is that it, too, lacks the ability to amplify small effects (wherein, for example, the drop of a single ball would unleash a cascade of other balls). In correspondence, however, David Deutsch pointed out a problem: namely, if we just watch a Digi-Comp in action, then it certainly looks like it has an amplification capability! Consider, forexample, the binary counter discussed earlier. Suppose a column of ten toggles isin the configuration RRRRRRRRRR, representing the integer 1023. Then the next ball to fall downwill hit all ten toggles in sequence, resetting them to LLLLLLLLLL (and thus, resetting the counter to 0). Why isnt this precisely the amplification of a small effect that we were looking for?
Well, maybe itsamplification, but its not of a kind that does what we want computationally. One way to see the difficulty is that we cant takeall those L settings weve produced as output, and feed them as inputs to furthergates in an arbitrary way. We could do it if the toggles were arranged in parallel, but theyre arranged serially, so that flippingany one toggle inevitably has the potential also to flip the toggles below it. Deutsch describes this as a failure of composition: in some sense, we do have a fan-out or copying operation, but the design of the Digi-Comp prevents us from composing the fan-out operation with other operations in arbitrary ways, and in particular, in the ways that would be needed to simulate any Boolean circuit.
So, what features could we add to the Digi-Comp to make it universal? Heres the simplest possibility I was able to come up with: suppose that, scattered throughout the device, there were balls precariously perched on ledges, in such a way that whenever one was hit by another ball, it would get dislodged, and both balls would continue downward. We could, of course, chain several of these together, so that the two balls would in turn dislodge four balls, the four would dislodge eight, and so on. I invite you to check that this would provide the desired fan-out gate, which, when combined with AND, OR, and NOT gates that we know how to implement (e.g., in the dual-rail representation described previously), would allow us to simulate arbitrary Boolean circuits. In effect, the precariously perched balls would function as transistors (of course, painfullyslow transistors, and ones that have to be laboriously reloaded with a ball after every use).
As asecondpossibility, Charles Leiserson points out to me that the Digi-Comp, as sold, has a few switches and toggles that can be controlled by other toggles. Depending on exactly how one modeledthis feature, its possible that it, too, could let us implement arbitrary fan-out gates, and thereby boost the Digi-Comp up to circuit-universality.
Open Problems
My personal favorite open problem is this:
What is the complexity of simulating a Digi-Comp II if the total number of balls dropped in is exponential, rather than polynomial? (In other words, if the positive integer T, representing the number of balls, is encoded in binary rather than in unary?)
From the equivalence between the Digi-Comp and pebble programs, we can already derive a conclusion about the above problem thats not intuitively obvious: namely, that its in P. Or to say it another way: its possible to predict the exact state of a Digi-Comp with n toggles, after T balls have passed through it, using poly(n, log T) computation steps. The reason is simply that, if there are T balls, then the total number of ballsthat pass through any givenedge (the only variable we need to track) can be specified using log2T bits. This, incidentally, gives us a second sense in which the Digi-Comp is not a universal computer: namely, even if we let the machinerun for exponential time (that is, drop exponentially manyballs into it), unlike a conventionaldigital computer it cant possibly solve all problems in PSPACE, unless P=PSPACE.
However, this situation also presents us with a puzzle: if we let DIGICOMPEXP be the problem of simulating a Digi-Comp with an exponential number of balls, then its clear that DIGICOMPEXP is hard for CC and contained in P, but we lack any information about its difficulty more precise than that. At present, I regard both extremesthat DIGICOMPEXPis in CC (and hence, no harder than ordinary DIGICOMP), and that its P-completeas within the realm of possibility (along with the possibility that DIGICOMPEXPis intermediate between the two).
By analogy, one can also consider comparator circuits where the entitiesthat getcompared are integers from 1 to T rather than bitsand one can then consider the power of such circuits, when T is allowed to grow exponentially. In email correspondence, however, Steve Cook sent me a proofthat such circuits have the same power as standard, Boolean comparator circuits. Its not clear whether this tells us anything about the power of a Digi-Comp with exponentially many balls.
A second open problem is to formalize the feature of Digi-Comp that Charles mentionednamely, toggles and switches controlled by other togglesand see whether, under some reasonable formalization, that feature bumps us up to P-completeness (i.e., to circuit-universality). Personally, though, I confess Id be even more interested if there were some feature we could add to the machine that gave us a larger classthan CC, but that still wasnt all of P.
A third problem is to pin down the power of Digi-Comps (or pebble programs, or comparator circuits) that are required to be planar. While my experience with woodcarving is limited, Iimaginethat planar or near-planar graphs are a lot easier to carve than arbitrarygraphs(even if the latter present no problems of principle).
A fourthproblem has to do with the classCC in general, rather than the Digi-Comp in particular, but I cant resist mentioning it. Let CCEXPbe the complexity class thats just like CC, but where the comparator circuit (or pebble program, or Digi-Comp) is exponentially large and specified only implicitly (that is, by a Boolean circuit that, given as input a binary encoding of an integer i, tells you the ith bit of the comparator circuits description). Then its easy to see that PSPACE CCEXP EXP. Do we have CCEXP= PSPACE or CCEXP= EXP? If not, then CCEXPwould be the first example Ive ever seen of a natural complexity class intermediate between PSPACEand EXP.
Acknowledgments
I thank Charles Leiserson for bringing the Digi-Comp II to MIT, and thereby inspiring this research. I also thank Steve Cook, both for giving a talk that first brought the complexity class CC to my attention, and for helpful correspondence. Finally I thank David Deutsch for the point about composition.The P-and-NP Show comes to Caltech

Here are the PowerPoint slides for a physics colloquium I gave at Caltech yesterday, on Computational Intractability as a Law of Physics.  The talk was delivered, so I was told, in the very same auditorium where Feynman gave his Lectures on Physics.  At the teatime beforehand, I was going to put both milk and lemon in my tea to honor the old man, but then I decided I actually didnt want to.
Im at Caltech till Tuesday, at which point I leave for New Zealand, to visit my friend Miriam from Berkeley and see a country I always wanted to see, and thence to Australia for QIP.  This Caltech visit, my sixth or seventh, has been every bit as enjoyable as Ive come to expect: its included using Andrew Childs as a straight man for jokes, shootin the qubits with Shengyu Zhang, Aram Harrow, and Robin Blume-Kohout, and arguing with Sean Carroll over which one of us is the second-funniest physics blogger (we both agree that Lubo is the funniest by far).  Indeed, John Preskill (my host) and everyone else at the Institute for Quantum Information have been so darn hospitable that from now on, I might just have to shill for quantum computing theory.Seth Teller (1964-2014)

Seth Teller was a colleague of mine in CSAIL and the EECS department, and was one of my favorite people in all of MIT. He was a brilliant roboticist, who (among many other things) spearheaded MITs participation in the DARPA Grand Challenge for self-driving cars, and who just recently returned from a fact-finding trip to Fukushima, Japan, to seehow robots could help in investigating the damaged reactor cores there. I saw Sethtwice a week at lab and department lunches, and he often struck up conversations with me about quantum computing, cosmology,and other things. His curiosity was immense, wide-ranging, and almost childlike (in the best way). One small indication of his character is that, in the DARPA challenge, Seth opted not topreload MITs car with detailed data about the course, because he thought doing so made thechallenge scientifically less interestingeven though DARPAsrules allowed such preloading, the other teams did it, and it almost certainly would haveimproved MITs standing in the competition.
Seth was a phenomenalspeaker, whose passion and clarity always won me over even though my research interests were far from his. I made it a point to show up for lab lunch whenever I knew hed be speaking. Seth was also, from what Ive heard, a superb mentorand teacher, whowon an award earlier this year for hisundergraduate advising.
Seth died ten days ago, on July 1st. (See here for MIT Newss detailed obituary, and here for an article in Cambridge Day.) While no cause of death was given at the time, according to an update yesterday in the MIT Tech, the death has been ruled a suicide. Seth is survived by his wife, Rachel, and by two daughters.
With his cheerful, can-do disposition, Seth is one ofthelastpeopleon earth Id imagine doing this: whatever he was going through, he did an unbelievablejob of hiding it. Im certain he wouldnt abandon his familyunless he was suffering unimaginablepain. If theres a tiny atomof good to come out of this, I hope thatat least one other personcontemplating suicide will reflect onhow much Seth had to live for, and that doing sowill inspire that person to get the medical helpthey need.
Incidentally, outside of his research and teaching, Seth was also an activist for protectingthe physical environment and open spaces of East Cambridge. At the Wild and Crazy Ideas Session of one CSAILretreat, Seth floated a truly wild idea: to replace Memorial Drive, or at least the part of it that separates the MIT campus from the Charles River, by an underground tunnel, so that the land above the tunnel could be turned into a beautiful riverfront park. In his characteristic fashion, Seth had already done apretty detailedengineering analysis, estimating the cost at merely a few hundred million dollars: a lot, but a worthy investment in MITs future. In any case, I cant imagine a better way to memorialize Seth than to name some green space in East Cambridge after him, and I hope that happens.
Seth will be sorely missed. My thoughts go out to his family at this difficult time.Favorite foods

Or, why I will weigh at least 3000 pounds by the time I get tenure.

Fresh fruit (eaten in highly nontrivial quantities): grapefruit, watermelon, raspberries, blackberries, cherries, mangoes.  Abnormally high tolerance for citrus (will eat plain lemons and limes with no problem).
Vegetables: boiled broccoli, corn on the cob, avocado, raw baby carrots, cucumber, mashed potatoes, cherry tomatoes
Peanuts, cashews, walnuts
Beverages: fruit smoothies (mango, raspberry, banana), sparkling grape juice, coconut juice, iced tea, iced coffee, Hong Kong style bubble tea, fresh OJ, fresh lemonade, beer, champagne.  Always looking for new and exotic fruit drinks.  Not big on water.  Trying to eliminate corn-syrup sodas.
Chicken
Steak, pot roast, burgers, pastrami
Fresh fish of all kinds: salmon, mahi-mahi, halibut, tuna (not shellfish)
Lots of soup: chicken-noodle, beef-vegetable, potato, chili
Breakfast: egg-and-cheese sandwich, veggie omelet, french toast, waffles with fresh fruit, Count Chocula (with whole milk, of course)
Italian: eggplant parm, spaghetti with meatballs, linguini with salmon, cheese ravioli, garlic bread, pizza with onions and mushrooms (if that counts as Italian)
Indian: samosas, garlic naan, numerous variations on lamb & rice, gulab jamun, chai
(American) Chinese: egg drop soup, crunchy noodles, mu shu chicken
Thai: cashew chicken, mango and sticky rice, Thai iced tea
Japanese: edamame, tuna sashimi with wasabi, udon noodles, teriyaki, beef sukiyaki.  Also all sorts of junk food (mochi ice cream, Hi-Chew)
Greek and Middle Eastern: falafel, pita with hummus, baklava
Jewish: latkes, fried matzo, fried artichokes, gefilte with horseradish (really  its good!), bagels with cream cheese and whitefish (not so much lox), beef brisket
Russian: borscht, potato pierogies
Ethiopian: injera bread (the edible tablecloth), Tej honey-wine
British:
American Thanksgiving dinner: turkey, stuffing, sweet potatoes, cranberry sauce, pumpkin pie  any time of year.
Sweets: candy apples, Jelly Bellys (especially licorice and coconut), Mentos, Tic-Tacs, peppermint patties, Charleston Chew, Peanut Chews (as mentioned earlier), Peanut M&Ms, cherry Starburst, saltwater taffy, fudge, funnel cake, smores, Australian candied apricots, Turkish Delight, Hot Tamales, Mint Milano, soft chocolate-chip cookies, chocolate-dipped strawberries, chocolate pudding, chocolate mousse, warm chocolate cake, chocolate-covered Rice Krispies squares, sugar cubes, pure granulated sugar straight out of the bag mmmmmmmm.
Ice cream (obviously a separate category): Ben & Jerrys Chocolate Fudge Brownie, Breyers coffee or mint chocolate chip, ice cream sandwiches, hot fudge sundaes (the hot fudge is crucial  not just chocolate syrup), banana splits, fruit sorbet, gelati (ice cream + water ice), fresh-made gelato, Freeze-Dried Astronaut Ice Cream (found in science museum gift shops)

Go ahead and list your own favorites in the comments section, together with your research area (or line of work if you have a real job).  Then well see if theres any correlation between the two.  See, this isnt procrastination: its serious research.
Update (1/23): I finally fixed the time stamps in the comments section.  Unfortunately, this will cause comments to appear out-of-order during an 8-hour window.How Might Quantum Information Transform Our Future?

So, the Templeton Foundation invited me to write a 1500-word essay on the above question. Its like a blog post, except they pay me to do it! My essay is now live, here. I hope you enjoy my attemptat techno-futurist prose. You can comment on the essay either here or over at Templetons site. Thanks very much to Ansley Roan for commissioning the piece.3-sentence summary of whats happening in Israel and Gaza

Hamas is trying to kill as many civilians as it can.
Israel is trying to kill as few civilians as it can.
Neither is succeeding very well.

Update (July 28): Please check out a superbessay by Sam Harris on the Israeli/Palestinian conflict. While, as Harris says, the essay contains something to offend everyoneeven meit also brilliantly articulates many of the points Ive been trying to make in this comment thread.
See also a good HuffPost article by Ali A. Rizvi, a Pakistani-Canadian writer, physician, and musician.Haere mai, kia ora tatou  eh, whatever

Ive just come from a thin strip of volcanic ash near Antarctica, on which no mammal except bats set foot until a thousand years ago, and which today is mostly inhabited by sheep and by people who say nigh-oh when they mean no.  Im referring, of course, to New Zealand  or as the locals call it, Middle Earth.  My colleague Andris Ambainis and I were in Auckland for four days, en route to QIP2007 in Brisbane.  While there, we were fed and sheltered by our friend Miriam and her boyfriend David.  Miriam was both my housemate and officemate my first year at Berkeley; she now does user-interface research for a web-design company called Shift.  You can see some of her handiwork, and learn more about her sheep-intensive homeland, by visiting this website.  Hey, if Miriam took you around a place like this
youd shill for her too.So, now that I was surrounded by one of the last relatively-intact wildernesses on Earth, what did I do there?   If it were up to me, mostly blog, eat, and check email.  Fortunately Miriam didnt let me get away with my default ways, and repeatedly dragged me by my ears on Cultural Learning Experiences.  And thats what allows me to present the following Shtetl-Optimized New Zealand Educational Supplement.

Auckland is almost certain to be destroyed sometime in the next few millennia by one of the fifty or so active volcanoes its built on. On the bright side, like most of the worlds current cities, it will probably be underwater long before that.


New Zealand is the first place Ive visited where the ozone hole is a serious everyday concern.  Especially now, in summertime, when the hole over Antarctica is largest, youre not supposed to go outside for even a few minutes without sunblock.


Id always imagined the Maori as a nearly-extinct people who lived on reservations doing tribal dances for tourists. Actually theyre ~15% of the population, and have so assimilated with the pakehas (whites) that these days Maori kids get sent to special schools, weekend programs, etc. to retain something of their language and culture.  (Like Hebrew day school but with more jade weapons.)  Andris and I did see a traditional Maori war-dance, but you could tell that the people doing it were going to check their text messages as soon as it was over.


New Zealand was pretty much the last habitable landmass on Earth to be reached by human beings  not even the Maori got there until 1000AD.  By comparison, the Aboriginals were already in Australia by 50,000BC.  So why was New Zealand so much harder to reach than Australia?  When we examine a map  a possible answer suggests itself: because New Zealand is so friggin far from everything else.  Australia is practically in swimming distance from Southeast Asia by comparison.  Because of this, reaching New Zealand and the other Pacific Islands took advances in boat-building and navigation that only happened recently in human history. Heres another thing I never really appreciated before: the people who did get to these islands werent just drifting around randomly in their canoes.  They knew exactly what they were doing.  Like the Europeans who came later, they were setting out repeatedly on large, organized expeditions with the specific goal of finding new islands, returning to where they started from, and then coming back to the new islands with a settling party.  Ideally the new islands would be chock-full of tasty animals like the moa that, unused to land-based predators, could then be hunted to extinction.

Alright, enough book-learnin  lets see some more picturesUS State Department: Let in cryptographers and other scientists

Predictably, my last post attracted plentyof outrage (someof it too vile to let through), along with the odd commenter who actually agreed with what I consider my fairlymiddle-of-the-road,liberal Zioniststance. But since theoutrage came fromboth sides of the issue, and the two sides were outraged about the opposite things, I guessI should feel OK about it.
Still, its hard not to smart from the burns of vituperation, so today Id like to blog about a verydifferent political issue: one where hopefully almostall Shtetl-Optimized readers will actually agree with me (!).
Ive learned from colleagues that, overthe past year, foreign-born scientists have been havingenormously more trouble getting visas to enter the US than they used to. The problem, Im told, is particularly severe for cryptographers: embassy clerks are now instructed to ask specificallywhether computer scientists seeking to enter the US workin cryptography. If anapplicant answers yes, it triggers a special process where the applicant hears nothing back for months, and very likely misses the workshop in the US that he or she had planned to attend. The rootof the problem, it seems, is something called the Technology Alert List (TAL), which has been around for a whilethe State Department beefed it up in response to the 9/11 attacksbut which, for some unknown reason, is only now being rigorously enforced. (Being marked as working in one of the sensitive fields on this listis apparently called getting TALd.)
The issue reached a comical extreme last October, when Adi Shamir, the Sin RSA, Turing Award winner, and foreign member of the US National Academy of Sciences, was prevented from entering the US to speak at a History of Cryptology conference sponsored by the National Security Agency. According to Shamirs open letter detailing the incident, not even his friends at the NSA, or the president of the NAS, were able to grease the bureaucracy at the State Department for him.
It should be obvious to everyone that a crackdown on academic cryptographers serves no national security purpose whatsoever, and if anything harms American security and economic competitiveness, by diverting scientific talent to other countries. (As Shamir delicately puts it, the number of terrorists among the members of the US National Academy of Science is rather small.) So:

Any readers who have more factsabout whats going on, or personal experiences, are strongly encouraged to share them in the comments section.
Any readers who might have any levers of influence to pull on this issuea Congressperson to write to, a phone call to make, an Executive Order to issue (Im talking to you, Barack), etc.are strongly encouraged to pull them.Is the P vs. NP problem ill-posed?  (Answer: no.)

A couple days ago, a reader wrote to me to ask whether its possible that the solution to the P vs. NP problem is simply undefinedand that one should enlarge the space of possible answers using non-classical logics (the reader mentioned something called Catukoi logic). Since other people have emailed me with similar questions in the past, I thought my response might be of more general interest, and decided to post it here.

Thanks for your mail! Im afraid I dont agree with you that theres a problem in the formulation of P vs. NP. Let me come at it this way:
Do you also think there might be a problem in the formulation of Goldbachs Conjecture? Or the Twin Prime Conjecture? (I.e., that maybe the definition of prime number needs to be modified usingCatukoi logic?) Or any other currently-unsolved problem in any other part of math?
If you dont, then my question would be: why single out P vs. NP?
After all, P vs. NP can be expressed as a 2-sentence: that is, as a certain relationship among positive integers, which either holds or doesnt hold. (In this case, the integers would encode Turing machines, polynomial upper bounds on their running time, and an NP-complete problem like 3SAT  all of which are expressible using the basic primitives of arithmetic.) In terms of its logical form, then, its really no different than the Twin Prime Conjecture and so forth.
So then, do you think that statements of arithmetic, like there being no prime number between 24 and 28, might also be like the Parallel Postulate? That there might be some other, equally-valid non-Euclidean arithmetic where there is a prime between 24 and 28? What exactly would one mean by that? I understand exactly what one means by non-Euclidean geometries, but to my mind, geometry is less fundamental (at least in a logical sense) than positive integers are. And of course, even if one believes that non-Euclidean geometries are just as fundamental as Euclidean geometry  an argument that seems harder to make for, say, the positive integers versus the Gaussian integers or finite fields or p-adics  that still doesnt change the fact that questions about Euclidean geometry have definite right answers.
Let me acknowledge two important caveats to what I said:
First, its certainly possible that P vs. NP might be independent of standard formal systems like ZF set theory (i.e., neither provable nor disprovable in them). Thats a possibility that everyone acknowledges, even if (like me) they consider it rather unlikely. But note that, even if P vs. NP were independent of our standard formal systems, that still wouldnt mean that the question was ill-posed! There would still either be a Turing machine that decided 3SAT in polynomial time, or else there wouldnt be. It would only mean that the usual axioms of set theory wouldnt suffice to tell us which.
The second caveat is that P vs. NP, like any other mathematical question, can be generalized and extended in all sorts of interesting ways. So for example, one can define analogues of P vs. NP over the reals and complex numbers (which are also currently open, but which might be easier than the Boolean version). Or, even if PNP, one can still ask if randomized algorithms, or nonuniform algorithms, or quantum algorithms, might be able to solve NP-complete problems in polynomial time. Or one can ask whether NP-complete problems are at least efficiently solvable on average, if not in the worst case. Every one of these questions has been actively researched, and you could make a case that some of them are just as interesting as the original P vs. NP question, if not more interesting  if history had turned out a little different, any one of these might have been what wed taken as our flagship question, rather than P vs. NP. But again, this still doesnt change the fact that the original P vs. NP question has some definite answer (like, for example, PNP), even if we cant prove which answer it is, even if we wont be able to prove it for 500 years.
And please keep in mind that, if P vs. NP were solved after being open for hundreds of years, it would be far from the first such mathematical problem! Fermats Last Theorem stayed open for 350 years, and the impossibility of squaring the circle and trisecting the angle were open for more than 2000 years. Any time before these problems were solved, one couldve said that maybe people had failed because the question itself was ill-posed, but one wouldve been mistaken. People simply hadnt invented the right ideas yet.
Best regards,
Scott

Unrelated Announcements: As most of you have probably seen, Subhash Khot won the Nevanlinna Prize, while Maryam Mirzakhani, Artur Avila, Manjul Bhargava and Martin Hairer won the Fields Medal. Mirzakhani is the first female Fields Medalist. Congratulations to all!
Also, I join the rest of the world in saying that Robin Williams was a great actorthere was no one better at playing the Robin Williams role in any given movieand his loss is a loss for humanity.Open Shtetl Day at QIP07

So, like, Im at QIP2007 in Brisbane, Australia?  And, like, everyones expecting me to blog about all the wild talks and poster presentations going down in Q-Town?  But, like, I dont actually want to blog about that stuff, since it seems suspiciously close to useful content, the very thing this blog was created to avoid?
Im therefore declaring an Open Shtetl Day, for all of my readers who happen to be in Brisbane.  Heres how it works: using the comments section, tell the world about your QIP experience.  What were the best talks/results/open problems?  What happened at the business meeting?  (I actually want to know  I skipped it.)  What are the most salacious rumors about whos coauthoring with whom?  Cmon, you know you want to post, and you know youve got nothing better to do.  I can see Im not the only one in this lecture hall whos typing away on a laptop.
And get this: after a day or two, Ill pick the best comments and QIPiest quips, and post them right here in the blog entry proper!  QIPers, dont miss what could be your big break in the competitive quantum blogosphere.
(To preempt the inevitable question: No, theres not going to be an after-dinner speech this year.  But I have it on good authority that therell be something in its place.)Could a Quantum Computer Have Subjective Experience?

Authors Note:Below is the prepared version ofa talk that I gavetwo weeks ago at theworkshop Quantum Foundations of a Classical Universe, which was held at IBMs TJ Watson Research Center in Yorktown Heights, NY. My talk is for entertainment purposes only; it should not be taken seriously by anyone. If you reply in a way that makes clear you didtake it seriously (Im shocked and outragedthat someone who dares to callhimself a scientist would  [blah blah]), I will log your IP address, hunt you down at night, and force you to put forward an account of consciousness and decoherence that deals with all the paradoxes discussed belowand then reply at length to all criticisms of your account.
If youd like to see titles, abstracts, and slides for all the talks from the workshopincluding by Charles Bennett, Sean Carroll, James Hartle, Adrian Kent, Stefan Leichenauer, Ken Olum, Don Page, Jason Pollack, Jess Riedel, Mark Srednicki, Wojciech Zurek, and Michael Zwolakclick here. Youre also welcome to discuss these other nice talks in the comments section, though I might or might not be able to answer questions about them. Apparently videos of all the talks will be available before long (Jess Riedel has announced that videos are now available).
(Note that, as is probably truefor other talks as well, the video of my talk differs substantially from the prepared versionit mostly just consists of interruptions and my responses to them! On the other hand, I did tryto work some of the more salient points from the discussion into the text below.)
Thanks so much to Charles Bennett and Jess Riedel for organizing the workshop, and to all the participants for great discussions.

I didnt prepare slides for this talkgiven the topic, what slides would I use exactly? Spoiler alert: I dont have any rigorous results about the possibility of sentient quantum computers, to state and prove on slides. I thought of giving a technical talk onquantum computing theory, but then I realized that I dont reallyhave technical results that bear directly on the subject of the workshop, which is how the classical world we experience emerges from the quantum laws of physics. So, given the choice between a technical talk that doesnt really address the questions were supposed to be discussing, or a handwavy philosophical talk that at least tries to address them, I opted for the latter, so help me God.
Let me start with a storythat John Preskill told me years ago. In the far future, humans have solved not only the problem of building scalable quantum computers, but also the problem of human-level AI. Theyve built a Turing-Test-passing quantum computer. The first thing they do, to make sure this is actually a quantum computer, is ask it to use Shors algorithm to factor a 10,000-digit number. So the quantum computer factors the number. Then they ask it, while you were factoring that number, what did it feel like? did you feel yourself branching into lots of parallel copies, which then recohered? or did you remain a single consciousnessa unitary consciousness, as it were? can you tell us from introspection which interpretation of quantum mechanics is the true one? The quantum computer ponders thisfor a while and then finally says, you know, I mightve known before, but now I just cant remember.
I like to tell this story when people ask me whether the interpretation of quantum mechanics has any empirical consequences.
Look, I understand the impulse to say lets discuss the measure problem, or the measurement problem, or derivations of the Born rule, or Boltzmann brains, or observer-counting, or whatever, but lets take consciousness off the table. (Compare: lets debate this state law in Nebraskathat says that, before getting an abortion, a woman has to be shown pictures of cute babies. But lets take the question of whether or notfetuses have human consciousnessi.e., the actual thing thats driving our disagreement about that and every other subsidiary questionoff the table, since that one is too hard.) The problem, of course, is that even after youve takenthe elephantoff the table (to mix metaphors), it keeps climbingback onto the table, oftenin disguises. So, for better or worse, my impulse tends to be the opposite: to confront the elephantdirectly.
Having said that, I still need to defend the claim that (a) the questions were discussing, centered around quantum mechanics,Many Worlds, and decoherence, and (b) the question of which physical systems should be consideredconscious, have anything to do with each other. Many people would say that the connection doesnt go any deeper than: quantum mechanics is mysterious, consciousness is also mysterious, ergo maybe theyre related somehow. But Im not sure thats entirely true. One thing that crystallized my thinking about this was a remark made in a lecture by Peter Byrne, who wrote a biography of Hugh Everett. Byrne was discussing the question, why did it take so many decades for Everetts Many-Worlds Interpretationto become popular? Of course, there are people who deny quantum mechanics itself, or who have basic misunderstandings about it, but lets leave those people aside. Why did people like Bohr and Heisenberg dismiss Everett? More broadly: why wasnt it just obvious to physicists from the beginning that branching worldsis a picturethat the math militates toward, probablythe simplest, easieststory one can tell around the Schrdinger equation? Even if early quantum physicists rejected the Many-Worlds picture, why didnt they at least discuss and debate it?
Here was Byrnes answer: he said, before you can really be on board with Everett, you first need to be on board with Daniel Dennett (the philosopher). He meant: you first need to accept that a mind is just some particular computational process. At the bottom of everything is the physical state of the universe, evolving via the equations of physics, and if you want to know where consciousness is, you need to go into that state, and look for where computations are taking place that are sufficiently complicated, or globally-integrated, or self-referential, or  something, and thats where the consciousness resides. And crucially, if following the equations tells you that after a decoherence event, one computation splits up into two computations, in different branches of the wavefunction, that thereafter dont interactcongratulations! Youve now got two consciousnesses.
And if everything abovestrikes you as so obvious as not to be worth stating  well,thats a sign of how much things changed in the latter half of the20th century. Before then, many thinkers wouldvebeen more likely to say, with Descartes: no, my starting point is not the physical world. I dont even know a priori that there is a physical world. My starting point is my own consciousness, which is the one thing besides math that I can be certain about. And the point of a scientific theory is to explain features of my experienceultimately, if you like, to predict the probability that Im going to see X or Y if I do A or B. (If I dont have prescientific knowledge of myself, as a single, unified entity that persists in time, makes choices, and later observes their consequences, then I cant even get started doing science.) Im happy to postulate a world external to myself, filled with unseen entities like electrons behaving in arbitrarily unfamiliarways, if it will help me understand my experiencebut postulating other versions of meis, at best, irrelevant metaphysics. This is a viewpoint that could lead you Copenhagenism, or to its newer variants like quantum Bayesianism.
Im guessing that many people in this room side with Dennett, and (not coincidentally, Id say) also with Everett. I certainly have sympathies in that direction too. In fact, I spent seven or eight years of my life as a Dennett/Everett hardcore believer. But, while I dont wantto talk anyoneout of the Dennett/Everett view, Id like to take you on a tour of what I see as some of theextremely interesting questions that that view leaves unanswered. Im not talking about deep questions of meaning, but about something much more straightforward: what exactly does a computational process have to do to qualify as conscious?
Of course, there are already tremendous difficulties here, even if we ignore quantum mechanics entirely. Ken Olum was over much of this ground in his talk yesterday (see here for a relevant paper by Davenport and Olum). Youve all heard the ones about, would you agree to be painlessly euthanized, provided that a complete description of your brain would be sent to Mars as an email attachment, and a perfect copy of you would be reconstituted there? Would you demand that the copy on Mars be up and running before the original was euthanized? But what do we mean by beforein whose frame of reference?
Some people say: sure, none of this is a problem! If Id been brought up since childhood taking family vacations where we all emailed ourselves to Mars and had ouroriginal bodies euthanized, I wouldnt think anything of it. But the philosophers of mind are barely getting started.
Theres this old chestnut, what if each person on earth simulated one neuron of your brain, by passing pieces of paper around. It took them several years just to simulate a single second of your thought processes. Would that bring your subjectivity into being? Would you accept it as a replacement for your current body? If so, then what if your brain were simulated, not neuron-by-neuron, but by a gigantic lookup table? That is, what if there were a huge database, much larger than the observable universe (but lets not worry about that), that hardwired what your brains response was to every sequence of stimuli that your sense-organs could possibly receive. Would that bring about your consciousness? Lets keep pushing: if it would, would it make a difference if anyone actually consulted the lookup table? Why cant it bring about your consciousness just by sitting there doing nothing?
To these standard thought experiments, we can add more. Lets suppose that, purely for error-correction purposes, the computer thats simulating your brain runs the code three times, and takes the majority vote of the outcomes. Would that bring three copies of your consciousness into being? Does it make a difference if the three copies are widely separated in space or timesay, on different planets, or in different centuries? Is it possible thatthe massive redundancy taking place in your brain right now is bringing multiple copies of you into being?
Maybe my favorite thought experiment along these lines was invented by my former student Andy Drucker. In the past five years, theres been a revolution in theoretical cryptography, around something called Fully Homomorphic Encryption (FHE), which was first discovered by Craig Gentry. What FHE lets you do is to perform arbitrary computations on encrypted data, without ever decrypting the data at any point. So, to someone with the decryption key, you could be proving theorems, simulating planetary motions, etc. But to someone without the key, it looks for all the world like youre just shuffling random strings and producing other random strings as output.
You can probably see where this is going. What if we homomorphically encrypted a simulation of your brain? And what if we hid the only copy of the decryption key, lets say in another galaxy? Would this computationwhich looks to anyone in our galaxy like a reshuffling of gobbledygookbe silently producing your consciousness?
When we consider the possibility of a conscious quantum computer, in some sense we inherit all the previous puzzles about conscious classical computers, but then also add a few new ones. So, lets say I run a quantum subroutine that simulates your brain, by applying some unitary transformation U. But then, of course, I wantto uncompute to get rid of garbage (and thereby enable interference between different branches), so I apply U-1. Question: when I apply U-1, does your simulated brain experience the same thoughts and feelings a second time? Is the second experience the same as the first, or does it differ somehow, by virtue of being reversed in time? Or, sinceU-1U is just a convoluted implementation of the identity function, are there no experiences at all here?
Heres a better one: many of you have heard of the Vaidman bomb. This is a famous thought experiment in quantum mechanics where theres a package, and wed like to query it to find out whether it contains a bombbut if we query it and there is a bomb, it will explode, killing everyone in the room. Whats the solution? Well, suppose we could go into a superposition of querying the bomb and not querying it, with only  amplitude on querying the bomb, and (1-2) amplitude on not querying it. And suppose we repeat this over and overeach time, moving amplitude onto the query the bomb state if theres no bomb there, but moving2 probability onto the query the bomb state if there is a bomb (since the explosion decoheres the superposition). Then after 1/ repetitions, well have order 1 probability of being in the query the bomb state if theres no bomb. By contrast, if there is a bomb, then the total probability weve ever entered that state is (1/)2 = . So, either way, we learn whether theres a bomb, and the probability that we set the bomb off can be made arbitrarily small. (Incidentally, this is extremely closely related to how Grovers algorithm works.)
OK, now how about the Vaidman brain? Weve got a quantum subroutine simulating your brain, and we want to ask it a yes-or-no question. We do so by querying that subroutine with  amplitude 1/ times, in such a way that if your answer is yes, then weve only ever activated the subroutine with total probability . Yet you still manage to communicate your yes answer to the outside world. So, should we say that you were conscious only in the  fractionof the wavefunction where the simulation happened, or that the entire system was conscious? (The answer could matter a lot for anthropic purposes.)
You might say, sure, maybe these questions are puzzling, but whats the alternative? Either we have to say that consciousness is a byproduct of any computation of the right complexity, or integration, or recursiveness (or something) happening anywhere in the wavefunction of the universe, or else were back to saying that beings like us are conscious, and all these other things arent, because God gave the souls to us, so na-na-na. Or I suppose we could say, like the philosopher John Searle, that were conscious, and the lookup table and homomorphically-encrypted brain and Vaidman brain and all these other apparitions arent, because we alone have biological causal powers. And what do those causal powers consist of? Hey, youre not supposed to ask that! Just accept that we have them. Or we could say, like Roger Penrose, that were conscious and the other things arent because we alone have microtubules that are sensitive to uncomputable effects from quantum gravity. But neither of those two options ever struck me asmuch of an improvement.
Yet I submit to you that, between these extremes, theres another position we can stake outone that I certainly dont know to be correct, but that would solve so many different puzzles if it were correct that, for that reason alone, it seems to me tomerit more attentionthan it usually receives. (In an effort to givethe view that attention, a couple years ago I wrote an 85-page essay calledThe Ghost in the Quantum Turing Machine, which one or two people told me they actually read all the way through.) If, after a lifetime of worrying (on weekends) about stufflike whether a giant lookup table would be conscious, I now seem to be arguing for this particular view, its less out of conviction in its truth than out of a sense of intellectual obligation: to whatever extent people careabout these slipperyquestionsat all, to whatever extent they think various alternative views deserve a hearing, I believe this one does as well.
The intermediate position that Id like to explore says the following. Yes, consciousness is a property of any suitably-organized chunk of matter. But, in addition to performing complex computations, or passing the Turing Test, or other information-theoretic conditions that I dont know (and dont claim to know), theres at least one crucial further thing that a chunk of matter has to do before weshouldconsider it conscious. Namely, it has to participate fully in the Arrow of Time. More specifically, it has to produce irreversible decoherence as an intrinsic part of its operation. It has to be continually taking microscopic fluctuations, and irreversibly amplifying them into stable, copyable, macroscopic classical records.
Before I go further, let me be extremely clear about what this view is not saying. Firstly, its not saying that the brain is a quantum computer, in any interesting senselet alone a quantum-gravitational computer, likeRoger Penrose wants! Indeed, I see no evidence, from neuroscience or any other field, that the cognitive information processing done by the brain is anything but classical. The view Im discussing doesnt challenge conventional neuroscience on that account.
Secondly, this viewdoesnt saythat consciousness is in any sensenecessary for decoherence, or for the emergence of a classical world. Ive never understood how one could holdsucha belief, while still being a scientific realist. After all, there are trillions of decoherence events happening every second in stars and asteroids and uninhabited planets. Do those events not count as real until a human registers them? (Or at least a frog, or an AI?) The view Im discussing only assertsthe converse: that decoherence is necessary for consciousness. (By analogy, presumably everyone agrees that some amount of computation is necessary for an interesting consciousness, but that doesnt mean consciousness is necessary for computation.)
Thirdly, the view Im discussing doesnt say that quantum magic is the explanation for consciousness. Its silent on the explanation for consciousness (to whatever extent that question makes sense); it seeks only to draw a defensible line between the systems we want to regard as conscious and the systems we dontto address what I recentlycalled the Pretty-Hard Problem. And the (partial) answer it suggests doesnt seem any more magical to me than any other proposed answer to the same question. For example, if one said that consciousness arises from any computation thats sufficiently integrated (or something), I could reply: whats the magical force that imbues those particular computations with consciousness, and not other computations I can specify? Or if one said (like Searle) that consciousness arises from the biology of the brain, I could reply: so whats the magic of carbon-based biology, that could neverbe replicated in silicon? Or even if one threw up ones hands and said everything was conscious, I could reply: whats the magical power that imbues my stapler with a mind? Each of these views, along with the view that stresses the importance of decoherence and the arrow of time, is worthconsidering. In my opinion, each should be judged according to how well it holds up under the most grueling battery of paradigm-cases, thoughtexperiments, and reductios ad absurdum we can devise.
So, whymight one conjecture thatdecoherence, and participation in the arrow of time, werenecessary conditions for consciousness? I suppose I could offersome argument about our subjective experience of the passage of time being a crucial component of our consciousness, and the passage of timebeing bound up with the Second Law. Truthfully, though,I donthave any a-priori argument that I find convincing. All I can do is show you how many apparentparadoxes get resolvedif you make this one speculative leap.
For starters, if you think about exactly how our chunk of matter is going to amplify microscopic fluctuations, it could depend on details like the precise spin orientations of various subatomic particles in the chunk. But that has an interesting consequence: if youre an outside observer who doesnt know the chunks quantum state, it might be difficult or impossible for you to predict what the chunk is going to do nexteven just to give decent statistical predictions, like you can for a hydrogen atom. And of course, you cant in general perform a measurement that will tell you the chunks quantum state, without violating the No-Cloning Theorem. For the same reason, theres in general no physical procedure that you can apply to the chunk to duplicate it exactly: that is, to produce a second chunk that you can be confident will behave identically (or almost identically) to the first, even just in a statistical sense. (Again, this isnt assuming any long-range quantum coherence in the chunk: only microscopic coherence that then gets amplified.)
It might be objected that there are all sorts of physical systems that amplify microscopic fluctuations, but that arent anything like what I described, at least not in any interesting sense: for example, a Geiger counter, or a photodetector, or any sortof quantum-mechanical random-number generator. You can make, if not an exact copy of a Geiger counter, surely one thats close enough for practical purposes. And, even though the two counters will record different sequences of clicks whenpointed at identical sources, the statistical distribution of clicks will be the same (and precisely calculable), and surely thats all that matters. So, what separates these examples from the sorts of examples I want to discuss?
What separates them is the undisputed existence of what Ill call aclean digital abstraction layer. By that, I meanamacroscopicapproximation to a physicalsystem thatan external observer can produce, in principle, without destroying the system; that can be used to predict what the system will do toexcellent accuracy (given knowledge of theenvironment); and that sees quantum-mechanical uncertaintyto whatever extent it doesas justa well-characterized source of random noise. If a system hassuch an abstraction layer, then we can regardany quantum noise as simply part of the environment that the system observes, rather than part of the system itself. Ill take it as clear that suchcleanabstraction layers exist for a Geiger counter, a photodetector, or a computer with a quantum random number generator. By contrast, for (say) an animal brain, I regard it as currently an open question whether such an abstraction layer exists or not. If, someday, it becomes routine for nanobots to swarm through peoples brains and make exact copies of themafter which the original brainscan be superbly predicted in all circumstances, except for some niggling differences that are traceable back to different quantum-mechanical dice rollsat that point, perhaps educated opinion will have shifted to the point where we all agreethe brain does have a clean digital abstraction layer. But from where we stand today, it seems entirelypossible to agree that the brain is a physical system obeyingthe laws of physics, while doubting that the nanobots would work as advertised. It seems possible thatas speculated by Bohr, Compton, Eddington, and even Alan Turingif you want to get itright youll need more than justthe neural wiring graph, the synaptic strengths,and the approximate neurotransmitter levels. Maybe you also need (e.g.) the internal states of the neurons, the configurationsof sodium-ion channels, orother datathat you simply cant get without irreparably damaging the original brainnot only as a contingent matter of technology but as a fundamental matter of physics.
(As a side note, I should stress that obviously, even without invasive nanobots, our brains are constantlychanging, but we normally dont say as a result that we become completely different people at eachinstant!To my way of thinking, though, this transtemporal identity is fundamentally different from a hypothetical identity between different copies of you,inthe sense were talking about. For one thing, all your transtemporal doppelgngers are connected by a single, linear chain of causation. For another, outside movies like Bill and Teds Excellent Adventure, you cant meet your transtemporal doppelgngersand have a conversation with them, nor can scientists do experiments on some of them, then apply what they learned to others that remainedunaffected by their experiments.)
So, on this view, a conscious chunk of matter would be one that not only acts irreversibly, but that might well beunclonable for fundamental physical reasons. If so, that would neatly resolvemany of the puzzles that I discussedbefore. So for example, theres now astraightforward reason why you shouldnt consent to being killed, while your copygets recreated on Mars from an email attachment. Namely, that copywill have a microstate with no direct causal link to your original microstateso while it might behave similarly to you in many ways, you shouldnt expect that your consciousness will transfer to it. If you wanted to get your exact microstate to Mars, you could do that in principle using quantum teleportationbut as we all know, quantum teleportation inherently destroys the original copy, so theres no longer any philosophical problem! (Or, of course, you could just get on a spaceship bound for Mars: from a philosophical standpoint, it amounts to the same thing.)
Similarly, in the case where the simulation ofyour brain was run three times for error-correcting purposes: that could bring about three consciousnesses if, and only if, the three simulations were tied to different sets of decoherence events. The giant lookup table and the Earth-sized brain simulation wouldnt bring about any consciousness, unless they were implemented in such a way that they no longer had a clean digital abstraction layer. What about the homomorphically-encrypted brain simulation? That might no longer work, simply because we cant assume that the microscopic fluctuations that get amplified are homomorphically encrypted. Those are in the clear, which inevitably leaks information. As for the quantum computer that simulates your thought processes and then perfectly reverses the simulation, or that queries you like a Vaidman bombin order to implement such things, wed of course need to use quantum fault-tolerance, so that the simulation of you stayed in an encoded subspace and didnt decohere. But under our assumption, that would mean the simulation wasnt conscious.
Now, it might seem to some of you like Im suggesting something deeply immoral. After all, the view Im considering implies that, even if a system passed the Turing Test, and behaved identically to a human, even if it eloquently pleaded for its life, if it wasnt irreversibly decohering microscopic events then it wouldnt be conscious, so it would be fine to kill it, torture it, whatever you want.
But wait a minute: if a system isnt doing anything irreversible, then what exactly does it mean to kill it? If its a classical computation, then at least in principle, you could always just restore from backup. You could even rewind and not only erase the memories of, but uncompute (untorture?) whatever tortures you had performed. If its a quantum computation, you could always invert the unitary transformation U that corresponded to killing the thing (then reapply U and invert it again for good measure, if you wanted). Only for irreversible systems are there moral acts with irreversible consequences.
This is related to something thats bothered me for years in quantum foundations. When people discuss Schrdingers cat, they alwaysalwaysinsert some joke about, obviously, this experiment wouldnt pass the Ethical Review Board. Nowadays, we try to avoid animal cruelty in our quantum gedankenexperiments. But actually, I claim that theres no animal cruelty at all in theSchrdingers cat experiment. And heres why: in order to prove that the cat was ever in a coherent superposition of |Alive and |Dead, you need to be able to measure it in a basis like {|Alive+|Dead,|Alive-|Dead}. But if you can do that, you must have such precise control over all the cats degrees of freedom that you can also rotate unitarily between the |Alive and |Dead states. (To see this, let U be the unitary that you applied to the |Alive branch, and V the unitary that you applied to the |Deadbranch, to bring them into coherence with each other; then consider applying U-1V.) But if you can do that, then in what sense should we say that the cat in the |Dead state was ever dead at all? Normally, when we speak of killing, we mean doing something irreversiblenot rotating to some point in a Hilbert space that we could just as easily rotate away from.
(There followed discussion among someaudience members about the question of whether, if you destroyed all records of some terrible atrocity, likethe Holocaust, everywhere in the physical world, you would thereby cause the atrocitynever to have happened. Many people seemed surprised bymy willingness to accept that implication of what I was saying. By way of explaining, I tried to stress just how far our everyday, intuitive notion of destroying all records of something falls short of what would actuallybe involved here: when we think of destroying records, we think about burning books, destroying the artifacts in museums, silencing witnesses, etc. But even if all those things were done and many others, still the exact configurations of the air, the soil, and photons heading away from the earth at the speed of light would retaintheir silent testimony to the Holocausts reality. Erasing all records in the physics sense would be something almost unimaginablymore extreme: it would meaninverting the entire physical evolution in the vicinity of the earth, stopping times arrow and running history itself backwards. Such unhappeningof whatshappened is something that we lack any experience of, at least outside of certain quantum interference experimentsthough in the case of the Holocaust,one could be forgiven for wishing it were possible.)
OK, so much for philosophy of mind and morality; what about the interpretation of quantum mechanics? If we think about consciousness in the way Ive suggested, then whos right: the Copenhagenists or the Many-Worlders? You could make a case for either. The Many-Worlders would be right that we could always, if we chose, think of decoherence events as splitting our universe into multiple branches, each with different versions of ourselves, that thereafter dont interact. On the other hand, the Copenhagenists would be right that, even in principle, we could never do any experiment where this splitting of our minds would have any empirical consequence. On this view, if you can control a system well enough that you can actually observe interference between the different branches, then it follows that you shouldnt regard the system as conscious, because its not doing anything irreversible.
In my essay, the implication that concerned me the most was the one for free will. If being conscious entails amplifying microscopic events in an irreversible and unclonable way, then someone looking at a conscious system from the outside might not, in general, be able to predict what its going to do next, not even probabilistically. In other words, its decisions might be subject to at least some Knightian uncertainty: uncertainty that we cant even quantify in a mutually-agreedway using probabilities, in the same sense that we can quantify our uncertainty about (say) the time of a radioactive decay. And personally, this is actually the sort of freedom that interests me the most. I dont really care if my choices are predictable by God, or by a hypothetical Laplace demon: that is, if they would be predictable (at least probabilistically), given complete knowledge of the microstate of the universe. By definition, theres essentially no way for my choices not to be predictable in that weak and unempirical sense! On the other hand, Id prefer that my choices not be completelypredictable by other people. If someone could put some sheets of paper into a sealed envelope, then I spoke extemporaneously for an hour, and then the person opened the envelopeto reveal an exact transcript of everythingI said, thats the sort of thing that really would cause me to doubt in what sense I existed as a locus of thought. But youd have to actuallydothe experiment (or convince me that it couldbe done): it doesnt count just to talkabout it, or to extrapolate from fMRI experiments that predict which of two buttons a subject is going to press with 60% accuracy a few seconds in advance.
But since weve got some cosmologists in the house, let me now turn to discussing the implications of this view for Boltzmann brains.
(For those tuning in from home: a Boltzmann brain is a hypothetical chancefluctuation in the late universe, which would includea conscious observerwith all the perceptions that a human beingsay, youis having right now, right down to false memories and false beliefs of having arisen via Darwinian evolution. On statistical grounds, the overwhelming majority of Boltzmann brains last just long enough to have a single thoughtlike, say, the oneyoure having right nowbefore theyencounter the vacuum and freeze to death. If you measured some part of the vacuum state toward which our universe seems to be heading, asking is there a Boltzmann brain here?, quantum mechanics predicts that the probability would be ridiculously astronomically small, but nonzero. But, so the argument goes, if the vacuum lasts for infinite time, then as long as the probability is nonzero, it doesnt matter how tinyit is: youll still get infinitely many Boltzmann brains indistinguishable from any given observer; and for that reason, any observer should consider herself infinitely likelier to be a Boltzmann brain than to be the real, original version. For the record, even among the strange people at the IBM workshop, no one actuallyworried about being a Boltzmann brain. The question, rather, is whether,if a cosmologicalmodel predicts Boltzmann brains, then thats reason enoughto reject the model, or whether we can live with sucha prediction, since we have independent groundsfor knowing that we cant be Boltzmann brains.)
At this point, you can probably guess where this is going. If decoherence, entropy production, full participation in the arrow of time are necessary conditions for consciousness, then it would follow, in particular, that a Boltzmann brain is not conscious. So wecertainly wouldnt beBoltzmann brains, even undera cosmological model that predicts infinitely more of them than of us. We can wipe our hands; the problem is solved!
I find it extremely interesting that, in their recent work, Kim Boddy, Sean Carroll, and Jason Pollack reached a similar conclusion, but from a completely different starting point. They said: look, under reasonable assumptions, the late universe is just going to stay forever in an energy eigenstatejust sitting there doing nothing. Its true that, if someone came along and measured the energy eigenstate, asking is there a Boltzmann brain here?, then with a tiny but nonzero probability the answer would be yes. But since no one is there measuring, what licenses us to interpret the nonzero overlap in amplitude with the Boltzmann brain state, as a nonzero probability of there being a Boltzmann brain? I think they, too, are implicitly suggesting:if theres no decoherence, no arrow of time, then were not authorized to say that anything is happening that counts for anthropic purposes.
Let me now mention an obvious objection. (In fact, when I gave the talk, this objection was raised much earlier.) You might say, look, if you really think irreversible decoherence is a necessary condition for consciousness, then you might find yourself forced to say that theres no consciousness, because there might not be any such thing as irreversible decoherence! Imagine that our entire solar system were enclosed in an anti de Sitter (AdS) boundary, like in Greg Egans science-fiction novel Quarantine. Inside the box, there would just be unitary evolution in some Hilbert space: maybeevena finite-dimensional Hilbert space. In which case, all these irreversible amplifications that you lay so much stress on wouldnt be irreversible at all: eventually all the Everett branches would recohere; in fact theyd decohere and recohere infinitely many times. So by your lights, how could anything be conscious inside the box?
My response to this involves one lastspeculation. I speculate that the fact that we dontappear to live in AdS spacethat we appearto live in (something evolving toward) a de Sitter space, with a positive cosmological constantmight be deep andimportant and relevant. I speculate that, in our universe, irreversible decoherencemeans: the records of what you did are now heading toward our de Sitter horizon at the speed of light, and for that reason aloneeven if for no othersyou cant put Humpty Dumpty back together again. (Here I should point out, as several workshop attendees did to me, that Bousso and Susskind explored something similar in their paper The Multiverse Interpretation of Quantum Mechanics.)
Does this mean that, if cosmologists discover tomorrow that the cosmological constant is negative, or will become negative, then it will turn out that none of us were ever conscious? No, thats stupid. What it would suggestis that the attempt Im now making on the Pretty-Hard Problem had smackedinto a wall (an AdS wall?), so that I, and anyone else who stressed in-principle irreversibility, shouldgo back to the drawing board. (By analogy, if some prescription for getting rid of Boltzmann brains fails, that doesnt meanwe areBoltzmann brains; it just means we need a new prescription. Tempting as it is to skewer our opponents positions with these sorts of strawman inferences, I hope we can give each other the courtesy of presuming a bare minimum of sense.)
Another question: am Isayingthat, in order to be absolutely certainof whether some entity satisfied the postulated precondition forconsciousness, onemight, in general,need to look billions of years into the future, to see whether the decoherence produced by the entity was really irreversible? Yes (pause to gulp bullet). I am saying that. On the other hand, I dont think itsnearly as bad as it sounds. After all, the categoryof consciousness might be morally relevant, or relevant for anthropic reasoning, but presumably we all agree that its unlikely to play anycausal role in the fundamental laws of physics. So its not as if weve introduced any teleology into the laws of physics by this move.
Let me end by pointing out whatIll call the Tegmarkian slippery slope. It feelsscientific and rationalfrom the perspective of many of us, even banalto say that, if were conscious, then any sufficiently-accurate computer simulation of us would also be. But I tried to convince you that this viewdepends, for its aura of obviousness, on our agreeing not to probe too closely exactlywhat wouldcountas asufficiently-accurate simulation. E.g., does it count if the simulation is donein heavily-encrypted form, or encoded as a giant lookup table? Does it matter if anyone actually runs the simulation, or consults the lookup table? Now, all the way at the bottom of the slope is Max Tegmark, who asks: to produce consciousness, what does it matter if the simulationis physically instantiated at all? Why isnt it enough for the simulation toexist mathematically? Or, better yet: if youre worried about your infinitely-many Boltzmann brain copies, then why not worry equally about the infinitely many descriptions of your life history that are presumably encoded in the decimal expansion of ? Why not holdworkshops about how to avoid the prediction that were infinitely likelier to be living in  than to be our real selves?
From this extreme, even most scientific rationalists recoil. They say, no, even if we dont yet know exactly whats meant by physical instantiation, we agreethat you only get consciousness if the computer program is physically instantiated somehow. But now I have the opening I want. I can say:oncewe agree that physical existence is a prerequisite for consciousness, why not participation in the Arrow of Time? After all, our ordinary ways of talkingabout sentient beingsoutside of quantum mechanics, cosmology, and maybe theologydont even distinguishbetween the concepts exists and exists and participates in the Arrow of Time. And to say we have no experience ofreversible, clonable, coherently-executable, atemporal consciousnesses is a massive understatement.
Of course, we should avoid the sort of arbitrary prejudice that Turing warned against in Computing Machinery and Intelligence. Just because we lack experience with extraterrestrial consciousnesses,doesnt mean it would be OK to murder an intelligent extraterrestrial if we met onetomorrow. In just the same way, just because we lack experience with clonable, atemporal consciousnesses, doesnt mean it would be OK to  wait! As we said before,clonability, and aloofness from times arrow, call severely into question what it even means to murder something. So maybe this case isnt as straightforward as the extraterrestrials after all.
At this point, Ive probably laid out enough craziness, so let me stop and open things up for discussion.Subhash Khots prizewinning research

I already congratulated Subhash Khot in my last post for winning the Nevanlinna Award, but this really deserves a separate post. Khot won theoretical computer sciences highest award largelyfor introducing and exploring theUnique Games Conjecture (UGC), which says (in one sentence) that a large number of theapproximationproblems that no one has been able to prove NP-hard, really are NP-hard. In particular, if the UGC is true, then for MAX-CUT and dozens of other important optimizationproblems,no polynomial-time algorithm can always get you closer to the optimal solution than some semidefinite-programming-based algorithm gets you, unless P=NP. The UGC might or might not be trueunlike with (say) PNP itself, theres no firm consensus around itbut even if its false, the effort to prove or disprove it has by nowhad a huge impact on theoretical computer science research, leading to connections with geometry, tiling, analysis of Boolean functions, quantum entanglement, and more.
There are a few featuresthat make the UGC interesting, compared to most other questions considered in complexity theory. Firstly, the problem that the UGC asserts is NP-hardbasically,given a list of linear equations in 2 variables each, to satisfy as many of the equations as you canis a problem with imperfect completeness. This means that, if you just wanted to know whether all the linear equations were simultaneously satisfiable, the question would be trivialto answer, using Gaussian elimination. So the problem only becomes interesting once youre told that the equations are not simultaneously satisfiable, but youd like to know (say) whether its possible to satisfy 99% of the equations or only 1%. A second feature is that, because of the 2010 work of Arora, Barak, and Steurer, we know that there is an algorithm that solves the unique games problem in subexponential time: specifically, in time exp(npoly()),where  is the completeness error (that is, the fraction of linear equations that are unsatisfiable, in the case that most of them are satisfiable). This doesnt mean that the unique games problem cant be NP-hard: it just means that, if there isan NP-hardness proof, then the reduction will need to blow up the instance sizes by an npoly(1/)factor.
To be clear, neither of the above features is unique (har, har) to unique games: weve long known NP-complete problems, like MAX-2SAT, that have the imperfect completeness feature, and we also know NP-hardness reductions that blow up the instance size by an npoly(1/)factor for inherent reasons (for example, for the Set Cover problem). But perhaps nothing points as clearly as UGC at the directions that researchers in hardness of approximation and probabilistically checkable proofs (PCP) would like to be able to go. A proof of the Unique Games Conjecture would basically be a PCP theorem on steroids. (Or, since we already have PCP theorems on steroids, maybe a PCP theorem on PCP?)
Its important to understand that, between the UGC being true and the unique games problem being solvable in polynomial time, theres a wide range of intermediate possibilities, many of which are being actively investigated. For example, the unique games problem could be NP-hard, but via a reduction that itself takes subexponential time (i.e., it could be hard assuming the Exponential-Time Hypothesis). It could be solvable much faster than Arora-Barak-Steurer but still not in P. Or, even if the problem werent solvable any fasterthan iscurrently known, it could be hard without being NP-hard, having a similar status to factoring or graph isomorphism. Much current research into the UGC is focused on a particular algorithm called the Sum-of-Squares algorithm (i.e., the Laserre hierarchy). Some researchers suspect that, if any algorithm will solve the unique games problem in polynomial time (or close to that), it will be Sum-of-Squares; conversely, if one could show that Sum-of-Squares failed, one wouldve taken a major step toward proving the UGC.
For more, I recommend this Quanta magazine article, or Luca Trevisans survey, or Subhashs own survey. Or those pressed for time can simply check outthis video interview with Subhash. If youd like to try my wife Danas puzzle games inspired by PCP, which Subhash uses 2 minutes into the video to explainwhat he works on, see here. Online, interactive versions of thesepuzzle games are currently under development. Also,if you have questions about the UGC or Subhashs work, go ahead and ask: Ill answer if I can, and otherwise rely on in-house expertise.
Congratulations again to Subhash!Alright, alright, alright (grumble)

If no one else is going to highlight some results from the conference, I guess Ill have to do it myself.  More nuggets coming soon (i.e., as soon as I have my layovers in Auckland and LAX en route to Toronto) Nope, I was too lazy.  Plus I caught a cold on the plane from which Im just now recovering.

Aram Harrow (joint work with Sean Hallgren) generalized the Recursive Fourier Sampling problem of Bernstein and Vazirani, to give superpolynomial quantum black-box speedups based not only on the Fourier transform, but on almost any unitary transformation.
Falk Unger discussed his joint result with Richard Cleve, William Slofstra, and Sarvagya Upadhyay, that if Alice and Bob share unlimited quantum entanglement and are playing n Bell inequality games in parallel, then they might as well just play each game separately (i.e., theres no advantage in correlating their strategies across multiple games).  Surprisingly, this is provably false if Alice and Bob dont share entanglement.
Alexandra Kolla discussed her joint result with Sean Hallgren, Pranab Sen, and Shengyu Zhang, that any classical statistical zero-knowledge protocol can be made secure against quantum attacks.  This generalizes a previous result of John Watrous (STOC06), that certain specific SZK protocols can be made secure against quantum attacks.  Shengyu was supposed to give the talk; Alexandra had to fill in for him on a few days notice since he couldnt get a travel visa.
Troy Lee discussed his new negative-weight adversary method for proving quantum lower bounds (joint work with Peter Hyer and Robert palek), which improves the previous methods of Ambainis, Zhang, and others, and finally breaks through the so-called certificate complexity barrier.  Unfortunately, the new method is so non-intuitive that right now the authors can only apply it with the aid of semidefinite programming solvers.  But this old lowerboundsgeezer is hoping that, once the young uns get a better handle on their new toy, theyll be able to use it to finally demolish some of the old open problems in quantum lower bounds.
Daniel Gottesman proved (joint work with Dorit Aharonov and Julia Kempe) that finding the ground state of a one-dimensional spin chain with nearest-neighbor interactions is already QMA-complete.  Since the analogous classical problem is solvable in polynomial time, it had been conjectured that the quantum version is too, but this intuition turns out to be wrong.
Yi-Kai Liu showed (joint work with Matthias Christandl and Frank Verstraete) that several problems of longstanding interest to chemists are QMA-complete.  These problems include deciding whether a set of local density matrices is compatible with some global density matrix; and the N-representability problem (namely, deciding whether a quantum state of two m-mode fermions is extendible to a state of N m-mode fermions, where m=O(poly(N)).
Francois Le Gall gave an exponential separation between randomized and quantum space complexity in the online setting (that is, the setting where the input bits are fed to an algorithm one at a time, with no possibility of going backward).
Gus Gutoski showed (joint work with John Watrous) that if two omniscient gods are playing a quantum chess game by shuttling qubits back and forth via a polynomial-time intermediary, who will measure the qubits at the end to decide the winner, then its possible in deterministic exponential time to decide which god will win.  Or to say it much more clearly, QRG=EXP.
Iordanis Kerenidis discussed his joint result with Dmitry Gavinsky, Julia Kempe, Ran Raz, and Ronald de Wolf, that there exists a partial Boolean function whose quantum one-way communication complexity is exponentially smaller than its randomized one-way communication complexity.  Previously this was only known for relation problems.
Ike Chuang gave an update on experimental quantum computing.  His talk included a lot of graphs of damped sine curves.
I gave my tired old talk on learnability of quantum states.Who wants to be a summer student?

Lately Ive been getting emails from undergrads with stellar-looking rsums who want to be my summer students.  My initial reaction was: who, me?  Im barely more than a summer student myself!  But today a light bulb went off: hey, if these ambitious whippersnappers really want to do my research for me, why shouldnt I let them do it  thereby freeing up my own time for more important priorities like blogging?
Ive therefore decided to list three project ideas.  If youre an undergrad or grad student who wants to tackle one of them this summer at the University of Waterloo, email me (scott at scottaaronson dot com).  Tell me about yourself and what you want to do, and attach a CV.  Ill pick up to two students.  Deadline: Feb. 21 or until positions are filled.
Scott Aaronson is an equal opportunity employer.  He doesnt have his own funding, so if you can bring your own, great; if not, hell try to scrounge some from under Mike Lazaridiss couch.  If the projects listed below dont interest you  or if youre more interested in physics, engineering, or information theory than in quantum complexity  there are many, many potential supervisors at both the Institute for Quantum Computing and the Perimeter Institute whod probably be a better match for you.
Project #1: The Learnability of Quantum States.  For this project, youd first read and understand my paper of the same name, ideally before the summer started.  Youd then implement my quantum state reconstruction algorithm in Matlab, Mathematica, or any other environment of your choice, and study its performance with realistic physical systems.  This is a crucial first step if experimentalists are ever going to be convinced to try my quantum state learning approach.  (The fact that I proved it works is completely irrelevant to them)  Theres also plenty of scope for new theoretical ideas if you swing that way.  The eventual goal would be to publish the results somewhere like Physical Review Letters.  This project is highly recommended.
Project #2: Multiple Quantum Proofs. Today we believe that there are mathematical truths that you could efficiently verify if given a small quantum state, but that you couldnt efficiently verify if given a short classical string.  But what if you were given two quantum states, which were guaranteed to be unentangled with each other?  Would that let you verify even more truths than you could with a single quantum state?  The answer is, we have no idea!  Nor do we know whether three quantum proofs are more powerful than two, etc.  When it comes to the power of multiple quantum proofs, even the most embarrassingly simple questions are open.  In this project, youd work with me to try and sort out the mess.  This project is only for students who are confident of their ability to do original research in theoretical computer science.
Project #3: Insert Your Own Project.  Wow me.  Dazzle me.  Give me a specific, detailed idea for a research project in quantum complexity theory or a related area, and convince me that youre ferocious enough to get somewhere with it in one summer.  Ill try to help where I can.A quiver springs his voice and breast

The March 2007 issue of Notices of the American Mathematical Society is out.  In it we find:

Fascinating conversations with three of the four Fields medalists (guess which one declined to be interviewed?)
An obituary of George Dantzig (linear programming pioneer), which I found incredibly frustrating for two reasons.  First, the article repeatedly sidesteps the most interesting questions about Dantzigs career: what were those open problems that he solved mistaking them for homework exercises?  What impact did his WWII work actually have?  Second, just as nothing in biology makes sense except in the light of evolution, so nothing in optimization makes sense except in the light of computational complexity  a topic this 19-page article somehow assiduously avoids.
A poem by Bill Parry (1934-2006), which stirred my soul as Walt Whitman never did back in 11th-grade English, and which I here reproduce in its entirety.

Argument
As he cleaned the board,
chalk-dust rose like parched mist.
A dry profession, he mused as morosely
they shuffled settling tier upon tier.
Now, almost half-way through the course,
(coughs, yawns, and automatic writing)
the theorem is ready.
Moving to the crucial point,
the sly unconventional twist,
a quiver springs his voice and breast;
soon the gambit will appear
opposed to whats expected.
The ploy will snip one strand
the entire skein sloughing to the ground.
His head turns sympathetically
from board to class.
They copy copiously.
But two, perhaps three pause and frown,
wonder will this go through,
questioning this entanglement
 yet they nod encouragement.
Then the final crux; the ropes relax and fall.
His reward: two smile, maybe three,
and one is visibly moved.
Q.E.D., the theorem is proved.
This was his sole intent.
Leaving the symbols on the board
he departs with a swagger of achievement.Do theoretical computer scientists despise practitioners?  (Answer: no, thats crazy)

A roboticist and Shtetl-Optimized fan named Jon Groff recently emailed me the following suggestion for a blog entry:
I think a great idea for an entry would be the way that in fields like particle physics the theoreticians and experimentalists get along quite well but in computer science and robotics in particular there seems to be a great disdain for the people that actually do things from the people that like to think about them. Just thought Id toss that out there in case you are looking for some subject matter.
After I replied (among other things,raising my virtual eyebrows over his rosyview of the current state of theoretician/experimentalist interaction in particle physics),Jonelaborated on his concerns in a subsequent email:
[T]here seems to be this attitude in CS that getting your hands dirty is unacceptable. You havent seen it because you sit a lofty heights and I tend to think you always have. I have been pounding out code since ferrite cores. Yes, Honeywell 1648A, so I have been looking up the posterior of this issue rather than from the forehead as it were. I guess my challenge would be to find a noteworthy computer theoretician somewhere and ask him:1) What complete, working, currently functioning systems have you designed?2) How much of the working code did you contribute?3) Which of these systems is still operational and in what capacity?
Or say, if the person was a famous robotics professor or something you may ask:
1) Have you ever actually built a robot?
2) Could you, if called upon, design and build an easily tasked robot safe for home use using currently available materials and code?
So I wrote a second reply, which Jon encouraged me to turninto a blog post (kindly givingme permission to quote him). In case its of interest to anyone else, my reply is below.

Dear Jon,
For whatever its worth, when I was an undergrad, I spent two years working as a coderfor Cornells RoboCup robot soccer team, handling things like thegoalie. (That was an extremely valuable experience, one reason beingthat it taught me how badly I sucked at meeting deadlines, documentingmy code, and getting my code to work with other peoples code.)  Evenbefore that, I wrote shareware games with my friend Alex Halderman(now a famous computer security expert at U. of Michigan); we made almost$30 selling them. And I spent several summers working on appliedprojects at Bell Labs, back when that was still a thing. And by mycount, Ive written four papers that involved code I personally wrote andexperiments I did (one on hypertext, one on stylometric clustering,one on Boolean function query properties, one on improved simulationof stabilizer circuitsfor the last of these, the code is actually still used by others). While this is all from the period 1994-2004 (these days, if I need anycoding done, I use the extremely high-level programming language calledundergrad), I dont think its entirely trueto say that I never got myhands dirty.
But even if I hadnt had any of those experiences, or other theoretical computer scientists hadnt had analogous ones, your questionsstill strike me as unfair. Theyre no more fair than cornering a starcoder or other practical person with questions like, Have you everproved a theorem? A nontrivial theorem? Why is BPP contained inP/poly? Whats the cardinality of the set of Turing-degrees? If thecoder cant easily answer these questions, would you say it means that shehas disdain for theorists? (I was expecting some discussion of thisconverse question in your email, and was amused when I didnt findany.)
Personally, Id say of course not: maybe the coder is great atcoding, doesnt need theory very much on a day-to-day basis anddoesnt have much free time to learn it, but (all else equal) would behappy to know more. Maybe the coder likes theory as an outsider, evenhas friends from her student days who are theorists, and whoshed go to if she ever did need their knowledge for her work. Ormaybe not. Maybe shes an asshole who looks down on anyone whodoesnt have the exact same skill-set that she does. But Icertainly couldnt conclude that from her inability to answer basictheory questions.
Id say just the sameabout theorists. If they dont have as muchexperience building robots as they should have, dont know as muchabout large software projects as they should know, etc., then thoseare all defects to add to the long list of their other, unrelateddefects. But it would be a mistake to assume that they failed toacquire this knowledge because of disdain for practical people,rather than for mundane reasons like busyness or laziness.
Indeed, its also possible that they respect practical people allthe more, because they tried to do the things the practical people aregood at, and discovered for themselves how hard they were. Maybe theybecame theorists partly because of that self-discoverythat wascertainly true in my case. Maybe theyd be happy to talk to or learnfrom a practical roboticist like yourself, but are too shy or toonerdy to initiate the conversation.
Speaking of which: yes, lets let bloom a thousand collaborationsbetween theorists and practitioners! Those are the lifeblood ofscience. On the other hand, based on personal experience, Im alsosensitive to the effect where, because of pressures from fundingagencies, theorists have to try to pretend their work ispractically relevant when theyre really just trying to discover somethingcool, while meantime, practitioners have to pretend their work istheoretically novel or deep, when really, theyre just trying to writesoftware that people will want to use. Id love to seeboth groups freed from this distorting influence, so that they cancollaborate for real reasons rather than fake ones.
(Ive also often remarked that, if I hadnt gravitated to theextreme theoretical end of computer science, I think I might have gone instead tothe extreme practical end, rather than to any of the points inbetween. Thats because I hate the above-mentioneddistorting influence: if Im going to try to understand the ultimatelimits of computation, then I should pursue that wherever it leads, even if itmeans studying computational models that wont be practical for amillion years. And conversely, if Im going to write useful software,I should throw myself 100% into that, even if it means picking anapproach thats well-understood, clunky, and reliable over an approachthats new, interesting, elegant, and likely to fail.)
Best,
ScottRaise a martini glass for Google and Martinis!

Weve already been discussing this in the commentssectionof my previous post, but a fewpeople emailed me to ask when Id devote a separateblog post to the news.
OK,so for those who havent yet heard: this week Googles Quantum AI Lab announced that its teaming up with John Martinis, of the University of California, Santa Barbara, to accelerate the Martinis groups already-amazing efforts in superconducting quantum computing. (Seehere for the MIT Techs article, here for Wireds, and here for theWSJs.) Besides building some ofthe best (if not the best) superconducting qubits in the world, Martinis, along with Matthias Troyer, was also one of the coauthors of twoimportant papers that found no evidence for any speedup in the D-Wave machines. (However,in addition to working with the Martinis group, Google says it will alsocontinue its partnership with D-Wave, in an apparent effortto keep reality more soap-operatically interesting than any hypothetical scenario one could make up on a blog.)
I have the great honor of knowingJohn Martinis, even once sharing the stage with him at a Physics Cafe in Aspen. Like everyone else in ourfield, I profoundly admire the accomplishments of his group: theyve achieved coherence times in the tens of microseconds, demonstrated some of the building blocks of quantum error-correction, andgotten tantalizingly close to the fault-tolerance threshold for the surface code. (When, in D-Wave threads, people have challengedme: OK Scott, so then which experimental quantum computinggroupsshouldbe supported more?, my answer has always been some variant of: groups like John Martiniss.)
So Im excited about this partnership, and I wish it the very best.
But I know people will ask: apart from the support and well-wishes, do I have any predictions? Alright, heres one. I predict that, regardless of what happens,commenters here will somehow make it out that I was wrong. So for example, if the Martinis group, supportedby Google, ultimately succeeds in building a useful, scalable quantum computerby emphasizing error-correction, long coherence times (measured in the conventional way), gate-model quantum algorithms, universality, and all the other things that D-Wave founder Geordie Rose has pooh-poohed from the beginningcommenters will claimthat still most of the credit belongs to D-Wave, for whetting Googles appetite, and for getting it involved insuperconducting QC in the first place. (The unstated implication being that, even if there were little or no evidencethat D-Waves approach would ever lead to a genuine speedup, we skeptics still wouldve been wrong to state that truthin public.) Conversely, if this venturedoesnt live up to theinitialhopes, commenters will claimthat that just proves Googles mistake: rather than selling out to appease the ivory-towerskeptics, they shouldve doubled down on D-Wave. Even if something completely different happenslets say, Google, UCSB, and D-Wave jointly abandon their quantum computing ambitions, and instead partner with ISIS to establish the worlds first Qualiphate, ruling with a niobium fist over California and parts of OregonI wouldve been wrong for having failed to foresee that. (Even if Ididsort of foresee it in the last sentence)
Yet, while Ill never live to see the blog-commentariat acknowledge the fundamental reasonableness of my views, I might live to see scalable quantum computers become a reality, and that would surelybe someconsolation. For that reason, even if for no others, I once again wish the Martinis group and Googles Quantum AI Lab the best in their new partnership.

Unrelated Announcement: Check out a lovely (very basic) introductory video on quantum computing and information, narrated by John Preskill and Spiros Michalakis, and illustrated by Jorge Cham of PhD Comics.The Orion Quantum Computer Anti-Hype FAQ

Grudgingly offered for your reading pleasure, and in the vain hope of forestalling further questions.
Q: Thanks to D-Wave Systems  a startup company thats been in the news lately for its soon-to-be-unveiled Orion quantum computer  is humanity now on the verge of being able to solve NP-complete problems in polynomial time?
A: No.  Were also not on the verge of being able to build perpetual-motion machines or travel faster than light.
Q: But couldnt quantum computers try all possible solutions in parallel, and thereby solve NP-complete problems in a heartbeat?
A: Yes, if the heart in question was beating exponentially slowly.
Otherwise, no.  Contrary to widespread misconception, a quantum computer could not try all possible solutions in parallel in the sense most people mean by this.  In particular, while quantum computers would apparently provide dramatic speedups for a few structured problems (such as factoring integers and simulating physical systems), its conjectured that they couldnt solve NP-complete problems in polynomial time.
Q: But isnt factoring an NP-complete problem?
A: Good heavens, no!  While factoring is believed to be intractable for classical computers, its not NP-complete, unless some exceedingly unlikely things happen in complexity theory.  Where did you get the idea that factoring was NP-complete?  (Now I know how Richard Dawkins must feel when someone asks him to explain, again, how life could have arisen by chance.)
Q: How could the people at D-Wave not understand that quantum computers couldnt solve NP-complete problems in polynomial time?
A: To his credit, Geordie Rose (the founder of D-Wave) does understand this; see here for example.  And yet, essentially every article Ive read about D-Wave gives readers exactly the opposite impression.  The charitable explanation is that the D-Wave folks are being selectively quoted or misquoted by journalists seeking to out-doofus one another.  If so, one hopes that D-Wave will try harder in the future to avoid misunderstandings.
Q: But even if it gave only polynomial speedups (as opposed to exponential ones), couldnt the adiabatic quantum computer that D-Wave built still be useful for industrial optimization problems?
A: D-Waves current machine is said to have sixteen qubits.  Even assuming it worked perfectly, with no decoherence or error, a sixteen-qubit quantum computer would be about as useful for industrial optimization problems as a roast-beef sandwich.
Q: But even if it wasnt practically useful, wouldnt a 16-qubit superconducting quantum computer still be a major scientific advance?
A: Yes, absolutely.
Q: So, can D-Wave be said to have achieved that goal?
A: As Dave Bacon pointed out earlier, its impossible to answer that question without knowing more about how their machine works.  With sixteen qubits, a working demo doesnt prove anything.  The real questions are: how high are the fidelities, and what are the prospects for scalability?
Q: But clearly D-Wave isnt going to give away its precious trade secrets just to satisfy some niggling academics!  Short of providing technical specifics, what else could they do to make computer scientists take them seriously?
A: Produce the prime factors of
1847699703211741474306835620200164403018549
3386634101714717857749106516967111612498593
3768430543574458561606154457179405222971773
2524660960646946071249623720442022269756756
6873784275623895087646784409332851574965788
4341508847552829818672645133986336493190808
4671990431874381283363502795470282653297802
9349161558118810498449083195450098483937752
2725705257859194499387007369575568843693381
2779613089230392569695253261620823676490316
036551371447913932347169566988069.
Q: Alright, what else could they do?
A: Avoid talking like this:
The system we are currently deploying, which we call Trinity, is a capability-class supercomputer specifically designed to provide extremely rapid and accurate approximate answers to arbitrarily large NP-complete problems  Trinity has a front-end software interface, implemented in a combination of Java and C, that allows a user to easily state any NP-complete problem of interest.  After such a problem has been stated the problem is compiled down to the machine language of the processors at the heart of the machine. These processors then provide an answer, which is shuttled back to the front end and provided to the user.  This capability can of course be called remotely and/or as a subroutine of some other piece of software.
Or to translate: Not only have we built a spaceship capable of reaching Pluto in a few hours, our spaceship also has tinted windows and deluxe leather seats!  If I were them, Id focus more on the evidence for their core technological claims, given that those claims are very much whats at issue.
Q: While Dave Bacon also expressed serious doubts about the Orion quantum computer, he seemed more enthusiastic than you are.  Why?
A: Generous and optimistic by nature, Dave strives to give others the benefit of the doubt (as the Chinese restaurant placemat would put it).  Furthermore, as Quantum Pontiff, hes professionally obligated to love the quantum sinner and forgive the wayward quantum sheep.  And these are all wonderful qualities to have.  On the other hand, when the hype surrounding some topic crosses a certain threshold, arguably a pricklier approach becomes called for.
Q: If D-Wave fizzles out, will many journalists and policymakers then conclude that quantum computing is bunk?
A: It doesnt seem unlikely.
Q: What would it take to get these people to recognize the most elementary distinctions?
A: Thats the question, isnt it?
Update (2/13): Lawrence Ip, my friend from Berkeley who now works at Google, went to the D-Wave launch in person and kindly provided the following report.
I just came back from the D-Wave announcement. Unfortunately I had to leave at the start of the Q&A session.
Heres what I took away from it (minus the marketing fluff):
 They claim to solve integer programming problems on their system. Geordie Rose was careful to explicitly say that they are only hoping to see a quadratic speedup. Herb Martin (the CEO) wasnt quite as careful in his opening remarks but then hes the suit. Geordie said that their current chip is not a universal QC (presumably because their space of Hamiltonians is limited) but with some work they expect to be able to make it universal.
 Geordie said compared their approach to the efforts in academia as similar to Celera and the Human Genome Project. He said they were trying to get something that would scale fast and worry about about the quality of the qubits later. He contrasted this to the academic communitys efforts to achieve fine control over qubits before scaling up. They say that they hope to reach 1024 qubits by the end of 2008.
 They demoed 3 real-world problems where they used their system as essentially a blackbox IP solver.
 Searching for protein matches. Given a protein try to find the closest match in a protein database. They serially fed all the items from the database to the chip and asked it to score the match against the given protein. They said it was solving a maximum independent set problem.
 Finding the best seating arrangement at a wedding reception. Given constraints on which people cant be seated together and who wants to sit together, find the optimal arrangement.
 Solving a Sudoku puzzle.
 At one point Geordie quoted you. He excerpted a paragraph from your SIGACT article (the one where you talk about generating Shakespeares 38th play) and mentioned your proposal of the inability to solve NP-hard problems as a physical law. As far as I can remember, the only other computer scientist he quoted was Gordon Moore so youre in good company.Chicken soup for the frequent flyers soul

Some of you might have read about how flight attendants at AirTran kicked a 3-year-old screaming brat and her parents off a plane, after the brat had already delayed takeoff for 15 minutes by refusing to get in her seat, and the parents had demonstrated their total unwillingness to control her.  The parents went to the media expecting sympathy; instead, AirTran was immediately deluged with messages of support and people vowing to fly them from then on. Unfortunately, the airline then squandered a PR bonanza by apologizing profusely to the parents and refunding their tickets.  In my opinion, there was no need to kick anyone off the plane: the child and parents shouldve been promptly moved to the luggage compartment, then whipped and beaten upon arrival.A prophet will arise

At last nights FOCS business meeting, there was a panel discussion on how to get the public excited about theoretical computer science. Unfortunately I missed it  Im skipping FOCS for the first time in years  so Im grateful to Rocco Servedio for this post about the discussion and to Dave Bacon for this one.
The obvious question is, why has there been so little success at popularizing theoretical computer science? Here Id like to propose an answer to this question: because no one in  human history has ever successfully popularized any field of science.
But thats absurd! you interject. What about Stephen Hawking, or Richard Dawkins, or Carl Sagan, or Richard Feynman, or Isaac Asimov, or Bertrand Russell?
My response is simple.  These people are not popularizers.  They are prophets.
Like Moses descending from Sinai, the scientific prophet emerges from the clouds of Platonic heaven with a vision for the huddled throng below: that yea, though our lives may be fleeting and our bodies frail, through reason we shall know the mind of God. We are apes with telescopes, star-stuff pondering the stars.
Often, as in the cases of Hawking and Feynman, the prophets own life is central to the vision. The prophet teaches by example, showing us that no physical impediment is too great to overcome, that the world is full of solvable mysteries, that Nature cannot be fooled.
The prophet does not confine himself to his area of expertise, any more than Moses limited himself to shepherding regulations or Jesus to carpentry tips. He draws on his field for illustration, to be sure, but his real interest is life itself. He never hesitates to philosophize or moralize, even if only to tell his listeners that philosophers and moralists are idiots.
The scientific prophet presents humanity with a choice: will we persist in our petty squabbles and infantile delusions, Neanderthals with computers and ICBMs? Or will we create a better world, one worthy of reasoning beings?
Even when the prophet exhorts us to reason, skepticism, and empiricism, he does so by hijacking a delivery system that is thousands of years old. And that is why he succeeds.
Theoretical computer science will capture the publics imagination when, and only when, it produces a prophet.Steven Pinkers inflammatory proposal: universities should prioritize academics

If you havent yet, I urge you to read Steven Pinkers brilliant piece in The New Republic about whats broken with Americas elite colleges and how to fix it. The piece starts out as an evisceration of an earlier New Republic article on the same subjectby William Deresiewicz. Pinker agrees with Deresiewiczthat something is wrong, but finds Deresiewiczs diagnosis of whatto be lacking. The rest of Pinkers article sets out his own vision, which involves Americastop universities taking the radical step of focusing on academics, and returning extracurricular activities likesports to their rightful place asextras: ways for students to unwind, rather than a universitys primary reason for existing, or a centralcriterion for undergraduate admissions. Most controversially, this would mean that theadmissions process at US universities would becomemore like that in virtuallyevery other advanced country: a relatively-straightforward matter of academic performance, rather than an exercise inpeering into theapplicants souls to find outwhether they have a specialje ne sais quoi, and the students (and their parents) desperately gaming the intentionally-opaque system, by paying consultants tens of thousands of dollars to develop souls for them.
(Incidentally, readers who havent experienced itfirsthandmight not be able tounderstand, or believe,just how strangethe undergraduate admissions process in the US has become, although Pinkers anecdotes give someidea. I imagine anthropologists centuriesfrom now studying American elite universityadmissions, and the parenting practices that have grown up around them, alongside cannibalism, kamikaze piloting,and otherhistorical extremes of the human condition.)
Pinker points out that a way toassess students ability to do college courseworkmuchmore quickly and accurately than by relying on the soul-detecting skillsof admissions officershas existed for a century. Its called the standardized test. Butunlike in the rest of the world (even in ultraliberal Western Europe), standardized tests are politicallytoxicin the US,seenas instrumentsof racism, classism, and oppression. Pinker reminds us of the immenseirony here: standardized testswere inventedas a radicaldemocratizing tool, as a way to give kids from poor and immigrant families the chanceto attend colleges that had previously only been open to the children of the elite. They succeeded at that goaltoo well for somepeoples comfort.
We now know that the Ivies current emphasis on sports, character, well-roundedness, and geographic diversity in undergraduate admissions wasconsciously designed(read that again) in the 1920s, by the presidents of Harvard, Princeton, and Yale, as a tacticto limit the enrollment of Jews. Nowadays, of course, the Ivies holistic admissions process no longer fulfills thatoriginal purpose, in part becauseAmerican Jews learned to play the well-roundedness game as well as anyone, shuttling their teenage kids between sports, band practice, and faux charity work, whilehiring professionals to ghostwrite application essays that speak searinglyfrom the heart. Today, a majoreffect of holistic admissionsis instead tolimitthe enrollment of Asian-Americans (especially recent immigrants), who tend disproportionately to have superbSAT scores, but to be deficient in lifesmore meaningfuldimensions,such as lacrosse,student government, and marching band. More generallyagain, pause to wallow inthe ironyour progressiveadmissions process works strongly in favor of the upper-middle-class families who knowhow to navigate it, and against the poor and working-class families who dont.
Defenders of the status quo have missed this reality on the ground, it seems to me, because theyre obsessed with the notionthatstandardized tests are reductive: that is, that they reduce a human being to a number. Arent there geniuses who bombstandardized tests, they ask, as well as unimaginative grinds who ace them? And if you make test scores a majorfactor in admissions, then wont students and teachers train for thetests, and wont that pervert open-ended intellectual curiosity? The answer to both questions, I think, is clearlyyes. But the status-quo-defenders never seem to take the next step, of examiningthe alternativesto standardized testing,to seewhethertheyre even worse.
Id saythe truth is this: spots at the top universities are so coveted, and so much rarer than the demand, that no matter what you use as youradmissions criterion, that thing willinstantlyget fetishized and turnedinto a commodity by students, parents, and companieseager to profit from their anxiety. If its grades, youll get a grades fetish; if sports, youll get a sportsfetish; if community involvement, youll get soup kitchenssproutingupfor the sole purpose of giving ambitious 17-year-olds something to write about in their applicationessays. If Harvard and Princeton announcedthatfrom now on, they only wanted the most laid-back, unambitious kids, the ones who spent their summers lazily skipping stones in a lake, rather than organizingtheir wholelives around getting in to Harvard and Princeton, tens of thousands ofparents in the New York metropolitan area would immediately enrolltheir kids in relaxation and stone-skipping prep courses. So, given that reality, why not at least make the fetishized criteriononethats uniform, explicit, predictively valid, relatively hard to game, and relevant to universities core intellectual mission?
(Here, Im ignoring criticisms specific to the SAT: for example, that it fails to differentiate students at the extreme right end of the bell curve, thereby forcing the top schoolsto useother criteria. Even if those criticisms are true, they could easilybe fixed by switching to other tests.)
I admit that my views on this mattermight becolored by my strange (though as Ive learned, not at allunique) experience, of gettingrejected from almostevery top collegein the United States, and then, ten years later, gettingrecruited forfaculty jobsby thevery same institutions that had rejected me as a teenager. Once you understand how undergraduate admissions work, the rejections wereunsurprising: I was a 15-year-old with perfect SATs and a published research paper, but not only was I young and immature, with spotty grades and a weirdacademic trajectory, I had no sports, no music, no diverse leadership experiences. I was a narrow, linear, A-to-B thinker who lacked depth and emotional intelligence: the exact opposite of what Harvard and Princeton were looking for in every way. The realmiracle is that despite these massive strikes against me, two schoolsCornell and Carnegie Mellonwere niceenough to give me a chance. (I ended up going to Cornell, where I got a great education.)
Some people would say: so then whats the big deal? If Harvardor MITreject some students that maybe they should have admitted,those students will simply go elsewhere, whereif theyre reallythat goodtheyll do every bitas well as theywouldve done at the so-called top schools. But to me, thatsuncomfortably closetosaying: there are millions of people who goon to succeed in life despite childhoods of neglect and poverty. Indeed, some of those people succeed partlybecause of their rough childhoods, which served as the crucibles of theircharacter and resolve. Ergo,letsneglect our ownchildren, so that they too can have the privilege of learning from the school of hard knocks justlike we did. The fact that manypeople turn out fine despite unfairness and adversity doesnt mean that we shouldinflict unfairness if we can avoid it.
Let me end with an important clarification. Am I saying that, if I had dictatorial control over a university (ha!), I would base undergraduate admissions solely on standardized test scores? Actually, no. Heres what I would do: I would admit the majority of students mostlybased ontest scores. A minority, I would admit because of something special about them that wasnt captured bytest scores,whether that something was musical or artistic talent, volunteer work in Africa, a bestselling smartphone app theyd written, a childhood as an orphaned war refugee, or membership in an underrepresented minority. Crucially, though, the special something would needtobe special. What I wouldnt do is whats done today: namely, to turn specialness and well-roundedness into commodities that the great mass of applicants have to manufacture before they caneven be considered.
Other than that, I would barely look at high-school grades, regarding them as too variable from one school to another. And, while concedingit might be impossible, I would try hard to keep my university in good enough financial shape that it didnt need any legacy or development admits at all.

Update (Sep. 14): For those who feel Im exaggerating the situation, please read the story of commenter Jon, about a homeschooled 15-year-old doing graduate-level work in math who, three years ago, was refused undergraduate admission to both Berkeley and Caltech, with the math faculty powerless to influence the admissions officers.  See also my response.Mistake of the Week: Belief is King

A couple days ago the Times ran a much-debated story about Marcus S. Ross, a young-earth creationist who completed a PhD in geosciences at the University of Rhode Island.  Apparently his thesis was a perfectly-legitimate study of marine reptiles that (as he writes in the thesis) went extinct 65 million years ago.  Ross merely disavows the entire materialistic paradigm of which his thesis is a part.
If you want some long, acrimonious flamewars about whether the guys PhD should be revoked, whether oral exams should now include declarations of (non)faith, whether Ross is a walking illustration of Searles Chinese Room experiment, etc., try here and here. Alas, most of the commentary strikes me as missing a key point: that to give a degree to a bozo like this, provided he indeed did the work, can only reflect credit on the scientific enterprise.  Will Ross now hit the creationist lecture circuit, trumpeting his infidel credentials to the skies?  You better believe it.  Will he use the legitimacy conferred by his degree to fight against everything the degree stands for?  It cant be doubted.
But heres the wonderful thing about science: unlike the other side, we dont need loyalty oaths in order to function. We dont need to peer into peoples souls to see if they truly believe (A or not(A)), or just assume it for practical purposes.  We have enough trouble getting people to understand our ideas  if they also assent to them, thats just an added bonus.
In his Dialogue Concerning the Two Chief World Systems, Galileo had his Salviati character carefully demolish the arguments for Ptolemaic astronomy  only to concede, in the final pages, that Ptolemaic astronomy must obviously be true anyway, since the church said it was true.  Mr. G, of course, was just trying to cover his ass.  The point, though, is that his ploy didnt work: the church understood as well as he did that the evidence mattered more than the conclusions, and therefore wisely arrested him.  (I say wisely because the church was, of course, entirely correct to worry that a scientific revolution would erode its temporal power.)
To say that science is about backing up your claims with evidence doesnt go far enough  it would be better to say that the evidence is the claim.  So for example, if you happen to prove the Riemann Hypothesis, youre more than welcome to believe the Hypothesis is nevertheless false, just as youre welcome to write up your proof in encrusted boogers or lecture about it wearing a live gerbil as a hat.  Indeed, you could do all these things and still not be the weirdest person to have solved a Clay Millennium Problem.  Believing your proof works can certainly encourage other people to read it, but strictly speaking is no more necessary than the little QED box at the end.
The reason Im harping on this is that, in my experience, laypeople consistently overestimate the role of belief in science.    Thus the questions I constantly get asked: do I believe the many-worlds interpretation?  Do I believe the anthropic principle?  Do I believe string theory?  Do I believe useful quantum computers will be built?  Never what are the arguments for and against: always what do I believe?
To explain why belief questions often leave me cold, I cant do better than to quote the great Rabbi Sagan.
Im frequently asked, Do you believe theres extraterrestrial intelligence?  I give the standard arguments  there are a lot of places out there, the molecules of life are everywhere, I use the word billions, and so on.  Then I say it would be astonishing to me if there werent extraterrestrial intelligence, but of course there is as yet no compelling evidence for it.
Often, Im asked next, What do you really think?
I say, I just told you what I really think.
Yes, but whats your gut feeling?
But I try not to think with my gut.  If Im serious about understanding the world, thinking with anything besides my brain, as tempting as that might be, is likely to get me into trouble.
In my view, science is fundamentally not about beliefs: its about results.  Beliefs are relevant mostly as the heuristics that lead to results.  So for example, it matters that David Deutsch believes the many-worlds interpretation because thats what led him to quantum computing.  It matters that Ed Witten believes string theory because thats what led him to  well, all the mindblowing stuff it led him to.  My beef with quantum computing skeptics has never been that their beliefs are false; rather, its that their beliefs almost never seem to lead them to new results.
I hope nobody reading this will mistake me for a woo-woo, wishy-washy, Kuhn-wielding epistemic terrorist.   (Some kind of intellectual terrorist, sure, but not that kind.) Regular readers of this blog will aver that I do have beliefs, and plenty of them. In particular, I dont merely believe evolution is good science; I also believe its true. But as Richard Dawkins has pointed out, the reason evolution is good science is not that its true, but rather that it does nontrivial explanatory work.  Even supposing creationism were true, it would still be too boring to qualify as science  as even certain creationists hunting for a thesis topic seem to agree.
Or anyway, thats what I believe.Speaking Truth to Parallelism: The Book

A few months ago,I signed a contract with MIT Press to publish a new book: an edited anthology of selected posts from this blog, along with all-new updates and commentary. The books tentative title (open to better suggestions) is Speaking Truth to Parallelism: Dispatches from the Frontier of Quantum Computing Theory. The new book should be more broadly accessible than Quantum Computing Since Democritus, although still far fromyour typicalpop-sciencebook. My goal is to have STTPout by next fall, to coincide withShtetl-Optimizeds tenth anniversary.
If youve been a regularreader, then this book is my way of thanking you for  oops, that doesnt sound right. If it were a gift, I should give it away for free, shouldnt I? So let me rephrase: buying this reasonably-priced book can be your way of thanking me, if youve enjoyed myblog all these years. But it will also (I hope) be a value-added proposition: not only will you be able to put the book on your coffee table to impress an extremely nerdy subset of yourfriends, youll also get exclusive content unavailable on the blog.
To be clear, the posts that make it into the book will beruthlesslyselected: nothing thats pure procrastination, politics, current events, venting, or travelogue, only thechoice filletsthat couldplausibly be claimedto advancethe public understanding of science. Even for those, Ill add additional background material, and take out digsunworthy of a book (making exceptions for anything that reallycracks me up on a second reading).
If I had to pick a unifying theme for the book, Id sigh and then say: its about a certainattitudetowardthe so-called deepest questions, like the nature of quantum mechanicsor the ultimate limits of computation or the mind/body problem or the objectivity of mathematics or whether ouruniverse is a computer simulation. Its an attitude that I wishmorepopular articles managedto get across, and at any rate, thatpeople ought toadoptwhen reading those articles. The attitude combines an openness to extraordinary claims, with an unceasing demand for clarity about the nature of those claims, and an impatience whenever that demand is met with evasion, obfuscation, or a lets notget into technicalities right now. Its an attitude that constantly asks questions like:
OK, so what can you actually do thats different?
Why doesnt that produce an absurd result when applied to simple cases?
Why isnt that just a fancy way of saying what I couldve said in simplerlanguage?
Why couldnt you have achievedthe same thing without your magic ingredient?
So whats your alternative account for how that happens?
Why isnt that obvious?
Whats reallyat stake here?
Whats the catch?
Its an attitude that acceptsthe possibility that suchquestions might have satisfying answersin which case, a changein worldview will be in order. But not before answers are offered, openly debated, and understoodby the community of interested people.
Of all the phrases I use on this blog, I felt Speaking Truth to Parallelism best captured the attitude in question. I coined the phrase back in 2007, when D-Waves claims to be solving Sudoku puzzles with a quantum computerunleashed a tsunami of journalismabout QCswhat they are, how they would work, what they could dothat (in my opinion) perfectlyillustratedhow not to approacha metaphysically-confusing new technology. Having said that, the endless debate around D-Wave wont by any means be the focus of this book: it will surface, of course, but only when it helps to illustrate some broader point.
In planning this book, the trickiest issue was what to do with comments. Ultimately, I decided that the comments make Shtetl-Optimizedwhat it isso for each post I include, Illinclude a briefselection of the most interesting comments, together with my responses to them. My policy will be this: by default, Ill consider any comments on this blog to be fair game for quoting in the book, in whole or in part, andattributed to whatever handle the commenter used. However, if youd like to opt out of having your comments quoted, I now offer you a three-month window in which to do so: just email me, or leave a comment (!) on this thread. You can also request that certain specific comments of yours not be quoted, or that your handle be removed from your comments, or your full name added to themwhatever you want.
Update (9/24): After hearing from several of you, Ive decided on the following modified policy. In all cases where I have an email address, I will contact the commenters about any of their comments that Im thinking of using, to request explicit permission to use them. In the hopefully-rare cases where I cant reach a given commenter, but where their comment raisedwhat seems like a crucial point requiring a response in the book, I might quote from the comment anywaybut in those cases, Ill be careful not to reproducevery long passages, in a way that might run afoul of the fair use exception.Microsoft SVC

By now, the news that Microsoft abruptly closed its Silicon Valley research lableaving dozens of stellar computer scientists joblesshas already been all over the theoretical computer science blogosphere: see, e.g., Lance, Luca, Omer Reingold, Michael Mitzenmacher. I never made a realvisit to Microsoft SVC (only went there once IIRC, for a workshop, while a grad student at Berkeley);now of course I wont have the chance.
The theoretical computer science community, in the Bay Areaand elsewhere, is now mobilizing to offer visiting positions to the refugees from Microsoft SVC, until theyre able to find more permanent employment. I was happy to learn, this week, that MITs theory group will likelyplay a small part in that effort.
Like many others, I confess to bafflement about Microsofts reasons for doing this. Wont the severe damage to MSRs painstakingly-built reputation, to its hiring and retention of the best people, outweigh the comparatively smallamount ofmoney Microsoft will save? Did they at least ask Mr.Gates, to see whether hed chip in the proverbial change under his couch cushions to keep the lab open? Most of all,why the suddenness? Why not wind the lab down over a year, giving thescientists time to applyfor new jobs in the academic hiring cycle? Its not like Microsoft is in a financial crisis, lacking thecash to keep the lights on.
Yet one could also view this announcement as a lesson in why academia exists and is necessary. Yes, one shouldapplaud those companies that choose to invest a portion of their revenue in basic researchlike IBM, the old AT&T, or Microsoft itself (which continues to operate great research outfits in Redmond, Santa Barbara, both Cambridges, Beijing, Bangalore, Munich, Cairo, and Herzliya). And yes, one shouldacknowledge the countless times when academia falls short of its ideals, when it too places the short term above the long. All the same, it seems essential that our civilizationmaintain institutions for which the pursuit and dissemination of knowledge are not just accoutrements forwhen financial times are good and the Board of Directors is sympathetic, but arethe institutions entire reasons for being: thoseactivitiesthat the institution has explicitly committed to support for as long as it exists.Speaking truth to parallelism

Today The Economist put out this paragon of hard-hitting D-Wave journalism.  At first I merely got angry  but then I asked myself what Winston Churchill, Carl Sagan, or Chip n Dales Rescue Rangers would do.  So lets see if The Economist prints the following.
SIR 
In a remarkably uncritical article about D-Waves announcement of the worlds first practical quantum computer (Feb. 15), you gush that [i]n principle, by putting a set of entangled qubits into a suitably tuned magnetic field, the optimal solution to a given NP-complete problem can be found in one shot.  This is simply incorrect.  Today it is accepted that quantum computers could not solve NP-complete problems in a reasonable amount of time.  Indeed, the view of quantum computers as able to try all possible solutions in parallel, and then instantly choose the correct one, is fundamentally mistaken. Since measurement outcomes in quantum mechanics are random, one can only achieve a computational speedup by carefully exploiting the phenomenon known as quantum interference.  And while it is known how to use interference to achieve dramatic speedups for a few problems  such as factorising large integers, and thereby breaking certain cryptographic codes  those problems are much more specialised than the NP-complete problems.
Over the past few days, many news outlets have shown a depressing willingness to reprint D-Waves marketing hype, without even attempting to learn why most quantum computing researchers are sceptical.  I expected better from The Economist.
Scott Aaronson
Institute for Quantum Computing
University of Waterloo
I thought factorising, specialised, and sceptical were a nice touch.
A Final Thought (2/16): As depressing as it is to see a lazy magazine writer, with a single harebrained sentence, cancel out your entire lifes work twenty times over, some good may yet come from this travesty.  Where before I was reticent in the war against ignorant misunderstandings of quantum computing, now I have been radicalized  much as 9/11 radicalized Richard Dawkins in his war against religion. We, the quantum complexity theorists, are far from helpless in this fight.  We, too, can launch a public relations campaign.   We can speak truth to parallelism.  So doofuses of the world: next time you excrete the words NP-complete, solve, and instantaneous anywhere near one another, brace yourselves for a Bennett-Bernstein-Brassard-Blitzirani the likes of which the multiverse has never seen.
Update (2/16): If you read the comments, Geordie Rose responds to me, and I respond to his response.  Also see the comments on my earlier D-Wave post for more entertaining and ongoing debate.Speaking Truth to Parallelism at Cornell

This week I was at my alma mater, Cornell, to give a talk at the 50th anniversary celebration of its computer science department. You can watch the streaming video here; my talk runs from roughly 1:17:30 to 1:56 (though if youve seen other complexity/physics/humor shows by me, this one is pretty similar, except for the riff about Cornell at the beginning).
The other two things in that videoa talk by Tom Henzinger about IST Austria, a bold new basic research institute that he leads, closely modeled after the Weizmann Institute in Israel; and a discussion panel about the future of programming languagesare also really interesting and worth watching. There waslots of other good stuff at this workshop, including a talk about Google Glass and its applications to photography (by, not surprisingly, a guy wearing a Google GlassMarc Levoy); a panel discussion with three Turing Award winners, Juris Hartmanis, John Hopcroft, and Ed Clarke, about the early days of Cornells CS department; a talk by Amit Singhal, Googles director of search; a talk about differential privacy by Cynthia Dwork, one of the leading researchers at the recently-closed Microsoft SVC lab (with a poignant and emotional ending); and a talk by my own lab director at MIT, Daniela Rus, about her research in robotics.
Along with the 50th anniversary celebration, Bill Gates was also on campus to dedicate Bill and Melinda Gates Hall, the new home of Cornells CS department. Click here for streaming video of a Q&A that Gates did with Cornell students, where I thought heacquitted himself quitewell, saying many sensible things about education, the developing world, etc. that other smart people could also say, but that have extragravitas coming from him. Gates has also become extremelyeffective at wrapping barbs of fact inside a soft mesh of politically-unthreatening platitudesbut listen carefully and youll hear the barbs. The amount ofpompand preparation around Gatess visit reminded me of when President Obama visited MIT, befitting the two mens approximatelyequal power. (Obama has nuclear weapons, but then again, he also has Congress.)
And no, I didnt get to meet Gates or shake his hand, though I did get to stand about ten feet from him at the Gates Hall dedication. (He apparently spent most of his time at Cornell meeting with plant breeders, and other people doing things relevant to the Gates Foundations interests.)
Thanks so much to Bobby and Jon Kleinberg, and everyone else who invited me to this fantasticevent and helped make it happen. May Cornells CS department have a great next 50 years.
One last remark before I close this post. Several readershave expressed disapproval and befuddlement over the proposed title of my next book, Speaking Truth to Parallelism. In the words of commenter TonyK:
That has got to be the worst title in the history of publishing! Speaking Truth to Parallelism? It doesnt even make sense! I count myself as one of your fans, Scott, but youre going to have to do better than that if you want anybody else to buy your book. I know you can do better  witness Quantum Computing Since Democritus.
However, my experiences at Cornell this week helped to convince me that, not only does Speaking Truth to Parallelism make perfect sense, its an activity thats needed nowmore than ever. What it means, of course, is fighting a certain nave, long-ago-debunkedviewof quantum computersnamely, that they would achieve exponential speedupsby simply trying every possible answer in parallelthats become so entrenched in the minds of many journalists, laypeople, and even scientists from other fields that it feels like nothing you say canpossibly dislodge it. The words out of your mouth will literally beignored, misheard, or even contorted to the opposite of what they mean, if thats what it takes topreserve the listeners misconception about quantum computers being able to solveNP-hard optimization problems by sheer magic. (Much like in the Simpsons-visit-Australia episode, where Marges request for coffee is misheard over and over as beer.) You probably think Im exaggerating, and Id agree with youif I hadnt experienced this phenomenonhundreds of times overthe last decade.
So, to take one example: after my talk at Cornell, an audience member came up to me to say that it was a wonderful talk, but that what he really wanted to know was whether I thought quantum computers could solve problems in the NP space in linear time, by trying allthe possible solutionsat once. He didnt seem to realize that Id spent the entireprevious half hour answering that exact question, explaining why the answer was no. Coincidentally, this week I also got an email from a longtime reader of this blog, saying that he read and loved Quantum Computing Since Democritus, and wanted my feedback on a popular article hed written about quantum computing. What was the gist of the article? You guessed it: quantum computing = generic exponential speedups for optimization, machine learning, and Big Data problems, by trying all the possible answers at once.
These peoples enthusiasmfor quantum computing tends to be so genuine, so sincere, that I find myself unable to blame themeven when theyve done the equivalent of goingup to Richard Dawkins and thanking him for having taughtthem that evolution works forthe good of the entire species, just as its wise Designer intended. I do blame the media and other careless or unscrupulous parties for misleading people about quantum computing, butmost of all I blame myself, for not making my explanations clear enough. In the end, then, meeting the NP spacefolksonly makes me want to redouble my efforts toSpeak Truth to Parallelism: eventually, I feel, the nerd world will getthis point.

Update (Oct. 4): I had regarded this (perhaps wrongly) as too obvious to state, but particularly for non-native English speakers, Id better clarify: speaking truth to parallelism is a deliberate pun on the left-wing protester phrase speaking truth to power. So whateverlinguistic oddness there is in my phrase, Id say it simply inherits from the original.
Another Update (Oct. 7): See this comment for my short summary of whats known about the actual technical question (can quantum computers solve NP-complete problems in polynomial time, or not?).
Another Update (Oct. 8): Many commenters wrote to point out that the video of my talk at Cornell is now password-protected, and no longer publicly available. I wrote to my contacts at Cornell to askabout this, and they said theyre planning to release lightly-edited versions of thevideos soon, but will look into the matter in the meantime.Bending WordPress to my will

Comment previewing has been enabled.
A new tagline has been added at the top (did you notice it?).
To deal with the single most common question I get asked, Ive added a list of introductory quantum computing links to the sidebar at the right.
The ability to translate into German, Spanish, Dutch, Italian, Japanese, Chinese and several other languages has also been added (Yiddish not yet supported).  In my field tests, the words meatspace, whippersnapper, doofosity, and booger were left untranslated.
Look out for further improvements in the days ahead  including a total-immersion virtual-reality tour of my Waterloo office, and actual writing of blog entries turned over to the RoboShtetl3000.A few quick announcements

I gave a new survey talk at Yale, entitled When Exactly Do Quantum Computers Provide a Speedup? Here are the PowerPoint slides. Thanks so much to Rob Schoelkopf for inviting me, and to everyone else at Yale for an awesome visit.
Aephraim Steinberg asks me to announce that the call for nominations for the 2015 John Stewart Bell Prize is now available.
Ronitt Rubinfeld asks me to remind people that the STOC2015 submission deadline is November 4. Heres the call for papers.
Likewise, Jeff Kinne asks me to remind people that the Complexity2015 submission deadline is November 26. Heres the call for papers.Interstellars dangling wormholes

Update (Nov. 15): A third of my confusions addressed by reading Kip Thornes book!  Details at the bottom of this post.

On SaturdayDana and I sawInterstellar, the sci-fi blockbusterco-produced by the famous theoretical physicist Kip Thorne (who told me about his work on this movie when I met him eight years ago). We had the rareprivilege of seeing the movie on the same day that we got to hang out with a realastronaut,Dan Barry, who flew three shuttle missions and did four spacewalks in the 1990s. (As the end result of a project thatDans roboticist daughter, Jenny Barry, did for mygraduate course on quantum complexity theory, Im now the coauthorwith both Barryson a paper in Physical Review A, about uncomputability in quantum partially-observable Markov decision processes.)
Before talking about the movie, let me say a little about the astronaut. Besides being an inspirational example of someone whos achieved more dreams in life than most of usseeing the curvature of the earth while floating in orbit aroundit, appearing on Survivor, and publishing a Phys. Rev. A paperDan is also a passionate advocate of humanitys colonizing other worlds. When I asked him whether there was any future for humans in space, he answered firmly thatthe only future for humans was in space, and then proceeded to tell me about the technicalviability of getting humansto Mars with limited radiation exposure, the abundant water there, the romantic appeal that would inspire people to sign up for the one-way trip, and the extinction risk for any species confined to a singleplanet. Hearing all this from someone whod actually been to spacegaveInterstellar, with its theme of humans needing to leave Earth to survive (and its subsidiary theme of the death of NASAs manned space program meaning the death of humanity), a specialvividness for me. Granted, I remain skeptical about several points: the feasibilityof a human colony on Mars in the foreseeable future (a self-sufficient human colony on Antarctica, or under the ocean, strike me as plenty hard enough for the next few centuries); whether a space colony, even if feasible, cracks the list of the top twentythings we ought tobe doing to mitigate the risk of human extinction; and whether theres anything more to be learned, at this point in history, by sending humans to space that couldnt be learned a hundred times more cheaply by sending robots. On the other hand, if there is a case for continuing to send humans to space, then Id sayits certainly the case that Dan Barry makes.
OK, but enough about the real-life space traveler: what did I think about the movie? Interstellaris a work of staggering ambition, grappling with someofthegrandestthemes of whichsci-fi is capable: the deterioration of the earths climate; the future of life in the universe;the emotional consequences of extreme relativistic time dilation; whether our survival wouldbeensured by hatching humanembryos in a faraway world, while sacrificing almost all the humans currentlyalive; to what extent humans canplacethe good of thespecies above family and self; the malleability of space and time; the paradoxes of time travel. Its also an imperfect movie, one with many dangling wormholesand unbalancedparentheses that are still generating compile-time errors in my brain. And its full ofstilteddialogue that made me giggleparticularlywhen the characters discussedjumping into a black hole to retrieve itsquantum data. Also, despite Kip Thornes involvement, I didnt find the movies science spectacularlyplausible or coherent(more about that below). On the other hand, if you just wanted a movie that scrupulously obeyed the laws of physics,rather than intelligently probing their implications and limits, you could watch any romantic comedy. So sure, Interstellarmightmake you cringe, but if you likescience fiction at all, then it will also make you ponder, stare awestruck, and argue with friends for days afterwardand enough of the latter to make it more thanworth your while. Just one tip: if youre prone to headaches, do not sit near the front of the theater, especially if youre seeing it in IMAX.
For other science bloggers takes, see John Preskill (who was at a meeting with Steven Spielberg to brainstorm the movie in 2006), Sean Carroll, Clifford Johnson, andPeter Woit.
In the rest of this post, Im going to list the questions about Interstellar that I still dont understandthe answers to (yes, the onesstill not answered by theInterstellar FAQ). No doubt some of theseare answered by Thornes book The Science of Interstellar, which Ive ordered (it hasnt arrived yet), but since myconfusions are more about plot thanscience, Im guessingthat othersare not.
SPOILER ALERT: My questions give away basicallythe entire plotso if youre planning to see the movie, please dont read any further. After youve seen it, though, come back and see if you can help with any of my questions.

1. Whats causing the blight, and the poisoning of the earths atmosphere? The movie is never clear about this. Is it a freak occurrence, or is it human-caused climate change? If the latter, then wouldnt it be worth some effort to try to reverse the damage and salvage the earth, rather than escaping through a wormhole to another galaxy?
2. Whats with the drone? Who sent it? Why are Cooper and Murph able to control it with their laptop? Most important of all, what does it have to do with the rest of the movie?
3. If NASA wanted Cooper that badlyif he was the best pilot theyd ever had and NASAknew itthen why couldnt they just call him up? Why did they have to wait for beings from the fifthdimension to send a coded message to his daughter revealing their coordinates? Once he did show up, did they just kind of decide opportunistically that it would be a good idea to recruit him?
4. What was with Coopers crash in his previousNASA career? If he was their best pilot, how and why did the crash happen? If this was such a defining, traumatic incident in his life, why is it never brought up for the rest of the movie?
5. How is NASA funded in this dystopian future? If official ideology holds that the Apollo missions were faked, and that growing crops is the only thing that matters, then why have the craven politicians been secretly funneling what must be trillions of dollars to ashadow-NASA, over a period of fifty years?
6. Why couldnt NASAhave reconnoitered the planets using robotsespecially since this is a future whereveryimpressive robots exist? Yes, yes, I know, Matt Damon explains in the movie that humans remainmore versatile than robots, because of their survival instinct. But the crew arrives at the planets missing extremely basic information about them, like whether theyre inhospitable to human life because of freezing temperatures or mile-high tidal waves. This is information that robotic probes, even of the sort we have today, could have easily provided.
7. Why are the people who scouted out the 12 planets so limited in the data they can send back? If they can send anything, then why not data that would make Coopers mission completely redundant (excepting, of course, the case of the lying Dr. Mann)? Does the wormhole limit their transmissions to 1 bit per decadeor something?
8. Rather than wasting precious decades waiting for Coopers mission to return, while (presumably)billions of people die of starvation on a fading earth, wouldnt it make more sense for NASA to start colonizing the planets now? They could simplystart trial colonieson allthe planets, even if they think most of the colonies will fail. Yes, this plan involves sacrificing individuals for the greater good of humanity,but NASA is already doing that anyway, with its slower, riskier, stupiderreconnaissance plan. The point becomes even stronger when we remember that, in Professor Brands mind, the only feasible plan is Plan B (the one involving the frozen humanembryos). Frozen embryos are (relatively) cheap: why not just spray them all over the place? And why wait for Plan A to fail before startingthat?
9. The movie involves aplanet, Miller, thats so close to the black hole Gargantua, that every hour spent there corresponds to seven years on earth. There was an amusing exchange on Slate, where Phil Plait made the commonsense point that a planet that deep in a black holes gravity well would presumably get ripped apartby tidal forces. Plait later had to issue an apology, since, in conceivingthis movie, Kip Thorne had made sure that Gargantua was a rapidlyrotatingblack holeand it turns out that the physics of rotating black holes are sufficiently different from those of non-rotating ones to allow such a planet in principle. Alas, this clever explanation still leaves me unsatisfied. Physicists, please help: even if such a planet existed, wouldnt safely landing a spacecraft on it, and getting it out again, requirea staggeringamountof energywell beyond what the humans shown in the movie canproduce? (If they could produce that much acceleration and deceleration, then why couldnt they have traveledfrom Earth to Saturn in days rather than years?) If one could land on Miller and then get off of it using the relatively conventional spacecraft shown in the movie, then the amusing thought suggests itself that one could get factor-of-60,000 computational speedups, free of charge, by simply leaving ones computer in spacewhile one spent some time on the planet. (And indeed, something like that happens in the movie: after Cooper and Anne Hathaway return from Miller, Romillythe character who stayed behindhas had 23 years to think about physics.)
10. Why does Cooper decide to go into the black hole? Surely he could jettison enough weight to escape the black holes gravity by sending his capsuleinto the hole, while he himself sharedAnne Hathaways capsule?
11. Speaking of which, does Cooper go into the black hole? I.e., is the tesseract something he encounters before or after he crosses the event horizon? (Or maybe it should be thought of as at the event horizonlike a friendlier version of the AMPS firewall?)
12. Why is Cooperable to send messages back in timebut only by jostlingbooks around, moving the hands of a watch, and creating patterns of dust in one particular room of one particular house? (Does this have something to do with love and gravity being the only two forces in the universe that transcend space and time?)
13. Why does Cooper desperately send the message STAY to his former self? By this point in the movie, isnt it clear that staying on Earth means the death of all humans, including Murph? If Cooper thought that a message could get throughat all, then why not a message like: go, and go directlyto Edmunds planet, since thats the best one? Also, given that Cooper now exists outside of time, why does he feel suchdesperate urgency? Doesnt he get, like, infinitely many chances?
14. Why is Cooper only able to send quantum data that saves the world to the older Murphthe one who lives when (presumably) billions of people are already dying of starvation? Why cant he send the quantum data back to the 10-year-old Murph, for example? Even if she cant yet understand it, surely she could hand it over to Professor Brand. And even if this plan would be unlikely to succeed: again, Cooper now exists outside of time. So cant he just keep going back to the 10-year-old Murph, rattling those books over and over until the message gets through?
15. What exactly is the quantum data needed for, anyway? I gather it has something to do with building a propulsion system that can get the entire human population out of the earths gravity well ata reasonable cost? (Incidentally, what about all the animals? If the writers of the Old Testament noticed that issue, surely the writers of Interstellar could.)
16. How does Cooper ever make it out of the black hole? (Maybe it was explained and I missed it: once he entered the black hole, things got extremely confusing.) Do the fifth-dimensional beings create a new copy of Cooper outside the black hole? Do they postselect on a branch of the wavefunction where he never entered the black hole in the first place? Does Murph use the quantum data to get him out?
17. At his tearful reunion with the elderly Murph, why is Cooper totallyuninterested in meeting his grandchildren and great-grandchildren, who are in the same room? And why are they uninterested in meeting him? I mean,seeing Murph again has been Coopers overriding motivationduringhis journey across the universe, and has repeatedly been weighed against the survival of the entire human race, including Murph herself. But seeing Murphs kidshis grandkidsisnt even worth five minutes?
18. Speaking of which, when did Murph ever find time to get married and have kids? Since shes such a major character, why dont we learn anything about this?
19. Also, why is Murph an old woman by the time Cooper gets back? Yes, Cooper lost a few decades because of the time dilation on Millers planet. I guess he lost the additional decades while entering and leaving Gargantua? If the five-dimensional beings were able to usetheir time-travel / causality-warping powers to get Cooper out of the black hole, couldnt they have re-synced his clock with Murphs while they were at it?
20. Why does Cooper need to steal a spaceship to get to Anne Hathaways planet? Isnt Murph, like, the one in charge? Cant she order that a spaceship be provided for Cooper?
21. Astute readers will note that I havent yet said anything about the moviescentral paradox, the one that dwarfs all the others. Namely, if humans were going to go extinctwithout a wormhole assist from the humans of the far future, then howwere there any humans in the far future to provide the wormhole assist? And conversely, if the humans of the far future find themselves already existing, then why do they go to the trouble to put the wormhole in their past (which now seems superfluous, except maybe for tidying up the story of their own origins)? The reason I didntask about this is that I realizeits supposed to be paradoxical; were supposed to feelvertigothinkingabout it. (And also, its not entirely unrelated to how PSPACE-complete problems get solved with polynomial resources, in my and John Watrouss paper on computation with closed timelike curves.) My problemis a different one: if the fifth-dimensional, far-future humanshave the power to moldtheir own past to make sure everything turned out OK, then what they actually do seems pathetic compared to what they could do. For example, why dont they send a coded message to the 21st-century humans (similar to the coded messages that Cooper sends to Murph), telling them how to avoid the blight that destroys their crops? Or just telling them that Edmunds planet is the right one to colonize? Like the God of theodicy arguments, do the future humanswant to use their superpowers only to giveus a little boosthere and there, while still leaving us a character-forming struggle? Even if this reticence means that billions of innocent peopleones who had nothing to do with the character-forming strugglewill die horrible deaths? If so, then I dont understand these supposedly transcendently-evolved humans any better than I understand the theodical God.

Anyway, rather than ending on that note of cosmic pessimism, I guessI couldrejoicethat were living throughwhat must be the single biggestmonth in the history of nerd cinemawhat with asci-fi filmco-produced by a great theoretical physicist, aStephen Hawking biopic, and the Alan Turing movie coming out in a few weeks. I havent yet seen the latter two. But it looks like the time might be ripeto pitch my own decades-oldfilmideas, like Radical: The Story of variste Galois.

Update (Nov. 15): I just finished reading Kip Thornes interesting book The Science of Interstellar. Id say that it addresses (doesnt always clear up, but at least addresses) 7 of my 21 confusions: 1, 4, 9, 10, 11, 15, and 19. Briefly:
1. Thorne correctly notes that the movie is vague about whats causing the blight and the change to the earths atmosphere, but he discusses a bunch of possibilities, which are more in the freak disaster than the manmade category.
4. Coopers crash was supposed to have been caused by a gravitational anomaly, as the bulkbeings of the far future were figuring out how to communicate with 21st-century humans. It was another foreshadowing of those bulk beings.
9. Thorne notices the problem of the astronomicalamount of energy needed to safely land on Millers planet and then get off of itgiven that this planet is deep inside thegravity well of the black hole Gargantua, and orbiting Gargantuaat a large fraction of the speed of light. Thorne offersa solution that can only be called creative: namely, while nothing about this was saidin the movie (since Christopher Nolan thought it would confuse people), it turns out that the crew accelerated to relativistic speed and then decelerated using a gravitational slingshot around a second, intermediate-mass black hole, which just happened to be in the vicinity of Gargantua at precisely the right times for this. Thorne again appeals to slingshots around unmentioned but strategically-placed intermediate-mass black holes several more times in the book, to explain other implausible accelerations and decelerations that I hadnt even noticed.
10. Thorne acknowledges that Cooper didnt really need to jump into Gargantua in order to jettison the mass of his body (which is trivial compared to the mass of the spacecraft). Coopers real reason for jumping, he says, was thedesperate hope that he could somehow find the quantum data there needed to save the humans on Earth, and then somehow get it out of the black hole and back to the humans. (This being a movie, it of course turns out that Cooper was right.)
11. Yes, Cooper encounters the tesseract while inside the black hole. Indeed, he hits it while flying into a singularity thats behind the event horizon, but that isnt the black holes main singularityits a different, milder singularity.
15. While this wasnt made clear in the movie, the purpose of the quantum data was indeed to learnhow to manipulate the gravitational anomalies in order to decrease Newtons constant G in the vicinity of the earthdestroying the earth but also allowing all the humans to escape its gravity with the rocket fuel thats available. (Again, nothing said about the poor animals.)
19. Yes, Cooper lost the additional decades while entering Gargantua. (Furthermore, while Thorne doesnt discuss this,I guess he must have lost them only when he was still with Anne Hathaway, not after he separates from her. For otherwise, Anne Hathaway would also be an old woman by the time Cooper reaches her on Edmunds planet, contrary to whats shown in the movie.)The Vazmeister enters the fray

Heres a letter that Umesh Vazirani (my adviser at Berkeley) sent to The Economist, and which he kindly permitted me to share.  Im guessing theyll print this one instead of mine, which is fine by me.
Sir,
Your article Orions belter regarding D-Waves demonstration of a practical quantum computer, sets a new standard for sloppy science journalism.  Most egregious is your assertion that quantum computers can solve NP-complete problems in one shot by exploring exponentially many solutions at once.  This mistaken view was put to rest in the infancy of quantum computation over a decade ago when it was established that the axioms of quantum physics severely restrict the type of information accessible during a measurement. For unstructured search problems like the NP-complete problems this means that there is no exponential speed up but rather at most a quadratic speed up.
Your assertions about D-Wave are equally specious.  A 16 qubit quantum computer has smaller processing power than a cell phone and hardly represents a practical breakthrough. Any claims about D-Waves accomplishments must therefore rest on their ability to increase the number of qubits by a couple of orders of magnitude while maintaining the fragile quantum states of the qubits.  Unfortunately D-Wave, by their own admission, have not tested whether the qubits in their current implementation are in a coherent quantum state. So it is quite a stretch to assert that they have a working quantum computer let alone one that potentially scales. An even bleaker picture emerges when one more closely examines their algorithmic approach. Their claimed speedup over classical algorithms appears to be based on a misunderstanding of a paper my colleagues van Dam, Mosca and I wrote on The power of adiabatic quantum computing.  That speed up unfortunately does not hold in the setting at hand, and therefore D-Waves quantum computer even if it turns out to be a true quantum computer, and even if it can be scaled to thousands of qubits, would likely not be more powerful than a cell phone.
Yours sincerely,
Umesh Vazirani
Roger A. Strauch Professor of Computer Science
Director, Berkeley Quantum Computing Center
Update (2/18): Theres now a Nature news article about D-Wave (hat tip to the Pontiff).  Like pretty much every other article, this one makes no attempt to address the fundamental howlers about the ability of quantum computers to solve NP-complete problems  but at least it quotes me saying that almost every popular article written on this has grotesquely over-hyped it.Der Quantencomputer

Those of you who read German (I dont) mightenjoy a joint interview of me and Seth Lloyd about quantum computing, which was conducted in Seths office by the journalist Christian Meier, and published in the Swiss newspaper Neue Zrcher Zeitung. Even if you dont read German, you can just feed the interview into Google Translate, like I did. While the interview covers ground that will be forehead-bangingly familiar to regular readers of this blog, Im happy with how itturned out; even the slightly-garbled Google Translate output is much better than most quantum computing articles in the English-language press. (And while Christian hoped to provoke spirited debate between me and Seth by interviewing us together, we surprised ourselves by finding very little that we actually disagreed about.) I noticedonlyone error, when Im quoted talking about the discovery of the transistor in the 1960s. I might have said something about the widespread commercialization of transistors (and integrated circuits) in the 1960s, but I know full well that the transistor was invented at Bell Labs in 1947.What does the NSA think of academic cryptographers?  Recently-declassified document provides clues

Brighten Godfrey was one of my officemates when we were grad studentsat Berkeley. Hes now a highly-successful computer networking professor at the University of Illinois Urbana-Champaign, where he studies the wonderfulquestion of howwe could get the latency of the Internet down to the physical limit imposed by the finitenessof the speed of light. (Right now, were away from that limitby a factor of about 50.)
Last week, Brighten brought to my attention a remarkable document: a 1994 issue of CryptoLog, an NSA internal newsletter, which was recently declassified with a few redactions. The most interesting thing in the newsletteris a trip report (pages 12-19 in the newsletter, 15-22 in the PDF file)by an unnamed NSA cryptographer, who attended the 1992 EuroCrypt conference, and who details his opinions onjust about every talk. If youre interested in crypto, you really need to read this thing all the way through, but heres a small sampling of the zingers:

Three of the last four sessions were of no valuewhatever, and indeed there was almost nothing at Eurocryptto interest us (this is good news!). The scholarshipwas actually extremely good; its just that the directionswhich external cryptologic researchers have taken areremarkably far from our own lines of interest.
There were no proposals of cryptosystems, nonovel cryptanalysis of old designs, even very little onhardware design. I really dont see how things couldhave been any better for our purposes. We can hope thatthe absentee cryptologists stayed away because they hadno new ideas, or even that theyve taken an interest inother areas of research.
Alfredo DeSantis spoke on Graph decompositions and secret-sharingschemes, a silly topic which brings joy to combinatoristsand yawns to everyone else.
Perhaps it is beneficialto be attacked, for you can easily augment yourpublication list by offering a modification.
Thisresult has no cryptanalytic application, but it serves toanswer a question which someone with nothing else tothink about might have asked.
I think I have hammered home my point oftenenough that I shall regard it as proved (by emphaticenunciation): the tendency at IACR meetings is for academicscientists (mathematicians, computer scientists,engineers, and philosophers masquerading as theoreticalcomputer scientists) to present commendable researchpapers (in their own areas) which might affect cryptologyat some future time or (more likely) in some otherworld. Naturally this is not anathema to us.
The next four sessions were given over to philosophicalmatters. Complexity theorists are quite happyto define concepts and then to discuss them even thoughthey have no examples of them.
Don Beaver (Penn State), in another era, wouldhave been a spellbinding charismatic preacher; young,dashing (he still wears a pony-tail), self-confident andglib, he has captured from Silvio Micali the leadershipof the philosophic wing of the U.S. East Coast cryptanalyticcommunity.
Those of you who know my prejudice againstthe zero-knowledge wing of the philosophical campwill be surprised to hear that I enjoyed the three talks ofthe session better than any of that ilk that I had previouslyendured. The reason is simple: I took along someinteresting reading material and ignored the speakers.That technique served to advantage again for three moresnoozers, Thursdays digital signature and electroniccash session, but the final session, also on complexitytheory, provided some sensible listening.
But it is refreshing to find acomplexity theory talk which actually addresses animportant problem!
The other two talks again avoided anything ofsubstance. [The authors of one paper]thought it worthwhile,in dealing [with] the general discrete logarithm problem,to prove that the problem is contained in thecomplexity classes NP and co-AM, but is unlikely to bein co-NP.
And Ueli Maurer, again dazzling us with hisbrilliance, felt compelled, in Factoring with an Oracleto arm himself with an Oracle (essentially an OmniscientBeing that complexity theorists like to turn towhen they cant solve a problem) while factoring. Hescalculating the time it would take him (and his Friend)to factor, and would like also to demonstrate his independenceby consulting his Partner as seldom as possible.The next time you find yourself similarly equipped,you will perhaps want to refer to his paper.
The conference again offered an interesting viewinto the thought processes of the worlds leading cryptologists.It is indeed remarkable how far the Agencyhas strayed from the True Path.

Of course, it would be wise not to read too much into this: its not some official NSA policy statement, but the griping of a single, opinionated individual somewhere within the NSA, who was probablybored and tryingto amuse his colleagues. All the same, its a fascinating document, not only for its zingersabout people who are still very much active on the cryptographic scene, but also for its candid insights into what the NSA cares about and why, and for its look into the subculture within cryptography that would lead, years later, to Neal Koblitzs widely-discussed anti-provable-security manifestos.
Reading this document drove home forme that the provable security wars are a very simple matter of the collision of two communities with different intellectual goals, not of one being right and the other being wrong. Heres afunexercise: try reading this trip report while remembering that, in the 1980si.e., the decade immediately preceding the malignedEuroCrypt conferencethe philosophic wing of cryptography that the writer lampoonsactually succeeded in introducing revolutionary concepts (interactive proofs, zero-knowledge, cryptographic pseudorandomness, etc.) that transformedthe field, conceptsthat have now beenrecognized withno fewerthanthree Turing Awards (to Yao, Goldwasser, and Micali). On the other hand, its undoubtedly true that this progress was of no immediate interest to the NSA. On the third hand, the philosophers might reply that helping the NSA wasnt their goal. The best interests of the NSA dont necessarilycoincide with the best interests of scientific advancement(not to mention the best interests of humanitybut thats a separate debate).Kuperbergs parable

Recently, longtime friend-of-the-blog Greg Kuperberg wrote aFacebook post that, with Gregs kind permission, Im sharing here.

A parable about pseudo-skepticism in response to climate science, and science in general.
Doctor: You ought to stop smoking, among other reasons because smoking causes lung cancer.
Patient: Are you sure? I like to smoke. It also creates jobs.
D: Yes, the science is settled.
P: All right, if the science is settled, can you tell me when I will get lung cancer if I continue to smoke?
D: No, of course not, its not that precise.
P: Okay, how many cigarettes can I safely smoke?
D: I cant tell you that, although I wouldnt recommend smoking at all.
P: Do you know that I will get lung cancer at all no matter how much I smoke?
D: No, its a statistical risk. But smoking also causes heart disease.
P: I certainly know smokers with heart disease, but I also know non-smokers with heart disease. Even if I do get heart disease, would you really know that its because I smoke?
D: No, not necessarily; its a statistical effect.
P: If its statistical, then you do know that correlation is not causation, right?
D: Yes, but you can also see the direct effect of smoking on lungs of smokers in autopsies.
P: Some of whom lived a long time, you already admitted.
D: Yes, but there is a lot of research to back this up.
P: Look, Im not a research scientist, Im interested in my case. You have an extended medical record for me with X-rays, CAT scans, blood tests, you name it. You can gather more data about me if you like. Yet youre hedging everything you have to say.
D: Of course, theres always more to learn about the human body. But its a settled recommendation that smoking is bad for you.
P: It sounds like the science is anything but settled. Im not interested in hypothetical recommendations. Why dont you get back to me when you actually know what youre talking about. In the meantime, I will continue to smoke, because as I said, I enjoy it. And by the way, since youre so concerned about my health, I believe in healthy skepticism.A complexity theorists (non)apology

Several respected physicists wrote to me privately to say how disappointed they were that Umesh and I would fight shoddy journalism by making a shoddy claim of our own: namely, that the inability of quantum computers to solve NP-complete problems efficiently is an established fact.  I took a lot of flak in the comments section over the same issue.
Ladies and gentlemen of the jury, I will answer the unjust charges being leveled against me and my advisor.
But first, lets review the facts.  As Ive said in pretty much every introductory talk Ive ever given, obviously we cant yet hope to prove that NP-complete problems are hard for quantum computers, since we havent even proved theyre hard for classical computers!  (Nor, for that matter, do we have any idea how to prove that if theyre hard for classical computers then theyre also hard for quantum computers.)  These are some of the most profound open problems in mathematics.  Solving them could easily take decades or centuries.
I dare say that Umesh and I know this as well as anyone on Earth.  And thats why, even while trying in the space of a few sentences to correct a breathtaking misconception about the nature of the physical world that was being endlessly repeated to millions of people, we still took care in what we said.
Heres Umesh:
Most egregious is your assertion that quantum computers can solve NP-complete problems in one shot by exploring exponentially many solutions at once.  This mistaken view was put to rest in the infancy of quantum computation over a decade ago  For unstructured search problems like the NP-complete problems this means that there is no exponential speed up but rather at most a quadratic speed up.

In the above passage, Umesh is talking about an epochal theorem that he and others did manage to prove: namely, that quantum computers could not solve NP-complete problems by any one-shot method based on exploring exponentially many solutions in parallel.   Throw away the structure of an NP-complete problem  consider it just as an abstract space of 2n solutions  and we know that quantum computers will give you at most a quadratic speedup over classical ones.
In the thirteen years since this BBBV theorem was proved, two interesting things happened:

Various experts dismissed the theorem as irrelevant, knocking down a straw man, stacking the deck in favor of its conclusion by imposing an utterly-unjustified black-box assumption, etc.
Hundreds of articles appeared, in both the popular press and the arXiv, that directly contradicted the theorem.

It reminds me of how theologians chide Richard Dawkins for refuting only a crude, anthropomorphic, straw-man god instead of a sophisticated Einsteinian one, and then (with an air of self-satisfaction) go off and pray to the crude god.
To be fair, we do have one quantum algorithm for NP-complete problems that falls outside the scope of the BBBV theorem: namely, the adiabatic algorithm of Farhi et al.  This algorithm can be seen as a quantum version of simulated annealing.  Intriguingly, Farhi, Goldstone, and Gutmann gave examples where simulated annealing gets stuck at local optima, whereas the adiabatic algorithm tunnels through to the global optimum. On the other hand, van Dam, Mosca, and Vazirani gave other examples where the adiabatic algorithm also gets stuck at local optima, taking exponential time to reach a global optimum.
The upshot is that, if a fast quantum algorithm for NP-complete problems existed, then just like a fast classical algorithm, it would have to be radically different from anything thats yet been imagined.  Because of this  not to mention the civilization-changing consequences that such an algorithm would have  Umesh and I feel strongly that claims to solve NP-complete problems should never be bandied about lightly.  As with perpetual-motion machines or antigravity shields, the burden of proof lies entirely with the would-be inventor.  In case of fire, break glass.  In case of algorithm, break skepticism.
It might be objected that, while the experts know that this is what Umesh meant, laypeople could easily misinterpret his words  or in other words, that Umesh has pulled a D-Wave of his own.    But heres the crucial difference.  Any motivated reader who wanted the real story behind Umeshs three-sentence caricature could find that story in peer-reviewed articles only a Google search away. But with D-Wave, all theyd have to go on is the PR.  Simplifying mathematical subtleties is a right you have to earn, by having the cards in case anyone calls your bluff.
So much for Umeshs letter.  Now lets look at mine:
Today it is accepted that quantum computers could not solve NP-complete problems in a reasonable amount of time. Indeed, the view of quantum computers as able to try all possible solutions in parallel, and then instantly choose the correct one, is fundamentally mistaken.

Notice I didnt say it was proved that quantum computers cant solve NP-complete problems in reasonable time: I said it was accepted.  This, I felt, was a difference few people would have trouble understanding. As an example, if biologists said it was accepted that the Loch Ness monster doesnt exist, presumably no one would interpret that as meaning theyd actually proved its nonexistence.  Indeed, the interesting difference between the two cases is that someday, it might actually be possible to prove the nonexistence of the fast quantum algorithm.
Or are we complexity theorists being too dogmatic?  Should we concede to a certain subset of our physicist friends that, until an actual proof has been discovered, we have no basis even to guess whether P versus NP or NP versus BQP will go one way or the other way?   Should we, in other words, hold ourselves to the same lofty standards of uncompromising mathematical rigor that the physicists themselves have always adhered to?
Oh  pardon me.  I had momentarily forgotten that we were talking about the headmasters of handwaving, the sultans of sloppiness, the princes of proof-by-example. Indeed, I think its fair to say that if physicists had discovered the P versus NP question, they would have immediately declared that PNP  and they would have hailed this discovery of theirs as another remarkable success for physics as a discipline. And everyone else  from other scientists to programmers to journalists to the general public  would have gone right along with it. The task of proving PNP would have been left as a technical detail, to be filled in by the mathematical hairsplitters  just like the task of proving quark confinement, or the ergodicity of particles in a box, or the existence of Yang-Mills theory, or the perturbative finiteness of string theory.
Clearly, the issue here cant be the intelligence of physicists, some of whom actually seem reasonably smart.  The issue, rather, is their different standard  much closer to the standard of everyday life  for saying that they know something is true.  My favorite example in this vein comes from Leonid Levin, who tells me he couldnt convince Richard Feynman that P versus NP was an open problem at all.
I believe Feynman was onto something, in that the only reason P versus NP is called an open problem is that we  the theoretical computer scientists and mathematicians  hold ourselves to a different standard of rigor than any other scientists.  Were we less cautious, we could easily talk about the hardness of NP-complete problems as one of our great discoveries, a discovery for which working out the mathematical underpinnings admittedly remains as a challenge for future generations.
Ironically, our higher standard of rigor often gets turned against us, when outsiders use it to argue that were just guessing, or building castles in the sky, or making conjectures that could all turn out to be wrong. The same charges could obviously be leveled against the central hypotheses of physics or economics or pretty much any other field, but they rarely are  at least not by the same people.
Im tired of double standards, is all Im saying.Lens of Computation on the Sciences

This weekend, the Institute for Advanced Study in Princeton hosted a workshop on theLens of Computation in the Sciences, which was organized by Avi Wigderson, and was meant to showcase theoretical computer sciences imperialistic ambitions to transformevery other field. I was proud to speak at the workshop, representing CS theorys designs on physics. But videos of all four of the talks are now available, and all are worth checking out:

Computational Phenomena in Biology, by Leslie Valiant
Computational Phenomena in Economics, by Tim Roughgarden
Computational Phenomena in Social Science, by Jon Kleinberg
Computational Phenomena in Physics, by me

Unfortunately, the videos were slow to buffer when I last tried it. While youre waiting, you could also check my PowerPoint slides, though they overlap considerably with my previous talks. (As always, if you cant read PowerPoint, then go ask another reader of this blog to convert the file into a format you like.)
Thanks so much to Avi, and everyone else at IAS, for organizing an awesome workshop!PostBQP Postscripts: A Confession of Mathematical Errors

tl;dr: This post reveals two errors in one of my most-cited papers, and also explains how to fix them. Thanks to Piotr Achinger, Michael Cohen, Greg Kuperberg, Ciaran Lee, Ryan ODonnell, Julian Rosen, Will Sawin, Cem Say, and others for their contributions to this post.

If you look at my Wikipedia page, apparently one of the two things in the worldthat Im known for (along with algebrization) is quantum Turing with postselection. By this, Wikipedia means my 2004 definition of the complexity class PostBQPthat is, the class of decision problems solvable in bounded-error quantum polynomial time, assuming the ability to postselect(or condition) on certain measurement outcomesand my proof that PostBQP coincides with the classical complexity PP (that is, the class of decision problems expressible in terms ofwhether the number of inputs that cause a given polynomial-time Turing machine to accept does or doesnt exceed some threshold).
To explain this a bit: even without quantum mechanics, its pretty obvious that, if you couldpostselect on exponentially-unlikely events, then youdgethuge, unrealistic amounts of computational power. For example (and apologies in advance for the macabre imagery), you could solve NP-complete problems in polynomial time by simply guessing a random solution, then checking whether the solution is right, and shooting yourselfif ithappened to be wrong! Conditioned on still being alive (and if you like, appealing to the anthropic principle), you must find yourself having guessed a valid solutionassuming, of course, that there were any valid solutions to be found. If there werent any, then youd seem to be out of luck! (Exercise for the reader: generalize this algorithm, so that it still works even if you dont know in advance whether your NP-complete problem instance has any valid solutions.)
So with the PostBQP=PP theorem, the surprise was not that postselection gives you lots of computational power, but rather that postselection combined with quantum mechanics gives you much more power even than postselection by itself (or quantum mechanics by itself, for that matter). Since PPP=P#P, the class PP basically captures the full difficulty of #P-complete counting problemsthat is, not justsolving an NP-complete problem, but counting how many solutions it has. Its not obvious that a quantum computer with postselection can solve counting problems, but thats what the theorem shows. That, in turn, has implications for other things: for example, I showed it can be used to prove classical factsabout PP, like the fact that PP is closed under intersection (the Beigel-Reingold-Spielman Theorem), in a straightforward way; and its also used to show the hardness of quantum sampling problems, in the work of Bremner-Jozsa-Shepherd as well as my BosonSampling work with Arkhipov.
Im diffident about being known for something so simple; once I had asked the question, the proof of PostBQP=PP took me all of an hour to work out. Yet PostBQP ended up being a hundred times more influential for quantum computing theory than thingson which I expended a thousand times more effort. So on balance, I guess Im happy to call PostBQP my own.
Thats why todays post comes with a special sense of intellectual responsibility. Within the last month, its come to my attention that there are at leasttwoembarrassingoversights in my PostBQP paper from a decade ago, one of them concerning the very definition of PostBQP. I hasten to clarify: once one fixes up the definition, the PostBQP=PP theorem remainsperfectly valid, and all the applications of PostBQP that I mentioned abovefor example, to reproving Beigel-Reingold-Spielman, and to the hardness of quantum sampling problemsgo through justfine. But if you think I have nothing to be embarrassed about: well, read on.

The definitional subtlety came clearly to my attention a few weeks ago, when I was lecturing about PostBQP in my 6.845 Quantum Complexity Theory graduate class. I defined PostBQP as the class of languages L{0,1}* for which there exists a polynomial-time quantum Turing machine M such that, for all inputs x{0,1}*,

M(x) succeeds (determined, say, by measuring its first output qubit in the {|0>,|1>} basis) with nonzero probability.
If xL, then conditioned on M(x) succeeding, M(x) accepts (determined, say, by measuring its second output qubit in the {|0>,|1>} basis) with probability at least 2/3.
If xL, then conditioned on M(x) succeeding, M(x) accepts with probability at most 1/3.

I then had to reassure the students that PostBQP, so defined, was a robust class: that is, that the definition doesnt depend on stupid things like which set of quantum gates we allow. I argued that, even though were postselecting on exponentially-unlikely events, its still OK, because the Solovay-Kitaev Theorem lets us approximate any desired unitary to within exponentially-small error, with only a polynomial increase in the size of our quantum circuit. (Here we actually need the full power of the Solovay-Kitaev Theorem, in contrast to ordinary BQP, where we only need part of the power.)
A student in the class, Michael Cohen, immediately jumped in with a difficulty: what if M(x) succeeded, not with exponentially-small probability, but with doubly-exponentially-small probabilitysay, exp(-2n)? In that case, one could no longer use the Solovay-Kitaev Theorem to show the irrelevance of the gate set. It would no longer even be clear that PostBQPPP, since the PP simulation might not be able to keep track of such tiny probabilities.
Thinking on my feet, I replied that we could presumably choose a set of gatesfor example, gates involving rational numbers onlyfor which doubly-exponentially-small probabilities would neverarise. Or if all else failed, we could simply add to the definition of PostBQP that M(x) had to succeed with probability at least 1/exp(n): after all, that was the only situationI ever cared about anyway, and the only one that ever arose in the applications of PostBQP.
But the question still gnawed atme: was there a problem with my original, unamended definition of PostBQP? If we werent careful in choosing our gate set, could we have cancellations that produced doubly-exponentially-small probabilities? I promised Id think about it more.
By a funny coincidence, just a coupleweeks later, Ciaran Lee, a student at Oxford, emailed me the exact same question. So on a train ride from Princeton to Boston, I decided to think about it for real. It wasnt hard to show that, if the gates involved square roots of rational numbers onlyfor example, if were dealing with the Hadamard and Toffoli gates, or the cos(/8) and CNOT gates, or other standard gate setsthen every measurement outcome has at least 1/exp(n) probability, sotheres no problem with the definition of PostBQP. But I didnt know what might happen with stranger gate sets.
As is my wont these dayswhen parenting, teaching, and so forth leave me with almost no time to concentrate on mathI posted the problem to MathOverflow. Almost immediately, I got incisive responses. First, Piotr Achinger pointed out that, if we allow arbitrary gates, then its easy to get massive cancellations. In more detail, let {an} be extremely-rapidly growing sequence of integers, say with an+1 > exp(an). Then define
$$ \alpha = \sum_{n=1}^{\infty} 0.1^{a_n}. $$
If we write out  in decimal notation, it will consist of mostly 0s, but with 1s spaced further and further apart, like so: 0.1101000000000001000. Now consider a gate setthat involves  as well as 0.1 and -0.1as matrix entries. Given n qubits, its not hard to see that we can set up an interference experiment in which one of the paths leading to a given outcome E has amplitude , and the other paths have amplitudes $$ -(0.1^{a_1}), -(0.1^{a_2}), \ldots, -(0.1^{a_k}), $$ where k is the largest integer such that akn. In that case, the total amplitude of E will be about $$0.1^{a_{k+1}},$$ which for most values of n is doubly-exponentially small in n. Of course, by simply choosing a faster-growing sequence {an}, we can cause an even more severe cancellation.
Furthermore, by modifying the above construction to involve two crazy transcendental numbers  and , I claim that we can set up a PostBQP computation such that deciding what happens is arbitrarily harder than PP (though still computable)say, outside of exponential space, or even triple-exponential space. Moreover, we can do this despite the fact that the first n digits of  and  remain computable in O(n) time. The details are left as an exercise for the interested reader.
Yet even though we can engineer massive cancellations with crazy gates, I still conjectured that nothing would go wrong with normal gates: for example, gates involving algebraic amplitudes only. More formally, I conjectured that any finite set A=(a1,,ak) of algebraic numbers is tame, in the sense that, if p is anydegree-n polynomial with integer coefficients at most exp(n) in absolute value, then p(a1,,ak)0 implies |p(a1,,ak)|1/exp(n). And indeed, Julian Rosen on MathOverflow found an elegant proof of this fact. Ill let you read it over there if youre interested, but briefly, it interprets the amplitude we want as one particular Archimedean valuation of a certain element of a number field, and then lower-bounds the amplitude by considering the product of all Archimedean and non-Archimedean valuations (the latter of which involves the p-adic numbers). Since this was a bit heavy-duty for me, I was grateful when Will Sawin reformulated the proof in linear-algebraic terms that I understood.
And then came the embarrassing part. A few days ago, I was chatting with Greg Kuperberg, the renowned mathematician and author of our climate-change parable. I thought hed be interested in this PostBQP progress, so I mentioned it to him. Delicately, Greg let me know that he had recently proved the exact same results, for the exact same reason (namely, fixing the definition of PostBQP), for the latest revision of his paper How Hard Is It to Approximate the Jones Polynomial?. Moreover, he actually wrote to me in June to tell me about this! At the time, however, I regarded it as pointless mathematical hairsplitting (who cares about these low-level gate-set issues anyway?). So I didnt pay it any attentionand then Id completely forgotten about Gregs work when the question resurfaced a few months later. This is truly a just punishment for looking down on mathematical hairsplitting, and not a lesson Ill soon forget.
Anyway, Gregs paper provides yet a third proof that the algebraic numbers are tame, this one using Galois conjugates (though it turns out that, from a sufficiently refined perspective, Gregs proof is equivalent to the other two).
There remains one obvious open problem here, one that I noted in the MathOverflow post and in which Greg is also extremely interested. Namely, we now know that its possible to screw up PostBQP using gates with amplitudes that are crazy transcendental numbers (closely related to the Liouville numbers). And we also know that, if the gates have algebraic amplitudes, then everything is fine: all events have at least 1/exp(n) probability. But what if the gates have not-so-crazy transcendental amplitudes, like 1/e, or (a bit more realistically) cos(2)? I conjecture that everything is still fine, but the proof techniques that worked for the algebraic case seem useless here.
Stepping back, how great are the consequences of all this for our understanding of PostBQP? Fortunately, I claim that theyre not that great, for the following reason. As Adleman, DeMarrais, and Huang already noted in 1997in the same paper that proved BQPPPwe can screw up the definition even of BQP, let alone PostBQP, using a bizarre enough gate set. For example, suppose we had a gate G that mapped |0> to x|0>+y|1>, where y was a real number whose binary expansion encoded the haltingproblem (for example, y might equal Chaitins ). Then by applying G more and more times, we could learn more and more bits of y, and thereby solve an uncomputable problem in the limit n.
Faced with this observation, most quantum computing experts would say something like: OK, but this is silly! It has no physical relevance, since well never come across a magical gate like Gif only we did! And at any rate, it has nothing to do with quantum computing specifically: even classically, one could imagine a coin that landed heads with probability equal to Chaitins . Therefore, the right way to deal with this is simply to define BQP in such a way as to disallow such absurd gates. And indeed, that is whats done todayusually without even remarking on it.
Now, it turns out that even gates that are perfectly safe for defining BQP, can turn unsafe when it comes to defining PostBQP. To screw up the definition of PostBQP, its not necessary that a gate involve uncomputable (or extremely hard-to-compute) amplitudes: the amplitudes could all be easily computable, but they could still be unsafe because of massive cancellations, as in the example above involving . But one could think of this as a difference of degree, rather than of kind. Its still true that theres a large set of gates, including virtually all the gates anyone has ever cared about in practice (Toffoli, Hadamard, /8, etc. etc.), that are perfectly safe for defining the complexity class; its just that the set is slightly smaller than it was for BQP.

The other issue with the PostBQP=PP paper was discovered by Ryan ODonnell and Cem Say. In Proposition 3 of the paper, I claim that PostBQP = BQPPostBQP||,classical, where the latter is the class of problems solvable by a BQP machine thats allowed to make poly(n) parallel, classical queries to a PostBQP oracle. As Ryan pointed out to me, nothing in my brief argument for this depended on quantum mechanics, so it would equally well show that PostBPP = BPPPostBPP||, where PostBPP (also known as BPPpath) is the classical analogue of PostBQP, and BPPPostBPP||is the class of problems solvable by a BPP machine that can make poly(n) parallel queries to a PostBPP oracle. But BPPPostBPP||clearly contains BPPNP||, which in turn contains AMso we would get AM in PostBPP, and therefore AM in PostBQP=PP. But Vereshchagin gave an oracle relative to which AM is not contained in PP. Since there was no nonrelativizing ingredient anywhere in my argument, the only possible conclusion is that myargument was wrong. (This, incidentally, provides a nice illustration of the value of oracle results.)
In retrospect, its easy to pinpoint what went wrong. If we try to simulate BPPPostBPP||in PostBPP, our random bits will be playing a dual role: in choosing the queries to be submitted to the PostBPP oracle, and in providing the raw material for postselection, in computingthe responses to those queries. But in PostBPP, we only get to postselect once. When we do, the two sets of random bits that wed wantedto keep separate will get hopelessly mixed up, with the postselection acting on the BPP random bits, not just on the PostBPP ones.
How can we fix this problem? Well, when defining the class BQPPostBQP||,classical, suppose we require the queries to the PostBQP oracle to be not only classical, but deterministic: that is, they have to be generated in advance by a P machine, and cant depend on any random bits whatsoever. And suppose we define BPPPostBPP||,classicalsimilarly. In that case, its not hard to see that the equalities BQPPostBQP||,classical= PostBQP and BPPPostBPP||,classical= PostBPP both go through. You dont actually care about this, do you? But Ryan ODonnell and Cem Say did, and thats good enough for me.

I wish I could say that these are the only cases of mistakes recently being found in decade-old papers of mine, but alas, such is not the case. In the near future, my student Adam Bouland, MIT undergrad Mitchell Lee, and Singapores Joe Fitzsimons will post to the arXiv a paper that grew out of an error in my 2005 paper Quantum Computing and Hidden Variables. In that paper, I introduced a hypothetical generalization of the quantum computing model, in which one gets to see the entire trajectory of a hidden variable, rather than just a single measurement outcome. I showed that this generalization would let us solve problems somewhat beyond what we think we can do with a standard quantum computer. In particular, we could solve the collision problem in O(1) queries, efficiently solve Graph Isomorphism (and all other problems in the Statistical Zero-Knowledge class), and search an N-element list in only ~N1/3 steps, rather than the ~N1/2 steps of Grovers search algorithm. That part of the paper remains fine!
On the other hand, at the end of the paper, I also gave a brief argument to show that, even in the hidden-variable model, ~N1/3 steps are required to search an N-element list. But Mitchell Lee and Adam Bouland discovered that that argument is wrong: it fails to account for all the possible ways that an algorithm could exploit the correlations between the hidden variables values at different moments in time.  (Ive previously discussed this error in other blog posts, as well as in the latest edition of Quantum Computing Since Democritus.)
If we suitably restrict the hidden-variable theory, then we can correctly prove a lower bound of ~N1/4, or even (with strong enough assumptions) ~N1/3; and we do that in the forthcoming paper. Even with no restrictions, as far as we know an ~N1/3 lower bound for search with hidden variables remains true. But it now looks like proving it will require a major advance in our understanding of hidden-variable theories: for example, a proof that the Schrdinger theory is robust to small perturbations, which Id given as the main open problem in my 2005 paper.
As if that werent enough, in my 2003 paper Quantum Certificate Complexity,I claimed (as a side remark) that one could get a recursive Boolean function f with an asymptotic gap between the block sensitivity bs(f) and the randomized certificate complexity RC(f). However, two and a half years ago, Avishay Tal discovered that this didnt work, because block sensitivity doesnt behave nicely under composition. (In assuming it did, I was propagating an error introduced earlier by Wegener and Zdori.) More broadly, Avishay showed that there is no recursively-defined Boolean function with an asymptotic gap between bs(f) and RC(f). On the other hand, if we just want some Boolean function with an asymptotic gap between bs(f) and RC(f), then Raghav Kulkarni observed that we can use a non-recursive function introduced by Xiaoming Sun, which yields bs(f)N3/7 and RC(f)N4/7. This is actually a larger separation than the one Id wrongly claimed.
Now that Ive come clean about all these things, hopefully the healing can begin at last.NAND now for something completely different

There was a real breakthrough in quantum algorithms last week  though you wouldnt have known about it from reading Slashdot, Yahoo News, The Economist, or (for that matter) this blog.
Farhi, Goldstone, and Gutmann  the feared MIT trio  announced a quantum algorithm for evaluating NAND trees in O(N) time.  This solves a problem that I worked on as an undergrad nine years ago (!), and that many a tyro had unsuccessfully tackled since.
Alright, so suppose weve got this ant at the root of a complete binary tree:

You and your friend take turns moving the ant: first you can move it either down-and-left or down-and-right, then your friend can make the same choice, then you, etc.  If the ant ends up at a sugar cube, you win the game; if it ends up at a boot, your friend wins.  (Your friend is an exterminator.)
In the above example, its not hard to see that youre the one with a winning strategy.  But more generally, we can imagine a tree d levels deep, with an arbitrary sequence of N=2d boots and sugar cubes at the leaf vertices.  Then the question is: how many of the leaf vertices do you have to examine, in order to decide whether you or your friend has the win?
The goal here is to model games of alternation like chess and go, abstracting away the details.  The boots and sugar cubes correspond to losing and winning board positions.  Then we want to know: how many board positions would a computer have to evaluate, in order to play the game perfectly?
Its clear that you generally dont have to examine all the positions.  For example, suppose that at some position where its your turn to move, you discover a move that always lets you win.  Then you dont care what happens if you make any other move from that position.
Based on this idea (which AI types call alpha-beta pruning), in 1986 Saks and Wigderson gave a randomized algorithm to find an optimal move in the ant game, after examining (on average) only N0.753 of the N leaf vertices.  (Here 0.753  log2(1+33)-2.)  On the other hand, they also showed that this running time was optimal for randomized algorithms with no error.  Then, in 1995, Santha showed that it was optimal even for randomized algorithms with error.
Alright, but what about the quantum case?  It was observed early on (by a simple reduction from the PARITY problem) that any quantum algorithm for playing the ant game would have to examine at least N of the N leaf vertices.  But was a N running time achievable?  Until last week, we knew of no quantum algorithm that did even slightly better than the classical bound of N0.753.
And now its time to eat some crow: I didnt believe there was such a quantum algorithm.  I thought N0.753 was optimal.  In my defense, though, this was never really a very serious belief, in contrast to (say) my belief that quantum computers cant solve NP-complete problems in polynomial time.  Really I only claimed N0.753 was optimal to try and goad people into proving me wrong.  And today, Im pleased to report that my strategy was successful.
Last Wednesday, Farhi, Goldstone, and Gutmann put out a preprint showing how to find an optimal move for the ant game in time O((N log N)).  However, their algorithm only worked in the Hamiltonian oracle model, a fanciful idealization preferred by physicists in which time is (get this) continuous rather than discrete. Two days later, Childs, Cleve, Jordan, and Yeung showed how to port the algorithm to the ordinary discrete model, except that there the running time goes up to N1/2+ for any >0.  Then, just yesterday, Farhi, Goldstone, and Gutmann improved the running time in the Hamiltonian oracle model to the optimal O(N).  One hopes and expects that further improvements in the discrete model are forthcoming.
Another obvious question is whether any game tree can be evaluated in O(N) time, not just the complete binary tree used in the ant game.  Since the complete binary tree was previously considered the hardest case, the natural conjecture would be yes.
Years ago, David Deutsch gave an interview in which he illustrated Grovers algorithm using chess.  I emailed Deutsch to point out that this was a bad example: at the time, we we had no idea how to get a Grover speedup for games of alternation with small branching factor.  Deutsch dutifully posted a correction.  Now I guess Ill have to email him again, to tell him one can get a Grover speedup for games like chess after all.
I put Grover in quotes because, even though the Farhi-Goldstone-Gutmann algorithm achieves a square-root speedup, it doesnt actually look anything like Grovers algorithm.  Instead its based on a quantum walk (reminiscent of this paper), which is analyzed using tools from scattering theory.  Apparently, physics occasionally does come in handy for quantum computing.
All in all, this business with NAND trees has only confirmed my core belief about theoretical computer science: that there are no miracles, except when there are.Shor, Ill do it

Ive been talking a lot recently about how quantum algorithms dont work. But last week JR Minkel, an editor at Scientific American, asked me to write a brief essay about how quantum algorithms do work, which he could then link to from SciAms website.OK! I replied, momentarily forgetting about the  quantum algorithm tutorials that are already on the web.  So, heres the task Ive set for myself: to explain Shors algorithm without using a single ket sign, or for that matter any math beyond arithmetic.
Alright, so lets say you want to break the RSA cryptosystem, in order to rob some banks, read your exs email, whatever.  We all know that breaking RSA reduces to finding the prime factors of a large integer N.  Unfortunately, we also know that trying all possible divisors in parallel, and then instantly picking the right one, isnt going to work.  Hundreds of popular magazine articles notwithstanding, trying everything in parallel just isnt the sort of thing that a quantum computer can do.  Sure, in some sense you can try all possible divisors  but if you then measure the outcome, youll get a random divisor, which almost certainly wont be the one you want.
What this means is that, if we want a fast quantum factoring algorithm, were going to have to exploit some structure in the factoring problem: in other words, some mathematical property of factoring that it doesnt share with just a generic problem of finding a needle in a haystack.
Fortunately, the factoring problem has oodles of special properties. Heres one example: if I give you a positive integer, you might not know its prime factorization, but you do know that it has exactly one factorization!  By contrast, if I gave you (say) a Sudoku puzzle and asked you to solve it, a priori youd have no way of knowing whether it had exactly one solution, 200 million solutions, or no solutions at all.  Of course, knowing that theres exactly one needle in a haystack is still not much help in finding the needle!  But this uniqueness is a hint that the factoring problem might have other nice mathematical properties lying around for the picking.  As it turns out, it does.
The property well exploit is the reducibility of factoring to another problem, called period-finding. OK, time for a brief number theory digression.  Lets look at my favorite sequence of integers since I was about five years old: the powers of two.
2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 
Now lets look at the powers of 2 mod 15: in other words, the remainder when 15 divides each power of 2.
2, 4, 8, 1, 2, 4, 8, 1, 2, 4, 
As you can see, taking the powers of 2 mod 15 gives us a periodic sequence, whose period (i.e., how far you have to go before it starts repeating) is 4.  For another example, lets look at the powers of 2 mod 21:
2, 4, 8, 16, 11, 1, 2, 4, 8, 16, 
This time we get a periodic sequence whose period is 6.
You might wonder: is there some general rule from which we could predict the period?  Gee, I wonder if mathematicians ever thought of that question
Well, duh, they did, and theres a beautiful pattern discovered by Euler in the 1760s. Let N be a product of two prime numbers, p and q, and consider the sequence
x mod N, x2 mod N, x3 mod N, x4 mod N, 
Then provided x is not divisible by p or q, the above sequence will repeat with some period that evenly divides (p-1)(q-1).
So for example, if N=15, then the prime factors of N are p=3 and q=5, so (p-1)(q-1)=8.   And indeed, the period of the sequence was 4, which divides 8.  If N=21, then p=3 and q=7, so (p-1)(q-1)=12.  And indeed, the period was 6, which divides 12.
Now, I want you to step back and think about what this means. It means that, if we can find the period of the sequence
x mod N, x2 mod N, x3 mod N, x4 mod N, 
then we can learn something about the prime factors of N!  In particular, we can learn a divisor of (p-1)(q-1).  Now, Ill admit thats not as good as learning p and q themselves, but grant me that its something.  Indeed, its more than something: it turns out that if we could learn several random divisors of (p-1)(q-1) (for example, by trying different  random values of x), then with high probability we could put those divisors together to learn (p-1)(q-1) itself.  And once we knew (p-1)(q-1), we could then use some more little tricks to recover p and q, the prime factors we wanted.
So whats the fly in the ointment?  Well, even though the sequence
x mod N, x2 mod N, x3 mod N, x4 mod N, 
will eventually start repeating itself, the number of steps before it repeats could be almost as large as N itself  and N might have hundreds or thousands of digits!  This is why finding the period doesnt seem to lead to a fast classical factoring algorithm.
Aha, but we have a quantum computer!  (Or at least, were imagining that we do.)  So maybe theres still hope.  In particular, suppose we could create an enormous quantum superposition over all the numbers in our sequence: x mod N, x2 mod N, x3 mod N, etc.  Then maybe theres some quantum operation we could perform on that superposition that would reveal the period.
The key point is that were no longer trying to find a needle in an exponentially-large haystack, something we know is hard even for a quantum computer.  Instead, were now trying to find the period of a sequence, which is a global property of all the numbers in the sequence taken together.  And that makes a big difference.
Look: if you think about quantum computing in terms of parallel universes (and whether you do or dont is up to you), theres no feasible way to detect a single universe thats different from all the rest.  Such a lone voice in the wilderness would be drowned out by the vast number of suburb-dwelling, Dockers-wearing conformist universes.  What one can hope to detect, however, is a joint property of all the parallel universes together  a property that can only be revealed by a computation to which all the universes contribute.
(Note: For safety reasons, please dont explain the above to popular writers of the quantum computing = exponential parallelism school.  They might shrivel up like vampires exposed to sunlight.)
So, the task before us is not hopeless!  But if we want to get this period-finding idea to work, well have to answer two questions:

Using a quantum computer, can we quickly create a superposition over x mod N, x2 mod N, x3 mod N, and so on?
Supposing we did create such a superposition, how would we figure out the period?

Lets tackle the first question first.  We can certainly create a superposition over all integers r, from 1 up to N or so.  The trouble is, given an r, how do we quickly compute xr mod N?  If r was (say) 300 quadrillion, would we have to multiply x by itself 300 quadrillion times?  That certainly wouldnt be fast enough, and fortunately it isnt necessary.  What we can do instead is whats called repeated squaring.  Its probably easiest just to show an example.
Suppose N=17, x=3, and r=14.  Then the first step is to represent r as a sum of powers of 2:
r = 23 + 22 + 21.
Then

Also, notice that we can do all the multiplications mod N, thereby preventing the numbers from growing out of hand at intermediate steps.  This yields the result
314 mod 17 = 2.
OK, so we can create a quantum superposition over all pairs of integers of the form (r, xr mod N), where r ranges from 1 up to N or so.  But then, given a superposition over all the elements of a periodic sequence, how do we extract the period of the sequence?
Well, weve finally come to the heart of the matter  the one part of Shors quantum algorithm that actually depends on quantum mechanics.  To get the period out, Shor uses something called the quantum Fourier transform, or QFT.  My challenge is, how can I explain the QFT to you without using any actual math?  Hmmmm
OK, let me try this.  Like many computer scientists, I keep extremely odd hours.  You know that famous experiment where they stick people for weeks in a sealed room without clocks or sunlight, and the people gradually shift from a 24-hour day to a 25- or 26- or 28-hour day?  Well, thats just ordinary life for me.  One day Ill wake up at 9am, the next day at 11am, the day after that at 1pm, etc.  Indeed, Ill happily loop all the way around if no classes or appointments intervene.  (I used to do so all the time at Berkeley.)
Now, heres my question: lets say I tell you that I woke up at 5pm this afternoon.  From that fact alone, what can you conclude about how long my day is: whether Im on a 25-hour schedule, or a 26.3-hour schedule, or whatever?
The answer, of course, is not much!  I mean, its a pretty safe bet that Im not on a 24-hour schedule, since otherwise Id be waking up in the morning, not 5pm.  But almost any other schedule  25 hours, 26 hours, 28 hours, etc.  will necessarily cause me to loop all around the clock, so that itd be no surprise to see me get up at 5pm on some particular afternoon.
Now, though, I want you to imagine that my bedroom wall is covered with analog clocks.  These are very strange clocks: one of them makes a full revolution every 17 hours, one of them every 26 hours, one of them every 24.7 hours, and so on for just about every number of hours you can imagine.  (For simplicity, each clock has only an hour hand, no minute hand.)  I also want you to imagine that beneath each clock is a posterboard with a thumbtack in it.  When I first moved into my apartment, each thumbtack was in the middle of its respective board.  But now, whenever I wake up in the morning, the first thing I do is to go around my room, and move each thumbtack exactly one inch in the direction that the clock hand above it is pointing.
Now, heres my new question: by examining the thumbtacks in my room, is it possible to figure out what sort of schedule Im keeping?
I claim that it is possible.  As an example, suppose I was keeping a 26-hour day.  Then what would happen to the thumbtack below the 24-hour clock?  Its not hard to see that it would undergo periodic motion: sure, it would drift around a bit, but after every 12 days it would return to the middle of the board where it had started.  One morning Id move the thumbtack an inch in this direction, another morning an inch in that, but eventually all these movements in different directions would cancel each other out.
On the other hand  again supposing I was keeping a 26-hour day  what would happen to the thumback below the 26-hour clock? Here the answer is different. For as far as the 26-hour clock is concerned, Ive been waking up at exactly the same time each morning!  Every time I wake up, the 26-hour clock is pointing the same direction as it was the last time I woke up. So Ill keep moving the thumbtack one more inch in the same direction, until its not even on the posterboard at all!

It follows, then, that just by seeing which thumbtack travelled the farthest from its starting point, you could figure out what sort of schedule I was on.  In other words, you could infer the period of the periodic sequence that is my life.
And that, basically, is the quantum Fourier transform.  Well, a little more precisely, the QFT is a linear transformation (indeed a unitary transformation) that maps one vector of complex numbers to another vector of complex numbers.  The input vector has a nonzero entry corresponding to every time when I wake up, and zero entries everywhere else.  The output vector records the positions of the thumbtacks on the posterboards (which one can think of as points on the complex plane).  So what we get, in the end, is a linear transformation that maps a quantum state encoding a periodic sequence, to a quantum state encoding the period of that sequence.
Another way to think about this is in terms of interference.  I mean, the key point about quantum mechanics  the thing that makes it different from classical probability theory  is that, whereas probabilities are always nonnegative, amplitudes in quantum mechanics can be positive, negative, or even complex.  And because of this, the amplitudes corresponding to different ways of getting a particular answer can interfere destructively and cancel each other out.
And thats exactly whats going on in Shors algorithm.  Every parallel universe corresponding to an element of the sequence contributes some amplitude to every parallel universe corresponding to a possible period of the sequence.  The catch is that, for all periods other than the true one, these contributions point in different directions and therefore cancel each other out.  Only for the true period do the contributions from different universes all point in the same direction.  And thats why, when we measure at the end, well find the true period with high probability.
Obviously theres a great deal Ive skipped over; see here or here or here or here or here or here or here or here or here or here or here or here for details.Walter Lewin

Yesterday I heard the sad news that Prof. Walter Lewin, age 78perhaps the most celebrated physics teacher in MITs historyhas been stripped of his emeritus status and barred from campus, and all of his physics lectures removed from OpenCourseWare, because an internal investigation found that he had been sexually harassing students online. I dont know anything about what happened beyond the terse public announcements, but thosewho do know tell me that the charges were extremely serious, and that this wasnt a borderline case.
Im someone who feels that sexual harassment mustnever be tolerated, neither here nor anywhere else. But I also feel that, if a public figureis going to be publicly brought down like this (yes, even by a private university), then the detailed findingsof the investigation should likewisebe made public, regardless ofhow embarrassing they are. I knowothers differ, but I thinkthe need of the world to see that justice was done overrides MITs internal administrative needs, and even Prof. Lewins privacy (the names of any victims could, of course, be kept secret).
More importantly, I wishto register that I disagree in the strongest possible terms with MITsdecision to remove Prof. Lewins lectures from OpenCourseWarethereby forcing the tens of thousands of students around the world who were watching theselegendary lecturesto hunt for ripped copies on BitTorrent. (Imagine that: physics lectures as prized contraband!) By all means, punish Prof. Lewin as harshly as he deserves, butas students have been pleading on Reddit, in the MIT Tech comments section, and elsewheredont also punish the countlessstudents of both sexes who continue to benefit from his work. (For godsakes, Id regard taking down the lecturesas a tough call if Prof. Lewin had gone on a murder spree.) Doing this sends the wrongmessage about MITs values, and is a gift to those who like tocompare modern American college campuses to the Soviet Union.
Update:For those who are interested, while the comment section starts out with a discussion of whether Walter Lewins physics lectures shouldve been removed from OCW, its now broadened to include essentially all aspects of the human condition.The Turing movie

Last week I finally sawThe Imitation Game, the movie withBenedict Cumberbatch as Alan Turing.
OK, so for those who havent yet seen it: should you? Heres my one paragraph summary: imagine that you told the story of Alan Turingone of the greatest triumphs and tragediesof human history, needing no embellishment whatsoeverto someone who only sort-ofunderstood it, and who filled in the gaps with weirdfabrications and Hollywood clichs. And imagine that person retold the story to a second person, who understood even less, and thatthat person retold it to a third, who understood least of all, but who was charged with making the movie that would bring Turings story before the largest audience its ever had. And yet,imagine that enough of the enormity of the originalstorymade it through this noisy channel, that the final product was still pretty good. (Except, imagine how much better it couldve been!)
The fabrications wereespecially frustrating to me, because we knowits possible to bring Alan Turings story to life in a way that fullyhonors the truescience and history. We know that, becauseHugh Whitemores 1986 play Breaking the Code did it. The producers of The Imitation Game wouldve done better just to junk their script, and remake Breaking the Codeinto a Hollywood blockbuster. (Note that there is a 1996 BBC adaptation of Breaking the Code, with Derek Jacobi as Turing.)
Anyway, the movie focuses mostly on Turings codebreaking work at Bletchley Park, but also jumps around in time to his childhood at Sherborne School, and to his arrest for homosexual indecency and its aftermath. Turings two world-changingpapersOn Computable Numbers and Computing Machinery and Intelligenceare both mentioned, though strangely, his paper about computing zeroes of the Riemann zeta function is entirely overlooked.
Here are my miscellaneous comments:

The boastful, trash-talking, humor-impaired badass-nerd of the movie seems a lot closer to The Big Bang Theorys Sheldon Cooper, or to some other Hollywood concept of why smart people are so annoying, than to the historical Alan Turing. (At least in Sheldons case, the archetype is usedfor laughs, not drama or veracity.) As portrayedin the definitive biography (Andrew Hodges Alan Turing: The Enigma), Turing was eccentric, sure, and fiercely individualistic (e.g., holding up his pants with pieces of string), but he didnt get off on insulting the intelligence of the peoplearound him.


In the movie, Turing is pretty much singlehandedly responsible for designing, building, and operating the Bombes (the codebreaking machines),which he does over the strenuous objections of his superiors. This, of course, is absurd: Bletchley employed about 10,000 people at its height. Turing mayhave been the single most important cog in the operation, but he was still a cog. And by November 1942, the operation was already running smoothly enough that Turing could set sail for the US (in waters that were now much safer, thanks to Bletchley!), to consulton other cryptographic projects at Bell Labs.


But perhaps the movies zaniestconceit is that Turing was also in charge ofdeciding what to do with Bletchleysintelligence (!). In the movie, it falls to him, not the military, todecide which ship convoys will be saved, and which sacrificed to prevent spilling Bletchleyssecret. If that had any historicity to it, it would surely be the most military and political power ever entrusted to a mathematician (update: see the comments section for potential counterexamples).


Its true that Turing (along with three other codebreakers) wrote a letter directly to Winston Churchill, pleading for more funding for Bletchley Parkand thatChurchill saw the letter, and ordered Action this day! Make sure they have all they want on extreme priority. However, the letter was not a power play to elevate Turing over Hugh Alexander and his other colleagues: in fact, Alexander co-signed the letter. More broadly, the fierce infightingbetween Turing and everyone else at Bletchley Park, central to the moviesplot, seems to have been almost entirelyinvented for dramatic purposes.


The movie actually deserves a lot of credit for getting rightthat the majortechnical problem of Bletchley Park was how to get the Bombes to search through keysfast enoughand that speeding things up iswhere Turing made acentral contribution. As a result, The Imitation Game might be the first Hollywood movie ever made whose plot revolves around computational efficiency. (Counterexamples, anyone?) Unfortunately, the movie presents Turings great insight as being that one can speed up the searchby guessing common phrases, like HEIL HITLER, that are likely to be in the plaintext. That was, I believe, obvious to everyone from the beginning.


Turing never built a computer in his own home, and he never named a computer Christopher, after his childhood crush Christopher Morcom. (On the other hand, Christopher Morcom existed, and his early death from tuberculosis really diddevastate Turing, sending him into morbid-yet-prescientruminations about whether a mind could exist separately from a brain.)


I found it ironic that The Imitation Game, produced in 2014, is far more squeamish about on-screen homosexuality than Breaking the Code, produced in 1986. Turing talks about being gay (which is animprovement over 2001s Enigma, which made Turing straight!), but is never shown embracing another man. However, the more important problem is that the movie botches the story of the burglary of Turings house (i.e.,the event that led to Turings arrest and conviction for homosexual indecency), omitting the role of Turings own naivet in revealing his homosexuality to the police, and substituting some cloak-and-dagger spy stuff. Once again, Breaking the Code handled this perfectly.


In one scene, Euler is pronounced Yooler.

For more, see an excellent piece in Slate, How Accurate Is The Imitation Game?. And for other science bloggers reactions, see this review by Christos Papadimitriou (which I thought was extremely kind, though it focuses more on Turing himself than on the movie),this reaction by Peter Woit, which largelyechoes mine, and this by Clifford Johnson.Quantum Computing Since Democritus Lecture 10: Quantum Computing

Youve waited for weeks.  Youve pestered me for it.  Now here it is.
For those who liked my Shors algorithm post but are ready for the next level: brace yourself for BQP  PP, Recursive Fourier Sampling, and so much more.  And for dessert, a brief discussion of quantum computing and the many-worlds interpretation.
Suggestions and bugfixes welcome; Ill continue revising over the next few days as time permits.Alright, alright, alright

Ive caved in to popular demand.  From now on, every embryonic insight, discursive jumble of neural firings, and missive from the depths of my soul will be filed under a pithy title, so that readers on the go can quickly decide which ones are worth their time to read.  To maintain consistency, I also went back and titled the 17 previous posts.Quantum Complexity Theory Student Project Showcase 3

Merry Christmas (belatedly)! This year Quanta Claus has brought us eightfascinating finalproject reports from students in my 6.845 Quantum Complexity Theory class, covering everything from interactive proofs to query and communication complexity to quantum algorithms to quantum gates (and one project even includes a web-baseddemo you can try!). Continuing in the tradition of the two previous showcases, Im sharing the reports here; some of these works might also be posted to the arXiv and/or submitted to journals. Thanks so much to the students who volunteered to participate in the showcase, and to all the students for making this such a great class.

On Applications of the Equilibrium Value Method, by Serena Booth. A survey about Xiaodi Wus simpler alternative approach to proving QIP=PSPACE, and whether it might also yield a proof of QRG=RG=EXP.
Improved Quantum Query Complexity Bounds for Some Graph Problems, by Prafulla Dhariwal and Vinay Mayar. Building on Lin and Lins striking recent work on Vaidman-bomb query complexity, obtains some new results about the quantum query complexity of k-source shortest paths and minimum vertex cover in bipartite graphs.
On Quantum Sieve Approaches to the Lattice Shortest Vector Problem, by Daniel Epelbaum. Surveys Greg Kuperbergs subexponential-time quantum algorithm for the dihedral Hidden Subgroup Problem, as well as Oded Regevs reduction of the approximate shortest vector problem to dihedral HSP. Discusses in detail why these two things, combined, do not yield a quantum algorithm for lattice problems that outperforms the best known classical algorithms.
Approximate Degree of AND-OR Trees, by Pritish Kamath and Prashant Vasudevan. Discusses the wonderful open problem of proving that every AND-OR tree with N leaves, even a highly-unbalanced one, has approximate degree (N) as a real polynomial. (We know from Reichardts seminal work on quantum query complexity that the degree is O(N).) Makes some partial progress on this conjecturee.g., resolves it up to a polylog(N) factor for trees of constant depth.
Infinite Separation of Quantum Information and Communication, by Dax Koh and Zi-Wen Liu. Wrings a further implication out of the striking recent work of Perry, Jain, and Oppenheim, about a communication task with infinite quantum/classical separation (infinite meaning that one of them is O(1)o(1) actuallyand the other is (N)).
Taming Quantum Amplitudes with Gateset Limitations, by Ross Rheingans-Yoo. Surveys the issue of doubly-exponentially small probabilities for PostBQP circuits, which I covered recently on this blog as well as on MathOverflow. Takes an initial step toward resolving the problem of whether and e are tame numbers, by using the concept of irrationality coefficients to show that a constant number ofgates with - and e-like amplitudes can be tolerated in a PostBQP circuit.
Tools for Quantum Circuit Synthesis, by Chelsea Voss. Click here to try Chelseas software! Discusses the creation of a web-based tool that lets you experiment with synthesizingquantum circuits and observingtheir behavior, and also gives you quantum-circuit-synthesis puzzles to solve.
Complexity of the Quantum Separability Problem and Its Variants, by Charles Xu. Surveys the problem of deciding whether a quantum state described in various ways is separable or far from separable (and the use of that problem to characterize quantum interactive proof classes), concentrating on recent work by Gutoski, Hayden, Milner, and Wilde.Quantum Computing Since Democritus Lecture 10.5: Penrose

Youve eaten your polynomial-time meatloaf and your BQP brussels sprouts.   So now please enjoy a special dessert lecture, which I didnt even deliver in class except as a brief coda to Lecture 10.  Watch me squander any remaining credibility, as I pontificate about Roger Penroses Gdel argument, strong AI, the No-Cloning Theorem, and whether or not the brain is a quantum computer.  So gravitationally collapse your microtubules to the basis state |fun, because even a Turing machine could assent to the proposition that youre in for a wild ride!
(Important Note: If you belong to a computer science department hiring committee, there is nothing whatsoever in this lecture that could possibly interest you.)What I believe

Two weeks ago, prompted by acommenter named Amy,I wroteby far the most personal thingIve ever made publicwhats now being referred to in some places asjust comment 171. My thinking was: Im giving up a privacy that I wontregain for as long as I live, opening myself to ridicule, doing the blogequivalent of a queen-and-two-rook sacrifice. But at leastand this is what mattersno one willever again be able to question the depth of myfeminist ideals. Not after they understand how I clungto those idealsthrougha decade when I wanted to die. And any teenage male nerds who read this blog, and who find themselves in a similar hole, will know that they too can get out without giving up on feminism. Surely thats a message any decent person could get behind?
Alas, I wasoveroptimistic. Twitter is now abuzz withpeople accusing me of holdingprecisely the barbaricattitudes that my story was all about resisting,defeating, and escaping, even when life throws you into those nasty attitudes gravity well, even when ittests you as mostof your criticswill never be tested. Many of the tweets are full of thecourageous clucks of those who speak for justice as long as theyre pretty sure their friendswill agree with them:wow just wow, so sad how he totes doesnt get it, expletives in place of arguments. This whole affairmakes me despair of the power of language to convey human realityor at least, of my own abilityto use languagefor that end. I tookthe most dramatic, almost self-immolating stepI could to getpeople to see me as I was,rather than according to somepreexisting mental template of aprivileged, entitled, elite male scientist. And many responded by pressing down the template all the more firmly, twistingmy words until they fit, and thencongratulating each other for their bravery in doing so.
Here, of course, these twitterers (and redditors and facebookers) inadvertently helpedmake my argumentfor me. Does anyone still not understandthe sort of paralyzing fear thatIenduredas a teenager, that millions of other nerds endure, and that I tried to explain in the commentthe fearthat civilized peoplewill condemn you as soon as they find outwhoyou really are(even if the truth seems far fromuncommonlybad), that your only escape is to hide or lie?
Thankfully, not everyone responded with snarls. Throughout the past two weeks, Ive been getting regular emails from shy nerds who thanked me profusely for sharing as I did, for giving them hope fortheir own lives, and for articulating a life-crushingproblemthat anyone whos spent a day amongSTEMnerdsknows perfectlywell, butthat no one acknowledges in polite company. I owe the writers of those emails more than they owe me, sincetheyre the ones who convincedme that on balance, I did the right thing.
Im equally grateful to have gotten some interesting, compassionate responses from feminist women. The most striking was that of Laurie Pennyin the New Statesmana response thatothers of Pennys viewsshould study, if they want to understand how towin hearts and change minds.
I do not intend for a moment to minimise Aaronsons suffering. Having been a lonely, anxious, horny young person who hated herself and was bullied I can categorically say that it is an awful place to be. I have seen responses to nerd anti-feminism along the lines of being bullied at school doesnt make you oppressed. Maybe its not a vector of oppression in the same way, but its not nothing. It burns. It takes a long time to heal.
Feminism, however, is not to blame for making life hell for shy, nerdy men. Patriarchy is to blame for that. It is a real shame that Aaronson picked up Dworkin rather than any of the many feminist theorists and writers who manage to combine raw rage with refusal to resort to sexual shame as an instructive tool. Weaponised shame- male, female or other- has no place in any feminism I subscribe to. Ironically, Aronson [sic] actually writes a lot like Dworkin- he writes from pain felt and relived and wrenched from the intimate core of himself, and because of that his writing is powerfully honest, but also flawed 
What fascinates me about Aaronsons piece, in which there was such raw, honest suffering, was that there was not one mention of women in any respect other than how they might relieve him from his pain by taking pity, or educating him differently. And Aaronson is not a misogynist. Aaronson is obviously a compassionate, well-meaning and highly intelligent man[damn straightSA]
Ill have more to say about Pennysarguments in a later postwhere I agree and where I part ways from herbut theres one factual point I should clear up now. When I started writing comment 171, I filled it with anecdotes from the happier part of my life (roughly, from age 24 onward): the part where I finally became able to ask; where women, with a frequency that I couldnt have imagined as a teenager, actually answered yes; and whereI got to learn abouttheir own fears and insecuritiesand quirks. In the earlier draft, I also wrote about my wifes experiences as a woman in computer science, which differedfrom Amys in some crucialways. But then I removedit all, for a simple reason: because while I have the right to bare my own soul on my blog, I dont have the right to bareother peoples unlessthey want me to.
Without further ado, and for the benefit of the worlds Twitterariat, Im now just goingto state nineof my core beliefs.
1. I believe thatwomen are authors of their own stories, that they dont exist merely to please men, that they are nothomogeneous, that theyre not slot machines that pay out but only if you say the right things. I dont want my two-year-old daughter to grow up to beanyone elses property, and Im happy thatshe wont. And Id hopeall this would no more need to be said, than (say) that Gentiles shouldnt be slaughtered to use their blood in making matzo.
2. I believe everyones story should be listened toand concretely, that everyone should feel300%welcometo participate inmycomments section. I dont promise to agree with you, but I promise to try to engage your ideas thoughtfully, whether youre a man, woman, child, AI-bot, or unusually-brightkeyboard-pecking chicken. Indeed, I spend a nontrivial fraction of my life doing exactly that (well, not so much with chickens).
3. I believe no one has the right to anyone elses sexual affections. I believe establishing this principle was one of the triumphs of modern civilization.
4. I believe womenwho go into male-dominated fields like math, CS, and physics deserve praise, encouragement,and support. But thats putting the pointtoo tepidly: if I get to pick 100 people (unrelated to me) to put onto aspaceship as the earth is being destroyed, I start thinking immediately about six or seven of my female colleagues in complexity and quantum computing. And no, Twitter: not because being female, they could help repopulate the species. Just because theyre greatpeople.
5. I believe there still existmen who thinkwomen are inferior, that they have no business in science, that theyre good only for sandwich-makingand sex. Though I dont consider it legally practicable, as a moral matter Id be fine if every such man werethrown in prison forlife.
6. I believe thateven if they dont hold views anything like the above (as, overwhelmingly, they dont),there might be nerdy males who unintentionally behavein waysthat tendto drive some women away from science. I believe this is a complicated problembestapproached with charity: wewant win-win solutions, where no one is made to feel despised because of who they are. Toward that end, I believe open, honest communication (as Ive been trying to foster on this blog) is essential.
7. I believe that no one should be ashamed of inborn sexual desires: not straight men, not straight women, not gays, not lesbians, not even pedophiles (though in the last case, there might reallybe no moral solution other than a lifetime of unfulfilled longing). Indeed,Ive always felt a special kinship with gays and lesbians, precisely becausethe sense of having to hide from the world, of being hissed at for a sexual makeup that you never chose, is one that I can relate to on a visceral level. This is one reason why Ive staunchly supported gay marriage since adolescence, when it was still radical. Its also why the tragedy of Alan Turing, of his court-ordered chemical castration and subsequent suicide, was one of the formative influences of my life.
8. I believe that the problem of the nerdy heterosexual maleis surely one of the worst social problems today that you cant even acknowledge as being a problemthe more so, if you weight the problems by how likely academics like me are to know the sufferers and to feel a personal stake in helping them. How to help all the young male nerdsI meet who suffer from this problem, in a way that passes feminist muster, and that triggers the worlds sympathy rather than outrage, is a problem that interests me as much asP vs. NP, and that right now seems about equally hard.
9. I believe that, just as there are shy, nerdy men, there are also shy, nerdy women, who likewisesuffer from feeling unwanted, sexually invisible, or ashamed to express their desires. On top of that, these women also have additional difficulties that come with being women! At the same time, I also thinkthere are crucial differences between the two casesat least in the world as it currently existswhich might make the shy-nerdy-male problem vastly harder to solve than the shy-nerdy-female one. Those differences, and my adviceforshy nerdy females, will be the subject of another post. (Thats the thing about blogging: in for a penny, in for a post.)

Update (Dec. 31): I struggle always to be ready to change my views in light of new arguments and evidence. After reflecting on the many thoughtful comments here, there are two concessions that Im now willing to make.
The first concession is that, as Laurie Penny maintained, my problems werent caused by feminism, but rather by the Patriarchy. One thing Ive learned these last few days is that, as many people use it, the notion of Patriarchy is sufficiently elastic as to encompass almost anything about the relations between the sexes that is, or has ever been, bad or messed upregardless of who benefits, whos hurt, or who instigated it. So if you tell such a person that your problem was not caused by the Patriarchy, its as if youve told a pious person that a certain evil wasnt the Devils handiwork: the person has trouble even parsing what you said, since within her framework, evil and Devil-caused are close to synonymous. If you want to be understood, far better just to agree that it was Beelzebub and be done with it. This might sound facetious, but its really not: I believe in the principle of always adopting the other sides terms of reference, whenever doing so will facilitate understanding and not sacrifice what actually matters to you.
Smash the Patriarchy!
The second concession is that, all my life, Ive benefited from male privilege, white privilege, and straight privilege. I would only add that, for some time, I was about as miserable as its possible for a person to be, so that in an instant, I wouldve traded all three privileges for the privilege of not being miserable. And if, as some suggested, there are many women, blacks, and gays who wouldve gladly accepted the other side of that tradewell then, so much the better for all of us, I guess. Privilege simply struck me as a pompous, cumbersome way to describe such situations: why not just say that person As life stinks in this way, and person Bs stinks in that way? If theyre not actively bothering each other, then why do we also need to spread person As stink over to person B and vice versa, by claiming theyre each privileged by not having the other ones?
However, I now understand why so many people became so attached to that word: if I wont use it, they think it means I think that sexism, racism, and homophobia dont exist, rather than just that I think people fixated on a really bad way to talk about these problems.

Update (Jan. 1): Yesterday I gave a seminar at the Hebrew University of Jerusalem. Since Id been spending all my time dealing with comment-171-gate, I showed up with no slides, no notes, no anythingjust me and the whiteboard. But for an hour and a half, I got to forget entirely about the thousands of people on the Internet Id never met who were now calling me an asshole because of wild, postmodernist misreadings of a blog comment, which twisted what I said (and meant) into its exact opposite, building up a fake-Scott-Aaronson onto whom the ax-grinders could project all of their own bogeymen. For 90 minutes I got to forget all that, and just throw myself into separations between randomized and quantum query complexity. It was the most cathartic lecture of my life. And in the near future, Id like more such catharses. Someday Ill say more about the inexhaustibly-fascinating topic of nerds and sexand in particular, Ill write the promised post about shy female nerdsbut not now. This will be my last post on the subject for a while.
On balance, I dont regret having shared my storybecause it prompted an epic discussion; because I learned so much from the dozens of other nerd coming-of-age stories that it drew out, similar to mine but also different; because what I learned will change the way I talk about these issues in the future; and most of all, because so many people, men and also some women, emailed me to say how my speaking out gave them hope for their own lives. But I do regret a few rhetorical flourishes, which I should have known might be misread maliciously, though I could never have guessed how maliciously. I never meant to minimize the suffering of other people, nor to deny that many others have had things as bad or worse than I did (again, how does one even compare?). I meant only that, if were going to discuss how to change the culture of STEM fields, or design sexual-conduct policies to minimize suffering, then I request a seat at the table not as the white male powerful oppressor figure, but as someone who also suffered something atypically extreme, overcame it, and gained relevant knowledge that way. I never meant to suggest that anyone else should leave the table.
To the people who tweeted that female MIT students should now be afraid to take classes with me: please check out the beautiful blog post by Yan, a female student who did take 6.045 with me. See also this by Lisa Danz and this by Chelsea Voss.
More broadly: thank you to everyone who sent me messages of support, but especially to all the female mathematicians and scientists who did so. I take great solace from the fact that, of all the women and men whose contributions to the world I had respected beforehand, not one (to my knowledge) reacted to this affair in a mean-spirited way.
Happy New Year, everyone. May 2015 be a year of compassion and understanding.

Update (Jan. 2): If youve been following this at all, then please, please, please read Scott Alexanders tour-de-force post. To understand what it was like for me to read this, after all Ive been through the past few days, try to imagine Galileos Dialogue Concerning the Two Chief World Systems, the American Declaration of Independence, John Stuart Mills The Subjection of Women, and Clarence Darrows closing arguments in the Scopes trial all rolled into one, except with you as the protagonist. Reason and emotion are traditionally imagined as opposites, but thats never seemed entirely right to me: while, yes, part of reason is learning how to separate out emotion, I never experience such intense emotion as when, like with Alexanders piece, I see reason finally taking a stand, reason used to face down a thousand bullies and as a fulcrum to move the world.

Update (Jan. 13): Please check out this beautiful Quora answer by Jean Yang, a PhD student in MIT CSAIL. Shes answering the question: What do you think of Scott Aaronsons comment #171 and the subsequent posts?
More generally, Ive been thrilled by the almost-unanimously positive reactionsthat Ive been getting these past two weeks from women in STEM fields, even as so many people outside STEM have responded with incomprehension and cruelty. Witnessing thatpattern hasif possiblemade me even more of a supporterand admirer of STEM womenthan I was before this thing started.

Update (Jan. 17): See this comment on Lavinia Collinss blog for my final response to the various criticisms that have been leveled at me.Back from vacation

Im told that the first rule of blogging is: never, ever apologize for the long delay in updating your blog. As it turns out, I have no need to apologize.  You see, for the past ten days, Ive been on an intense, meeting-packed, emotionally-draining sightseeing vacation around the United States.  The places I picked to see on my vacation  more-or-less at random  included Princeton, New Jersey; the Hyde Park neighborhood of Chicago; and the southern riverbank of Cambridge, Massachusetts.  To get the most out of my vacation, I made sure to wear my best nerd attire everywhere I went, and to sample all the fine restaurants, seminar rooms, and offices of computer science department chairs and deans.  And since I still havent had enough R&R, in April Im going on a second vacation  this time to Pasadena, Palo Alto, and other exotic locations on the west coast.  As with everything else about my personal life, you can be sure to learn all the juicy details, in real-time, right here on this blog.The Nintendo stork

In January, the online magazine spiked asked me to write 200 words or less on the question, What is the greatest innovation in your field?  I thought it was a dumb question, but I answered it anyway.  The magazine still hasnt put up the responses  I guess not enough thinkers got back to them yet  but today, since I feel like blogging and dont have anything else to post, here is my response.  Enjoy.
The greatest innovation in computer science was to represent machines  objects that do things, respond to their environments, surprise their creators  as nothing but strings of information.  When I was a kid, my overriding ambition was to write my own Nintendo games.  But while I could draw the characters and the levels, I had no idea what it would be like to breathe life into a game  to teach the game how to respond to the controller.  I pictured thousands of engineers in white lab coats crafting a game cartridge using enormous factory equipment, as they would a 747.
Then a friend showed me a rudimentary spaceship game written in AppleBASIC.  Look: here were the lines of code, and here was the game. Slowly it dawned on me that these screenfuls of funny-looking commands werent just some sort of blueprint for the game  they were the game.  Change the code, and the game would do something different.  Better yet, the task of writing the commands was ultimately just a big math problem.  This was Alan Turings great insight of 1936.  For me, it was a revelation comparable only to finding out where babies came from.
(Unfortunately, Ive long since lost touch with the AppleBASIC-game-playing friend  last I heard through mutual acquaintances, he went off to fight in Afghanistan, and came back injured by a shrapnel bomb.)The event horizons involved, but the singularity is committed

Lenny Susskind  the Stanford string theorist who Shtetl-Optimized readers will remember from this entry  is currently visiting Perimeter Institute to give a fascinating series of lectures on Black Holes and Holography.
After this mornings lecture (yes, Im actually getting up at 10am for them), the following question occurred to me: whats the connection between a black hole having an event horizon and its having a singularity?  In other words, once youve clumped enough stuff together that light cant escape, why have you also clumped enough together to create a singularity?  I know theres a physics answer; what Im looking for is a conceptual answer.
Of course, one direction of the correspondence  that you cant have a singularity without also having an event horizon  is the famous Cosmic Censorship Hypothesis popularized by Hawking.  But what about the other direction?
When I posed this question at lunch, Daniel Gottesman patiently explained to me that singularities and event horizons just sort of go together, like bacon and eggs.  However, this answer was unsatisfying to me for several reasons  one of them being that, with my limited bacon experience, I dont know why bacon and eggs go together.  (I have eaten eggs with turkey bacon, but I wouldnt describe their combined goodness as greater than the sum of their individual goodnesses.)
So then Daniel gave me a second answer, which, by the time it lodged in my brain, had morphed itself into the following.  By definition, an event horizon is a surface that twists the causal structure in its interior, so that none of the geodesics (paths taken by light rays) lead outside the horizon.  But geodesics cant just stop: assuming there are no closed timelike curves, they have to either keep going forever or else terminate at a singularity.  In particular, if you take a causal structure that wants to send geodesics off to infinity, and shoehorn it into a finite box (as you do when creating a black hole), the causal structure gets very, very angry  so much so that it has to vent its anger somewhere by forming a singularity!
Of course this cant be the full explanation, since why cant the geodesics just circle around forever?  But if its even slightly correct, then it makes me much happier.  The reason is that it reminds me of things I already know, like the hairy ball theorem (there must be a spot on the Earths surface where the wind isnt blowing), or Cauchys integral theorem (if the integral around a closed curve in the complex plane is nonzero, then there must be a singularity in the middle), or even the Nash equilibrium theorem.  In each of these cases, you take a geometric structure with some global property, and then deduce that having that property makes the structure angry, so that it needs a special point (a singularity, an equilibrium, or whatever) to blow off some steam.
So, question for the relativistas: is there a theorem in GR anything like my beautiful story, or am I just talking out of my ass as usual?
Update (3/22): Well, it turns out that I was ignorantly groping toward the famous Penrose-Hawking singularity theorems.  Thanks to Dave Bacon, Sean Carroll, and ambitwistor for immediately pointing this out.At most finitely many years

Paul Cohen, who proved that one can imagine infinite sets larger than the set of integers but smaller than the set of real numbers without leading to contradiction, and who won (to date) the only Fields Medal ever awarded for work in logic, died yesterday.  He was 72.  You can read more about his achievements here or in Lecture 3.
I only saw Cohen once, when he participated in a panel discussion at Berkeley about Hilberts problems from 1900. He came across as funny and likable  which was good since, to my mind, it might as well have been Euclid or Aristotle sitting there trading quips with the other panelists.  (As Rebecca Goldstein wrote about Gdel, the man whose work paved the way for Cohens: I once found the philosopher Richard Rorty standing in a bit of a daze in Davidsons food market.  He told me in hushed tones that hed just seen Gdel in the frozen food aisle.)
Like Cantor himself, Cohen started out not as a logician but as an analyst.  The famous story is that Cohen was once teasing a logician friend about how there were no meaty, nontrivial open problems in logic  certainly nothing that an analyst couldnt swoop in and solve.  Oh yeah? the friend shot back.  Id like to see you prove the independence of the Continuum Hypothesis! So thats what he did.  Id love to know whether the story has any grain of truth to it.Quantum computing news items (by reader request)

Within the last couple months, there was a major milestone in the quest to build a scalable quantum computer, and also a major milestone in the quest to figure out what you would do with a quantum computer if you had one. As Ive admitted many times, neither of those two quests is really the reason why I got into quantum computingIm one of the people who would still want to study this field, even if there were no serious prospect either of building a quantum computer or of doing anything useful with it for a thousand yearsbut for some reason that I dont fully understand, both of those goals do seem to excite other people.
So, OK, the experimental breakthrough was the Martinis groups use of quantum error-correction with superconducting qubits, to preserve a logical bit for several times longer than the underlying physical qubits survived for. Shortly before this came out, I heard Krysta Svore give a talk at Yale in which she argued that preserving a logical qubit for longer than the physical qubits was the next experimental milestone (the fourth, out of seven she listed) along the way to a scalable, fault-tolerant quantum computer. Well, it looks like that milestone may have been crossed. (update: Ive since learned from Graeme Smith, in the comments section,that the milestone crossed should really be considered the 3.5th, since even though quantum error-correction was used, the information that was being protected was classical. I also learned from commenter Jacob that the seven milestones Krysta listed came from a Science paper by Schoelkopf and Devorret. She cited the paper; the forgetfulness was entirely mine.)
In more detail, the Martinis group used a linear array of 9 qubits: 5 data qubits interleaved with 4 measurement qubits. The authors describe this setup as a precursor to Kitaevs surface code (which would involve a 2-dimensional array). They report that, after 8 cycles of error detection and correction, they were able to suppress the effective error rate compared to the physical qubits by a factor of 8.5. They also use quantum state tomography to verify that their qubits were indeed in entangled states as they did this.
Of course, this is not yet a demonstration of any nontrivial fault-tolerant computation, let alone of scaling such a computation up to where its hard to simulate with a classical computer. But it pretty clearly lies along the critical path to that.
As I blogged back in September, Google recently hired Martiniss group away from UC Santa Barbara, where theyll work on superconducting quantum annealing, as a step along the way to full universal QC. As I mentioned then, the Martinis groups Xmon qubits have maybe 10,000 times the coherence times of D-Waves qubits, at least when you measure coherence in the usual ways. The fact that Martinis et al. are carefully doing quantum state tomography and demonstrating beneficial error-correction before scaling up are further indications of the differences between their approach and D-Waves. Of course, even if you do everything right, theres still no guarantee that youll outperform a classical computer anytime soon: it might simply be that the things you can do in the near future (e.g., quantum annealing for NP-complete problems) are not things where youre going to outperform the best classical algorithms. But its certainly worth watching closely.
Meanwhile, the quantum algorithms breakthrough came in a paper last month by an extremely well-known trio down the Infinite Corridor from me: Farhi, Goldstone, and Gutmann. In slightly earlier work, Farhi et al. proposed a new quantum algorithm for NP-hard optimization problems. Their algorithm badly needs a name; right now theyre just calling it the QAOA, or Quantum Approximate Optimization Algorithm. But heres what you need to know: their new algorithm is different from their famous adiabatic algorithm, although it does become equivalent to the adiabatic algorithm in a certain infinite limit. Rather than staying in the ground state of some Hamiltonian, the QAOA simply

starts with a uniform superposition over all n-bit strings,
applies a set of unitary transformations, one for each variable and constraint of the NP-hard instance,
repeats the set some number of times p (the case p=1 is already interesting), and then
measures the state in the computational basis to see what solution was obtained.

The unitary transformations have adjustable real parameters, and a bigpart of the game is figuring out how to set the parameters to get a good solution.
The original, hyper-ambitious goal of the QAOA was to solve the Unique Games problem in quantum polynomial timethereby disprovingthe Unique Games Conjecture (which I previously blogged about here), unless NPBQP. It hasnt yet succeeded at that goal. In their earlier work, Farhi et al. managed to show that the QAOA solves the MAX-CUT problem on 3-regular graphs with approximation ratio 0.6924, which is better than random guessing, but not as good as the best-known classical algorithms (Goemans-Williamson, or for the degree-3 case, Halperin-Livnat-Zwick), let alone better than those algorithms(which is what would be needed to refute the UGC).
In their new work, Farhi et al. apply the QAOA to a different problem: the poetically-named MAX E3LIN2. Here youre given a collection of linear equations mod 2 in n Boolean variables, where each equation involves exactly 3 variables, and each variable appears in at most D equations. The goal is to satisfy as many of the equations as possible, assuming that theyre not all satisfiable (if they were then the problem would betrivial). If you just guess a solution randomly, youll satisfy a 1/2 fraction of the equations. Hstad gave a polynomial-time classical algorithm that satisfies a 1/2+c/D fraction of the maximum number of satisfiable equations, for some constant c. This remains the best approximation ratio that we know how to achieve classically. Meanwhile, Trevisan showed that if theres a polynomial-time classical algorithm that satisfies a 1/2+c/D fraction of the max number of satisfiable equations, for a sufficiently large constant c, then P=NP.
OK, so what do Farhi et al. do? They show that the QAOA, with suitably tuned parameters, is able to satisfy a 1/2+c/D3/4 fraction of the total number of equations in polynomial time, for some constant c. (In particular, this implies that a 1/2+c/D3/4fraction of the equations are satisfiableassuming, as Farhi et al. do, that two equations directly contradicting each other, like x+y+z=0 and x+y+z=1, never appear in the same instance.)
Now, the above is a bigger fraction than the best-known classical algorithm satisfies! (And not only that, but here the fraction is of the total number of equations, rather than the number of satisfiable equations.) Farhi et al. also show that, if the constraint hypergraph doesnt contain any small cycles, then QAOA can satisfy a1/2+c/D fraction of the equationsin polynomial time, which is essentially the best possible unless NPBQP.
The importance of this result is not that anyone cares about the MAX E3LIN2 problem for its own sake. Rather itsthat, as far as I know, this is the first time that a quantum algorithm has been proved to achieve a better approximation ratio for a natural NP-hard optimization problem than the best known classical algorithm achieves. People have discussed that as a hypothetical possibility for 20 years, but (again, unless Im missing something) we never had a good example until now. The big question now is whether the 1/2+c/D3/4performance can be matched classically, or whether there trulyis an NP-intermediate region of this optimization problem where quantum outperforms classical. (The third possibility, that doing as well as the quantum algorithm is already NP-hard, is one that I wont even speculate about. For, as Boaz Barak rightly points out in the comments section, the quantum algorithm is still being analyzed only in the regime where solutions are combinatorially guaranteed to existand that regime cant possibly be NP-hard, unless NP=coNP.)
[Above, I corrected some errors that appeared in the original version of this postthanks to Ed Farhi and to the commenters for bringing them to my attention.]

Update (Feb. 3, 2015): Boaz Barak has left the following comment:
in a work with Ankur Moitra, Oded Regev, David Stuerer and Aravindan Vijayaraghavan we were able to match (in fact exceed) the guarantees of the Farhi et al paper via a classical efficient algorithm. (Namely satisfy 1/2 + C/D fraction of the equations).  p.s. we hope to post this on the arxiv soonBarbeque ribs and AWPP forever

Lance has announced, completely unexpectedly, that he is ending his blog.  In shock and sadness, I posted the following comment, which I thought I should share here as well.
No, Lance, no  tell me it isnt true! Yours was the first blog I ever read. That familiar puke-green background was my rock, my North Star, in the vast and ever-shifting blogosphere. Your invitation to have me guest-blog gave me my first taste of being flamed by angry commenters  thereby leading directly to Shtetl-Optimized, where I get to repeat that same masochistic experience every single day.
The burden youve placed on my shoulders  and Lucas, and Dave Bacons, etc.  is an extremely heavy one.
Lance, we will miss you (turn speakers on before clicking the link).

To honor Lances blogs memory, the background of my own blog will temporarily be puke-green as well.BQP/LHC collision

This afternoon, Igavemy usual spiel aboutQuantum Computing and the Limits of the Efficiently Computableat the CERN Colloquium. (If you watched the webcast of the Higgs boson discovery announcement a couple years ago, it was in the same auditorium they used for that, except this time it was less packed.) Beforehand, Dana and I got to join a tour of the CMS detector at the Large Hadron Colliderone of the very lasttours, before CMS shuts down (as ATLAS already has) to get ready forcollisions at the LHCs new, higher energy.
Considered as eye candy, Id say that the CMS detector holds its own against the Taj Mahal, Machu Picchu, the Great Wall of China, or any of the other engineering marvelsof the world. So, OK, let me describe what its like to visit it. The first step is to take a tram from downtown Geneva to CERN, which is headquartered inthe town of Meyrin. This is easier than youd imagine: a tram actually arrives in Geneva every few minutes with CERN (its final stop) written right on it! Next you take a 20-minute bus ride from the CERN reception hall to the CMS building, which is across the French border. You dont really think about it until youre here, but:
(a) The Large Hadron Collider is largeits, like, a whole drive through the countryside to get from the main CERN buildings to CMS.
(b) All inside the LHC ring is just a normal rural/suburban area, with restaurants, roads, gas stations, cows, etc.
Anyway, then you arrive at CMS, which looks from the outside like just a big warehouse-type building.

And you go inside, wondering if now youre going to see the detector. But no, theres just a giant tarp hanging from the ceiling with a picture of the detector on it. Maybe this tour wont include the detector?

But then you go outside, back in through some back entrance, then into a staging area where you get hard hats to wear. Then you get into an elevator that goes about 150 feet down. Meanwhile, your tour guide is carrying a geiger counter to make sure youre not exposed to too much radiation. Now will you see the detector? No, just a bunch of dark corridors. You pass through a room full of computers on rackscool, this must bewhere they analyze the collision data! (Actually, according to Panflutist in the comments section, these computers are only for control and for the trigger system, which decides which events to store for later analysis.)

Then, afterthat room, theres a door with a sign indicating that beyond it isthe LHC ring. Cool!

Of course, youre not actually going into the ring. But then you turn a different way, and emerge onto a platform where you to get to the big reveal: the detector, two giant circular pieces that obviously screw together but are now separated, and engineers making final tweaks to them before theyre reunited for the next collider run. (I forgot to mention: the whole tour is being conducted in French. Thats why you sort of need to guess whats happening.)
Anyway, thanks so much to Wolfgang Lerche and everyone else at CERN for an awesome visit.A hole in the web

The sun rose this morning on a radically transformed blogosphere: sparser, emptier, populated by only one Cornell-educated prover of complexity class inclusions and oracle separations from the Northeast US.
To everyone in the CS theory community, I want you to know that Im acutely aware of the central role that Lances weblog played for all of us; and the burden of somehow filling the void he left now weighs heavily on me.  To that end, Id like to offer you the following sneak preview of upcoming topics on Shtetl-Optimized.

Paper vs. Electronic Proceedings: The Debate Continues


Ordering of Authors: Who Should Go Third?


Greatest Hits of the 60s and 70s: Why Can One-Tape Turing Machines Polynomially Simulate Multitape Turing Machines?


Complexity Class of the Week:



Baseball and Complexity: They Might Not Seem Related, But They Are


Giving The Man His Due: Why We Should All Support Bush, Diebold, and Elsevier

Oh, who am I kidding?  I cant speak for the Establishment the way Lance could!  Having me serve as a clearinghouse for the theory community would be putting one of the very worst-behaved inmates in charge of the asylum.
So maybe I should just stick to biting vagina jokes.
OK, I will.  Without further ado, heres an article sent to me by my good friend Sharon Haiduck, about a South African company thats finally accomplished what a billion years of natural selection couldnt.The Republican Partys intellectual

The debate is over.  I mean, how many more thousands and thousands of scientists do we need to say, We have done a study that there is global warming?  I am here to make businesses boom, but lets also protect our environment. Lets make our air clean. Lets make our water clean. And lets fight global warming because we know now that this is a major danger, that this is not a debate anymore.
Addendum: Unfortunately Friedmans NYT column on the Rights scientific muscleman is only available to subscribers, so Ive quoted the relevant passages in the comments section.Happy Second Birthday Lily

Two years ago, I blogged when Lily was born. Today I canblog that she runs, climbs, swims (sort of),constructs 3-word sentences, demands chocolate cake, counts to 10 in both English and Hebrew, and knowscolors,letters, shapes, animals, friends,relatives, the sun, and the moon. To all external appearances shes now conscious as you and I are (and considerablymore so than the cat in the photo).
But the most impressive thing Lily doesthe thing that puts her farbeyond where her parents were at the same age, in a fewareasis her use of the iPad. There she does phonics exercises, plays puzzle games that arentalways trivial for me to win, and watches educationalvideos on YouTube (skipping past the ads, and complaining if the Internet connection goes down). She chooses theapps and videosherself, easily switching between them when she gets bored. Its a sight to behold, and definitelysomething to try with your own toddler if you have one. (Theres a movement these days that encourages parents to ban kids from using touch-screen devices, fearfulthat too much screen time will distract them from the real world. To which I reply: for better or worse, thisis the real world that our kidswill grow up into.)
People often ask whether Dana and I willsteer Lily into becoming a theoretical computer scientist like us. My answer ishell no: Ill supportLily in whatever she wants to do, whether that means logic, combinatorics, algebraic geometry, or even something further afield liketheoretical neuroscienceor physics.
As recent events illustrated, the world is not always the kindestplace for nerds (male or female), with our normal ways of thinking, talking, and interactingsometimes misunderstood by othersin the cruelest ways imaginable. Yet despite everything, nerds do sometimes manage to meet, get married, and even produce offspring with nerd potential of their own. Were here, were sometimesinappropriatelyclear, and were not going anywhere.
So to life! And happy birthday Lily!Quantum Computing Since Democritus Lecture 11: Decoherence and Hidden Variables

After a week of brainbreaking labor, here it is at last: My Grand Statement on the Interpretation of Quantum Mechanics.
Granted, I dont completely solve the mysteries of quantum mechanics in this lecture.  I didnt see any need to  since to judge from the quant-ph arXiv, those mysteries are solved at least twenty times a week.  Instead I merely elucidate the mysteries, by examining two very different kinds of stories that people tell themselves to feel better about quantum mechanics: decoherence and hidden variables.
But along the way, youre wondering, will Scott also touch on the arrow of time, the Second Law of Thermodynamics, Bells Inequality, the Kochen-Specker Theorem, the preferred-basis problem, discrete vs. continuous Hilbert spaces, and even the Max-Flow/Min-Cut Theorem?  Man oh man, is someone in for a treat.
I assume that, like Lecture 9, this will be one of the most loved and hated lectures of the course.  So bring it on, commenters.  You think I cant handle you?
Update (4/5): Peter Shor just posted a delightful comment that I thought Id share here, in the hope of provoking more discussion. 
Interpretations of quantum mechanics, unlike Gods, are not jealous, and thus it is safe to believe in more than one at the same time. So if the many-worlds interpretation makes it easier to think about the research youre doing in April, and the Copenhagen interpretation makes it easier to think about the research youre doing in June, the Copenhagen interpretation is not going to smite you for praying to the many-worlds interpretation. At least I hope it wont, because otherwise Im in big trouble.Quantum Machine Learning Algorithms: Read the Fine Print

So, Ive written a 4-page essay of that title, which examines the recent spate of quantum algorithms for clustering, classification, support vector machines, and other Big Data problems that grew out ofa2008 breakthroughon solving linear systems by Harrow, Hassidim, and Lloyd, as well as the challengesin applying these algorithms to get genuineexponential speedups over the best classical algorithms. An edited version of the essay will be published as a Commentary in Nature Physics. Thanks so much to Iulia Georgescu at Nature for suggesting that I write this.
Update (April 4, 2015): The piece has now been published.Quantum gravity computation: you, too, can be an expert in this field

I am, Im slightly embarrassed to admit, quoted pretty extensively in the cover story of this weeks New Scientist magazine (alas, only available to subscribers or those willing to shell out $4.95).  The story, by Michael Brooks, is about an interesting recent paper by Lucien Hardy of Perimeter Institute, on the power of quantum gravity computers. Luciens paper considers the following question: by exploiting quantum fluctuations in the causal structure of spacetime, can one efficiently solve problems that are not efficiently solvable with a garden-variety quantum computer?
As I told Brooks, I really do think this is a hell of a question, one thats intimately related to the challenge of understanding quantum gravity itself. The trouble is that, until an actual quantum theory of gravity chooses to make itself known to us, almost everything we can say about the question is pure speculation.
But of course, pure speculation is what New Scientist gobbles up with french fries and coleslaw. And so, knowing what kind of story they were going to run, I did my best to advocate giving reality at least a few column inches. Fortunately, the end result isnt quite as bad as Id feared.
(Full disclosure: recently New Scientist asked me to write an article for them on theoretical computer science breakthroughs of the last 30 years.  Remembering some of the steamers NS has unloaded in the recent past, I faced a moral dilemma for approximately five minutes. I then wrote back to them and said Id be delighted to do it.)
Anyway, here are a few relevant excerpts from the article. If New Scientist wants me to take these down, then of course Ill have to comply  though I imagine that being linked to from the 25,000th most popularest blog on the entire Internet could only boost their sales.

A NEW computer is always welcome, isnt it? Its always faster than your old one, and it always does more stuff. An upgrade, the latest model with all the bells and whistles is an exciting prospect.
And when it comes to the kind of machine physicists are hoping for, you really are looking at something special. No ordinary upgrade for them: this will be the ultimate computer, and radically different from anything we have ever seen. Not only might it be supremely powerful, defying the logic of cause and effect to give instantaneous answers, it might also tell us exactly how the universe works. It might even tell us how our minds produce the phenomenon we call consciousness. Clear a space on your desk, then, for the quantum gravity computer.
Of course, theres a chance it may not fit on your desktop because we dont yet know what the machine will look like. Neither do we know how to build it, or even whether it will do all that its proponents hope. Nevertheless, just thinking about how this processor works could improve our understanding of the universe. The power of quantum gravity computers is one of the deepest problems in physics, says Scott Aaronson, a mathematician based at the University of Waterloo in Ontario, Canada.

Put [quantum theory and general relativity] together to make a quantum theory of gravity and it is almost inevitable that we are going to have trouble with notions of cause and effect: the logic of tock following tick or output following input just wont apply in the quantum-gravity universe.

Aaronson agrees with Hardy. General relativity says that the causal structure can vary, and quantum mechanics says that anything that can vary can be in superposition, he says. So to me, an indefinite causal structure seems like the main new conceptual feature.

The big question is how powerful [a quantum gravity computer] could be: will it be the ultimate processor?
It turns out this is a hard question to answer. Traditionally, a computers power is rated by the number of computations it can do in a given time. IBMs Blue Gene computer currently tops the world rankings for classical computers: it can do 280 trillion calculations per second. In theory, a quantum computer can do even better. It will be able to crack the worlds toughest codes in the blink of an eye.
The quantum gravity computer, on the other hand, cant compete under these rules because quickly doesnt mean anything in a scheme where space and time cant be separated. Or, as Aaronson puts it: It would be nice if the quantum gravity theorists could at least tell us what they mean by time.
Nevertheless, Hardy thinks there is good reason to suppose the quantum gravity computer would indeed be a more powerful machine than anything we have so far envisioned. The fact that it might glimpse its results without running a computation hints at this, he says  though he admits this is just speculation.
Whats more convincing, he says, is the difficulty of simulating a quantum gravity computer on a quantum computer. The fact that we have no algorithm for simulating quantum systems on classical computers highlights the gulf between a classical computer and a quantum computer. If a quantum computer cannot simulate a quantum gravity computer, then that implies there might be another huge leap in computing power waiting to be exploited.

It is a controversial conclusion, though. Seth Lloyd of the Massachusetts Institute of Technology thinks there is no reason to invoke a discontinuity that separates quantum gravity from more familiar processes  Aaronsons money is on the Lloyd camp: quantum gravity computers cant be more powerful than quantum computers, he says. In his view, it is a short step from ultra-powerful quantum gravity computers to total cosmic anarchy. If, as Hardy suggests, a quantum gravity computer might be able to see its result without having to run its algorithms, it is essentially no different to having a quantum computer strapped to a time machine. As we all know, time machines dont make sense: they would enable us to do things like travel back in history to kill our grandparents and thereby cease to exist. Its hard to come up with any plausible way to make quantum computers more powerful that wouldnt make them absurdly more powerful, he says.

Whatever the truth, this is why investigating the characteristics of the quantum gravity computer is so valuable. It ties theories to the real world, Aaronson says, and stops the important issues, such as a link with observable facts or staying within the bounds of whats physically possible, from being swept under the carpet. After all, a computer has to produce an observable, measurable output based on an input and a known set of rules. The connection to observation is no longer a minor detail, Aaronson says. Its the entire problem.

Two obvious corrections:

I certainly dont think that quantum gravity computers cant be more powerful than ordinary quantum computers. What I think is that, at the moment, theres no good evidence that they would be.
I am not a mathematician.

Update: Six months ago, New Scientist ran a credulous, uncomprehending story about a rocket propulsion system that flagrantly violates conservation of momentum (!). This led to interesting discussions here, here, and here about what can be done to improve the magazines standards.  If you enjoyed the D-Wave fiasco, youll also like the spectacle of commenters rushing to defend the article against those elitist, ivory-tower academics with their oh-so-sacred conservation laws. In a world of Homer Simpsons, its not easy being a Lisa.Oh, Canada

A headline in yesterdays Toronto Sun:
TWO MORE SHOT DEAD
Grim Rexdale total at three as bloody weekend ends citys month of gun-death peace
It occurred to me that in the US, the headline would be a bit different:
A MIRACLE
In a city of 2.5 million inhabitants, an entire month with no gun homicidesPhysics for Doofuses: Understanding Electricity

Welcome to an occasional new Shtetl-Optimized series, where physicists get to amuse themselves by watching me struggle to understand the most basic concepts of their discipline.  Ill consider my post  on black hole singularities to be retroactively part of this series.
Official motto: Because if I talked about complexity, you wouldnt understand it.
Unofficial motto: Because if I talked about climate change, Id start another flamewar  and as much as I want to save civilization, I want even more for everyone to like me.
Todays topic is Understanding Electricity. First of all, what makes electricity confusing?  Well, besides electricitys evil twin magnetism (which well get to another time), what makes it confusing is that there are six things to keep track of: charge, current, energy, power, voltage, and resistance, which are measured respectively in coulombs, amps, joules, watts, volts, and ohms.  And I mean, sure you can memorize formulas for these things, but what are they, in terms of actual electrons flowing through a wire?
Alright, lets take em one by one.
Charge is the q in kqq/r2.  Twice as many electrons, twice as much charge.  Nuff said.
Current is charge per unit time.  Its how many electrons are flowing through a cross-section of the wire every second.  If youve got 100 amps coming out, you can send 50 this way and 50 that way, or  this way and 100- that way, etc.
Energy  Alright, even I know this one.  Energy is what we fight wars to liberate. In our case, if you have a bunch of electrons going through a wire, then the energy scales like the number of electrons times the speed of the electrons squared.
Power is energy per unit time: how much energy does your appliance consume every second?  Duh, thats why a 60-watt light bulb is environmentally-friendlier than a 100-watt bulb.
Voltage is the first one I had trouble with back in freshman physics.  Its energy per charge, or power per current.   Intuitively, voltage measures how much energy gets imparted to each individual electron.  Thus, if you have a 110-volt hairdryer and you plug it into a 220-volt outlet, then the trouble is that the electrons have twice as much energy as the hairdryer expects.   This is what transformers are for: to ramp voltages up and down.
Incidentally, the ability to transform voltages is related to why what comes out of your socket is alternating current (AC) instead of direct current (DC).  AC, of course, is the kind where the electrons switch direction 60 times or so per second, while DC is the kind where they always flow in the same direction.  For computers and other electronics, you clearly want DC, since logic gates are unidirectional.  And indeed, the earliest power plants did transmit DC.  In the 1890s, Thomas Edison fought vigorously against the adoption of AC, going so far as to electrocute dogs, horses, and even an elephant using AC in order to prove that it was unsafe.  (These demonstrations proved about as much as D-Waves quantum computer  since needless to say, one can also electrocute elephants using DC.  To draw any conclusions a comparative study is needed.)
So why did AC win?  Because it turns out that its not practical to transmit DC over distances of more than about a mile.  The reason is this: the longer the wire, the more power gets lost along the way.  On the other hand, the higher the voltage, the less power gets lost along the way.  This means that if you want to send power over a long wire and have a reasonable amount of it reach its destination, then you want to transmit at high voltages.  But high voltages are no good for household appliances, for safety and other reasons.  So once the power gets close to its destination, you want to convert back down to lower voltages.
Now, the simplest way to convert high voltages to low ones was discovered by Michael Faraday, and relies on the principle of electromagnetic induction.  This is the principle according to which a changing electric current creates a changing magnetic field, which can in turn be used to drive another current.  (Damn, I knew we wouldnt get far without bumping into electricitys evil and confusing magnetwin.)  And that gives us a simple way to convert one voltage to another  analogous to using a small, quickly-rotating gear to drive a big, slowly-rotating gear.
So to make a long story short: while in principle its possible to convert voltages with DC, its more practical to do it with AC.  And if you dont convert voltages, then you can only transmit power for about a mile  meaning that youd have to build millions of tiny power plants, unless you only cared about urban centers like New York.
Resistance is the trickiest of the six concepts.  Basically, resistance is the thing you need to cut in half, if you want to send twice as much current through a wire at the same voltage.  If you have two appliances hooked up serially, the total resistance is the sum of the individual resistances: Rtot = R1 + R2.  On the other hand, if you have two appliances hooked up in parallel, the reciprocal of the total resistance is the sum of the reciprocals of the individual resistances: 1/Rtot = 1/R1 + 1/R2.   If youre like me, youll immediately ask: why should resistance obey these identities?  Or to put it differently, why should the thing that obeys one or both of these identities be resistance, defined as voltage divided by current?
Well, as it turns out, the identities dont always hold.  That they do in most cases of interest is just an empirical fact, called Ohms Law.  I suspect that much confusion could be eliminated in freshman physics classes, were it made clear that theres nothing obvious about this Law: a new physical assumption is being introduced.  (Challenge for commenters: can you give me a handwaving argument for why Ohms Law should hold?  The rule is that your argument has to be grounded in terms of what the actual electrons in a wire are doing.)
Here are some useful formulas that follow from the above discussion:
Power = Voltage2/Resistance = Current2 x Resistance = Voltage x Current
Voltage = Power/Current = Current x Resistance = (Power x Resistance)
Resistance = Voltage/Current = Power/Current2 = Voltage2/Power
Current =  Power/Voltage = Voltage/Resistance = (Power/Resistance)
Understand? Really?  Take the test!
Update (4/16): Chad Orzel answers my question about Ohms Law.Memrefuting

(in which I bringthis blog back to the safe, uncontroversial territory of arguing with people who think they can solve NP-complete problems in polynomial time)
A few people have asked my opinion about memcomputing:a computing paradigm thats being advertised, by its developers, as a way to solve NP-complete problems in polynomial time. According to the paperMemcomputing NP-complete problems in polynomial time using polynomial resources and collective states,memcomputing is based on the brain-like notion that one can process and store information within the same units (memprocessors) by means of their mutual interactions. The authors are explicit that, in their view, this idea allows the Subset Sum problem to be solved with polynomial resources, by exploring all 2n possible subsets in parallel, and that this refutes the Extended Church-Turing Thesis. Theyve actuallybuilt memcomputersthat solve small instances of Subset Sum, and they hope to scale them up, though they mention hardware limitations that have made doing so difficultmore about that later.
A bunch ofpeople (on Hacker News, Reddit, and elsewhere) tried to explainthe problems with the Subset Sum claim when the above preprint was posted to the arXivlast year. However, an overlapping set of authors has now simply repeated the claim, unmodified, in afeature article in this months Scientific American. Unfortunately the SciAm article is behind a paywall, but heres the relevant passage:
Memcomputing really shows advantages when applied to one of the most difficult types of problems we know of in computer science: calculating all the properties of a large series of integers. This is the kind of challenge a computer faces when trying to decipher complex codes. For instance, give the computer 100 integers and then ask it to find at least one subset that adds up to zero. The computer would have to check all possible subsets and then sum all numbers in each subset. It would plow through each possible combination, one by one, which is an exponentially huge increase in processing time. If checking 10 integers took one second, 100 integers would take 1027 secondsmillions of trillions of years  [in contrast,] a memcomputer can calculate all subsets and sums in just one step, in true parallel fashion, because it does not have to shuttle them back and forth to a processor (or several processors) in a series of sequential steps. The single-step approach would take just a single second.
For those tuning in from home: in theSubset Sum problem, were given n integers a1,,an, and we want to know whether there exists a subset of them that sums to a target integer k. (To avoid trivializingthe problem, either k should be nonzero or else the subset should be required to be nonempty, a mistakein the passage quoted above.)
To solve Subset Sum in polynomial time, the basic idea of memcomputing is to generate waves at frequencies that encode the sums of all possible subsets of ais, and then measure the resulting signal to see if theres a frequency there that corresponds to k.
Alas, theres aclear scalability problem that seems to me to completely kill this proposal, as a practical way of solving NP-complete problems. The problem is that the signal being measured is (in principle!) a sum of waves of exponentially many different frequencies. By measuring this wave and taking a Fourier transform, one will not be able to make out the individual frequencies until one has monitored the signal for an exponential amount of time. There are actually two issues here:
(1) Even if there were just a single frequency, measuring the frequency to exponential precision will take exponential time. This can be easily seen by contemplating even a moderately large n. Thus, suppose n=1000. Then we would need to measure a frequency to a precision of one part in ~21000. If the lowest frequency were (say) 1Hz, then we would be trying to distinguish frequencies that differ by far less than the Planck scale. But distinguishing frequencies that close would require so much energy that one would exceed the Schwarzschild limit and create a black hole! The alternative is to make the lowest frequency slower than the lifetime of the universe, causing an exponential blowup in the amount of time we need to run the experiment.
(2) Because there are exponentially many frequencies, the amplitude of each frequency will get attenuated by an exponential amount. Again, suppose that n=1000, so that were talking about attenuation by a ~2-1000 factor. Then given any amount of input radiation that could be gathered in physical universe, the expected amount of amplitude on each frequency would correspond to a microscopically small fraction of 1 photon  so again, it would take exponential time for us to notice any radiation at all on the frequency that interests us (unless we used an insensitive test that was liable to confuse that frequency with many other nearby frequencies).
What do the authors have to say about these issues? Here are the key passages from the above-mentioned paper:
all frequencies involved in the collective state (1) are dampened by the factor2-n. In the case of the ideal machine, i.e., a noiseless machine, this would not represent an issue because no information is lost. On the contrary, when noise is accounted for, the exponential factor represents the hardest limitation of the experimentally fabricated machine, which we reiterate is a technological limit for this particular realization of a memcomputing machine but not for all of them 
In conclusion we have demonstrated experimentally a deterministic memcomputing machine that is able to solve an NP-complete problem in polynomial time (actually in one step) using only polynomial resources. The actual machine we built clearly suffers from technological limitations due to unavoidable noise that impair [sic] the scalability. This issue can, however, be overcome in other UMMs [universal memcomputing machines] using other ways to encode such information.
The troubleis that no other way to encode such information is ever mentioned. And thats not an accident: as explained above, when n becomes even moderately large, this is no longer a hardware issue; itsa fundamental physics issue.
Its important to realize that the idea of solving NP-complete problems in polynomial time using an analog device is far from new: computer scientists discussed such ideas extensively in the 1960s and 1970s. Indeed, the whole point of my NP-complete Problems and Physical Reality paperwas to survey the history of such attempts, and (hopefully!) to serve as a prophylactic against people making more such attempts without understanding the history. Forcomputer scientistsultimately came to realize that all proposals along these lines simply smuggle the exponentiality somewhere that isnt being explicitly considered, exactly like all proposals for perpetual-motion machines smuggle the entropy increase somewhere that isnt being explicitly considered. The problem isnt a practical one; its one of principle. And I find itunfortunate that the recentmemcomputing papersshow no awareness of this story.
(Incidentally, quantum computing is interesting precisely because, out of all post-Extended-Church-Turing computing proposals, its the only one for which wecant articulate a clear physical reason why it wontscale, analogous to the reasons given above for memcomputing. With quantum computing the tables are turned, withthe skeptics forced to handwave about present-day practicalities, while the proponents wield the sharp steel of accepted physical law. But as readers of this blog well know, quantum computing doesnt seemto promise the polynomial-time solution of NP-complete problems, only of more specialized problems.)My job situation

A lot has happened this past week concerning my job prospects for next year.  I didnt want to comment on the situation while it was still in flux, but now that the options are all on the table, I might as well let people know, and solicit advice about what to do.
First the bad news: against my and many other peoples expectations, I will not be starting a tenure-track position in CS this coming fall.  Several of my interviews were cancelled, while at the schools where I did interview, Ive been told that other candidates were chosen.  Again and again I heard the same story: that while there was initially strong support for my application (particularly among theorists), concerns had arisen about some of my extra-academic activities.
A phone conversation last night, with someone Ill call Prof. X from University Y, was typical.  Prof. X started by explaining that, while the whole blog phenomenon had passed by him personally, some questions had come up during a hiring committee meeting with the more junior faculty  and, to get straight to the point, was it true that I wrote one of these blogs myself?
Yes, I said.
And was it true that this blog was known, in large part, for a debate about battling vaginas?
Biting vaginas, I corrected him.
And was it also true that I made frequent pronouncements about C*-algebras, modern art, and even string theory and loop quantum gravity, despite knowing next to nothing about any of these things?
Yes, I said.
And was it also true that, in the past few days, Id spent much of my time defending the General Theory of Relativity against someone who calls himself assman?
Yes, I said.
Prof. X said he hoped Id understand that, as far as he was concerned, I could write whatever I damn well pleased, but that, in an age of increasing sensitivities, and particularly in the wake of the well-known Lubo Motl debacle at Harvard, concerns had naturally arisen over whether a department could afford to gamble on someone with an erratic personality.
As you can imagine, this was all pretty depressing and unexpected for me.  But I havent yet told you the second part of the story  which is that, over the last two days, some interesting new options have opened up.
On Thursday I got a call from Geordie Rose, asking whether I wanted to come work for D-Wave Systems in Vancouver.  He said D-Wave had been stung by the criticism from experts following its announcement of the worlds first commercial quantum computer, and wanted to prevent a recurrence.  So their idea was to hire an in-house skeptic, similar to the white hats hired by computer security companies to try and break their systems.  I told Geordie Id think about it, but that it mostly just depended on what sort of compensation package they could put together.
Meanwhile a second option has come up.  Yesterday I got a call from the provost at Maharishi University of Management in Fairfield, Iowa, who wanted to know if Id come to MUM to jump-start their quantum computing group.  Apparently the Maharishi  himself recently came across my paper on NP-complete Problems and Physical Reality, and, based on its contents, thought Id make a perfect fit for MUMs physics department. In particular, he wants me to lead a new project on whether NP-complete problems can be solved in polynomial time via NDTM (Nondeterministic Transcendental Meditation), thereby  as I wrote in the paper  making humanity one with God.  The provost also reminded me that all the food at MUM is organic and vegetarian, so I wouldnt have to worry about pork.
I have mixed feelings about all of this.  On the one hand, Ive been on a conventional academic track my whole life, so leaving that behind will be a big adjustment for me.  On the other hand, perhaps this is a decision I already made a while ago  specifically, the moment I started this blog.How can we fight online shaming campaigns?

Longtime friend and colleague Boaz Barak sent me a fascinating New York Times Magazine articlethat profiles peoplewho losttheir jobs or otherwise had their lives ruined,because of a single remarkthat then got amplified a trillionfold in importance by social media. (The author, Jon Ronson, also has a forthcoming book on the topic.) The articleopens with Justine Sacco: a woman who, about to board a flight to Cape Town, tweeted Going to Africa. Hope I dont get AIDS. Just kidding. Im white!
To the few friends who read SaccosTwitter feed, it wouldve been obviousthat she was trying to mock the belief of many well-off white people that they live in a bubble, insulated from the problems of the Third World; she wasnt actually mocking black Africans who suffer from AIDS. In a just world, maybe Saccodeserved someone to take her aside and quietly explain that hertweetmight be read the wrong way, that she should bemore careful next time. Instead, by the time she landed in Cape Town, she learned that shed become the #1 worldwide Twitter trendand a globalsymbol of racism. She lost her career, she lost her entireprevious life, and tens of thousands of people expressed glee about it. The article rather heartbreakingly describes Saccosattempts to start over.
There are many morestories like the above. Some Id already heard about: the father of threewho lost his job after he whispered a silly joke involving dongles to the person next to him at a conference, whereupon Adria Richards, a woman in front of him, snapped his photo and posted it to social media, to make an example of him as a sexist pig. (Afterwards, a counter-reaction formed, which successfully gotRichardsfired fromher job: justice??) Other stories I hadnt heard.
Reading this article made it clear to me just how easilyI got off, in my own recent brush with the online shaming-mobs. Yes, I made the mistake of writing too openlyabout myexperiencesas a nerdy male teenager, and the impact that one specificaspectof feminist thought (not all of feminism!) had had on me. Within the context of the conversationthata few nerdy men and women werehaving on this blog, my opening upled to exactly the results I was hoping for: readers thoughtfully sharingtheir own experiences, ameaningfulexchange of ideas, even (dare I say it?) glimmers of understanding and empathy.
Alas, once the comment was wrestedfrom its original setting into the clickbait bazaar, the story became MIT professor explains: the real oppression is having to learn to talk to women (the title of Amanda Marcottes hit-piece, somethingeven someinMarcottes ideologicalcamp calledsickeningly cruel). My photowas on the front page of Salon, next to the headline The plight of the bitter nerd. I was subjectedto hostile psychoanalysis not once but twiceon Dr. Nerdlove, a nerd-bashingsite whose very name drips with irony, ratherlike the Democratic Peoples Republic of Korea. There were tweets and blog comments that urgedMIT to fire me, that compared me to a mass-murderer, and that deduced (from first principles!) all the ways in which my parents screwed upin raising meand my female students cower in fear of me. And yes, when you Google me, this affair now more-or-lessovershadows everything else Ive done in my life.
But then there were alsohundreds of men and womenwho roseto my defense, and they were heavily concentrated among the people I most admire and respect. My supportersranged fromtheactual female students who took my classes or worked with me or who I encouraged in their careers, from whom there was only kindness, not a single negativeword; to the shy nerds who thanked me for being one of the onlypeople to acknowledge their reality;to the lesbians and bisexual women who told memy experience also resonated with them; to the female friends and colleagues who sent me notes urging me to ignore the nonsense. In the end, not only have I not lost any friends over this, Ive gained new ones, and Ive learned new sides ofthe friends I had.
Oh, and I didnt getany death threats: I guess thats good! (Once in my life I did get death threatsgraphic, explicit threats, about which I had to contact the policebut it was because I refused to publicize someones P=NP proof.)
Since I was away from campus when this blew up, I did feelsome fearabout the professional backlash that would await me on my return. Would my office be vandalized? Would activistgroupsbe protestingmy classes? Would MIT police be theretoescort me from campus?
Well, you want to know what happened instead? Students and colleagues have stopped me in the hall, or come by my office, just to say they support me. My class has record enrollment this term. I was invited to participate in MITs Diversity Summit, since the organizers feltit would mean a lotto the students to see someone there who had opened up about diversity issues in STEM in such a powerfulway. (I regretfully had to decline, since the summit conflicted with a trip to Stanford.) And an MIT graduate womens reading group invited me for a dinnerdiscussion(at my suggestion, Laurie Penny participated as well). Imagine that: not only are MITs womens groupsnot picketing me,theyre inviting me over fordinner! Is there any better answerto the claim, urged on me by some of my overzealous supporters, that the bile of Amanda Marcotterepresents all of feminism these days?
Speaking of which,I met Laurie Penny for coffee last month, and she and I quickly hit it off. Weve evenagreed to write a joint blog post about our advice for shy nerds. (In my What I Believe post, I had promised a post of advice for shy female nerdsbut at Lauries urging, were broadening the focus to shy nerds of both sexes.) Even though Lauriesessayis the thingthat brought me to the attention of the Twitter-mobs (which wasnt Lauries intent!), and even though I disagreed with several pointsin heressay, I knew on reading itthat Laurie was someone Id enjoytalking to. Unlike so muchwriting byonline social justice activists, whichtends to be encrusted with the specializedtechnical terms of that fieldyou know, terms like asshat, shitlord, douchecanoe, and precious feefees of entitled white dudesLauries prose shone withhumanity and vulnerability: her own, which she freely shared, and mine, which she generouslyacknowledged.
Overall, the response to my comment has never made me happier or more grateful to be part of the STEM community (I never liked the bureaucratic acronym STEM, but fine, Ill own it). To many outsiders, we STEM nerds are a sorry lot: were sperglords (yes, slurs are fine, as long as theyre directed against the right targets!) who might be competent in certain narrow domains, but who lack empathy and emotional depth, and are basically narcissistic children. Yet somehow when the chips were down, its my fellow STEMnerds,and people who hang out with STEMnerdsa lot, who showed me farmoreempathy and compassion than many of the normals did. So if STEM nerds are psychologically broken, then I say: may I surround myself, for the restof my life, with men and womenwho are psychologically broken likeI am. May Iraise Lily, and any future children I have, to be as psychologically broken as they can be. And mayI stay as far as possible from anyone whos too well-adjusted.
I reserve my ultimategratitude for the many women in STEM, friends and strangers alike, who sent memessagesof support these past two months. Im not ashamedto say it:witnessinghow so many STEM women stood up for me has made me want to stand up for them, even more than I didbefore. If theyre not called on often enough in class, Ill call on them more. If theyre subtly discouraged from careers in science, Illblatantlyencourage them back. If theyre sexually harassed, Ill confront their harassers myself (well, if asked to). I will listen to them, and I will try to improve.
Is it selfish that I want to helpfemale STEM nerds partlybecause they helpedme? Heres the thing: one ofmy deepest moralbeliefs is in the obligationto fight for those among the disadvantaged whodont despise you, and who wouldnt gladly rid the planetof everyone like you if they could. (As Ive written before, on issue after issue, this belief makes me a left-winger by American standards, and a right-winger by academic ones.) In the present context, Id say I havea massive moral obligation toward female STEM nerds and toward Laurie Pennys version of feminism, and none at all toward Marcottes version.
All thisis just to say thatIm unbelievably luckyprivileged(!)to havehad so many at MIT and elsewhere willing to stand up forme, and to havereached in a stage in life where Im strong enough to say what I thinkand to weather anything theInternet says back. What worries me is that others, more vulnerable, didnt and wont have it as easy when the Twitter hate-machine turns its barrel on them. So in the rest of this post,Id like to discuss the problem ofwhat to do about social-media shaming campaigns that aim to, and do, destroythe lives of individuals. Im convinced that this is a phenomenonthats only going to get more and more common: somethingsprung on us faster than our social norms have evolved to deal with it. And it would be nice if we could solve itwithout having to wait for a few high-profile suicides.
But first, let me address a few obvious questions about why this problem is even a problem at all.
Isntsocial shaming as old as society itselfand permanent records of the shaming as old as print media?
Yes, but theres also something fundamentally new about the problem of the Twitter-mobs. Before, it would take someonesay, a newspaper editorto make a conscious decision to the effect, this comment is worth destroying someones life over. Today, there mightbe such an individual, but its also possible for livesto be destroyedin a decentralized, distributed fashion, with thousands of Twitterers collaborating to push a non-story past the point of no return. And among the people who break the story, not one has tointendto ruin the victims life, or acceptresponsibility for it afterward: after all, each one made the story only bigger than it already was. (Incidentally, this is one reason why I havent gotten a Twitter account: whileit has manyworthwhileuses, its also a medium that might as well have beendesigned for mobs, for ganging up, for status-seekingamongallies strippedof rational arguments. Its like the worlds biggest high school.)
Dont some targets of online shaming campaigns, yknow, deserveit?
Of course! Some aregenuineracists or misogynists or homophobes,who once wouldve been able to inflict hatred their entirelives without consequence, and were only brought down thanks to social media. The trouble is, the participants in online shaming campaigns willalwaysthinktheyre meting out righteous justice, whether they are or arent. Buttheres an excellent reason why weve learned in modern societies not to avengeeven the worst crimes vialynch mobs. Theres a reason why we have trials and lawyers and the opportunity for the accused to showtheir innocence.
Some might say that no safeguards are possible or necessary here, since were not talking about state violence, just individualsexercising their free speech right to vilifysomeone, demandtheir firing, that sort of thing. Yet in todays world, trial-by-Internet can be more consequentialthan the old kind of trial: would you rather spend a yearin jail,butthen be freeto move to another town where no one knew about it, or have your Google search results tarnished with lurid accusations (lets say, that you molested children) for the restof your lifeto have that forever prevent you from getting a job or a relationship, and have no way to correct the record? With trial by Twitter,theres no presumption of innocence, no requirement to provethat any otherparty was harmed, just the law of the schoolyard.
Whether shaming is justified in a particular case is a complicated question, but for whatever its worth, here are a fewof the questions I would ask:

Did the person express a wish for anyone (or any group of people) to come to harm, or for anyones rights to be infringed?
Did the person express glee or mockery about anyone elses suffering?
Did the person perpetrate a grievous factual falsehoodlike, something onecould prove was a falsehood in a court of law?
Did the person violate anyone elses confidence?
How muchdoes the speakers identity matter? If it had been a man rather than a woman (or vice versa) saying parallelthings, would we have taken equal offense?
Does the comment have what obscenity law calls redeeming social value? E.g., does it express an unusual viewpoint, or lead to an interesting discussion?

Of course, even in those cases where shaming campaigns are justified, theyll sometimesbe unproductive and ill-advised.
Arent societys mostpowerful fair targets for public criticism, even mocking or vicious criticism?
Of course. Few would claim, for example, that we have an ethicalobligation to ease up onTodd Akin over his legitimate rape remarks, since all the rage mightgive Akin an anxiety attack. Completely apart from the (de)merits of the remarks, we accept that, when you become (lets say) an elected official, a CEO, or a university president, part of the bargain is that you no longerget to complain ifpeople organize to express their hatred of you.
But whats striking about the cases in the NYT article is that itsnot public figures being gleefully destroyed: just ordinary people who in most cases, made one ill-advised joke or tweet, no worse than countless things you or I have probablysaid in private among friends. The social justice warriors try to justify what would otherwise look like bullying by shifting attention away from individuals: sure, Justine Sacco might be a decentperson, but she stands forthe entire category ofupper-middle-class, entitled white women, a powerful structural force against whom the underclass is engaged in a righteous struggle. Like in a war, the enemy must be fought by any means necessary, even if it means picking off one haplessenemy foot-soldier to make anexample tothe rest. And anyway, why do you care more about this one professional white woman, than about the millions of victims of racism? Is it because youre a racist yourself?
I find this lineof thinking repugnant. For it perverts worthy struggles for social equality into something callous and inhuman, and thereby undermines the struggles themselves. It seems to me to haveroughly the same relation to real human rights activism as the Inquisition did to the ethical teachings of Jesus. Its also repugnant because of its massivechilling effect: watching a few shaming campaignsis enough to make even the most well-intentioned writerwant to hide behind a pseudonym, or only offer those ideas and experiences that are sureto win approval. Andthe chilling effect isnot some accidental byproduct; its the goal. This negates what, for me, is a large part of the promise of the Internet: that if people from all walks of life can just communicate openly, everything made common knowledge, nothing whispered or secondhand, thenall the well-intentionedpeople willeventually come to understand each other.

If Im right that online shaming of decentpeople is a realproblem thats only going to get worse, whats the solution? Lets examine five possibilities.
(1) Libel law. For generations, libel has been recognized as one of the raretypes of speech that even a liberal, democratic society can legitimately censor (along with fraud, incitement to imminent violence, national secrets, childporn, and a few others). That libel is illegal reflects a realistic understanding of the importance of reputation: if, for example, CNN falsely reports that you raped your children, then it doesnt reallymatterif MSNBC later corrects the record; your life as you knew it is done.
The trouble is, its not clear how to apply libel law in the age of social media. In the cases were talking about, an innocent persons life gets ruinedbecause of the collective effect of thousands of people piling on to make nasty comments, and its neither possible nor desirable to prosecute all of them. Furthermore, in many cases the problem is not that the shamers said anything untrue: rather, its that they merely took something true andspitefullymisunderstood it, or blew it wildly, viciously, astronomically out of proportion. I dont see any legal remedies here.
(2) Shame the shamers. Some people will say the only answer is to hit the shamerswith their own weapons. If an overzealous activist gets an innocent jokesterfired from hisjob, shame the activist until shesfired from her job. If vigilantes post the jokesters home address on the Internet with crosshairs overlaid, find the vigilantes home addresses and post those. It probably wont surprise many people that Im not a fan of this solution. For it only exacerbatesthe realproblem: that of mob justice overwhelming reasoned debate. The most I can say in favor of vigilantism is this: you probably dont getto complain about online shaming, if what youre being shamed for is itself a shaming campaign that you prosecuted against a specific person.
(In a decade writing this blog, I can think of exactly one casewhere I engaged in what might be called a shaming campaign: namely, against the Bells inequality denier Joy Christian. Christian had provoked me over six years, not merely bybeing forehead-bangingly wrongabout Bells theorem, but by insulting me and others when we tried to reason with him, and by demanding prize money from me because he had proved that quantum computing was a fraud. Despite that, I still regret the shaming aspects of my Joy Christian posts, and will strive notto repeat them.)
(3) Technological solutions. We could try tochange the functioning of the Internet, to make it harder to use it to ruin peoples lives. This, more-or-less, is what the European Court of Justice was goingfor, with its much-discussed recent ruling upholding a right to be forgotten (more precisely, a rightforindividuals to petition forembarrassing information about them to be de-listedfrom search engines). Alas, I fear that the Streisand effect, the Internets eternal memory, and the existence of different countries with different legal systems will forever make a mockery of all such technological solutions. But, OK, given that Google is constantly tweaking its ranking algorithms anyway, maybe it could give less weight to cruel attacksagainst non-public-figures? Or more weight (or even special placement) to sites explaining how the individualwas cleared of the accusations? There might be scope for such things, but I have the strong feeling that they should be done, if at all, on a voluntary basis.
(4) Self-censorship. We could simplytrain people not to express any viewsonline that might jeopardize their lives or careers, or at any rate, not to express those views under their real names. Many people Ive talked to seem to favor this solution, but I cantget behind it. For it effectively cedes to the most militant activists the right to decide what is or isnt acceptable onlinediscourse. It tells them that they can use social shame as a weapon to get what they want. When women are ridiculed for sharing stories of anorexia or being sexually assaultedor being discouraged from careers in science, its reprehensible tosay that the solution is to teach those women to shut up about it. I not only agree with that but go further: privacy is sometimesimportant, but is also anoverrated value. The respect that onerational person affords another for openly sharingthe truth (or his or herunderstanding of the truth), in a spirit of sympathy and goodwill, is a higher value than privacy. And the Internets ability to foster that respect (sometimes!) is worth defending.
(5) Standing up. And so we come to the only solutionthat I can wholeheartedly stand behind. This is for people who abhor shaming campaigns to speak out, loudly, for those who are unfairly shamed.
Atthe nadir of my own Twitter episode, when it felt like my life was now finished, throw in the towel, the psychiatristScott Alexander wrote a 10,000-word essay in my defense, which also ranged controversially into numerous other issues. In a comment on his girlfriend Ozys blog, Alexander now says that he regrets aspects of Untitled (then again, it was already tagged Things I Will Regret Writing when he posted it!). In particular, he now feels thatthe piecewas too broadin its critique of feminism. However, he then explains as follows what motivated him to write it:
Scott Aaronson is one of the nicest and most decent people in the world, who does nothing but try to expand human knowledge and support and mentor other people working on the same in a bunch of incredible ways. After a lot of prompting he exposed his deepest personal insecurities, something I as a psychiatrist have to really respect. Amanda Marcotte tried to use that to make mincemeat of him, casually, as if destroying him was barely worth her time. She did it on a site where she gets more pageviews than he ever will, among people who dont know him, and probably stained his reputation among nonphysicists permanently. I know I have weird moral intuitions, but this is about as close to pure evil punching pure good in the face just because it can as Ive ever seen in my life. It made me physically ill, and I mentioned the comments of the post that I lost a couple pounds pacing back and forth and shaking and not sleeping after I read it. That was the place I was writing from. And it was part of what seemed to me to be an obvious trend, and although feminists vs. nerds is a really crude way of framing it, I couldnt think of a better one in that mental state and I couldnt let it pass.
I had three reactions on reading this. First, if there is a Scott in this discussion whos pure good, then its not I. Second, maybethe ultimate solution to the problem of onlineshamingmobs is to make a thousand copiesof Alexander, and give each one a laptop with an Internet connection. But third, as long as we have only one of him, the rest of us have a lot ofwork cut out for us. I know, without having to ask, that the only real way I can thank Alexander for coming to my defense, is to use this blog to defend otherpeople(anywhere on the ideologicalspectrum) who are attacked online for sharing in a spirit of honesty and goodwill. So if you encounter such a person, let me knowId much prefer that to letting me know about the latestattempt to solve NP-complete problems in polynomial time with some analog contraption.

Unrelated Update: Since I started this post with Boaz Barak, let me also point to his recent blog poston why theoretical computer scientists care so much about asymptotics, despite understandingfull well that the constants can overwhelm them in practice. Boazarticulatessomething that Ive tried to saymany times, but hescrisper and more eloquent.

Update (Feb. 27): Since a couple people asked, I explain here what I see as the basic problems with the Dr. Nerdlove site.

Update (Feb. 28): In the middle of this affair, perhaps the one thing that depressed me the most was Salons Plight of the bitter nerd headline. Random idiots on the Internet were one thing, but how could a serious, respectable magazine lend its legitimacy to such casual meanness? Ive now figured out the answer: I used to read Salon sometimes in the late 90s and early 2000s, but not since then, and I simply hadnt appreciated how far the magazine had descended into clickbait trash. Theres an amusing fake Salon Twitter account that skewers the magazine with made-up headlines (Ten signs your cat might be racist / Nerd supremacism: should we have affirmative action to get cool people into engineering?), mixed with actual Salon headlines, in such a way that it would be difficult to tell many of them apart were they not marked. (Indeed, someone should write a web app where you get quizzed to see how well you can distinguish them.) The plight of the bitter nerd is offered there as one of the real headlines thats indistinguishable from the parodies.Not an April Fools joke

Lances blog HATH RISEN! (Though ith now some fast-talking bearded guys blog.)The Man Who Tried to Redeem the World with Logic

No, Im nottalking about me!
Check out an amazing Nautilus article of that title by Amanda Gefter, afinescience writer of my acquaintance. The article tells the story of Walter Pitts, who [spoiler alert]grew up on the mean streets of Prohibition-era Detroit, discovered Russell and Whiteheads Principia Mathematica in the library at age 12 while hiding frombullies, corresponded with Russell about errors hed found in the Principia, then ran away from home at age 15, co-invented neural networks with Warren McCulloch in 1943, became the protg of Norbert Wiener at MIT, was disowned by Wiener because Wieners wife concocted a lie that Pitts and others who she hated had seduced Wieners daughter, and then became depressed and drank himself to death. Interested yet? Its not often that I encounter a piece of nerd history thats important and riveting and that had been totallyunknown to me; this is one of thetimes.
Update (Feb. 19): Also in Nautilus, you can check out a fun interview with me.
Update (Feb. 24):In loosely-related news, check out a rivetingprofile of Geoffrey Hinton (and more generally, of deep learning, a.k.a. re-branded neural networks) in the Chronicle of Higher Education. I had the pleasure of meeting Hinton when he visited MIT a few months ago;he struck me as an extraordinary person. Hat tip to commenter Chris W.D-Wave: Still propagating

Last night Jason Pontin, the Editor-in-Chief of MITs Technology Review, published a hard-hitting article about D-Wave, the Vancouver startup that claims to have built the worlds first commercial quantum computer.  A condensed (and, alas, considerably mangled and dumbed-down) version of his article will appear in Sundays New York Times.
Jason wrote to me a couple weeks ago and said that, while he knew that most journalists had gotten the D-Wave story wrong, he was determined to get it right, and wanted my help in understanding the computer-science issues.  He didnt have to ask me twice.
Since I come across as pretty harsh on D-Wave in the article, I think its worth recalling how we got to this point.  When the D-Wave story broke, my first reaction was to give them some benefit of the doubt (as you can see from the mild tone of my Orion Anti-Hype FAQ).  So what changed?  Well, four things:

I asked Geordie Rose (the founder of D-Wave and sometime commenter on this blog) twice for actual information about the speedup D-Wave claimed to be seeing over classical algorithms, and he never provided any.
Instead of answering my and others technical questions, D-Wave decided to attack academic science itself.  Heres what Herb Martin, the CEO of D-Wave, told an interviewer from ITworld: Businesses arent too fascinated about the details of quantum mechanics, but academics have their own axes to grind. I can assure you that our VCs look at us a lot closer than the government looks at the academics who win research grants.  The track record of companies that engage in this sort of behavior is not good.
I read article after article claiming that quantum computers can solve NP-complete problems in polynomial time.  I reflected on the fact that a single one of these articles will probably reach more people than every quantum complexity paper ever written.
It became clear, both from published interviews and from talking to Jason, that D-Wave was doing essentially nothing to correct journalists misconceptions about what sorts of problems are believed to be efficiently solvable by quantum computers.

Update (4/6): Geordie Rose has responded to me.  A few responses to his response:

I apologize for getting the CEOs name wrong.  Id originally written Herb Martin, but then noticed that the ITworld article referred to him as Ed Martin and therefore changed it.  This seems like another case where D-Wave has to work harder to correct journalists misconceptions!


In a discussion with Geordie on my blog, following my Orion Anti-Hype FAQ, I asked:
You say youre seeing a speedup in your experiments  but (1) how big of a speedup, and (2) do you mean compared to the best-known classical algorithms (like simulated annealing), or compared to brute-force search?
Then, in another discussion with Geordie following my Speaking truth to parallelism post, I asked him again:
Im certainly glad that youre not claiming an exponential speedup.  But at least based on the evidence I know about, whether youre seeing a quadratic speedup  or indeed any asymptotic speedup  is very much open to question. Hence the question I asked you earlier: have you compared the empirical scaling for your adiabatic algorithm to the empirical scaling for the best classical algorithms like simulated annealing? If so, what were the results?



Geordie now says that the only way scaling can be extracted is empirically, and we cant build big enough systems (yet) to answer scaling questions.  Thanks; thats actually extremely helpful to me.  I must have gotten a wrong impression from some of D-Waves previous statements.  For example, heres from D-Waves recently-released Introduction to Orion document (which now seems to be available for premium subscribers only):
Q: Are D-Wave processors quantum computers?
A: Yes.  We have determined that quantum effects are being harnessed to accelerate computation in our processors.
And heres from a comment on Dave Bacons blog (blog comments seem to be D-Waves preferred venue for announcing scientific results):
While the jury is still not in, our studies of these systems seem to indicate that AQCs, in the presence of thermal and spin bath environments, can still provide O(sqrt(N)) scaling even though the central QC system is definitely NOT a system thats globally phase coherent over the entire calculation.



The core of Geordies response is the following paragraph:
This is worth emphasizing, because I thought it was obvious, but it turns out alot of people dont get this.  Most of the poorly thought out comments related to what were trying to do have come from theoretical computer scientists, who assume that the things they hold dear are likewise treasured by everyone else. Because they worship efficiency, they have assumed thats the objective of our projects, when I have repeatedly said its not.
When I read this to Umesh Vazirani over the phone, he sardonically replied, it will be interesting to find out whats left of this field after youve removed the notion of efficiencyThe flow of emails within the block inbox

As a diversion from the important topics of shaming, anti-shaming, and anti-anti-shaming, I thought Id share a littleemail exchange (with my interlocutors kind permission), which gives a goodexample of what I find myself doing allday when Im not blogging, changing diapers, or thinking about possiblydoing some real work(but where did all the timego?).

Dear Professor Aaronson,
I would be very pleased to know your opinion about time. In a letter of condolence to the Besso family, Albert Einstein wrote: Nowhe has departed from this strange world a little ahead of me. That meansnothing. People like us, who believe in physics, know that the distinctionbetween past, present and future is only a stubbornly persistent illusion. Im a medical doctor and everyday I see times effect over human bodies. Is Einstein saying time is an illusion? For who believe inphysics is death an illusion? Dont we lose our dears and will theycontinue to live in an eternal world?
Is time only human perceptive illusion (as some scientists say physics has proved)?

Dear [redacted],
I dont read Einstein in that famous quote as saying that time itself is an illusion, but rather, that the sense of time flowing from past to present to future is an illusion. He meant, for example, that the differential equations of physics can just as easily be run backward (from future to past) as forward (from past to future), and that studying physics can strongly encourage a perspectivewhich philosophers call the block universe perspectivewhere you treat the entire history of spacetime as just a fixed, 4-dimensional manifold, with time simply another dimension in addition to the three spatial ones (admittedly, a dimension that the laws of physics treat somewhat differently than the other three). And yes, relativity encourages this perspective, by showing that different observers, moving at different speeds relative to each other, will divide up the 4-dimensional manifold into time slices in different ways, with two events judged to be simultaneous by one observer judged to be happening at different times by another.
But even after Einstein is read this way, Id personally respond: well, thats just one perspective you can take. A perfectly understandable one, if youre Einstein, and especially if youre Einstein trying to comfort the bereaved. But still: would you want to say, for example, that because physics treats the table in front of you as just a collection of elementary particles held together by forces, therefore the table, as such, doesnt exist? That seems overwrought. Physics deepens your understanding of the table, of courseshowing you what its microscopic constituents are and why they hold themselves togetherbut the table still exists. In much the same way, physics enormously deepened our understanding of what we mean by the flow of timeshowing how the flow emerges from the time-symmetric equations of physics, combined with the time-asymmetric phenomena of thermodynamics, which increase the universes entropy as we move away from the Big Bang, and thereby allow for the creation of memories, records, and other irreversible effects (a part of the story that I didnt even get into here). But it feels overwrought to say that, because physics gives us a perspective from which we can see the flow of time as emerging from something deeper, therefore the flow doesnt exist, or is just an illusion.
Hope that helps!
Best,
Scott

(followup question)
Dear Professor,
Ive been thinking about the block universe and it seems to me thatin it past,present and future all coexist. Soon the basis of Einsteins theory,do all exist eternally, and why do we perceive only the present?

(reply)
But you dont perceive only the present! In the past, you perceived whats now the past (and which you now remember), and in the future, youll perceive whats now the future (and which you now look forward to), right? And as for why the present is the present, and not some other point in time? Well, that strikes me as one of those questions like why youre you, out of all the possible people who you could have been instead, or why, assuming there are billions of habitable planets, you find yourself on earth and not on any of the other planets. Maybe the best answer is that you had to be someone, living somewhere, at someparticular point in time when you asked this questionand you couldve wondered the same thing regardless of what the answer had turned out to be.D-Wave Easter Spectacular

Look, I promise this will be the last D-Wave post in a while.  But there have been two developments that, as Planet Earths primary D-Wave skepticism clearinghouse, I feel a duty to report.
First, Jason Pontins article in the Sunday New York Times has appeared.  Its not perfect, but to get in a description of quantum computing that was even somewhat accurate required a long, word-by-word and phrase-by-phrase battle with the editors of the business section.
Second, Umesh Vazirani sent me a document summarizing the skeptical case against D-Wave, which anyone coming to this blog from the Tech Review or New York Times might find helpful.  (Hey, as long as youre here, stick around for a bit!)  Ive posted Umeshs criticisms below.
Finally, Happy Easter from all of us here in the shtetl!
Reasons To Be Skeptical About D-Waves Claims
by Guest Blogger Umesh Vazirani
1. An Unconvincing Demo: D-waves demo consisted of a computer in a box that could solve simple problems. We have no way of knowing whether the computer in the box was an ordinary classical computer or a quantum computer. For the problem the computer solves  finding ground states for 16 bit Ising problems  a classical computer would work just as quickly.  This demo is the only public evidence D-wave has presented in support of its claims.
2. A Physics Breakthrough?: Achieving 16 coherent superconducting quantum bits would be quite a breakthrough. Physicists working on superconducting qubits have not been able to achieve more than two coherent quantum bits in the lab. In the absence of evidence from D-Wave that their 16 qubits are coherent, scientists are understandably skeptical. If D-Waves qubits are not coherent, as many scientists suspect, their computer would be classical, not quantum. This would still be consistent with the results of the demo, since the decohering qubits would act like classical random bits, and the adiabatic computer would act like a classical computer implementing simulated annealing, which would be quite fast for a small 16 bit Ising problem. It is possible to test the quantum states of D-Waves computer for coherence, but Geordie Roses statements suggest that no such tests have been made.
3. Claims of Big Algorithmic Breakthrough Without Evidence: 16-bit quantum computers are useless from a practical standpoint because they can only solve very small problems that could just as easily be solved using a classical computer. Thus, D-Waves demo, even if it really was a quantum computer, will only be practically useful if the technology will scale to the larger problems that cannot be solved with a classical computer. Unless D-Wave has made a major algorithmic breakthrough as well as a major practical one, however, D-Waves computer, even if implemented with thousands of qubits, will not provide a speedup over classical computers. D-Wave does not implement a general purpose quantum computer, only one that can implement adiabatic optimization. They wish to use it to solve the Ising model, which is thought to be beyond the reach of classical computers, but there is no known efficient algorithm for solving the Ising model using this adiabatic approach. It is possible to achieve a quadratic speedup for unstructured search problems using adiabatic optimization, but that result requires an ability to tune the rate of the adiabatic process  something which appears to researchers to be extremely hard if not impossible for the Ising problem. Geordie Roses public statements suggest that he doesnt understand this issue, which makes computer scientists skeptical that any breakthrough has been made.
To summarize: For D-Wave to achieve a practically useful quantum computer using their technology, they would have to have made a breakthrough in physics, as well as a breakthrough in the design of their algorithm. Scientists are skeptical both because D-Wave has failed to provide any supporting evidence, and also because their public statements suggest a lack of understanding of the issues involved.
You might ask why researchers are putting so much energy into debunking the D-Wave hype. One reason is that QC researchers feel a responsibility to the public to not overhype quantum computers. Quantum computing is an exciting field that has caught the imagination of the public. This is a good thing. But if the quantum computing effort starts to mingle fact with fiction, then the entire effort loses its credibility.
Another reason is that D-Waves unsupported claims are undermining the efforts of the researchers who are working very hard on these problems. Its as if there was a new biotech company claiming to be at the brink of a revolutionary cure for cancer. If it is true, it is great, but if its not, then it undermines the efforts of the legitimate cancer researchers.The ultimate physical limits of privacy

Somewhat along the lines of my last post, the other day a reader sent me an amusing list of questions about privacy and fundamental physics. The questions, and my answers, are below.
1. Does the universe provide us with a minimum level of information security?
Im not sure what the question means. Yes, there are various types of information security that are rooted in the known laws of physicssome of them (like quantum key distribution) even relying on specific aspects of quantum physicswhose security one can argue for by appealing to the known properties of the physical world. Crucially, however, any information security protocol is only as good as the assumptions it rests on: for example, that the attacker cant violate the attack model by, say, breaking into your house with an ax!
2. For example, is my information safe from entities outside the light-cone I project?
Yes, I think its safe to assume that your information is safe from any entities outside your future light-cone. Indeed, if information is notin your future light-cone, then almost by definition, you had no role in creating it, so in what sense should it be called yours?
3. Assume that there are distant alien cultures with infinite life spans  would they always be able to wait long enough for my light cone to spread to them, and then have a chance of detecting my private information?
First of all, the aliens would need to be in your future light-cone (see my answer to 2). In 1998, it was discovered that theres a dark energy pushing the galaxies apart at an exponentially-increasing rate. Assuming the dark energy remains there at its current density, galaxies that are far enough away from us (more than a few tens of billions of light-years) will always recede from us faster than the speed of light, meaning that theyll remain outside our future light-cone, and signals from us can never reach them. So, at least youre safe from those aliens!
For the aliens in your future light-cone, the question is subtler. Suppose you took the only piece of paper on which your secrets were written, and burned it to ashnothing high-tech, just burned it. Then theres no technology that we know today, or could even seriously envision, that would piece the secrets together. It would be like unscrambling an egg, or bringing back the dead from decomposing corpses, or undoing a quantum measurement. It would mean, effectively, reversing the Arrow of Time in the relevant part of the universe. This is formally allowed by the Second Law of Thermodynamics, since the decrease in entropy within that region could be balanced by an increase in entropy elsewhere, but it would require a staggeringlevel of control over the regions degrees of freedom.
On the other hand, its also true that the microscopic laws of physics are reversible: they never destroy information. And for that reason, as a matter of principle, we cant rule out the possibility that some civilization of the very farfuture, whether human or alien, could piece together what was written on your paper even after youd burned it to a crisp. Indeed, with suchgodlike knowledge and control, maybe they could even reconstruct the past states of your brain, and thereby piece together private thoughts that youd never written anywhere!
4. Does living in a black hole provide privacy? Couldnt they follow you into the hole?
No, I would not recommend jumping into a black hole as a way to ensure your privacy. For one thing, you wont get to enjoy the privacy for long (a couplehours, maybe, for a supermassive black hole at the center of a galaxy?) before getting spaghettified on yourway to the singularity. For another, as you correctly pointed out, other people could still snoop on you by jumping into the black hole themselvesalthough theyd have to want badly enough to learn your secrets that they wouldnt mind dying themselves along with you, and also not being able to share whatever they learned with anyone outside the hole.
But a third problem is that even inside a black hole, your secrets might not be safe forever! Since the 1970s, its been thoughtthat all information dropped into a black hole eventually comes out, in extremely-scrambled form, in the Hawking radiation that black holes produce as they slowly shrink and evaporate. What do I mean by slowly? Well, the evaporation would take about 1070 years for a black hole the mass of the sun, or about 10100 years for the black holes at the centers of galaxies. Furthermore, even after the black hole had evaporated, piecing together the infalling secrets from the Hawking radiation would probably makereconstructing what was on the burned paper from the smoke and ash seem trivial by comparison! But just like in the case of the burned paper, the information is still formally present(if current ideas about quantum gravity are correct), so one cant rule out that it could be reconstructed by some civilization of the extremely remote future.The wisdom of Gian-Carlo Rota (1932-1999)

From www.rota.org:
Graph theory, like lattice theory, is the whipping boy of mathematicians in need of concealing their feelings of insecurity.
Mathematicians also make terrible salesmen. Physicists can discover the same thing as a mathematician and say Weve discovered a great new law of nature. Give us a billion dollars. And if it doesnt change the world, then they say, Theres an even deeper thing. Give us another billion dollars.
When an undergraduate asks me whether he or she should major in mathematics rather than in another field that I will simply call X, my answer is the following: If you major in mathematics, you can switch to X anytime you want to, but not the other way around.
Flakiness is nowadays creeping into the sciences like a virus through a computer system, and it may be the greatest present threat to our civilization. Mathematics can save the world from the invasion of the flakes by unmasking them, and by contributing some hard thinking. You and I know that mathematics, by definition, is not and never will be flaky.
Note: Quotation here does not necessarily imply endorsement by Shtetl-Optimized LLC or any of its subsidary enterprises.Two papers

Just to get myself back into the habit of blogging:
For those of you who dont read Lances and Bills blog, there was a pretty significant breakthrough in complexity theory announced last week. (And yes, Im now spending one of the two or so uses of the word breakthrough that I allow myself per yearwait, did I just spend the second one with this sentence?) Ben Rossman (aformer MIT PhD studentwhose thesis committee I was honored to serve on), Rocco Servedio, and Li-Yang Tan have now shown that the polynomial hierarchy is infinite relative to a random oracle, thereby solving the main open problem from Johan Hstads 1986 PhD thesis. While it feels silly even to mention it, the best previous result in this direction was to separate PNP from 2P relative to a random oracle, which I did in myCounterexample to the Generalized Linial-Nisan Conjecturepaper. In some sense Rossman et al. infinitely improve on that (using completely different techniques). Proving their result boils down to proving a new lower bound on the sizes of constant-depth circuits. Basically, they need to show that, for every k, there are problems that can be solved by small circuits with k layers of AND, OR, and NOT gates, but for which the answer cant even be guessed, noticeably better than chance, by any small circuit with only k-1 layers of AND, OR, and NOT gates. They achieve that using a new generalization of the method of random restrictions. Congratulations to Ben, Rocco, and Li-Yang!
Meanwhile, if you want to know what Ive been doing for the last couple months, one answer is contained in this 68-page labor of love preprint by me and my superb PhD students Daniel Grier and Luke Schaeffer. There we givea fullclassification of all possible sets of classical reversible gates acting on bits (like the Fredkin, Toffoli, and CNOT gates), as well as a linear-time algorithm to decide whether one reversible gate generates another one (previously, that problem wasnt even known to be decidable). We thereby completely answer a question that basicallyno one was asking, although I dont understand whynot.Is There Something Mysterious About Math?

When it rains, it pours: after not blogging for a month, I now have a second thing to blog about in as many days. Aeon, an online magazine, asked me to write a short essay responding to the question above, so I did. My essay is here. Spoiler alert: my thesis is that yes, theres something mysterious about math,butthe main mysteryis why there isnt evenmore mystery than there is. Alsoshameless attempt to get you to clickthe essay discussesthe discrete math is just a disorganized mess of random statementsview of Lubo Motl, whos useful for putting flesh on what mightotherwise be a strawman position. Comments welcome (when arent they?). You shouldalso readother interesting responses tothe same question by Penelope Maddy, James Franklin, and Neil Levy. Thanks very much to Ed Lake at Aeon for commissioning these pieces.

Update (4/22): On rereading my piece, I felt bad that it didnt make a clear enough distinction between two separate questions:

Are there humanly-comprehensible explanations for why themathematical statements that we care about are true or falsethereby rendering their truth or falsity non-mysterious to us?
Are there formalproofs or disproofs of the statements?

Interestingly, neither of the above implies the other. Thus, to take an example from the essay, no one has any ideahow to prove that the digits 0 through 9 occur with equal frequency in the decimal expansion of , and yet its utterly non-mysterious (at a physics level of rigor) why that particular statement should be true. Conversely, there are manyexamples of statements for which we do have proofs, but which experts in the relevant fields still seeas mysterious, because the proofs arent illuminating or explanatory enough. Any proofs thatrequiregigantic manipulations of formulas, magically terminating in the desired outcome, probably fall into that class, as do proofs that require computer enumeration of cases (like that of the Four-Color Theorem).
But its not just that proof and explanation are incomparable; sometimes they might evenbeat odds. In this MathOverflow post, Timothy Gowersrelates an interestingspeculationof Don Zagier, that statements like the equidistribution of the digits of  might be unprovable from the usual axioms of set theory, precisely because theyre so obviously trueand for that very reason, there need not be anything deeper underlying their truth. As Gowers points out, we shouldnt go overboard with this speculation, because there are plenty ofother examples of mathematical statements (the Green-Tao theorem, Vinogradovs theorem, etc.) that also seem like they mightbe true just becausetrue only because their falsehood would require a statistical miraclebutfor which mathematicians nevertheless managed to give fullyrigorous proofs, in effectformalizingthe intuition that it would take a miracle to make them false.
Zagiers speculation is related to another objection one could raise against my essay: while I said that the Gdelian gremlin has remained surprisingly dormant in the 85 years since its discovery (and that this is a fascinating fact crying out for explanation), whos to say that its not lurking in some of the very open problems that I mentioned, like s equidistribution, the Riemann Hypothesis, the Goldbach Conjecture, or PNP? Conceivably, not only are all those conjectures unprovable from the usual axioms of set theory, but their unprovability is itself unprovable, and so on,so that we could never even have the satisfaction of knowing why well never know.
My response to these objections isbasically just to appeal yetagain tothe empirical record. First, while proof and explanation need notgo together and sometimes dont, by and large they dogo together: over thousands over years, mathematicians learned to seek formal proofs largelybecause they discoveredthat without them, their understanding constantly went awry. Also, while no one can rule out that P vs. NP, the Riemann Hypothesis, etc., might be independent of set theory, theres very littlein the history of mathincluding in the recent history, which saw spectacular proofs of (e.g.) Fermats Last Theorem and the Poincar Conjecturethat lends concretesupport to such fatalism.
So in summary, Id say that history doespresent us with two mysteriesof the mathematical supercontinentnamely, why do so manyof the mathematical statements that humanscare about turn out to betightly linked in webs of explanation, and also in webs of proof, rather than occupying separate islands?and that these two mysteries are very closely related, if not quite the same.Five announcements

1. Sanjeev Arora sent me a heads-up that theres a discussion about the future of the STOC conferenceat the Windows on Theory blogin particular, about the idea of turning STOC into a longer CS theory festival. If you have opinions about this, dont miss the chance to make your voice heard.
2. Back in January, I blogged about a new quantum optimization algorithm by Farhi, Goldstone, and Gutmann, which was notable for being, as far as anyone could tell, the first quantum algorithm to achieve a provably better approximation ratio than the best-known classical algorithm for an NP-hard optimization problem. Today, I report that a fearsome list of authorsBoaz Barak, Ankur Moitra, Ryan ODonnell, Prasad Raghavendra, Oded Regev, David Steurer, Luca Trevisan, Aravindan Vijayaraghavan, David Witmer, and John Wrighthas put out an eagerly-awaited paperthat gives a classical algorithm for the same problem, with betterperformance than the quantum algorithms. (They write thatthis improves both qualitatively and quantitatively on Farhi et al.s work; I assume qualitatively refers to the fact that the new algorithm is classical.) What happened, apparently, is that after I blogged (with enthusiasm) about the Farhi et al. result, a bunch of classical complexity theoristsread my post and decidedindependently that they could match or beat the quantum algorithms performance classically; then they found out about each other and decided to merge their efforts. Im proud to say that this isnt the first example of this blog catalyzing actual research progress, though its probably the best exampleso far. [Update: Luca Trevisan now has a great post explaining what happened in much more detail, entitled How Many Theoreticians Does It Take to Approximate Max 3Lin?]
Another update: Farhi et al. have posted a new version of their paper, in which they can almost match the performance of the classical algorithm using their quantum algorithm.
3. Jennifer Ouellette has a wonderful article in Quantamagazine about recent progress in AdS/MERA (i.e., the emergence of spacetime from entanglement), centered around the ideas of Brian Swingle. This is one of the mainthings that Id loveto understand better right nowif I succeed even partially, youll know because Ill write a blog post trying to explain it to others. See also this blog post by Sean Carroll (about this paper by Ning Bao et al.), and this paper by Pastawski, Yoshida, Harlow, and Preskill, which explicitly minesthe AdS/CFT correspondence forexamples of quantum error-correcting codes.
4. Celebrity rationalist Julia Galef, who I had the great honor of meeting recently, has a podcast interview with Sean Carroll about why Carroll acceptsthe many-worlds interpretation. (Or if, like me, you prefer the written word to the spoken one, click here for a full transcript.) Unfortunately, Sean is giventhe opportunity at the end of the interview to recommend one science book to his listenersjust one!buthe squanders it by plugging some weird, self-indulgent thing called Quantum Computing Since Democritus. Julia also has a YouTube video about what she learned from the interview, but I havent yet watched it(is thereatranscript?).
5. I came across aninsightful if meandering essayabout nerd culture by Meredith L. Patterson. In particular, noticing howthe term nerd has been co-opted by normal, socially-skilled people, whovequicklyset about remaking nerd social normsto make them identical to the rest of the worlds norms,Pattersoncoins the term weird-nerd to describe people like herself, who are still nerds in the original sense and who dontsee nerd culture as something horribly, irreparably broken. As she writes: Well start to feel less defensive when we get some indicationany indicationthat our critics understand what parts of our culture we dont want to lose and why we dont want to lose them. (But is this the startofa linguistic treadmill? Will we eventually need to talk about weird-weird-nerds, etc.?)NSA in P/poly: The Power of Precomputation

Even after the Snowden revelations, there remained at least one big mystery about what the NSA was doing and how. The NSAs classified 2013 budget request mentioned, as a priority item,groundbreaking cryptanalytic capabilities to defeat adversarial cryptography and exploit internet traffic. There was a requested increase, of several hundred million dollars, for cryptanalytic IT services and cryptanalysis and exploitation services program C (whatever that was). And a classified presentation slide showed encrypted data being passed to a high-performance computing system called TURMOIL, and decrypts coming out. But whatever was going on inside TURMOILseemed to be secret even within NSA; someone atSnowdens level wouldnt have had accessto thedetails.
So, what was (or is) inside the NSAs cryptanalytic black box? A quantum computer? Maybe even one that they bought from D-Wave? (Rimshot.) A fast classical factoring algorithm? A proof of P=NP? Commentators on the Internet rushed to suggest each of these far-reaching possibilities. Some of us tried topour cold water on these speculationspointing out that one could envisionmanyscenariosthat were a littlemore prosaic, a little more tied to the details of how public-key crypto is actually used in the real world. Were we just nave?
This week, anew bombshell 14-author paper(see also the website) advances an exceedingly plausible hypothesis about what may have beenthe NSAs greatestcryptanalytic secret of recent years. One of the authors is J. Alex Halderman of the University of Michigan, mybest friend since junior high school, who Ive blogged about before. Because of that,I had some advance knowledgeof this scoop, and found myself having to do what regular Shtetl-Optimized readers will know is the single hardest thing in the world for me: bite my tongue and not sayanything. Until now, that is.
Besides Alex, the other authors areDavid Adrian, Karthikeyan Bhargavan, Zakir Durumeric, Pierrick Gaudry, Matthew Green,Nadia Heninger, Drew Springall, Emmanuel Thom, Luke Valenta,Benjamin VanderSloot, Eric Wustrow, Santiago Zanella-Bguelink, and Paul Zimmermann (two of these, Green and Heninger, have previously turned up on Shtetl-Optimized).
These authors study vulnerabilities in Diffie-Hellman key exchange, theoriginal (but still widely-used) public-key cryptosystem, the one that predates even RSA. Diffie-Hellman is the thing where Alice and Bob first agree on a huge prime number p and a number g, then Alice picks a secret a and sends Bob ga (mod p), and Bob picks a secret b and sends Alice gb (mod p), and then Alice and Bobcan both compute (ga)b=(gb)a=gab (mod p), but an eavesdropper whos listening in only knows p, g, ga (mod p), and gb (mod p), and one can plausibly conjecture that its hard from those things alone to get gab (mod p). So then Alice and Bob share a secret unknown to the eavesdropper, which they didnt before, and they can use that secret to start doing cryptography.
As far as anyone knows today, the bestway to break Diffie-Hellman is simply by calculating discrete logarithms: that is, solving the problem of recovering a given only g and h=ga (mod p). At least on a classical computer, the fastest known algorithm for discrete logarithms (over fields of prime order) is the number field sieve (NFS). Under plausible conjectures about the distribution of smooth numbers, NFS uses time that grows like exp((1.923+o(1))(log p)1/3(log log p)2/3), where the exp and logs are base e (and yes, even the lower-order stuff like (log log p)2/3makes a big difference in practice). Of course, once you know the running time of the best-known algorithm, you can then try to choose a key size (that is, a value of log(p)) thats out of reach for that algorithm on the computing hardware of today.
(Note that the recent breakthrough of Antoine Joux, solving discrete log in quasipolynomial time in fields of small characteristic, also relied heavily on sievingideas. But there are no improvements from thisyet for the original discrete log problem, over prime fields.)
But theres onecrucial further fact, which has been understoodfor at least a decade by theoretical cryptographers, but somehow was slow tofilter out to the people who deploypractical cryptosystems. The further fact is that in NFS, you can arrange things so that almost all the discrete-logging effortdepends only on the prime number p, and not at all on the specific numbers g and h for which youre trying to takethe discrete log. After this initial precomputation step, you then have a massive databasethat you can use to speed up the descent step: the step of solving ga=h (mod p), for any(g,h) pair that you want.
Its a little like the complexity class P/poly, where a single, hard-to-compute advice string unlocks exponentially many inputs once you have it. (Ora bit more precisely, one could say that NFS revealsthat exponentiation modulo a prime number is sort ofa trapdoor one-way function, except that the trapdoor information is subexponential-size, and given the trapdoor, inverting the function is stillsubexponential-time, but a milder subexponential than before.)
The kicker is that,in practice, a large percentage of all clients and servers thatuse Diffie-Hellman key exchange use the same few prime numbers p. This means that, if you wanted to decrypt a large fraction of all the traffic encrypted with Diffie-Hellman, you wouldnt needto do NFS over and over: you could just do it for a few ps and cache the results. This fact can singlehandedly change the outlook forbreaking Diffie-Hellman.
The story is different depending on the key size, log(p). In the 1990s, the US government insisted on export-grade cryptography for products sold overseas (what a quaint concept!), which meant that the key size was restricted to 512 bits. For 512-bit keys, Adrian et al. were able to implement NFS and use it to do the precomputationstep in about 7 days on a cluster with a few thousand cores. After this initial precomputation step (which produced 2.5GB of data), doing the descent, to find the discrete log for a specific (g,h) pair, took only about 90 seconds on a 24-core machine.
OK, but no one still uses 512-bit keys, do they? The first part of Adrian et al.s paper demonstratesthat, because of implementation issues, even today you can force many servers to downgrade to the 512-bit, export-grade keysand then, having done so, you can stall for time for 90 seconds as you figure out the session key, and then do a man-in-the-middle attack and take over and impersonate the server. Its an impressive example of the sort of game computer security researchers have been playing for a long timebut its really just a warmup to the main act.
As youd expect, many servers today are configured more intelligently, and will only agree to 1024-bit keys. But even there, Adrian et al. found that a large fraction of serversrely on just a single 1024-bit prime (!), and many of the ones that dont rely on just a few other primes. Adrian et al. estimate that, for a single 1024-bit prime, doing the NFS precomputation would take about 45 million years using a single coreor to put it more ominously, 1 year using 45 million cores. If you built special-purpose hardware, that could go down by almost two orders of magnitude, putting the monetary cost at a few hundred million dollars, completely within the reach of a sufficiently determined nation-state. Once the precomputation was done, and the terabytesof output stored in a data center somewhere, computing a particular discrete log would then take about 30 days using 1 core, or mere minutes using a supercomputer. Once again, none of this is assuming any algorithmic advances beyond whats publicly known. (Of course, its possible that the NSA also has some algorithmic advances; even modest ones could obviate the need for special-purpose hardware.)
While writing this post, I did my own back-of-the-envelope, and got that using NFS, calculatinga 1024-bit discrete log should be about7.5 million times harder than calculatinga 512-bit discrete log. So, extrapolating from the 7 days it took Adrian et al.to do it for 512 bits, this suggests that it mightvetaken them about143,840 years to calculate1024-bit discrete logs with the few thousandcoresthey had, or 1 year if they had 143,840 times as many cores(since almost all this stuff is extremely parallelizable). Adrian et al. mention optimizations that they expect would improve this by a factor of 3,giving us about 100 million core-years, verysimilar toAdrian et al.sestimate of 45 million core-years (the lower-order terms in the running time of NFS might account for some of the remaining discrepancy).
Adrian et al. mount a detailed argument in their paper that allof the details about NSAs groundbreaking cryptanalytic capabilities that we learned from the Snowden documents match what wouldbe true if the NSA were doing something like the above. The way Alex put it to me is that, sure, the NSA might not have been doing this, but if not, then he would liketounderstand why notfor it wouldve been completelyfeasible within the cryptanalytic budget they had, and the NSA wouldve known that, and it wouldve been avery goodcodebreaking value for the money.
Now that we know about this weakness of Diffie-Hellman key exchange, what can be done?
The most obvious solutionbut a good one!is just to use longer keys. For decades, when applied cryptographers would announce some attack like this, theorists like me would say with exasperation: dude, why dont you fixall these problems in one stroke byjust, like, increasing the key sizes by afactor of 10? when its an exponential against a polynomial, we all know the exponentialwill win eventually, so why not just go out to where it does? The applied cryptographers explain to us, with equal exasperation in their voices, that there are all sorts of reasons why not, from efficiency to(maybe the biggest thing) backwards-compatibility. You cant unilaterally demand 2048-bit keys, if millions of your customers are using browsers that only understand1024-bit keys. On the other hand, given the new revelations, it looks like there really will bea bigpushto migrate to larger key sizes, as the theorists wouldve suggested from their ivory towers.
A second, equally-obvious solution is to stop relying so much on the same few prime numbers in Diffie-Hellman key exchange. (Note that the reason RSA isnt vulnerable to this particular attack is that it inherently requires a different composite number N for each public key.) In practice, generating a new hugerandom prime number tends to be expensivetaking, say, a few minuteswhich is why people so often rely on standard primes. At the least, we could uselibraries of millions of safe primes, from which a prime for a given session ischosen randomly.
A thirdsolution is to migrate to elliptic-curve cryptography (ECC), which as far as anyone knows today, is much less vulnerable to descent attacks than the original Diffie-Hellman scheme. Alas, theres been a lot of understandable distrust of ECC after the DUAL_EC_DBRG scandal, in which it came outthat the NSA backdoored some of NISTs elliptic-curve-basedpseudorandom generators by choosing particular parametersthat it knew how handle. But maybe the right lesson to draw is mod-pgroups and elliptic-curve groupsbothseem to be pretty good for cryptography, but the mod-p groups are less good if everyone is using the same few prime numbers p (andthose primes are within nation-state range), and the elliptic-curve groups are less good if everyone is using the same few parameters. (A lot of these things do seem prettypredictablewith hindsight, but how many did you predict?)
Many people will use this paper to ask political questions, like: hasnt the NSAs codebreaking mission once again usurpedits mission to ensure the nations information security? Doesnt the 512-bit vulnerability that many Diffie-Hellman implementations still face, as a holdover from the 1990s export rules, illustrate whyencryption should neverbe deliberately weakened for purposes of national security? How can we get over the issue of backwards-compatibility, and get everyone using strong crypto? People absolutely should be asking suchquestions.
But forreaders of this blog, theres one question that probably looms even larger than those of freedom versus security, openness versus secrecy, etc.: namely, the question of theory versus practice. Which side should be said to have won this round? Some will say: those useless theoretical cryptographers, they didnt even know how their coveted Diffie-Hellman system could be broken in the real world! The theoretical cryptographers might reply: of courseweknew about the ability to do precomputation with NFS! This wasnt some NSA secret; its something we discussed openly for years. And if someone told ushow Diffie-Hellmanwas actually being used (with much of theworld relying on the same few primes), we couldve immediately spottedthe potential for such an attack. To which others might reply: then why didnt you spot it?
Perhaps the right lesson to draw is how silly such debates really are. In the end, piecing this story togethertook a team that was willing to do everything from learning some fairly difficult number theory tocoding upsimulationstoporing over the Snowden documents for clues about the NSAs budget. Clear thought doesnt respect the boundaries between disciplines, or between theory and practice.
(Thanks very much to Nadia Heninger and Neal Koblitz for reading this post and correcting a few errors in it. For more about this, see Bruce Schneiers postor Matt Greens post.)New comment policy

If you reject an overwhelming consensus on some issue in the hard sciences  whether its evolution, general relativity, climate change, or anything else  this blog is an excellent place to share your concerns with the world.  Indeed, youre even welcome to derail discussion of completely unrelated topics by posting lengthy rants against the academic orthodoxy  the longer and angrier the better!  However, if you wish to do this, I respectfully ask that you obey the following procedure:

Publish a paper in a peer-reviewed journal setting out the reasons for your radical departure from accepted science.
Reference the paper in your rant.

If you attempt to skip to the rant part without going through this procedure, your comments may be deleted without warning.  Repeat offenders will be permanently banned from the blog.  Life is short.  I make no apologies.
Scott Aaronson
Rebel for the Scientific Consensus
Update (4/11): I am, of course, under no illusions whatsoever that my requirement of having published a relevant peer-reviewed paper will eliminate all tinfoil-hat rants from the comments section.  My hope, rather, is that it will make those rants that I do receive more interesting and original.Missing the boat

This morning I got an email from Eric Klien of the Lifeboat Foundation, an organization that advocates building a space ark as an insurance policy in case out-of-control nanorobots destroy all life on Earth. Klien was inviting me to join the foundations scientific advisory board, which includes such notables as Ray Kurzweil.  I thought readers of this blog might be interested in my response.
Dear Eric,
Im honored (and surprised) that you would consider me for your board. But Im afraid Im going to decline, for the following reasons:
(1) Im generally skeptical of predictions about specific future technologies, especially when those predictions are exactly the sort of thing that a science fiction writer would imagine. In particular, I consider the risk of self-replicating nanobots converting our entire planet into gray goo to be a small one.
(2) Once were dealing with such unlikely events, I dont think we can say with confidence what protective measures would be effective. For all we know, any measures we undertake will actually increase the risk of catastrophe. For example, maybe if humanity launches a space ark, that will tip off a hostile alien civilization to our existence. And maybe the Earth will then be besieged by alien warships, which can only be destroyed using gray goo  the development of which was outlawed as a protective measure. Im not claiming that this scenario is likely, only that I have no idea whether its more or less likely than the scenarios youre considering.
(3) There are several risks to humanity that I consider more pressing than that of nanotechnology run amok. These include climate change, the loss of forests and freshwater supplies, and nuclear proliferation.
Best regards,
Scott AaronsonThe End of Suffering?

Acomputer science undergrad who reads this blog recently emailed me about an anxiety hes been feeling connected to the Singularitynot that it will destroy all human life, but rather that it will make life suffering-free and therefore no longer worth living (more Brave New World than Terminator, one might say).
As he puts it:
This probably sounds silly, but Ive been existentially troubled by certain science fiction predictions for about a year or two, most of them coming from the Ray Kurzweil/Singularity Institute types What really bothers me is the idea of the abolition of suffering as some put it. I just dont see the point. Getting rid of cancer, premature death, etc., that all sounds great. But death itself? All suffering? At what point do we just sit down and ask ourselves, why not put our brains in a jar, and just activate our pleasure receptors for all eternity? That seems to be the logical conclusion of that line of thinking. If we want to reduce the conscious feeling of pleasure to the release of dopamine in the brain, well, why not?
I guess what I think Im worried about is having to make the choice to become a cyborg, or to upload my mind to a computer, to live forever, or to never suffer again. I dont know how Id answer, given the choice. I enjoy being human, and that includes my suffering. I really dont want to live forever. I see that as a hedonic treadmill more than anything else. Crazy bioethicists like David Pearce, who want to genetically re-engineer all species on planet Earth to be herbivores, and literally abolish all suffering, just add fuel to my anxiety.
 Do you think were any closer to what Kurzweil (or Pearce) predicted (and by that I mean, will we see it in our lifetimes)? I want to stop worrying about these things, but something is preventing me from doing so. Thoughts about the far flung (or near) future are just intrusive for me. And it seems like everywhere I go Im reminded of my impending fate. Ernst Jnger would encourage me to take up an attitude of amor fati, but I cant see myself doing that. My father says Im too young to worry about these things, and that the answer will be clear when Ive actually lived my life. But I just dont know. I want to stop caring, more than anything else. Its gotten to a point where the thoughts keep me up at night.
I dont know how many readers might have had similar anxieties, but in any case, I thought my reply might be of some interest to others, so with the questionerskind permission, Im reproducing it below.
1. An end to suffering removing the meaning from life? As my grandmother might say, we should only have such problems! I believe, alas, that suffering will always be with us, even after a hypothetical technological singularity, becauseof basic Malthusian logic. I.e., no matter how many resources there are, population will expand exponentially to exploit them and make the resources scarce again, thereby causing fighting, deprivation, and suffering. Whats terrifying about Malthuss logic is how fully general it is: it applies equally to tenure-track faculty positions, to any extraterrestrial life that might exist in our universe or in any other bounded universe, and to the distant post-Singularity future.
But if, by some miracle, we were able to overcome Malthus and eliminate all suffering, my own inclination would be to say go for it! I can easily imagine a life that was well worth livingfilled with beauty, humor, play, love, sex, and mathematical and scientific discoveryeven though it was devoid of any serious suffering. (We could debate whether the ideal life would include occasional setbacks, frustrations, etc., even while agreeing that at any rate, it should certainly be devoid of cancer, poverty, bullying, suicidal depression, and ones Internet connection going down.)
2. If you want to worry about something, then rather than an end to suffering, I might humbly suggest worrying about a large increase in human suffering within our lifetimes. A few possible culprits: climate change, resurgent religious fundamentalism, large parts of the world running out of fresh water.
3. Its fun to think about these questions from time to time, to use them to hone our moral intuitionsand I even agree with Scott Alexander that its worthwhile to have a small number of smart people think about them full-time for a living. But I should tell you that, as I wrote in my post The Singularity Is Far, I dont expect aSingularity in my lifetime or my grandchildrens lifetimes. Yes, technically, if theres ever going to be a Singularity, then were 10 years closer to it now than we were 10 years ago, but it could still be one hell of a long way away! And yes, I expect that technology will continue to change in my lifetime in amazing waysnot as much as it changed in my grandparents lifetimes, probably, but still by a lotbut how to put this? Im willing to bet any amount of money that when I die, peoples shit will still stink.Ecoprocrastination

While the reasons I havent updated this blog for a week are complex and multifaceted, the fact that Ive been flying to another university every 2-3 days, waking up at 7 (AM, not PM) each morning, defending quantum computing research all day including mealtimes, and collapsing in my hotel room during rare free intervals is undoubtedly one of the contributing factors.
And so it is, alas, that I dont have time to share anything nontrivial today.  Instead, in honor of Earth Day, Ill just link to the text of the landmark US Supreme Court ruling three weeks ago, which forced Bushs emasculated EPA to either regulate CO2 emissions or else give scientific reasons for refusing to do so.  If you the time (and who doesnt?), Id also recommend reading the oral arguments, wherein you can enjoy the acidic barbs of Justice Scalia, surely one of the most interesting and articulate assholes of our time.
As with intelligent design cases, its not the science thats on trial here but rather the legal system itself.  Is a system set up to decide which farmer was grazing his cows on which other farmers land capable of weighing the origin and future of eukaryotic life on Earth?  In this particular case, the legal system eked out a 5-4 victory; it could easily have gone the other way.
And yes, I know that Massachusetts v. EPA wasnt really about global warming: it was about whether Massachusetts had standing to sue, the definition of the word pollutant in the Clear Air Act, whether the EPA can decline to regulate based on foreign-policy considerations, and so on. Similarly, Plessy v. Ferguson wasnt really about racism, Griswold v. Connecticut wasnt really about contraception, etc.   In each case, it was just a happy coincidence, p1/512, that all nine justices found that the legal technicalities lined up perfectly with how they felt about the underlying issue.
For those who dont want to read the whole decision, here are a few key passages:
When a State enters the Union, it surrenders certain sovereign prerogatives. Massachusetts cannot invade Rhode Island to force reductions in greenhouse gas emissions, it cannot negotiate an emissions treaty with China or India  These sovereign prerogatives are now lodged in the Federal Government, and Congress has ordered EPA to protect Massachusetts (among others) by prescribing standards applicable to the emission of any air pollutant which may reasonably be anticipated to endanger public health or welfare.
The harms associated with climate change are serious and well recognized  That these climate-change risks are widely shared does not minimize Massachusetts interest in the outcome of this litigation  According to petitioners unchallenged affidavits, global sea levels rose somewhere between 10 and 20 centimeters over the 20th century as a result of global warming  These rising seas have already begun to swallow Massachusetts coastal land  The severity of that injury will only increase over the course of the next century: If sea levels continue to rise as predicted, one Massachusetts official believes that a significant fraction of coastal property will be either permanently lost through inundation or temporarily lost through periodic storm surge and flooding events.
EPA does not dispute the existence of a causal connection between man-made greenhouse gas emissions and global warming. At a minimum, therefore, EPAs refusal to regulate such emissions contributes to Massachusetts injuries.   EPA nevertheless maintains that its decision not to regulate greenhouse gas emissions from new motor vehicles contributes so insignificantly to petitioners injuries that the agency cannot be haled into federal court to answer for them  But EPA overstates its case. Its argument rests on the erroneous assumption that a small incremental step, because it is incremental, can never be attacked in a federal judicial forum. Yet accepting that premise would doom most challenges to regulatory action.
Unlike EPA, we have no difficulty reconciling Congress various efforts to promote interagency collaboration and research to better understand climate change with the agencys pre-existing mandate to regulate any air pollutant that may endanger the public welfare  Collaboration and research do not conflict with any thoughtful regulatory effort; they complement it.
EPA no doubt has significant latitude as to the manner, timing, content, and coordination of its regulations with those of other agencies. But once EPA has responded to a petition for rulemaking, its reasons for action or inaction must conform to the authorizing statute. Under the clear terms of the Clean Air Act, EPA can avoid taking further action only if it determines that greenhouse gases do not contribute to climate change or if it provides some reasonable explanation as to why it cannot or will not exercise its discretion to determine whether they do  To the extent that this constrains agency discretion to pursue other priorities of the Administrator or the President, this is the congressional design.
EPA has refused to comply with this clear statutory command. Instead, it has offered a laundry list of reasons not to regulate. For example, EPA said that a number of voluntary executive branch programs already provide an effective response to the threat of global warming  that regulating greenhouse gases might impair the Presidents ability to negotiate with key developing nations to reduce emissions  and that curtailing motor-vehicle emissions would reflect an inefficient, piecemeal approach to address the climate change issue 
Although we have neither the expertise nor the authority to evaluate these policy judgments, it is evident they have nothing to do with whether greenhouse gas emissions contribute to climate change. Still less do they amount to a reasoned justification for declining to form a scientific judgment. In particular, while the President has broad authority in foreign affairs, that authority does not extend to the refusal to execute domestic laws.
Nor can EPA avoid its statutory obligation by noting the uncertainty surrounding various features of climate change and concluding that it would therefore be better not to regulate at this time.  If the scientific uncertainty is so profound that it precludes EPA from making a reasoned judgment as to whether greenhouse gases contribute to global warming, EPA must say so.
In short, EPA has offered no reasoned explanation for its refusal to decide whether greenhouse gases cause or contribute to climate change. Its action was therefore arbitrary, capricious,  or otherwise not in accordance with law.Can blog posts nourish the soul?  Scott A. (alas, not me) as existence proof

Reading the essays and speculative fiction of Scott Alexander, as theyve grown in awesomenesseven just within the past half-year, has for me been like witnessing the birth of a new Asimov. (For more Alexandery goodness, check outUniversal Love, Said the Cactus Person.) That this nerd-bard, this spinner of stupid Internet memes into reflections on eternity, came to my attention by way of his brilliantly defending me, is almost immaterial at this point; I dont think it plays anyrole in my continuing admiration forhis work. Whatever you do, just keep writing, other Scott A.97% environmentalist

I decided to addmy name toa petitionby, as of this writing, 81 MIT faculty, calling onMIT to divest its endowment from fossil fuel companies. (My co-signatories include Noam Chomsky, so I guess theres somethingwe agree about!) Theres also awider petition signed by nearly 3500 MIT students, faculty, and staff, mirroring similar petitions all overthe world.
When the organizers asked mefor a brief statement about why I signed, I sent them the following:
Signing this petition wasnt an obvious choice for me, since Im sensitive to the charge that divestment petitions are just meaningless sanctimony, a way for activists to feel morally pure without eithermaking serious sacrifices or engaging the realcomplexities of an issue. In the end, though, that kind of meta-level judgment cant absolve us of the need to consider each petition on itsmerits: if we think of a previouscrisis for civilization (say, inthe late 1930s), thenit seemsobvious that evensymbolic divestment gestures werebetter than nothing. What made up my mindwas reading the arguments pro and con, and seeing that the organizers of this petition had a clear-eyed understanding of what they were trying to accomplish and why: they know thatdivestment cant directly drive down oil companies stock prices, but it can powerfully signalto the world a scientific consensusthat, if global catastrophe is to be averted, most of the known fossil-fuelreserves need to be left in the ground, and that current valuations of oil, gas, and coal companies fail to reflect that reality.
For some recent prognoses of the climate situation, see (for example)thisor thisfrom Vox. My own senseis that thethreathas been systematicallyunderstated even by environmentalists, because of the human impulseto shoehorn all newsinto ahopefulnarrative (buttheres still time! if we just buy locally-grown produce, everything canbe OK!). Logically, theres an obvious tension between the statements:
(a) there was already an urgent need to act decades ago, and
(b) havingfailed to act then, we can stillfeasibly avert adisaster now.
And indeed, (b) appearsfalse to me. Were probablywell into the erawhere, regardless of what we do or dont do, someof uswilllive toseea climate dramaticallydifferent from the one in whichhuman civilization developed for the past 10,000 years,at least as different as the last Ice Ages were.
And yet thatfactstill doesnt relieve us of moral responsibility. We canbuy more time to prepare, hoping for technological advances in the interim;we can try to bend the curve of CO2 concentration away from the worst futuresand toward the merely terrible ones. Alas,even those stepswillrequirepolitical will thats unprecedented outside of major wars. For the capitalist free market (which Im a bigfan of) to work its magic, actual costs first need to getreflected in priceswhich probably meansmassively taxing fossil fuels,to the point where its generallycheaper to leave them in the ground and switch to alternatives. (Lest anyone call me a doctrinaire treehugger, I also support wayless regulation of the nuclear industry, to drive down the cost of building the hundreds of new nuclear plants that well probably need.)
These realities have a counterintuitive practical implication that I wish both sides understood better. Namely,if you share my desperation and terror about thiscrisis, the urgent desire to do something, thenlimiting your personal carbon footprint should be very far from your main concern. Like, its great if you can bike to work, and you should keep it up(fresh air andexercise and all). But Id saythe anti-environmentalists areright that such voluntary steps are luxuries of the privileged, andwill accordingly never add up to a hill of beans. Let megofurther: even to conceptualize thisproblemin terms of personal virtueand blameseems to me likeatragic mistake, one onwhich the environmentalistsand theiropponentscolluded. Given the choice, Id much rather that the readers of this blogflew to all the faraway conferences theywanted, drove gas-guzzling minivans, ate steaks every night, and had ten kids, but thenalsotook some steps that made serious political action to leave most remaining fossil fuels in the groundeven more likely,  closer to the middle of ourOverton window. I signed the MIT divestment petition because it seemed to me like such a step, admittedly with an emphasis on the.The Hiring Scott Aaronson FAQ

Last weekend, I got back from interviewing at the University of Washington, Stanford, Caltech, Berkeley, and Cornell.   Then I fell asleep, and am only just now waking up.  On this trip  surely the most exhausting Ive ever been on   I seem to remember giving  a talk on The Limits of Quantum Computers.  (Youll have to go to presentation mode to get the full effect of my PowerPoint animations, and especially the D-Wave montage on slide 2.)
The bulk of the time, however, was taken up with interviews.  My interviewers  maybe 20 or 30 at each school, in CS, physics, applied math, even chemistry and electrical engineering  asked me good questions, questionable questions, hard questions, soft questions, loaded questions, lots of questions.   And thats what enables me, without further ado, to present for your reading enjoyment The Official Hiring Scott Aaronson FAQ.
[Note: The questions below are all things that I was actually asked by at least one interviewer  in some cases, by dozens of interviewers.]
Q: What will you do if quantum computing doesnt pan out in the next 20 years?
A: This question presupposes that quantum computing should be judged as a high-risk engineering project.   But thats never been my view.  My view is that it should be judged as basic science. What were trying to do is unify the theory of computing with our best theory of the physical world, and to perform the most stringent tests to which quantum mechanics itself has ever been subjected. For me, the payoff for better scientific understanding is not in some remote future  its as soon as the understanding is achieved.
Q: But why should we care about basic science?
A: Uhh, we are called the computer science department
Q: Does quantum computing really belong in CS departments, as opposed to physics departments?
A: It belongs if we want it to belong!   In my experience, the physicists have a bigger hurdle than the computer scientists in getting started with quantum computing research.  All we need to do is ask ourselves: what happens if we generalize probability theory to allow minus signs, and base it on the L2 norm instead of the L1 norm?  From then on its just the concepts we know and love: states, transformations, recursion, reductions, universality, asymptotic efficiency, and so on.  Physicists, by contrast, have to learn most of this stuff for the first time. Its been a great personal pleasure to watch physicists who once suspected that CS was devoid of intellectual content, struggle with that content while trying to learn quantum computing!
Now, if we want to take a dramatic scientific development that wouldnt have been possible without computer science, and hand it over to the physicists on a silver platter, thats certainly our prerogative.  But is it in our interest as a field?
Q: What if quantum computing is fundamentally impossible?
A: That would be much more interesting than if its possible!  Merely building a quantum computer would be the more boring outcome  the one consistent with all the physics we already know.
Q: But no one really questions quantum mechanics, do they?
A: Well, you just did!
Q: No, I only questioned whether quantum computing is possible.  Couldnt quantum mechanics be valid, but quantum computing still be impossible because of noise and decoherence?
A: If so, then theres something enormous that we dont yet understand about the relevant physics.  Look, in light of the Threshold Theorem (that if the rate of decoherence per qubit per time step is smaller than some constant threshold, then one can perform an arbitrarily long quantum computation), its hard to maintain that were talking about some niggling technical issue.  What were really talking about is this: to keep track of the state of N entangled particles, does Nature have to do an amount of computational work that increases exponentially with N?  And if it doesnt, then (turning the question around) is there an efficient classical algorithm to simulate the behavior of N entangled particles?  These are not questions that will just go away for some trivial reason that everyones overlooked.
Q: Suppose Ed Witten spent a week thinking about it, and came up with some profound reason why quantum computing is impossible.  What would you do next?
A: Id drop whatever else I was doing, and devote all of my time to understanding the implications of his discovery for computer science and physics!
[Pause]
Of course, since this is Witten, maybe he wouldve spent a second week and worked out all the implications himself. So I guess all I can say is that to my knowledge, he hasnt in fact been thinking about these issues.
Q: How long until we have practical quantum computers?
A: In my opinion, quantum computing experiments are not yet at a stage where one can make Moores Law type predictions.  We might be in the same situation with quantum computing that Babbage was with classical computing in the 1840s.  In other words, we think we know the fundamental principles, and were right  but the technology isnt there yet, and might not be for a long time.
Of course, as with any technology, progress could happen faster than almost any of us expect.   But I prefer to be pessimistic: that way either youre right, or else you dont mind being wrong!
Q: How many qubits are the experimentalists at so far?
A: It depends how you measure.  People got up to twelve qubits in liquid-state NMR, the platform that was used some years ago to factor 15 into 35 (at least with high probability!).  The trouble with liquid NMR is that no one knows how to scale it: currently the signal decreases exponentially with the number of qubits.  So people turned their attention to other platforms, such as ion traps, photonics, and solid-state NMR.  With these platforms the quantum computers state is much closer to being pure, so the prospects for scalability are much better.  But manipulating the qubits is correspondingly harder.  With ion traps, Rainer Blatts group in Innsbruck did tomography of an 8-qubit state, and other groups have done computations involving 2 or 3 qubits.  With photonics, its easy to get a huge number of qubits that are highly coherent; the problem is that photons dont like to talk to each other (in fact they fly right past each other), and therefore you can only apply two-qubit gates by using matter particles as intermediaries.
There are other more exotic proposals for scalable quantum computing, such as nonabelian anyons.  With these I think its fair to say were not even at one qubit yet.  But if these proposals did work, then the hope would be that they could leapfrog over the other proposals by building in error-correction for free.
Q: Which universities in North America are the major centers for quantum computing theory?
A: Right now there are four: Waterloo, Caltech, MIT, and Berkeley.
Q: Supposing we had scalable quantum computers, are your lower-bound results telling us that they would have no applications?
A: Absolutely not.  Aside from their intrinsic scientific interest, quantum computers would have real applications.  In my opinion, the most important would be the one so obvious that we computer scientists hardly ever talk about it: namely, simulating quantum physics and chemistry!  This, of course, is what a quantum computer does in its sleep.  At the same time, its also a fundamental problem in nanotechnology, high-temperature superconductivity, QCD, and other areas, important enough that Nobel prizes have been awarded even for ways to solve special cases efficiently on a classical computer.
Admittedly, you could say that every physical system in the universe is a quantum computer computing its own evolution!   But the goal here would be to build a universal quantum simulator: a single machine that can be programmed to efficiently simulate any quantum system of interest.  Its the difference between building a wind tunnel versus writing code in order to simulate an airplane.
Now, by a sort of lucky accident, we can sometimes coax a quantum computer into solving classical problems asymptotically faster than we know how to solve them with a classical computer.  The famous examples are of course (1) breaking RSA and other cryptographic codes, and (2) solving generic search problems quadratically faster than a classical computer.  These discoveries have enormous theoretical interest,  but (as far I can tell) only limited practical interest.  Maybe Im wrong though.
Q: Granted that quantum computing is already interesting as basic science, do you agree that it would be more interesting if we had practical quantum computers?
A: Well, I certainly wouldnt mind it.
Q: You work on quantum computing, yet most of your research is about how quantum computers wouldnt be very powerful.  Isnt that a bit strange?
A: In the long run, I dont think quantum computing research is helped by falsehood.   If were going to be scientists and not PR flaks, then obviously we ought to welcome the truth, whichever way it goes.
But personally, Id go even further than that.  For me, a model of computation without any limitations would be like Superman without kryptonite.  There just wouldnt be a whole lot to say about it!  To my way of thinking, a model that lets you factor integers efficiently but not solve NP-complete problems is actually more interesting than a model that gives you everything!
Oh, and one further point: if youre interested (as I am) in the ultimate limits of computation, then youre almost professionally obligated to study quantum computing.   Why?  Because any time you prove a limit of classical computers, you now have to ask yourself: is this something fundamental, or is it just an artifact of my working in a high-decoherence regime?
Q: Why are you so interested in the limits of computation?
A: To show that something is possible, you just have to find a way to do it.  But to show that somethings not possible, you have to consider every way of doing it, and prove that none of them work.  This is why negative results are so much rarer than positive results, but also why they often give us deeper understanding.
Q: That seems like an extremely male perspective! [said, jokingly, by a female interviewer]
A: I respectfully disagree.   Look, as with pretty much every area of CS, we could certainly use more talented women in quantum computing theory: maybe a few dozen more Dorit Aharonovs, Julia Kempes, and Barbara Terhals.    I find the gender imbalance in CS depressing, and Ive long been interested in what it would take to correct it.  But the relevant question is this: is the proportion of women working on quantum lower bounds smaller than the proportion working on quantum algorithms?  I dont think that it is.
Q: Whats your vision for where your research is headed in the next 5-10 years?
A: I know Im not supposed to say this in an interview, but I dont have a vision.  I have this annoying open problem, that conjecture, this claim that seems wrong to me.   I know some people have a coherent vision for where their research is headed.  And in experimental areas, obviously you have to justify what youre going to do with your $200 million of equipment.  But at least in theoretical computer science, having a vision always seemed incredibly difficult to me.
For example, lets say you have a vision that youre going to solve problem X using techniques A, B, C.  Then what do you do when you find out that techniques A and C are total nonstarters  but that technique B, while its useless for X, does solve a completely unrelated problem Y?  What you do is make up a story about how Y was the problem you wanted to solve all along! We all do that: drawing targets around where the arrows hit is simply the business were in.
What I can tell you is this: Im interested in fundamental limits on what can be efficiently computed in the physical world. I look for problems that can be addressed with tools from theoretical computer science, but that also have some physical or philosophical point: something that makes me feel like the universe would be a different place if the conjecture were true than if it were false.
In the past, quantum computing has been an incredibly rich source of that sort of problem for me.  But its never been my exclusive interest  Ive also worked on circuit complexity, Bayesian agreement protocols, and even information retrieval and clustering.  And if quantum computing ever stops being a source of conceptually rich open problems, then Ill look for those problems somewhere else.
Q: I noticed that, on at least three occasions where you proved a new quantum lower bound, other people quickly improved it to an optimal bound.  Is there a reason why you didnt prove the optimal bounds yourself?
A: Yeah, I dont seem to be very good at tightening my lower bounds!  Ive had more success in proving the first nontrivial lower bound for a given problem  that is, in understanding why the complexity scales exponentially rather than polynomially. After that, Im more than happy to let others pin down the order of the exponential.  Every time thats happened, far from feeling disappointed over being scooped, I felt great that my work gave other people a foundation to build on.
Q: You look tired.  Would you like some coffee?
A: Yes.
Q: How did you get interested in quantum computing?
A: When I first learned about programming as an 11-year-old, it wasnt only a revelation  to me because I now understood how video games worked (though that was definitely important).  The real revelation was: this is how the entire universe must work!  Its all just bits getting updated by simple rules.  I dont have to understand physics if I want to understand physics.
Of course Id heard of quantum effects, and I knew they were supposed to be important  but since I didnt understand them, they made no difference to me.  Then later, as an undergrad at Cornell, I read the early quantum computing papers, and found out that this quantum weirdness the physicists kept babbling about was nothing more than linear algebra over the complex numbers.  Hey, linear algebra  even I can do that!
But I didnt really become engrossed in quantum computing until a summer internship at Bell Labs.  As a diversion from my real work that summer (which had to do with multivariate isotone regression), I went through the Bernstein-Vazirani paper, and managed to improve their containment BQP  P#P to BQP  PP.  Then I found out that Lov Grover worked in the same building as me, so I went and told him about my result.  Well, it turned out that BQP  PP was already known  it had been proved by Adleman, DeMarrais, and Huang the year before.  But one consequence of my talking to Lov was that I ended up doing an internship with him the next summer, working (mostly unsuccessfully) on quantum lower bounds.  Ashwin Nayak was also working with Lov that summer; from Ashwin I found out about Umesh Vaziranis group at Berkeley and how all the cool people were there.
After that, the main questions in my mind were whether I could get accepted to Berkeley, whether Umesh would take me on as a student, and whether I was good enough to do anything original in this field.  I emailed Umesh and he never responded, which I took as an extremely bad sign  how little I knew back then! Luckily I did get in to Berkeley, I did start working with Umesh, I did stumble on some new results, and I guess the rest is history.
Q: How many people work on the computer science side of quantum computing?
A: Probably the best way to measure that is by how many people attend the annual QIP conference (for if they dont go to QIP, do they really exist?)  Last years QIP drew almost 200 attendees.
Q: Would you be willing to supervise grad students in classical theoretical computer science?
A: Willing is an understatement!  I would love to supervise talented grad students in derandomization, circuit lower bounds, learning theory, or any of the other classical areas that I try hard to keep up with and occassionally even work on.  Admittedly, when it comes to (say) list decoding, extractors, approximation algorithms, or PCP, the students would first have to teach me whats going on, but after that Id be happy to supervise them.
Q: What would you say if I told you that I think quantum computing is like postmodern literary criticism, just a way for people to churn out one paper after another by switching words around, citing each other in a circular way, recycling the same few mathematically trivial ideas over and over  and indeed, that the whole field of theoretical computer science has no real ideas and no connections to anything outside itself?
A: Id say thank you very much for your opinion, and youve got me for  lets see, 25 more minutes, so what can I do for you?A query complexity breakthrough

Update (June 26): See this just-released paper, which independently obtains a couple of the same results as the Ambainis et al. paper, but in a different way (using the original Gs et al. function, rather than modifications of it).

Lots of people have accused me of overusing the word breakthrough on this blog. So I ask them: what word should I use when a paper comes out that solves not one, not two, but three of the open problems Ive cared about most for literally half of my life, since I was 17 years old?
Yesterday morning, Andris Ambainis, Kaspars Balodis, Aleksandrs Belovs, Troy Lee, Miklos Santha, and Juris Smotrovs posted a preprint to ECCC in which they give:
(1) A total Boolean function f with roughly a fourth-power separation between its deterministic and bounded-error quantum query complexities (i.e., with D(f)~Q(f)4). This refutes the conjecture, which people have been making since Beals et al.s seminal work in 1998, that the biggest possible gap is quadratic.
(2) A total Boolean function f with a quadratic separation between its deterministic and randomized query complexities (with D(f)~R0(f)2). This refutes a conjecture of Saks and Wigderson from 1986, that the best possible gap is R0(f)~D(f)0.753 (from the recursive AND/OR tree), and shows that the known relation D(f)=O(R0(f)2) is close to tight.
(3) The first total Boolean function f with any asymptotic gap between its zero-error and bounded-error randomized query complexities (in particular, with R0(f)~R(f)3/2).
(There are also other new separationsfor example, involving exact quantum query complexity and approximate degree as a real polynomial. But the above three are the most spectacular to me.)
In updates to this post (coming soon), Ill try my best to explain to general readers what D(f), R(f), and so forth are (see here for the classic survey of these measures), and Ill also discuss how Ambainis et al. designed the strange functions f that achieve the separations (though their paper already does a good job of explaining it). For now, Ill just write the stuff thats easier to write.
Im at the Federated Computing Research Conference in Portland, Oregon right now, where yesterday I gave my STOC talk (click here for the PowerPoint slides) about the largest possible separations between R(f) and Q(f) for partial Boolean functions f. (That paper is also joint work with Andris Ambainis, who has his fingers in many pies, or his queries in many oracles, or something.) Anyway, when I did a practice run of my talk on Monday night, I commented that, of course, for total Boolean functions f (those not involving a promise), the largest known gap between R(f) and Q(f) is quadratic, and is achieved when f is the OR function because of Grovers algorithm.
Then, Tuesday morning, an hour before I was to give my talk, I saw the Ambainis et al. bombshell, which made that comment obsolete. So, being notoriously bad at keeping my mouth shut, I mentioned to my audience that, while it was great that they came all the way to Portland to learn what was new in theoretical computer science, if they wanted real news in the subfield I was talking about, they could stop listening to me and check their laptops.
(Having said that, I have had a wonderful time at FCRC, and have learned lots of other interesting thingsI can do another addendum to the post about FCRC highlights if people want me to.)
Anyway, within the tiny world of query complexityi.e., the world where I cut my teeth and spent much of my careerthe Ambainis et al. paper is sufficiently revolutionary that I feel the need to say what it doesnt do.
First, the paper does not give a better-than-quadratic gap between R(f) and Q(f) (i.e., between bounded-error randomized and quantum query complexities). The quantum algorithms that compute their functions f are still just variants of the old standbys, Grovers algorithm and amplitude amplification. Whats new is that the authors have found functions where you can get the quadratic, Grover speedup between R(f) and Q(f), while also getting asymptotic gaps between D(f) and R(f), and between R0(f) and R(f). So, putting it together, you get superquadratic gaps between D(f) and Q(f), and between R0(f) and Q(f). But it remains at least a plausible conjecture that R(f)=O(Q(f)2) for all total Boolean functions fi.e., if you insist on a fair comparison, then the largest known quantum speedup for total Boolean functions remains the Grover one.
Second, as far as I can tell (I might be mistaken) (Im not), the paper doesnt give new separations involving certificate complexity or block sensitivity (e.g., between D(f) and bs(f)). So for example, it remains open whether D(f)=O(bs(f)2), and whether C(f)=O(bs(f)) for some <2. (Update: Avishay Tal, in the comments, informs me that the latter conjecture was falsified by Gilmer, Saks, and Srinivasan in 2013. Wow, Im really out of it!)
In the end, achieving these separations didnt require any sophisticated new mathematical machineryjust finding the right functions, something that couldve been done back in 1998, had anyone been clever enough. So, where did these bizarre functions f come from? Ambainis et al. directly adapted them from a great recent communication complexity paper by Mika Gs, Toniann Pitassi, and Thomas Watson. But the Gs et al. paper itself couldve been written much earlier. Its yet another example of something Ive seen again and again in this business, how theres no substitute for just playing around with a bunch of examples.
The highest compliment one researcher can pay another is, I wish Id found that myself. And I do, of course, but having missed it, Im thrilled that at least I get to be alive for it and blog about it. Huge congratulations to the authors!

Addendum: Whats this about?
OK, so lets say you have a Boolean function f:{0,1}n{0,1}, mapping n input bits to 1 output bit. Some examples are the OR function, which outputs 1 if any of the n input bits are 1, and the MAJORITY function, which outputs 1 if the majority of them are.
Query complexity is the study of how many input bits you need to read in order to learn the value of the output bit. So for example, in evaluating the OR function, if you found a single input bit that was 1, you could stop right there: youd know that the output was 1, without even needing to look at the remaining bits. In the worst case, however, if the input consisted of all 0s, youd have to look at all of them before you could be totally sure the output was 0. So we say that the OR function has a deterministic query complexity of n.
In this game, we dont care about any other resources used by an algorithm, like memory or running time: just how many bits of the input it looks at! There are many reasons why, but the simplest is that, unlike with memory or running time, for many functions we can actually figure out how many input bits need to be looked at, without needing to solve anything like P vs. NP. (But note that this can already be nontrivial! For algorithms can often cleverly avoid looking at all the bits, for example by looking at some and then deciding which ones to look at next based on which values they see.)
In general, given a deterministic algorithm A and an n-bit input string x, let DA,x (an integer from 0 to n) be the number of bits of x that A examines when you run it. Then let DA be the maximum of DA,x over all n-bit strings x. Then D(f), or the deterministic query complexity of f, is the minimum of DA, over all algorithms A that correctly evaluate f(x) on every input x.
For example, D(OR) and D(MAJORITY) are both n: in the worst case, you need to read everything. For a more interesting example, consider the 3-bit Boolean function
f(x,y,z) = (not(x) and y) or (x and z).
This function has D(f)=2, even though it depends on all 3 of the input bits. (Do you see why?) In general, even if f depends on n input bits, D(f) could be as small as log2n.
The bounded-error randomized query complexity, or R(f), is like D(f), except that now we allow the algorithm to make random choices of which input bit to query, and for each input x, the algorithm only needs to compute f(x) with probability 2/3. (Here the choice of 2/3 is arbitrary; if you wanted the right answer with some larger constant probability, say 99.9%, you could just repeat the algorithm a constant number of times and take a majority vote.) The zero-error randomized query complexity, or R0(f), is the variant where the algorithm is allowed to make random choices, but at the end of the day, needs to output the correct f(x) with probability 1.
To illustrate these concepts, consider the three-bit majority function, MAJ(x,y,z). We have D(MAJ)=3, since if a deterministic algorithm queried one bit and got a 0 and queried a second bit and got a 1 (as can happen), it would have no choice but to query the third bit. But for any possible setting of x, y, and z, if we choose which bits to query randomly, theres at least a 1/3 chance that the first two queries will return either two 0s or two 1sat which point we can stop, with no need to query the third bit. Hence R0(MAJ)(1/3)2+(2/3)3=8/3 (in fact it equals 8/3, although we havent quite shown that). Meanwhile, R(MAJ), as we defined it, is only 1, since if you just need a 2/3 probability of being correct, you can simply pick x, y, or z at random and output it!
The bounded-error quantum query complexity, or Q(f), is the minimum number of queries made by a quantum algorithm for f, which, again, has to output the right answer with probability at least 2/3 for every input x. Here a quantum algorithm makes a query by feeding a superposition of basis states, each of the form |i,a,w, to a black box, which maps each basis state to |i, a XOR xi, w, where i is the index of the input bit xi to be queried, a is a 1-qubit answer register into which xi is reversibly written, and w is a workspace that doesnt participate in the query. In between two queries, the algorithm can apply any unitary transformation it wants to the superposition of |i,a,ws, as long as it doesnt depend on x. Finally, some designated qubit is measured to decide whether the algorithm accepts or rejects.
As an example, consider the 2-bit XOR function, XOR(x,y). We have D(XOR)=R0(XOR)=R(XOR)=2, since until youve queried both bits, youve learned nothing about their XOR. By contrast, Q(XOR)=1, because of the famous Deutsch-Jozsa algorithm.
Its clear that
0  Q(f)  R(f)  R0(f)  D(f)  n,
since a quantum algorithm can simulate a randomized one and a randomized one can simulate a deterministic one.
A central question for the field, since these measures were studied in the 1980s or so, has been how far apart these measures can get from each other. If you allow partial Boolean functionsmeaning that only some n-bit strings, not all of them, are valid inputs for which the algorithm needs to return a definite answerthen its easy to get enormous separations between any two of the measures (indeed, even bigger than exponential), as for example in my recent paper with Andris.
For total functions, by contrast, its been known for a long time that these measures can differ by at most polynomial factors:
D(f) = O(R(f)3) (Nisan)
D(f) = O(R0(f)2) (folklore, I think)
R0(f) = O(R2 log(n)) (Midrijanis)
D(f) = O(Q(f)6) (Beals et al. 1998)
OK, so what were the largest known gaps? For D versus R0 (as well as D versus R), the largest known gap since 1986 has come from the recursive AND/OR tree: that is, an OR of two ANDs of two ORs of two ANDs of  forming a complete binary tree of depth d, with the n=2d input variables comprising the leaves. For this function, we have D(f)=n, whereas Saks and Wigderson showed that R0(f)=(n0.753) (and later, Santha showed that R(f)=(n0.753) as well).
For D versus Q, the largest gap has been for the OR function: we have D(OR)=n (as mentioned earlier), but Q(OR)=(n) because of Grovers algorithm. Finally, for R0 versus R, no asymptotic gap has been known for any total function. (This is a problem that I clearly remember working on back in 2000, when I was an undergrad. I even wrote a computer program, the Boolean Function Wizard, partly to search for separations between R0 versus R. Alas, while I did find one or two functions with separations, I was unable to conclude anything from them about asymptotics.)
So, how did Ambainis et al. achieve bigger gaps for each of these? Ill try to have an explanation written by the time my flight from Portland to Boston has landed tonight. But if you cant wait for that, or you prefer it straight from the horses mouth, read their paper!

Addendum 2: The Actual Functions
As I mentioned before, the starting point for everything Ambainis et al. do is a certain Boolean function g recently constructed by Gs, Pitassi, and Watson (henceforth GPW), for different purposes than the ones that concern Ambainis et al. We think of the inputs to g as divided into nm cells, which are arranged in a rectangular grid with m columns and n rows. Each cell contains a bit thats either 0 or 1 (its label), as well as a pointer to another cell (consisting of ~log2(nm) bits). The pointer can also be null (i.e., can point nowhere). Well imagine that a query of a cell gives you everything: the label and all the bits of the pointer. This could increase the query complexity of an algorithm, but only by a log(n) factor, which we wont worry about.
Let X be a setting of all the labels and pointers in the grid. Then the question we ask about X is the following:
Does there exist a marked column: that is, a column where all n of the labels are 1, and which has exactly one non-null pointer, which begins a chain of pointers of length m-1, which visits exactly one 0 cell in each column other than the marked column, and then terminates at a null pointer?
If such a marked column exists, then we set g(X)=1; otherwise we set g(X)=0. Crucially, notice that if a marked column exists, then its unique, since the chain of pointers zeroes out all m-1 of the other columns, and prevents them from being marked.
This g already leads to a new query complexity separation, one that refutes a strengthened form of the Saks-Wigderson conjecture. For its not hard to see that D(g)=(mn): indeed, any deterministic algorithm must query almost all of the cells. A variant of this is proved in the paper, but the basic idea is that an adversary can answer all queries with giant fields of 1 labels and null pointersuntil a given column is almost completed, at which point the adversary fills in the last cell with a 0 label and a pointer to the last 0 cell that it filled in. The algorithm just cant catch a break; it will need to fill in m-1 columns before it knows where the marked one is (if a marked column exists at all).
By contrast, its possible to show that, if n=m, then R(g) is about O(n4/3). I had an argument for R(g)=O((n+m)log(m)) in an earlier version of this post, but the argument was wrong; I thank Alexander Belov for catching the error. Ill post the R(g)=O(n4/3) argument once I understand it.
To get the other separationsfor example, total Boolean functions for which D~R02, D~Q4, R0~Q3, R0~R3/2, and R~approxdeg4Ambainis et al. need to add various enhancements to the basic GPW function g defined above. There are three enhancements, which can either be added individually or combined, depending on ones needs.
1. Instead of just a single marked column, we can define g(X) to be 1 if and only if there are k marked columns, which point to each other in a cycle, and which also point to a trail of m-k 0 cells, showing that none of the other columns contain all 1 cells. This can help a bounded-error randomized algorithmwhich can quickly find one of the all-1 columns using random samplingwhile not much helping a zero-error randomized algorithm.
2. Instead of a linear chain of pointers showing that all the non-marked columns contain a 0 cell, for g(X) to be 1 we can demand a complete binary tree of pointers, originating at a marked column and fanning out to all the unmarked columns in only log(m) layers. This can substantially help a quantum algorithm, which cant follow a pointer trail any faster than a classical algorithm can; but which, given a complete binary tree, can fan out and run Grovers algorithm on all the leaves in only the square root of the number of queries that would be needed classically. Meanwhile, however, putting the pointers in a tree doesnt much help deterministic or randomized algorithms.
3. In addition to pointers fanning out from a marked column to all of the unmarked columns, we can demand that in every unmarked column, some 0 cell contains a back-pointer, which leads back to a marked column. These back-pointers can help a randomized or quantum algorithm find a marked column faster, while not much helping a deterministic algorithm.
Unless Im mistaken, the situation is this:
With no enhancements, you can get D~R2 and something like D~R03/2 (although I still dont understand how you get the latter with no enhancements; the paper mentions it without proof Andris has kindly supplied a proof here).
With only the cycle enhancement, you can get R0~R3/2.
With only the binary tree enhancement, you can get R~approxdeg4.
With only the back-pointer enhancement, you can get D~R02.
With the cycle enhancement and the binary-tree enhancement, you can get R0~Q3.
With the back-pointer enhancement and the binary-tree enhancement, you can get D~Q4.
Its an interesting question whether there are separations that require both the cycle enhancement and the back-pointer enhancement; Ambainis et al. dont give any examples.
And heres another interesting question not mentioned in the paper. Using the binary-tree enhancement, Ambainis et al. achieve a fourth-power separation between bounded-error randomized query complexity and approximate degree as a real polynomiali.e., quadratically better than any separation that was known before. Their proof of this involves cleverly constructing a low-degree polynomial by summing a bunch of low-degree polynomials derived from quantum algorithms (one for each possible marked row). As a result, their final, summed polynomial does not itself correspond to a quantum algorithm, meaning that they dont get a fourth-power separation between R and Q (which wouldve been even more spectacular than what they do get). On the other hand, purely from the existence of a function with R~approxdeg4, we can deduce that that function has either
(i) a super-quadratic gap between R and Q (refuting my conjecture that the Grover speedup is the best possible quantum speedup for total Boolean functions), or
(ii) a quadratic gap between quantum query complexity and approximate degreesubstantially improving over the gap found by Ambainis in 2003.
I conjecture that the truth is (ii); it would be great to have a proof or disproof of this.Religions rules of inference

Besides defending quantum computing day and night, having drinks with Cosmic Variances Sean Carroll, and being taken out to dinner at lots of restaurants with tablecloths, the other highlight of my job interview tour was meeting a friendly, interesting, articulate divinity student on the flight from San Francisco to Philadelphia, who tried to save my soul from damnation.
Heres how it happened: the student (call him Kurt) was reading a Christian theological tract, while I, sitting next to him, was reading Russell on Religion.  (This is true.)  I sheepishly covered the spine of my book, trying to delay the inevitable conversation  but it finally happened, when Kurt asked me how I was liking ole Bert.  I said I was liking him just fine, thank you very much.
Kurt then made some comment about the inadequacy of a materialistic worldview, and how, without God as the basis of morality, the whole planet would degenerate into what we saw at Virginia Tech.  I replied that the prevention of suffering seemed like a pretty good basis for morality to me.
Oh! said Kurt. So then suffering is bad. How do you know its bad?
How do you know its bad?
Because I believe the word of God.
So if God said that suffering was good, that would make it good?
I cant remember Kurts response, but Im sure it was eloquent and well-practiced  nothing I said really tripped him up, nor did I expect it to.  Wanting to change the subject, I asked him about his family, his studies, his job, what hed been doing in the vipers den of San Francisco, etc.   I told him a little about quantum computing and my job search.   I mused that, different though we were, we both valued something in life more than money, and that alone probably set us apart from most people on the plane.  Kurt said it was fitting that Id gone to grad school at Berkeley.  I replied that, as a mere Democrat, I was one of the most conservative people there.
Finally I blurted out the question I really wanted to ask.  In his gentle, compassionate, way, Kurt made it clear to me that yes, I was going to roast in hell, and yes, Id still roast in hell even if I returned to the religion of my ancestors (that, of course, being at best a beta version of the true religion).  In response, I told Kurt that when I read Dantes Inferno in freshman English, I decided that the place in the afterlife I really wanted to go was the topmost layer of hell: the place where Dante put the righteous unbaptized such as Euclid, Plato, and Aristotle.  There, these pre-Christian luminaries could carry on an eternal intellectual conversation  cut off from Gods love to be sure, but also safe from the flames and pitchforks.   How could angels and harps possibly compete with infinite tenure at Righteous Unbaptized University?  If God wanted to lure me away from that, Hed probably have to throw in the Islamic martyr package.
San Francisco to Philadelphia is a five-hour flight, and the conversation ranged over everything you might expect: the age of the earth (Kurt was undecided but leaning toward 6,000 years), whether the universe needs a reason for its existence external to itself, etc.  With every issue, I resolved not to use the strongest arguments at my disposal, since I was more interested in understanding my adversarys reasoning process  and ideally, in getting him to notice inconsistencies within his own frame of reference.  Alas, in that I was to be mostly disappointed.
Heres an example. I got Kurt to admit that certain Bible passages  in particular, the ones about whipping your slaves  reflected a faulty, limited understanding of Gods will, and could only be understood in the historical context in which they were written.  I then asked him how he knew that other passages  for example, the ones condemning homosexuality  didnt also reflect a limited understanding of Gods will.  He replied that, in the case of homosexuality, he didnt need the Bible to tell him it was immoral: he knew it was immoral because it contradicted human beings biological nature, gay couples being unable to procreate.  I then asked whether he thought that infertile straight couples should similarly be banned from getting married.  Of course not, he replied, since marriage is about more than procreation  its also about love, bonding, and so on.  I then pointed out that gay and lesbian couples also experience love and bonding. Kurt agreed that this was true, but then said the reason homosexuality was wrong went back to the Bible.
What fascinated me was that, with every single issue we discussed, we went around in a similar circle  and Kurt didnt seem to see any problem with this, just so long as the number of 2SAT clauses that he had to resolve to get a contradiction was large enough.
In the study of rationality, theres a well-known party game: the one where everyone throws a number from 0 to 100 into a hat, and that player wins whose number was closest to two-thirds of the average of everyones numbers.  Its easy to see that the only Nash equilibrium of this game  that is, the only possible outcome if everyone is rational, knows that everyone is rational, knows everyone knows everyone is rational, etc.  is for everyone to throw in 0.  Why? For simplicity, consider the case of two people: one can show that I should throw in 1/2 of what I think your number will be, which is 1/2 of what you think my number will be, and so on ad infinitum until we reason ourselves down to 0.
On the other hand, how should you play if you actually want to win this game?  The answer, apparently, is that you should throw in about 20.  Most people, when faced with a long chain of logical inferences, will follow the chain for one or two steps and then stop.  And, here as elsewhere in life, being rational is just a question of adjusting yourself to everyone elses irrationalities.  Two-thirds of 50 is 33, and two-thirds of that is 22, and  OK, good enough for me!
Ive heard it said that the creationists are actually perfectly rational Bayesians; they just have prior probabilities that the scientifically-minded see as perverse.  Inspired by conversations with Kurt and others, I hereby wish to propose a different theory of fundamentalist psychology.  My theory is this: fundamentalists use a system of logical inference wherein you only have to apply the inference rules two or three times before you stop.  (The exact number of inferences can vary, depending on how much you like the conclusion.)  Furthermore, this system of bounded inference is actually the natural one from an evolutionary standpoint.  Its we  the scientists, mathematicians, and other nerdly folk  who insist on a bizzarre, unnatural system of inference, one where you have to keep turning the modus ponens crank whether you like where its taking you or not.
Kurt, who looked only slightly older than I am, is already married with two kids, and presumably more on the way.  In strict Darwinian terms, hes clearly been more successful than Ive been.  Are those of us who can live with AB or BC or Cnot(A) but not all of them at once simply evolutionary oddities, like people who have twelve fingers or cant stand sunlight?FCRC Highlights

By popular request, here are some highlights from this weeks FCRC conference in Portland, Oregon:

The edit distance between two strings means the minimum number of insertions, deletions, and replacements needed to convert one string to the other: for example, SHTETL and SHETLAND have an edit distance of 4. Edit distance has major, obvious applications to DNA sequence comparison, as well as plagiarism detection and many other things. Theres a clever dynamic programming algorithm to compute the edit distance between two n-bit strings, but it takes ~n2 time, which is already too slow for many applications. Can you do better? I remember wondering about that 15 years ago, as a beginning grad student taking Richard Karps computational biology course. Now Arturs Backurs and Piotr Indyk have shown that, if you can compute edit distance in O(n2-) time for any >0, then you can also solve CNF-SAT in 2cn time for some c<1, thereby refuting the Strong Exponential Time Hypothesis. For more about this important result, see this MIT News article.


Olivier Temam gave a superb keynote talk about hardware neural networks. His main points were these: implementing neural nets with special-purpose hardware was a faddish idea a few decades ago, but was abandoned once people realized that (a) it didnt work that great, and (b)more to the point, anything you could do with special-purpose hardware, you could do better and more easily with silicon chips, after waiting just a few years for Moores Law to catch up. Today, however, two things have spurred a revival of the idea: firstly, neural nets (renamed deep learning, and done with bigger networks and way more training data) are delivering spectacular, state-of-the-art results; and second, transistors have stopped shrinking, so it now makes more sense to think about the few orders-of-magnitude speed improvement that you can get from special-purpose hardware. This would mean organizing computers kind-of, sort-of like the brain is organized, with (for example) memory integrated into the connections between the neurons (processing elements), rather than on a separate chip thats connected to the processor by a bus. On the other hand, Temam also stressed that computer architects shouldntslavishly copy the brain: instead, they should simply build the fastest hardware they can to implement the best available machine-learning algorithms, and they should rely on the machine-learning theorists to incorporate whatever broadlessons are to be gleanedfrom neuroscience (as theyve done several times in the past).


Three separate sets of authors (Koppula, Lewko, and Waters; Canetti, Holmgren, Jain, and Vaikuntanathan; and Bitansky, Garg, Lin, Pass, and Telang) independently wrote papers that showed how to achieve indistinguishability obfuscation (i.o.) for Turing machines rather than for circuits. For those not in the world of theoretical crypto, i.o.is a hot concept that basically means: obfuscating a program in such a way that no adversarycan figure outanything about which program you started with, among all the possible programs that compute the same function in roughly the same amount of time. (On the other hand, the adversary might be able to learn more than she could if merely given a black box for the function. And thatswhy this kind of obfuscation falls short of the gold standard, whichwas shown to be impossible in general in seminal work by Barak et al.) Recent papers have shown how to achieve the weaker notion of i.o., but they first require converting your program to a Boolean circuitsomething thats absurdly inefficient in practice, and also has the theoretical drawback of producing an obfuscated program whose size grows, not merely with the size of the original, unobfuscated program, but also with the amount of time the original program is supposed to run for. So, the new work gets around that drawback, by cleverly obfuscating a program whose purpose is to compute the next step function of the original program, on data thats itself encrypted. The talk was delivered in tag team format, with one representative from each group of authors speaking for 6-7 minutes. Surprisingly, it worked extremely well.


Laci Babai gave a truly epic hour-long KnuthPrize lecture, basically tryingto summarize all of his work overthe past 35 years (and related work by others), in 170 or so slides. The talk had not a single word of filler: it was just pure beef, result after result, some of them well-known and seminal (e.g., MIP=NEXP, AM[2]=AM[k], AlmostNP=MA, group membership in NP, group non-membership in AM) and others obscure little gems. Boaz Barak commented that an entire semester-long course could be taught from the PowerPoint slides. Laci ended the talk by defining the Babai point, and then saying having made my point, Im done.


Ambainis (yes, the same Ambainis), Filmus and Le Gall had a paper about the limitations of the techniques used to achieve all matrix multiplication algorithms from Coppersmith-Winograd (O(n2.3755)) onward, including those of Stothers 2010 (O(n2.3730)), Vassilevska Williams 2012 (O(n2.3728642)), and Le Gall 2014 (O(n2.3728639)). Their basic conclusionnot surprising, but still nice to establish formallyis that applying more and more massive computer search to the current ideas cant possibly get you below O(n2.308); new ideas will be needed to push further.


At the STOC business meeting, there was a long discussion about the proposal to turn STOC into a weeklong theory festival, with more plenary talks (including from other fields), possibly more parallel sessions, etc. There were lots of interesting arguments, but alas, I was too tired and jetlagged to remember what they were. (Anyone who does remember is welcome to chime in.)

There are many great things that I havent written aboutfor example, I havent even said a word about any of the three best paper talks!but Im out of energy right now. Others are more than welcome to share other FCRC highlights in the comments section.Purely out of intellectual duty

Alright, alright  two separate readers pointed me to this story (from todays New York Times), about recent research into defense mechanisms in female duck genitalia (not quite biting, but it sure looks unpleasant, as one of them says).
Even I have gotten bored of this topic.Can Quantum Computing Reveal the True Meaning of Quantum Mechanics?

I now have a 3500-word post on that questionup at NOVAs Nature of Reality blog. If youve been reading Shtetl-Optimizedreligiously for the pastdecade(why?), there wontbe much new to you there, but if not, well, I hope you like it! Comments are welcome, either here or there. Thanks so much to Kate Becker at NOVA for commissioning this piece, and for her help editing it.Celebrate gay marriageand its 2065 equivalent

Yesterday was a historic day for the United States, and I was as delighted as everyone else I know. Ive supported gay marriage since the mid-1990s, when as a teenager, I read Andrew Hodges classic biography of Alan Turing, and burned with white-hot rage at Turings treatment. In the world he was born intoour world, until fairly recentlyTuring was free: free to prove the unsolvability of the halting problem, free to help save civilization from the Nazis, just not free to pursue the sexual and romantic fulfillment that nearly everyone else took for granted. I resolved then that, if I was against anything in life, I was against the worldview that had hounded Turing to his death, or anything that even vaguely resembled it.
So Im proud for my country, and Im thrilled for my gay friends and colleagues and relatives. At the same time, seeing my Facebook page light up with an endless sea of rainbow flags and jeers at Antonin Scalia, theres something that gnaws at me. To stand up for Alan Turing in 1952 wouldve taken genuine courage. To support gay rights in the 60s, 70s, 80s, even the 90s, took courage. But celebrating a social change when you know all your friends will upvote you, more than a decade after the tide of history has made the change unstoppable? Its fun, its righteous, its justified, Im doing it myself. But lets not kid ourselves by calling it courageous.
Do you want to impress me with your moral backbone? Then go and find a group that almost all of your Facebook friends still consider it okay, even praiseworthy, to despise and mock, for moral failings that either arent failings at all or are no worse than the rest of humanitys. (I promise: once you start looking, it shouldnt be hard to find.) Then take a public stand for that group.Quantum query complexity: the other shoe drops

Two weeks ago I blogged about a breakthrough in query complexity: namely, the refutation by Ambainis et al. of a whole slew of conjectures that had stood for decades (and that I mostly believed, and that had helped draw me into theoretical computer science as a teenager) about the largest possible gaps between various complexity measures for total Boolean functions. Specifically, Ambainis et al. built on a recent example of Gs, Pitassi, and Watson to construct bizarre Boolean functions f with, among other things, near-quadratic gaps between D(f) and R0(f) (where D is deterministic query complexity and R0 is zero-error randomized query complexity), near-1.5th-power gaps between R0(f) and R(f) (where R is bounded-error randomized query complexity), and near-4th-power gaps between D(f) and Q(f) (where Q is bounded-error quantum query complexity). See my previous post for more about the definitions of these concepts and the significance of the results (and note also that Mukhopadhyay and Sanyal independently obtained weaker results).
Because my mental world was in such upheaval, in that earlier post I took pains to point out one thing that Ambainis et al. hadnt done: namely, they still hadnt shown any super-quadratic separation between R(f) and Q(f), for any total Boolean function f. (Recall that a total Boolean function, f:{0,1}n{0,1}, is one thats defined for all 2n possible input strings x{0,1}n. Meanwhile, a partial Boolean function is one where theres some promise on x: for example, that x encodes a periodic sequence. When you phrase them in the query complexity model, Shors algorithm and other quantum algorithms achieving exponential speedups work only for partial functions, not for total ones. Indeed, a famous result of Beals et al. from 1998 says that D(f)=O(Q(f)6) for all total functions f.)
So, clinging to a slender reed of sanity, I said it remains at least a plausible conjecture that, if you insist on a fair comparisoni.e., bounded-error quantum versus bounded-error randomizedthen the biggest speedup quantum algorithms can ever give you over classical ones, for total Boolean functions, is the square-root speedup that Grovers algorithm easilyachieves for the n-bit OR function.
Today, I can proudlyreport that my PhD student, Shalev Ben-David, has refuted that conjecture as well. Building on the Gs et al. and Ambainis et al. work, but adding a new twist to it, Shalev has constructed a total Boolean function f such that R(f) grows roughly like Q(f)2.5 (yes, thats Q(f) to the 2.5th power). Furthermore, if a conjecture that Ambainis and I made in our recent Forrelation paper is correctnamely, that a problem called k-fold Forrelation has randomized query complexity roughly (n1-1/k)then one would get nearly a cubic gap between R(f) and Q(f).
The reason I found this questionso interesting is that it seemed obvious to me that, to produce a super-quadratic separation between R and Q, one would need a fundamentally new kind of quantum algorithm: one that was unlike Simons and Shors algorithms in that it worked for total functions, but also unlike Grovers algorithm in that it didnt hit some impassable barrier at the square root of the classical running time.
Flummoxing my expectations once again, Shalev produced the super-quadratic separation, but not by designing any new quantum algorithm. Instead, he cleverly engineered a Boolean function for which you can use a combination of Grovers algorithm and the Forrelation algorithm (or any other quantum algorithm that gives a huge speedup for some partial Boolean functionForrelation is just the maximal example), to get an overall speedup thats a little more than quadratic, while still keeping your Boolean function total. Ill let you read Shalevs short paper for the details, but briefly, it once again uses the Gs et al. / Ambainis et al. trick of defining a Boolean function that equals 1 if and only if the input string contains some hidden substructure, and the hidden substructure also contains a pointer to a certificate that lets you quickly verify that the hidden substructure was indeed there. You can use a super-fast algorithmlets say, a quantum algorithm designed for partial functionsto find the hidden substructure assuming its there. If you dont find it, you can simply output 0. But if you do find it (or think you found it), then you can use the certificate, together with Grovers algorithm, to confirm that you werent somehow misled, and that the substructure really was there. This checking step ensures that the function remains total.
Are there further separations to be found this way? Almost certainly! Indeed, Shalev, Robin Kothari, and I have already found some more things (as well as different/simpler proofs of knownseparations), though nothing quite as exciting as the above.
Update (July 1): Ronald de Wolf points out in the comments that this trust-but-verify trick, fordesigningtotal Boolean functions with unexpectedly lowquantum query complexities, was also used in a recent paper by himself and Ambainis (while Ashley Montanaro points out that asimilar trick was used even earlier, in a different context, by Le Gall). Whats surprising, you might say, is that it took as long as it did for people to realize how many applications this trick has.
Update (July 2): In conversation with Robin Kothari and Cedric Lin, I realized that Shalevs superquadratic separation between R and Q, combined with a recent result of Lin and Lin, resolves another open problem that had bothered me since 2001 or so.  Given a Boolean function f, define the projective quantum query complexity, or P(f), to be the minimum number of queries made by a bounded-error quantum algorithm, in which the answer register gets immediately measured after each query.  This is a model of quantum algorithms thats powerful enough to capture (for example) Simons and Shors algorithms, but not Grovers algorithm.  Indeed, one might wonder whether theres any total Boolean function for which P(f) is asymptotically smaller than R(f)thats the question I wondered about around 2001, and that I discussed with Elham Kashefi.  Now, by using an argument based on the Vaidman bomb, Lin and Lin recently proved the fascinating result that P(f)=O(Q(f)2) for all functions f, partial or total.  But, combining with Shalevs result that there exists a total f for which R(f)=(Q(f)2.5), we get that theres a total f for which R(f)=(P(f)1.25).  In the other direction, the best I know is that P(f)=(bs(f)) and therefore R(f)=O(P(f)3).Refilling your RSS glass before the entre arrives

A reader points me to this recent Topology paper by Nabutovsky and Weinberger, which probably contains the biggest numbers to have ever arisen naturally in mathematics.  Specifically, the authors show that, if we maximize the kth Betti number (for k3) over all groups whose presentation has size N (while keeping the number finite), then it grows like the super-duper Busy Beaver function (that is, Busy Beaver with an oracle for the halting problem with an oracle for the halting problem).
The spiked magazine survey I blogged about earlier has finally been published.  (Warning: Spouters ahead.)The most trivial theorem Ive ever written up

Theorem: Suppose NP-complete problems are efficiently solvable by quantum computers.  Then either the polynomial hierarchy collapses, or else BQP  AM (that is, quantum computations cant be efficiently simulated by Arthur-Merlin protocols).
Proof: Suppose NP  BQP and BQP  AM.  Then coNP  BQP  AM, and hence the polynomial hierarchy collapses to the second level by a result of Boppana, Hstad, and Zachos.
Note: If only we could delete the weasel phrase or else BQP  AM from my Most Trivial Theorem, we wouldve achieved a long-sought breakthrough in quantum computing theory.  In particular, we wouldve shown that any fast quantum algorithm to solve NP-complete problems would imply an unlikely collapse of classical complexity classes.  But while the weasel phrase is weaselly enough to make the Most Trivial Theorem a triviality, I dont think its infinitely weaselly.  The reason is my growing suspicion that BQP  AM in the unrelativized world.
Second Note: When I call this my Most Trivial Theorem, obviously Im excluding homework exercises.Two Sunday-morning breakfast links

On Thursday NEC put out a press release announcing the worlds first controllably coupled qubits.  See here for the abstract of the accompanying Science paper by Niskanen et al. (unfortunately the full text requires a subscription).  NECs announcement led to the usual fluffified popular articles; see here, here, and here for example.  But to satisfy Geordie Roses curiosity, my hype-o-meter has not yet reached D-Wave levels, for three reasons.

These claims havent garnered nearly as much quonfusion as D-Waves in the popular press.
In this case there is a peer-reviewed paper.
Theres no claim here about solving NP-complete problems, or indeed about asymptotic complexity at all.  The sole claim to originality has to do with tunable two-qubit couplings, and Im not at all well-placed to evaluate it.

Anyway, I thought I should at least mention this work, in the hope that commenters more knowledgeable than I am will weigh in on its significance.  Eternal vigilance is the price of quantum computing research.
OK, on to the second breakfast link.  Bill Gasarch has reviewed my blog for SIGACT News (scroll down to page 15), together with Lance Fortnows and Luca Trevisans.  Favorite quotes:
Lance is Walter Cronkite.  Scott is Stephen Colbert.
The name of the blog, Shtetl-Optimized does not really say what it is about.  With this in mind one can never say Scott has gone off topic since its [sic] not clear what the topic should be.
Incidentally, an uncharitable person might suspect a slight conflict of interest in Bill reviewing Lances blog, seeing as Bill now writes Lances blog.  But Bill assures us that he reviewed the blog before taking it over.Five reasons why I was in a good mood yesterday

I went on my first hot-air balloon ride (click here for photos). We landed in a Mennonite farm a half hours drive from Waterloo. Seven kids came out of the farmhouse to greet us, wearing caps and bonnets. These were the best-behaved kids I had ever seen in my life: they literally walked in formation, and only the oldest one spoke to us, the other six remaining silent. Having a balloon land on their farm was not at all a new experience for them.
I saw this xkcd cartoon, which succinctly captures a point that Ive been trying to make for the last fifteen years, in arguments against conspiracy-mongers and other associated doofiati.
I read Elizabeth Kolberts New Yorker article about the Large Hadron Collider and the future of particle physics. I hereby nominate her for a Pulitzer; this is one of the best popular science articles Ive ever read.
I saw Spider-Man 3, a profound philosophical drama that spoke to me on numerous levels. It is indeed true that with great power comes great responsibility; that we all have the capacity for good; and that, if we wish to vanquish the evil without, then we must first confront the arrogance within. My one complaint is that the Sandman was not a particularly effective villain. Lets face it: sand just isnt scary.
I got a job offer from MIT.

[Note: To clear up any confusion, Im now lucky enough to have several great offers, and have not yet decided where Im going, even unofficially.]Quantum Computing Since Democritus Lecture 12: Proof

After a ten-month hiatus, the Quantum Computing Since Democritus series sheepishly returns with Lecture 12, which explores how, over the past couple of decades, theoretical computer scientists have bent, twisted, and kneaded the concept of mathematical proof into strange and barely-recognizable forms.  Read about proofs that dont impart any knowledge beyond their own validity, proofs you can check by examining a few random symbols, and (for those who already know that stuff) proofs that certain interpretations of quantum mechanics would predict you can see over the course of your life, yet cant hold in your mind at any individual time.
I apologize if this lecture isnt as polished as some earlier ones  but while Im working on this, Im now also teaching a new course at MIT, 6.080/6.089 Great Ideas in Theoretical Computer Science.  Barring unforeseen delays, the lecture notes for that course should be available by 2043.The Myth of the Ivory Tower

I know I promised no more posts about D-Wave and its commercial quantum computer for a while.  But will you look at the bait that D-Wave founder Geordie Rose has been dangling in front of me on his blog?
People tend to approach problems and form opinions through the lens of their expertise. This happens all the time when disciplines are close  but it also happens in wierder [sic] situations, where the area of expertise is entirely disjoint from the situation being analyzed  like when theoretical computer scientists have opinions about real computers for example.
In Geordies comments section, the message is clearer still.   One commenter writes that the Professors didnt get there first and they are angry; all truth must first come from them.  Another imagines the Aaronsons of the world fervently hoping that their fragile self-created self-contained ecosystem can be re-built just the way they like it.
For commenters like these, it would seem that the issue has nothing to do with decoherence rates or scalability, or with what the evidence is that D-Wave is actually harnessing quantum effects to obtain a computational speedup.  So in this post, I want to step back and try to understand what the real issue is.
I propose that more than a few technology enthusiasts  not just the D-Wave supporters quoted above  are in the thrall of The Myth of the Ivory Tower.   According to this Myth, the basic function of academic scientists is to sit around in their armchairs, pompously declaring to be impossible what plucky inventors like Thomas Edison or the Wright Brothers then roll up their sleeves and do.  Now, I might be an academic myself, but Im also a proud American (currently residing in the 51st state), and I wont deny that this most American of myths has a certain resonance even for me.  In the end, though, I believe that the Myth tells us more about our Zeitgeist, or our collective psyche, or something like that, than it does about the actual history of technology.
The evidence for the Myth (when such is offered) usually consists of famous last words from distinguished scientific authorities.  You know the sort of thing Im talking about:
Heavier-than-air flying machines are impossible.
Radio has no future.
X-rays will prove to be a hoax.
-William Thomson (Lord Kelvin)
I think there is a world market for maybe five computers.
-Thomas Watson
There is no reason anyone would want a computer in their home.
-Ken Olsen
(Watson and Olsen were of course CEOs, but for the purposes of the Myth they stand in here as academics.)
However, as soon as we think about these predictions and what theyre supposed to demonstrate, we notice some glaring problems.  The first one is confirmation bias.   No one compiles lists of pessimistic technological forecasts made by experts that turned out to be right  where would you even start?
The second problem is that many of the juiciest predictions come from a single individual: Lord Kelvin.  Furthermore, they come from the twilight of his career, when he was considered to have lost his vortices even by most of his colleagues.  Seeking to better understand this great physicist of the 19th century who was so wrong about the technologies of the 20th, I just read an excellent biography called Degrees Kelvin.  One thing I learned is that, if the selective historians chose to focus on the first half of Kelvins career rather than the second, they could find equally exquisite anecdotes illustrating the reliability of academic opinions.
In the laying of the first transatlantic telegraph cable in the 1850s, there were two colorful personalities: Kelvin and Wildman Whitehouse.  Whitehouse, the practical man, detested any math or physics he couldnt understand, and insisted that a transatlantic cable would just be a longer version of existing cables.  Kelvin, the theorist, said that while a transatlantic cable was certainly possible, it would need thicker insulation, a different kind of receiver, etc. than previous cables to work reliably, and that more testing and research was needed.  As it happened, after laying a cable that was every bit as unreliable as Kelvin said it would be, Whitehouse (1) had to use Kelvins receiver to get any signal through at all, (2) faked the transcripts to make it look like he used his own receiver, (3) fatally damaged the cable by sending 2,000 volts through it in a desperate attempt to get it to work properly, and then (4) insisted the cable was still fine after it had permanently gone silent.  Eventually the cable companies learned their lesson.
Despite this and other successes (e.g., the Second Law of Thermodynamics), Kelvins doofus predictions in later life do illustrate two important points.  The first is that, if youre going to make skeptical pronouncements, youd better distinguish clearly between the provably impossible, the presumably impossible, and the merely difficult and not yet achieved.  The second is that, if youre going to claim somethings impossible, youd better have an argument, and youd better understand what assumptions it rests on.
Alright, so lets move on to Watson and Olsens predictions about the computer industry.  The funny thing is, these predictions werent nearly as stupid as they sound!  Why?  Because theres nothing inevitable about the concept of a personal computer.  Instead of billions of home PCs, we could just as easily imagine most of the worlds computing power concentrated in a few servers, accessible remotely to anyone who wanted it.   In this alternate universe, your desktop PC would be little more than a glorified information portal  a browser, if you will  while most of the actual application software (email, calendars, maps, etc.) ran elsewhere. I admit that this is just a fanciful, hypothetical scenario, but what does that matter to a theorist like me?
Speaking of which, the Internet was of course the child of DARPA and NSF, raised to adolescence in university CS departments.  (DARPA has since reoriented itself toward projects with shorter-term payoff, its previous funding model having failed so disastrously.)  The Web was created by Tim Berners-Lee at CERN, and the first popular web browser by Marc Andreessen at the University of Illinois.  (And yes, Al Gore had a nontrivial role in funding this work.)  R, S, and A were all at MIT.  If youre going to argue for the irrelevance of academic research, the Internet is not the place to start.
But what about some of the other spectacular inventions of the last fifty years: the laser, the transistor, the fiber-optic cable, the communications satellite?  Didnt those come from the private sector?  As it happens, they came from Bell Labs, which is interesting as the sort of mammoth exception that proves the rule.  Because of AT&Ts government-sanctioned monopoly, for much of the 20th century Bell Labs was able to function like the worlds largest university, devoting billions of dollars to irrelevant research.  So in the 1980s, when Congress decided to deregulate the phone system, many people predicted that Bell Labs would die a slow, agonizing death  a prediction thats been borne out over the last 25 years.
But surely other companies must have picked up the slack? No, not really.  While Microsoft, IBM, NEC, Xerox, and a few others all provide welcome support for basic research, none of them do so on the old Ma Bells scale.  From a CEOs perspective, the problem with basic research is obvious: a rising tide lifts all boats, your competitors as well as yours.  (The famous cautionary example here is Xerox PARC, which made the mistake of giving the world the windowing system, the mouse, and the laser printer.)
For those who adhere to the religion of capitalism, have the Arrow-Debreu Theorem tattoed across their chests, etc., it might be difficult to understand how a system based on peer review rather than the free market could lead so consistently to technological breakthroughs.  I mean, all those ivory-tower academics growing fat off government grants: what incentive could they possibly have to get the right answers?   Without picky customers or venture capitalists breathing down their necks, whats the penalty for being wrong?
Im lucky enough to be friends with Robin Hanson, a brilliant economist and futurist who starts where Ayn Rand wouldve suffered a loss of nerve and keeps going from there.  Robin has long argued that the scientific peer review process is broken, and ought to be supplanted by a futures market that would reward scientists for making correct predictions.  As he writes:
The pace of scientific progress may be hindered by the tendency of our  academic institutions to reward being popular, rather than being right  Academia is still  largely a medieval guild, with a few powerful elites, many slave-like  apprentices, and members who hold a monopoly on the research patronage of  princes and the teaching of their sons 
Imagine that academics are expected to put up  or shut up and accompany claims with at least token bets, and that  statistics are collected on how well people do.  Imagine that funding  agencies subsidize pools on questions of interest to them, and that  research labs pay for much of their research with winnings from previous  pools.  And imagine that anyone could play, either to take a stand on an  important issue, or to insure against technological risk.
Personally, I hope that Robins science futures market gets tried on a significant scale, and I cant wait to see the results.  (Naturally, even the marketplace of ideas has to compete in the marketplace of ideas!)  I agree with Robin that academic science is often tradition-bound to the point of absurdity, and that its institutions ought to be as open to scrutiny and replacement as its theories.   But I dont go as far as he apparently does in the direction of the Myth of the Ivory Tower.  For me, the interesting thing about science is not that its broken, but rather that its about the least broken enterprise in the whole sorry history of our species.Insert string pun here

Over at Peter Woits blog theres a lively discussion about the differences between string theory and intelligent design. There are a few obvious ones: one is based Fields Medal caliber math and the other on elementary mistakes in probability; one is studied at an Institute and the other at an Institute. But arguably, neither theory has yet made a clear prediction or explained what it sets out to in a non-circular way. String theorists explain the muon mass by invoking an infinite set of Calabi-Yau manifolds, some of which presumably yield the right value; IDers explain the complicated dance of bees by invoking a yet more complicated designer.
Of course, an important difference is that most string theorists admit the situation sucks. Many are searching for some deeper principle that would pick out a preferred vacuum (or set of vacua, or probability distribution over vacua) non-anthropically. Based on what little I know, it doesnt sound like an enviable task. Today I had lunch with Frederik Denef, a string theorist whos interested in the computational complexity of finding a minimum-energy vacuum, given a collection of scalar fields. Hes formulated some toy problems, all of which are provably NP-hard (or as hard as unique-SVP under a uniqueness assumption). I was impressed by Denefs knowledge of complexity, and by his willingness to state precise problems that I could understand. But his work suggests an obvious conundrum: if finding an optimal Calabi-Yau is so hard, then how did Nature do it in the first place? (If the string theorists ever succeed, will a voice in the sky boom Thanks, dudes! just before space as we know it disappears?)
In short, if the IDers are armed squatters in the apartment building of science, openly scorning the materialistic concept of rent, then the string theorists are model tenants who often drop by the landlords office to say good afternoon, and by the way, that check from 20 years ago should clear any day. (In their defense, the other quantum gravity theorists checks havent cleared either.) To me, this raises an interesting question: does science need a notion of resource-bounded falsifiability, which is to Poppers original notion as complexity is to computability?Introducing some British people to P vs. NP

Heres a 5-minute interview that I did with The Naked Scientists(a radio showsyndicated by the BBC, and no, Im not sure why its called that),explaining the P vs. NP problem. For readers of this blog, there wont be anythingnew here, but, well  you might enjoythe rest of the hour-long programme [sic], which also includes segments about a few other Clay Millennium problems (the Riemann Hypothesis, Navier-Stokes, and Poincar), as well as a segment about fat fish that livein caves and gorge themselves on food on the rare occasions when it becomes available, and which turn out to share a gene variant with humans with similartendencies.A Woitian links, links, links post (slightly stale but still edible)

Razborov and Rudich won the Gdel Prize for Natural Proofs, which probably did as much as any single paper to elucidate the nature of the P vs. NP problem.  (More from the Bearded One and the Pontiff.) Loosely speaking, R&R showed that any circuit lower bound satisfying certain extremely broad criteria would bite its own tail, and lead to efficient algorithms to distinguish random from pseudorandom functions  the very sort of thing that we wanted to prove was hard. This doesnt by any means imply that a PNP proof is impossible, but it does show how the problem has a strange, self-referential character thats not quite like anything previously encountered in mathematics, including in the work of Gdel and Turing.  Technically simple but conceptually profound, the paper is also a masterpiece of clear, forceful exposition.  When I first came across it as an undergrad at Cornell, I knew complexity was my subject.
Following on the heels of the New Yorker, the New York Times ran its own epic on the Large Hadron Collider.  So science writers can do a decent job when they feel like it.  Why cant they write about P vs. NP the same way?  Oh, right  them big machines 
Andy Drucker poses the following problem: suppose there are n blog posts, and for each post bi, youre told only that it was posted during the time interval [ti,ui].  Is there an efficient algorithm to count how many orderings of the blog posts are compatible with that information?  Alternatively, is the problem #P-complete?  Let me stress that Andy doesnt know the answer to this question, and neither do I.
A certain MIT undergrad of my acquaintance sent the following letter to MITs DMCA enforcement office.
Dear MIT DMCA Agent,
After viewing Scoop and receiving your notice, I was more than happy to comply with NBCs request to destroy it. Rest assured that I will no longer be downloading or sharing any post-Manhattan Woody Allen films.Common Knowledge and Aumanns Agreement Theorem

The following is the prepared versionof a talk that I gave at SPARC: a high-school summer program about applied rationality held in Berkeley, CA for the past two weeks. I had a wonderful time in Berkeley, meeting new friends and old, but Im now leaving to visit the CQT in Singapore, and then to attend the AQIS conference in Seoul.

Common Knowledge and Aumanns Agreement Theorem
August 14, 2015
Thank you so much for inviting me here! I honestly dont know whether its possible to teach applied rationality, the way this camp is trying to do. What I know is that, if it is possible, then the people running SPARC are some of the awesomestpeople on earth to figure out how. Im incredibly proud that Chelsea Voss and Paul Christiano are both former students of mine, and Im amazed by the program they and the others have put together here. I hope youre all having funor maximizing your utility functions, or whatever.
My research is mostly about quantum computing, and more broadly, computation and physics. But I was asked to talk about something you can actually use in your lives, so I want to tell a different story, involving common knowledge.
Ill start with the Muddy Children Puzzle, which is one of the greatest logic puzzles ever invented. How many of you have seen this one?
OK, so the way it goes is, there are a hundred children playing in the mud. Naturally, they all have muddy foreheads. At some point their teacher comes along and says to them, as they all sit around in a circle: stand up if you know your forehead is muddy. No one stands up. For how could they know? Each kid can see all the other 99 kids foreheads, so knows that theyre muddy, but cant see his or her own forehead. (Well assume that there are no mirrors or camera phones nearby, and also that this is mud that you dont feel when its on your forehead.)
So the teacher tries again. Knowing that no one stood up the last time, now stand up if you know your forehead is muddy. Still no one stands up. Why would they? No matter how many times the teacher repeats the request, still no one stands up.
Then the teacher tries something new. Look, I hereby announce that at least one of you has a muddy forehead. After that announcement, the teacher again says, stand up if you know your forehead is muddyand again no one stands up. And again and again; it continues 99 times. But then the hundredth time, all the children suddenly stand up.
(Theres a variant of the puzzle involving blue-eyed islanders who all suddenly commit suicide on the hundredth day, when they all learn that their eyes are bluebut as a blue-eyed person myself, thats always struck me as needlessly macabre.)
Whats going on here? Somehow, the teachers announcing to the children that at least one of them had a muddy forehead set something dramatic in motion, which would eventually make them all stand upbut how could that announcement possibly have made any difference? After all, each child already knew that at least 99 children had muddy foreheads!
Like with many puzzles, the way to get intuition is to change the numbers. So suppose there were two children with muddy foreheads, and the teacher announced to them that at least one had a muddy forehead, and then asked both of them whether their own forehead was muddy. Neither would know. But each child could reason as follows: if my forehead werent muddy, then the other child wouldve seen that, and would also have known that at least one of us has a muddy forehead. Therefore she wouldve known, when asked, that her own forehead was muddy. Since she didnt know, that means my forehead is muddy. So then both children know their foreheads are muddy, when the teacher asks a second time.
Now, this argument can be generalized to any (finite) number of children. The crucial concept here is common knowledge. We call a fact common knowledge if, not only does everyone know it, but everyone knows everyone knows it, and everyone knows everyone knows everyone knows it, and so on. Its true that in the beginning, each child knew that all the other children had muddy foreheads, but it wasnt common knowledge that even one of them had a muddy forehead. For example, if your forehead and mine are both muddy, then I know that at least one of us has a muddy forehead, and you know that too, but you dont know that I know it (for what if your forehead were clean?), and I dont know that you know it (for what if my forehead were clean?).
What the teachers announcement did, was to make it common knowledge that at least one child has a muddy forehead (since not only did everyone hear the announcement, but everyone witnessed everyone else hearing it, etc.). And once you understand that point, its easy to argue by induction: after the teacher asks and no child stands up (and everyone sees that no one stood up), it becomes common knowledge that at least two children have muddy foreheads (since if only one child had had a muddy forehead, that child wouldve known it and stood up). Next it becomes common knowledge that at least three children have muddy foreheads, and so on, until after a hundred rounds its common knowledge that everyones forehead is muddy, so everyone stands up.
The moral is that the mere act of saying something publicly can change the worldeven if everything you said was already obvious to every last one of your listeners. For its possible that, until your announcement, not everyone knew that everyone knew the thing, or knew everyone knew everyone knew it, etc., and that could have prevented them from acting.
This idea turns out to have huge real-life consequences, to situations way beyond children with muddy foreheads. I mean, it also applies to children with dots on their foreheads, or kick me signs on their backs
But seriously, let me give you an example I stole from Steven Pinker, from his wonderful book The Stuff of Thought. Two people of indeterminate genderlets not make any assumptions herego on a date. Afterward, one of them says to the other: Would you like to come up to my apartment to see my etchings? The other says, Sure, Id love to see them.
This is such a clich that we might not even notice the deep paradox here. Its like with life itself: people knew for thousands of years that every bird has the right kind of beak for its environment, but not until Darwin and Wallace could anyone articulate why (and only a few people before them even recognized there was a question there that called for a non-circular answer).
In our case, the puzzle is this: both people on the date know perfectly well that the reason theyre going up to the apartment has nothing to do with etchings. They probably even both know the other knows that. But if thats the case, then why dont they just blurt it out: would you like to come up for some intercourse? (Or fluid transfer, as the John Nash character put it in the Beautiful Mind movie?)
So heres Pinkers answer. Yes, both people know why theyre going to the apartment, but they also want to avoid their knowledge becoming common knowledge. They want plausible deniability. There are several possible reasons: to preserve the romantic fantasy of being swept off ones feet. To provide a face-saving way to back out later, should one of them change their mind: since nothing was ever openly said, theres no agreement to abrogate. In fact, even if only one of the people (say A) might care about such things, if the other person (say B) thinks theres any chance A cares, B will also have an interest in avoiding common knowledge, for As sake.
Put differently, the issue is that, as soon as you say X out loud, the other person doesnt merely learn X: they learn that you know X, that you know that they know that you know X, that you want them to know you know X, and an infinity of other things that might upset the delicate epistemic balance. Contrast that with the situation where X is left unstated: yeah, both people are pretty sure that etchings are just a pretext, and can even plausibly guess that the other person knows theyre pretty sure about it. But once you start getting to 3, 4, 5, levels of indirectionwho knows? Maybe you do just want to show me some etchings.
Philosophers like to discuss Sherlock Holmes and Professor Moriarty meeting in a train station, and Moriarty declaring, I knew youd be here, and Holmes replying, well, I knew that you knew Id be here, and Moriarty saying, I knew you knew I knew Id be here, etc. But real humans tend to be unable to reason reliably past three or four levels in the knowledge hierarchy. (Related to that, you might have heard of the game where everyone guesses a number between 0 and 100, and the winner is whoevers number is the closest to 2/3 of the average of all the numbers. If this game is played by perfectly rational people, who know theyre all perfectly rational, and know they know, etc., then they must all guess 0exercise for you to see why. Yet experiments show that, if you actually want to win this game against average people, you should guess about 20. People seem to start with 50 or so, iterate the operation of multiplying by 2/3 a few times, and then stop.)
Incidentally, do you know what I wouldve given for someone to have explained this stuff to me back in high school? I think that a large fraction of the infamous social difficulties that nerds have, is simply down to nerds spending so muchtime in domains (like math and science) where the point is to struggle with every last neuron to make everything common knowledge, to make all truthsas clear and explicit as possible. Whereas in social contexts, very often youre managing a delicate epistemic balance where you need certain things to be known, but not known to be known, and so forthwhere you need to prevent common knowledge from arising, at least temporarily. Normal people have an intuitive feel for this; it doesnt need to be explained to them. For nerds, by contrast, explaining itin terms of the muddy children puzzle and so forthmight be exactly whats needed. Once theyre told the rules of a game, nerds can try playing it too! They might even turn out to be good at it.
OK, now for a darker example of common knowledge in action. If you read accounts of Nazi Germany, or the USSR, or North Korea or other despotic regimes today, you can easily be overwhelmed by this sense of, so why didnt all the sane people just rise up and overthrow the totalitarian monsters? Surely there were more sane people than crazy, evil ones. And probably the sane people even knew, from experience, that many of their neighbors were saneso why this cowardice? Once again, it could be argued that common knowledge is the key. Even if everyone knows the emperor is naked; indeed, even if everyone knows everyone knows hes naked, still, if its not common knowledge, then anyone who says the emperors naked is knowingly assuming a massive personal risk. Thats why, in the story, it took a child to shift the equilibrium. Likewise, even if you know that 90% of the populace will join your democratic revolt provided they themselves know 90% will join it, if you cant make your revolts popularity common knowledge, everyone will be stuck second-guessing each other, worried that if they revolt theyll be an easily-crushed minority. And because of that very worry, theyll be correct!
(My favorite Soviet joke involves a man standing in the Moscow train station, handing out leaflets to everyone who passes by. Eventually, of course, the KGB arrests himbut they discover to their surprise that the leaflets are just blank pieces of paper. Whats the meaning of this? they demand. What is there to write? replies the man. Its so obvious! Note that this is precisely a situation where the man is trying to make common knowledge something he assumes his readers already know.)
The kicker is that, to prevent something from becoming common knowledge, all you need to do is censor the common-knowledge-producing mechanisms: the press, the Internet, public meetings. This nicely explains why despots throughout history have been so obsessed with controlling the press, and also explains how its possible for 10% of a population to murder and enslave the other 90% (as has happened again and again in our species sorry history), even though the 90% could easily overwhelm the 10% by acting in concert. Finally, it explains why believers in the Enlightenment project tend to be such fanatical absolutists about free speechwhy they refuse to balance it against cultural sensitivity or social harmony or any other value, as so many well-meaning people urge these days.
OK, but let me try to tell you something surprising about common knowledge. Here at SPARC, youve learned all about Bayes rulehow, if you like, you can treat probabilities as just made-up numbers in your head, which are required obey the probability calculus, and then theres a very definite rule for how to update those numbers when you gain new information. And indeed, how an agent that wanders around constantly updating these numbers in its head, and taking whichever action maximizes its expected utility (as calculated using the numbers), is probably the leading modern conception of what it means to be rational.
Now imagine that youve got two agents, call them Alice and Bob, with common knowledge of each others honesty and rationality, and with the same prior probability distribution over some set of possible states of the world. But now imagine they go out and live their lives, and have totally different experiences that lead to their learning different things, and having different posterior distributions. But then they meet again, and they realize that their opinions about some topic (say, Hillarys chances of winning the election) are common knowledge: they both know each others opinion, and they both know that they both know, and so on. Then a striking 1976 result called Aumanns Theorem states that their opinions must be equal. Or, as its summarized: rational agents with common priors can never agree to disagree about anything.
Actually, before going further, lets prove Aumanns Theoremsince its one of those things that sounds like a mistake when you first hear it, and then becomes a triviality once you see the 3-line proof. (Albeit, a triviality that won Aumann a Nobel in economics.) The key idea is that knowledge induces a partition on the set of possible states of the world. Huh? OK, imagine someone is either an old man, an old woman, a young man, or a young woman. You and I agree in giving each of these a 25% prior probability. Now imagine that you find out whether theyre a man or a woman, and I find out whether theyre young or old. This can be illustrated as follows:

The diagram tells us, for example, that if the ground truth is old woman, then your knowledge is described by the set {old woman, young woman}, while my knowledge is described by the set {old woman, old man}. And this different information leads us to different beliefs: for example, if someone asks for the probability that the person is a woman, youll say 100% but Ill say 50%. OK, but what does it mean for information to be common knowledge? It means that I know that you know that I know that you know, and so on. Which means that, if you want to find out whats common knowledge between us, you need to take the least common coarsening of our knowledge partitions. I.e., if the ground truth is some given world w, then what do I consider it possible that you consider it possible that I consider possible that  etc.? Iterate this growth process until it stops, by zigzagging between our knowledge partitions, and you get the set S of worlds such that, if were in world w, then whats common knowledge between us is that the world belongs to S. Repeat for all ws, and you get the least common coarsening of our partitions. In the above example, the least common coarsening is trivial, with all four worlds ending up in the same set S, but there are nontrivial examples as well:

Now, if Alices expectation of a random variable X is common knowledge between her and Bob, that means that everywhere in S, her expectation must be constant  and hence must equal whatever the expectation is, over all the worlds in S! Likewise, if Bobs expectation is common knowledge with Alice, then everywhere in S, it must equal the expectation of X over S. But that means that Alices and Bobs expectations are the same.
There are lots of related results. For example, rational agents with common priors, and common knowledge of each others rationality, should never engage in speculative trade (e.g., buying and selling stocks, assuming that they dont need cash, theyre not earning a commission, etc.). Why? Basically because, if I try to sell you a stock for (say) $50, then you should reason that the very fact that Im offering it means I must have information you dont that its worth less than $50, so then you update accordingly and you dont want it either.
Or heres another one: suppose again that were Bayesians with common priors, and were having a conversation, where I tell you my opinion (say, of the probability Hillary will win the election). Not any of the reasons or evidence on which the opinion is basedjust the opinion itself. Then you, being Bayesian, update your probabilities to account for what my opinion is. Then you tell me your opinion (which might have changed after learning mine), I update on that, I tell you my new opinion, then you tell me your new opinion, and so on. You might think this could go on forever! But, no, Geanakoplos and Polemarchakis observed that, as long as there are only finitely many possible states of the world in our shared prior, this process must converge after finitely many steps with you and me having the same opinion (and moreover, with it being common knowledge that we have that opinion). Why? Because as long as our opinions differ, your telling me your opinion or me telling you mine must induce a nontrivial refinement of one of our knowledge partitions, like so:

I.e., if you learn something new, then at least one of your knowledge sets must get split along the different possible values of the thing you learned. But since there are only finitely many underlying states, there can only be finitely many such splittings (note that, since Bayesians never forget anything, knowledge sets that are split will never again rejoin).
And something else: suppose your friend tells you a liberal opinion, then you take it into account, but reply with a more conservative opinion. The friend takes your opinion into account, and replies with a revised opinion. Question: is your friends new opinion likelier to be more liberal than yours, or more conservative?
Obviously, more liberal! Yes, maybe your friend now sees some of your points and vice versa, maybe youve now drawn a bit closer (ideally!), but youre not going to suddenly switch sides because of one conversation.
Yet, if you and your friend are Bayesians with common priors, one can prove that thats not what should happen at all. Indeed, your expectation of your own future opinion should equal your current opinion, and your expectation of your friends next opinion should also equal your current opinionmeaning that you shouldnt be able to predict in which direction your opinion will change next, nor in which direction your friend will next disagree with you. Why not? Formally, because all these expectations are just different ways of calculating an expectation over the same set, namely your current knowledge set (i.e., the set of states of the world that you currently consider possible)! More intuitively, we could say: if you could predict that, all else equal, the next thing you heard would probably shift your opinion in a liberal direction, then as a Bayesian you should already shift your opinion in a liberal direction right now. (This is related to whats called the martingale property: sure, a random variable X could evolve in many ways in the future, but the average of all those ways must be its current expectation E[X], by the very definition of E[X])
So, putting all these results together, we get a clear picture of what rational disagreements should look like: they should follow unbiased random walks, until sooner or later they terminate in common knowledge of complete agreement. We now face a bit of a puzzle, in that hardly any disagreements in the history of the world have ever looked like that. So what gives?
There are a few ways out:
(1) You could say that the failed prediction of Aumanns Theorem is no surprise, since virtually all human beings are irrational cretins, or liars (or at least, its not common knowledge that they arent). Except for you, of course: youre perfectly rational and honest. And if you ever met anyone else as rational and honest as you, maybe you and they could have an Aumannian conversation. But since such a person probably doesnt exist, youre totally justified to stand your ground, discount all opinions that differ from yours, etc. Notice that, even if you genuinely believed that was all there was to it, Aumanns Theorem would still have an aspirational significance for you: you would still have to say this is the ideal that all rationalists should strive toward when they disagree. And that would already conflict with a lot of standard rationalist wisdom. For example, we all know that arguments from authority carry little weight: what should sway you is not the mere fact of some other person stating their opinion, but the actual arguments and evidence that theyre able to bring. Except that as weve seen, for Bayesians with common priors this isnt true at all! Instead, merely hearing your friends opinion serves as a powerful summary of whatyour friend knows. And if you learn that your rational friend disagrees with you, then even without knowing why, you should take that as seriously as if you discovered a contradiction in your own thought processes. This is related to an even broader point: theres a normative rule of rationality that you should judge ideas only on their meritsyet if youre a Bayesian, of course youre going to take into account where the ideas come from, and how many other people hold them! Likewise, if youre a Bayesian police officer or a Bayesian airport screener or a Bayesian job interviewer, of course youre going to profile people by their superficial characteristics, however unfair that might be to individualsso all those studies proving that people evaluate the same resume differently if you change the name at the top are no great surprise. It seems to me that the tension between these two different views of rationality, the normative and the Bayesian, generates a lot of the most intractable debates of the modern world.
(2) Orand this is an obvious oneyou could reject the assumption of common priors. After all, isnt a major selling point of Bayesianism supposed to be its subjective aspect, the fact that you pick whichever prior feels right for you, and are constrained only in how to update that prior? If Alices and Bobs priors can be different, then all the reasoning I went through earlier collapses. So rejecting common priors might seem appealing. But theres a paper by Tyler Cowen and Robin Hanson called Are Disagreements Honest?one of the most worldview-destabilizing papers Ive ever readthat calls that strategy into question. What it says, basically, is this: if youre really a thoroughgoing Bayesian rationalist, then your prior ought to allow for the possibility that you are the other person. Or to put it another way: you being born as you, rather than as someone else, should be treated as just one more contingent fact that you observe and then conditionalize on! And likewise, the other person should condition on the observation that theyre them and not you. In this way, absolutely everything that makes you different from someone else can be understood as differing information, so were right back to the situation covered by Aumanns Theorem. Imagine, if you like, that we all started out behind some Rawlsian veil of ignorance, as pure reasoning minds that had yet to be assigned specific bodies. In that original state, there was nothing to differentiate any of us from any otheranything that did would just be information to condition onso we all shouldve had the same prior. That might sound fanciful, but in some sense all its saying is: what licenses you to privilege an observation just because its your eyes that made it, or a thought just because it happened to occur in your head? Like, if youre objectively smarter or more observant than everyone else around you, fine, but to whatever extent you agree that you arent, your opinion gets no special epistemic protection just because its yours.
(3) If youre uncomfortable with this tendency of Bayesian reasoning to refuse to be confined anywhere, to want to expand to cosmic or metaphysical scope (I need to condition on having been born as me and not someone else)well then, you could reject the entire framework of Bayesianism, as your notion of rationality. Lest I be cast out from this camp as a heretic, I hasten to say: I include this option only for the sake of completeness!
(4) When I first learned about this stuff 12 years ago, it seemed obvious to me that a lot of it could be dismissed as irrelevant to the real world for reasons of complexity. I.e., sure, it might apply to ideal reasoners with unlimited time and computational power, but as soon as you impose realistic constraints, this whole Aumannian house of cards should collapse. As an example, if Alice and Bob have common priors, then sure theyll agree about everything if they effectively share all their information with each other! But in practice, we dont have time to mind-meld, swapping our entire life experiences with anyone we meet. So one could conjecture that agreement, in general, requires a lot of communication. So then I sat down and tried to prove that as a theorem. And you know what I found? That my intuition here wasnt even close to correct!
In more detail, I proved the following theorem. Suppose Alice and Bob are Bayesians with shared priors, and suppose theyre arguing about (say) the probability of some future eventor more generally, about any random variable X bounded in [0,1]. So, they have a conversation where Alice first announces her expectation of X, then Bob announces his new expectation, and so on. The theorem says that Alices and Bobs estimates of X will necessarily agree to within , with probability at least 1- over their shared prior, after theyve exchanged only O(1/(2)) messages. Note that this bound is completely independent of how much knowledge they have; it depends only on the accuracy with which they want to agree! Furthermore, the same bound holds even if Alice and Bob only send a few discrete bits about their real-valued expectations with each message, rather than the expectations themselves.
The proof involves the idea that Alice and Bobs estimates of X, call them XA and XB respectively, follow unbiased random walks (or more formally, are martingales). Very roughly, if |XA-XB| with high probability over Alice and Bobs shared prior, then that fact implies that the next message has a high probability (again, over the shared prior) of causing either XA or XB to jump up or down by about . But XA and XB, being estimates of X, are bounded between 0 and 1. So a random walk with a step size of  can only continue for about 1/2 steps before it hits one of the absorbing barriers.
The way to formalize this is to look at the variances, Var[XA] and Var[XB], with respect to the shared prior. Because Alice and Bobs partitions keep getting refined, the variances are monotonically non-decreasing. They start out 0 and can never exceed 1 (in fact they can never exceed 1/4, but lets not worry about constants). Now, the key lemma is that, if Pr[|XA-XB|], then Var[XB] must increase by at least 2 if Alice sends XA to Bob, and Var[XA] must increase by at least 2 if Bob sends XB to Alice. You can see my paper for the proof, or just work it out for yourself. At any rate, the lemma implies that, after O(1/(2)) rounds of communication, there must be at least a temporary break in the disagreement; there must be some round where Alice and Bob approximately agree with high probability.
There are lots of other results in my paper, including an upper bound on the number of calls that Alice and Bob need to make to a sampling oracle to carry out this sort of protocol approximately, assuming theyre not perfect Bayesians but agents with bounded computational power. But let me step back and address the broader question: what should we make of all this? How should we live with the gargantuan chasm between the prediction of Bayesian rationality for how we should disagree, and the actual facts of how we do disagree?
We could simply declare that human beings are not well-modeled as Bayesians with common priorsthat weve failed in giving a descriptive account of human behaviorand leave it at that. OK, but that would still leave the question: does this stuff have normative value? Should it affect how we behave, if we want to consider ourselves honest and rational? I would argue, possibly yes.
Yes, you should constantly ask yourself the question: would I still be defending this opinion, if I had been born as someone else? (Though you might say this insight predates Aumann by quite a bit, going back at least to Spinoza.)
Yes, if someone you respect as honest and rational disagrees with you, you should take it as seriously as if the disagreement were between two different aspects of yourself.
Finally, yes, we can try to judge epistemic communities by how closely they approach the Aumannian ideal. In math and science, in my experience, its common to see two people furiously arguing with each other at a blackboard. Come back five minutes later, and theyre arguing even more furiously, but now their positions have switched. As weve seen, thats precisely what the math says a rational conversation should look like. In social and political discussions, though, usually the very best youll see is that two people start out diametrically opposed, but eventually one of them says fine, Ill grant you this, and the other says fine, Ill grant you that. We might say, thats certainly better than the common alternative, of the two people walking away even more polarized than before! Yet the math tells us that even the first caseeven the two people gradually getting closer in their viewsis nothing at all like a rational exchange, which would involve the two participants repeatedly leapfrogging each other, completely changing their opinion about the question under discussion (and then changing back, and back again) every time they learned something new. The first case, you might say, is more like hagglingmore like Ill grant you that X is true if you grant me that Y is truethan like our ideal friendly mathematicians arguing at the blackboard, whose acceptance of new truths is never slow or grudging, never conditional on the other person first agreeing with them about something else.
Armed with this understanding, we could try to rank fields by how hard it is to have an Aumannian conversation in them. At the bottomthe easiest!is math (or, lets say, chess, or debugging a program, or fact-heavy fields like lexicography or geography). Crucially, here I only mean the parts of these subjects with agreed-on rules and definite answers: once the conversation turns to whose theorems are deeper, or whose fault the bug was, things can get arbitrarily non-Aumannian. Then theres the type of science that involves messy correlational studies (I just mean, talking about whats a risk factor for what, not the political implications). Then theres politics and aesthetics, with the most radioactive topics like Israel/Palestine higher up. And then, at the very peak, theres gender and social justice debates, where everyone brings their formative experiences along, and absolutely no one is a disinterested truth-seeker, and possibly no Aumannian conversation has ever been had in the history of the world.
I would urge that even at the very top, its still incumbent on all of us to try to make the Aumannian move, of what would I think about this issue if I were someone else and not me? If I were a man, a woman, black, white, gay, straight, a nerd, a jock? How much of my thinking about this represents pure Spinozist reason, which could be ported to any rational mind, and how much of it would get lost in translation?
Anyway, Im sure some people would argue that, in the end, the whole framework of Bayesian agents, common priors, common knowledge, etc. can be chucked from this discussion like so much scaffolding, and the moral lessons I want to draw boil down to trite advice (try to see the other persons point of view) that you all knew already. Then again, even if you all knew all this, maybe you didnt know that you all knew it! So I hope you gained some new information from this talk in any case. Thanks.

Update: Coincidentally, theres a moving NYT piece by Oliver Sacks, which (among other things) recounts his experiences with his cousin, the Aumann of Aumanns theorem.

Another Update: If I ever did attempt an Aumannian conversation with someone, the other Scott A. would be a candidate! Here he is in 2011 making several of the same points I did above, using the same examples (I thank him for pointing me to his post).Jacob Bekenstein (1947-2015)

Today I learned the sad news that Jacob Bekenstein, one of the great theoretical physicists of our time, passed away at the too-early age of 68.
Everyone knows what a big deal it was when Stephen Hawking discovered in 1975 that black holes radiate. Bekenstein was the guy who, as a grad student in Princeton in the early 1970s, was already raving about black holes having nonzero entropy and temperature, and satisfying the Second Law of Thermodynamicssomething just about everyone, including Hawking, considered nuts at the time. It was, as I understand it, Hawkings failed attempt to prove Bekenstein wrong that led to Hawkings discovery of the Hawking radiation, and thence to the modern picture of black holes.
In the decades since, Bekenstein continued to prove ingenious physical inequalities, often using thought experiments involving black holes. The most famous of these, the Bekenstein bound, says that the number of bits that can be stored in any bounded physical system is finite, and is upper-bounded by ~2.61043 MR, where M is the systems mass in kilograms and R is its radius in meters. (This bound is saturated by black holes, and only by black holes, which therefore emerge as the most compact possible storage mediumthough probably not the best for retrieval!) Bekensteins lectures were models of clarity and rigor: at conferences full of audacious speculations, he stood out to my non-expert eyes as someone who was simply trying to follow chains of logic from accepted physical principles, however mind-bogglingly far those chains led but no further.
I first met Bekenstein in 2003, when I was a grad student spending a semester at Hebrew University in Jerusalem. I was struck by the kindness he showed a 21-year-old nobody, who wasnt even a physics student, coming to bother him. Not only did he listen patiently to my blather about applying computational complexity to physics, he said that of course physics should ultimately aim to understand everything as the output of some computer program, that he too was thinking in terms of computation when he studied black-hole entropy. I remember pondering the fact that the greatest reductionist Id ever met was wearing a yarmulkeand then scolding myself for wasting precious brain-cycles on such a trivial thought when there was science to discuss. I met Bekenstein maybe four or five more times on visits to Israel, most recently a year and a half ago, when we shared walks to and from the hotel at a firewall workshop at the Weizmann Institute. He was unfailingly warm, modest, and generoustotally devoid of the egotism that Ive heard can occasionally afflict people of his stature. Now, much like with the qubits hitting the event horizon, the information that comprised Jacob Bekenstein might seem to be gone, but it remains woven into the cosmos.Wanna bet?

A commenter on my previous post writes:
What all these scientists who are crying about the teaching of evolution should do is propose bets to creationists based on the outcomes of experiments  You think that these D-wave guys wont be able to do something theyre claiming to be able to do? It might be a good exercise to make that statement precise  If someone has a conjecture of the form There should exist a theory that explains X, people roll their eyes, essentially because theres no way of deciding the implicit bet.
Alright, imagine the following conversation:
Layperson: I just heard on the radio about this new Yood dShnood Theory of the Universe.  What do you think the odds are that itll turn out to be true?
Scientist: Well, so far I havent seen any good evidence that
Layperson: Sure, but whats your prediction?
Scientist: As I said, the evidence seems to be explained a lot more easily by
Layperson: But what if you had to bet?
Scientist: Well, there are two ways to think about this.  What the Yood dShnood proponents argue is that
Layperson: No, dont give me a dissertation, just give me a number!
Heres the thing: when my PhD diploma arrived in the mail, it didnt imbue me with some sort of supernatural power to predict the outcomes of future quantum computing experiments, unmediated by the evidence and arguments of the temporal world.  (This despite the fact that my diploma was signed by a time-travelling cyborg, in his official capacity as Governor of California and Regent of the UC system.)
Of course, the reason scientists worry about evidence is that ultimately, we want our theories to cohere with reality and our predictions to come out right.  The experience of the last four centuries suggests this hope is far from futile.  The trouble is that, once youve decided to adopt the evidence-centric strategy thats worked so well in the past, you have to forget temporarily about betting odds.  For the mindset of the scientist toying with rival explanations, and that of the Bayesian handicapping horses in a race, are (at least in my experience) simply too incompatible to inhabit the same brain at the same time.
If youll forgive the metaphor, asking for gambling odds on every scientific question is like asking a woman to sleep with you on the first date.  Of course its in the back of your mind (and possibly not only yours), but it tends to be counterproductive even to bring it up.  If youre ever going to reach the summit, then you have to act like all that really matters to you is the climb, and the only reliable way to act like it is to remake yourself into the sort of person for whom its true.  Such is the paradox of science and of life.
So, did D-Wave succeed in using the quantum adiabatic algorithm to solve Sudoku puzzles in fewer steps than those same puzzles would be solved with classical simulated annealing?  I dont know.  To repeat, I dont know.  What I know is that I havent seen the evidence, and that the burden of providing such evidence rests with the people making the claim.6-photon BosonSampling

The news is more-or-less what the title says!
In Science, a group led by Anthony Laingat Bristol has nowreported BosonSampling with 6 photons, beating their own previous record of 5 photons, as well as the earlier record of 4 photons achieved a few years ago by the Walmsley group at Oxford (as well as the 3-photon experiments done by groups around the world). I only learnedthe big news from a commenter on this blog, after the paper was already published (protip: if youve pushed forward the BosonSampling frontier, feel free to shoot me an email about it).
As several people explain in the comments, the main advance in the paper is arguably not increasing the number of photons, but rather the fact that the device is completely reconfigurable: you can try hundreds of different unitary transformations with the same chip. In addition, the 3-photon results have an unprecedentedly high fidelity (about 95%).
The 6-photon results are, of course, consistent with quantum mechanics: the transition amplitudes are indeed given by permanents of 66 complex matrices. Key sentence:
After collecting 15 sixfold coincidence events, a confidence of P = 0.998 was determined that these are drawn from a quantum (not classical) distribution.
No one said scaling BosonSampling would be easy: Im guessing that ittook weeks of data-gathering to get those 15 coincidence events. Scaling up further will probably require improvements to the sources.
Theres also a caveat: their initial state consisted of 2 modes with 3 photons each, as opposed towhat we really want, which is 6 modes with 1 photon each. (Likewise, in the Walmsley groups 4-photon experiments, the initial state consisted of 2 modes with 2 photons each.) If the number of modes stayed2 forever, then the output distributions would remaineasy to sample with a classical computer no matter how many photons we had, since wed then get permanents of matrices with only 2 distinct rows. So scaling up needsto mean increasing not only the number of photons, but also the number of sources.
Nevertheless, this is an obvious step forward, and it came sooner than I expected. Huge congratulations to the authors on their accomplishment!
But you might ask: given that66 permanents are still pretty easy for a classical computer (the more so when the matrices have only 2 distinct rows), why should anyone care? Well, the new result has major implications for what Ive always regarded as the central goal of quantum computing research, much more important than breaking RSA or Grover search or even quantum simulation: namely,getting Gil Kalai to admit he was wrong. Gil is on record, repeatedly, on this blog as well as his(see for examplehere),as saying that he doesnt think BosonSampling will ever be possible even with 7 or 8 photons. I dont know whether the 6-photon result is giving him second thoughts (or sixth thoughts?) about that prediction.The groupies of science

A friend sent me this Stanford Daily article about the strange tale of Elizabeth Okazaki, who
[f]or the last four years  has attended graduate physics seminars, used the offices reserved for doctoral and post-doctoral physics students and for all intents and purposes made the Varian Physics Lab her home.  The only problem is that Okazaki appears to have no affiliation with Stanford and, according to physics professors and students, no real reason to be there.
The article quotes two people I know: Lenny Susskind (as far as I can tell, she has a very limited knowledge of physics itself) and Alessandro Tomasiello (I feel really bad for her  I dont want to have a conversation with her that will actually hurt her).  From both the article and the many impassioned comments, its clear that opinions in the physics department were mixed.  Of course, by now Stanford has predictably reacted by banning Okazaki from campus.
Heres the thing: while Okazaki is admittedly an extreme case, she reminds me of people Ive known throughout my academic career.   These are the groupies of science: those non-scientists who, for one reason or another, choose to build their whole social lives around science and scientists.  When asked about their research, such people usually mention some vague interdisciplinary project that never seems to come to fruition.
After long deliberation, Ive reached the following conclusion: generally speaking, SCIENCE NEEDS MORE GROUPIES, NOT LESS.
And no, not just for the obvious reason. At their best, groupies perform a vital role in the socially-impoverished scientific ecosystem, by serving as the conveyors of gossip, the organizers of parties, the dispensers of advice, and the matchmakers of lonely nerds with eligible humanists.
Furthermore, science needs a freewheeling culture to function, a point that seems lost on many of the Stanford Daily commenters.  There we find enraged alumni wondering how anyone could possibly get away with this, and declaring that they certainly wont be sending their kids to any school that tolerates such inanity.  We find bigots comparing Okazaki to the Virginia Tech shooter Cho Seung-Hui (the common thread being, apparently, that both of them are Asian). And we find people asking rhetorically whether any corporation or government agency would tolerate a freeloader hanging around its offices for years.   (My answer: probably not, and thats one reason why Im happy not to work at such places!)
On the other hand, we also find commenters denouncing the spoiled bourgeoisie capitalists at Stanford, who would deny a poor homeless woman the right to sleep in their physics building. Unless the critics are Mother Teresas themselves, that doesnt seem fair to me either.
I have no desire to pass judgment on someone Ive never met; any decision on Okazaki ought to rest with the people who actually work in Varian and know the specifics of her case.  But Id like to offer a general suggestion to any department that finds itself in a similar situation in the future: unless the groupie is insane or incompetent, find her some low-paying job as a lab assistant or social programming director or something like that.  When we discover a stowaway on the great Ship of Science, why throw her overboard when we could make her swab the decks?
Update (6/6): Peter Woit now has his own post on this affair, with several entertaining comments.  Im skeptical of the idea that Okazaki had no real interest in science or scientists and only wanted free digs.  Even in the insane housing market of Palo Alto, surely there must be ways to get a roof over your head that dont require sitting in on theoretical physics seminars?
I also found the following comment priceless:
I think Scott Aaronsons opinion is quite shallow  Scott wants groupies, and he wants to hire them to swab the decks. Only someone who thinks he is so special he should have serfs to serve him would think that way. College Professors already have a bunch of poorly paid workers(graduate students) who write papers for them. Do these aristocrats need an additional class of poorly paid servants
It always amuses me when those looking for an elite to rail against pick people who strive for a decade against staggering odds to have ideas that no one in the history of the world ever had before, in order that they might possibly qualify for a stressful, ~90-hour-a-week job offering the same money, power, and prestige that would accrue automatically to a mid-level insurance salesman.D-Wave Open Thread

A bunch of people have asked me to comment on D-Waves release of its 1000-qubit processor, and a paper by a group including Cathy McGeoch saying that the machine is 1 or 2 orders of faster (in annealing time, not wall-clock time) than simulated annealing running on a single-core classical computer. Its even been suggested that the Scott-signal has been shining brightly for a week above Quantham City, but that Scott-man has been too lazy and out-of-shape even to change into his tights.
Scientifically, its not clear if much has changed. D-Wave now has a chip with twice as many qubits as the last one. That chip continues to be pretty effective at finding its own low-energy states: indeed, depending on various details of definition, the machine can even find its own low-energy states faster than some implementation of simulated annealing running on a single-core chip. Of course, its entirely possible that Matthias Troyer or Sergei Isakov or Troels Ronnow or someone like that will be able to find a better implementation of simulated annealing that closes even the modest gapas happened the last timebut Ill give the authors the benefit of the doubt that they put good-faith effort into optimizing the classical code.
More importantly, Id say it remains unclear whether any of the machines performance on the instances tested here can be attributed to quantum tunneling effects. In fact, the paper explicitly states (see page 3) that its not going to consider such questions, and I think the authors would agree that you could very well see results like theirs, even if what was going on was fundamentally classical annealing. Also, of course, its still true that, if you wanted to solve a practical optimization problem, youd first need to encode it into the Chimera graph, and that reduction entails a loss that could hand a decisive advantage to simulated annealing, even without the need to go to multiple cores. (This is what Ive described elsewhere as essentially all of these performance comparisons taking place on the D-Wave machines home turf: that is, on binary constraint satisfaction problems that have precisely the topology of D-Waves Chimera graph.)
But, I dunno, Im just not feeling the urge to analyze this in more detail. Part of the reason is that I think the press might be getting less hyper-excitable these days, thereby reducing the need for a Chief D-Wave Skeptic. By this point, there may have been enough D-Wave announcements that papers realize they no longer need to cover each one like an extraterrestrial landing. And there are more hats in the ring now, with John Martinis at Google seeking to build superconducting quantum annealing machines but with ~10,000x longer coherence times than D-Waves, and with IBM Research and some others also trying to scale superconducting QC. The realization has set in, I think, that both D-Wave and the others are in this for the long haul, with D-Wave currently having lots of qubits, but with very short coherence times and unclear prospects for any quantum speedup, and Martinis and some others having qubits of far higher quality, but not yet able to couple enough of them.
The other issue is that, on my flight from Seoul back to Newark, I watched two recent kids movies that were almost defiant in their simple, unironic, 1950s-style messages of hope and optimism. One was Disneys new live-action Cinderella; the other was Brad Birds Tomorrowland. And seeing these back-to-back filled me with such positivity and good will that, at least for these few hours, its hard to summon my usual crusty self. I say, lets invent the future together, and build flying cars and jetpacks in our garages! Let a thousand creative ideas bloom for how to tackle climate change and the other crises facing civilization! (Admittedly, mass-market flying cars and jetpacks are probably not a step forward on climate change  but, see, theres that negativity coming back.) And let another thousand ideas bloom for how to build scalable quantum computerssure, including D-Waves! Have courage and be kind!
So yeah, if readers would like to discuss the recent D-Wave paper further (especially those who know something about it), theyre more than welcome to do so in the comments section. But Ive been away from Dana and Lily for two weeks, and will endeavor to spend time with them rather than obsessively reloading the comments (lets see if I succeed).
As a small token of my goodwill, I enclose two photos from my last visit to a D-Wave machine, which occurred when I met with some grad students in Waterloo this past spring. As you can see, I even personally certified that the machine was operating as expected. But more than that: surpassing all reasonable expectations for quantum AI, this model could actually converse intelligently, through a protruding head resembling that of IQC grad student Sarah Kaiser.Physics for Doofuses: Mass vs. charge deathmatch

Back in high school, I was struck by the apparent symmetry between mass and charge. For the one youve got Newtons F=Gm1m2/r2, for the other youve got Coulombs F=Kq1q2/r2. So then why, in our current understanding of the universe, are mass and charge treated so differently? Why should one be inextricably linked to the geometry of spacetime, whereas the other seems more like an add-on? Why should it be so much harder to give a quantum-mechanical treatment of one than the other? Notwithstanding that such questions occupied Einstein for the last decades of his life, lets plunge ahead.
When we look for differences between mass and charge, we immediately notice several.
(1) Charge can be negative whereas mass cant.
Thats why gravity is always attractive, whereas the Coulomb force is both attractive and repulsive. Since positive and negative charges tend to neutralize each other, this already explains why gravity is relevant to the large-scale structure of the universe while electromagnetism isnt. It also explains why there cant be any charge black holes analogous to gravitational black holes. (I dont mean charged black holes; I mean black holes that are black because of electric charge.) Unfortunately, it still doesnt explain why mass should be related to the geometry of spacetime.
(2) Charge appears to be quantized (coming in units of 1/3 of an electron charge), whereas mass appears not to be quantized, at least not in units we know.
(3) The apparent mass of a moving object increases Lorentzianly, whereas the charge is invariant.
These are interesting differences, but they also dont seem to get us anywhere.
(4) Gravity is many orders of magnitude weaker than electromagnetism.
One hears this statement often; the trouble is, what does it mean? How does one compare the intrinsic strength of gravity and electromagnetism, without plugging in the masses and charges of typical particles that we happen to find in the universe? (Help me.)
(5) Gravity is transmitted by a spin-2 particle, whereas electromagnetism is transmitted by a spin-1 particle.
This difference is surely crucial; the trouble with it (to use a pomo word) is that its too theory-laden.  Since no one has ever seen a graviton, the reason we know gravitons are spin-2 particles in the first place must have to do with more basic properties of gravity.  So if we want a non-circular explanation for why gravity is different from the Coulomb force, itd be better to phrase the explanation directly in terms of the more basic properties.
(6) Charge shows up in only one fundamental equation of physics  F=Kq1q2/r2  whereas mass shows up in two equations: F=Gm1m2/r2 and F=ma.
Now we finally seem to be getting somewhere. Difference (6) was the basis for Einsteins equivalence principle, which was one of the main steps on the road to general relativity.
But while the equivalence principle suggests the possibility of relating mass to spacetime geometry, I could never understand why it implies the necessity of doing so. If we wanted, why couldnt we simply regard the equivalence of gravitational and inertial mass as a weird coincidence? Why are we forced to take the drastic step of making spacetime itself into a pseudo-Riemannian manifold?
The answer seems to be that were not!  Its possible to treat general relativity as just a complicated field theory on flat spacetime, involving a tensor at every point  and indeed, this is a perspective that both Feynman and Weinberg famously adopted at various times.  Its just that most people see it as simpler, more parsimonious, to interpret the tensors geometrically.
So the real question is: why should the field theory of Gmm/r2 involve these complicated tensors (which also turn out to be hard to quantize), whereas the field theory of Kqq/r2 is much simpler and easier to quantize?
After studying this question assiduously for years (alright, alright  I Googled it), I came across the following point, which struck me as the crucial one:
(7) Whereas the electric force is mediated by photons, which dont themselves carry charge, the gravitational force is mediated by gravitons, which do themselves carry energy.
Photons sail past each other, ships passing in the night. Theyre too busy tugging on the charges in the universe even to notice each others presence. (Indeed, this is why its so hard to build a quantum computer with photons as qubits, despite photons excellent coherence times.) Gravitons, by contrast, are constantly tugging at the matter in the universe and at each other. This is why Maxwells equations are linear whereas Einsteins are nonlinear  and that, in turn, is related to why Einsteins are so much harder than Maxwells to quantize.
When I ran this explanation by non-doofus friends like Daniel Gottesman, they immediately pointed out that Ive ignored the strong nuclear force  which, while its also nonlinear, turns out to be possible to quantize in certain energy regimes, using the hack called renormalization.  Incidentally, John Preskill told me that this hack only works in 3+1 dimensions: if spacetime were 5-dimensional, then the strong force wouldnt be renormalizable either.  And in the other direction, if spacetime were 3-dimensional, then gravity would become a topological theory that we do sort of know how to quantize.
However, I see no reason to let these actual facts mar our tidy explanation.  Think of it this way: if electromagnetism (being linear) is in P and gravity (being nonlinear) is NP-complete, then the strong force is Graph Isomorphism.
My physicist friends were at least willing to concede to me that, while the explanation Ive settled on is not completely right, its not completely wrong either. And that, my friends, means that it more than meets the standards of the Physics for Doofuses series.Ask Me Anything: Diversity Edition

With the fall semester imminent, andby popular request, I figured Id do another Ask Me Anything (see here for the previous editions). This one has a special focus: Im looking for questions from readers who consider themselves members of groups that have historically been underrepresented in the Shtetl-Optimized comments section. Besides the obviouse.g.,women andunderrepresented ethnic groupsother examples might include children,traditionally religious people, jocks, liberal-arts majors (but any group that includesJohn Sidles is probablynotan example). If I left out your group, please go ahead and bring it to my and your fellow readers attention!
My overridingideal in lifewhatis to me as Communismwas to Lenin, as Frosted Flakes are to Tony the Tigeris people of every backgroundcoming together to discover and debate universal truths that transcend their backgrounds. Sofew things have ever stung me morethanaccusations ofbeing a closed-minded ivory-tower elitist white male nerd etc. etc. Anyway, to anyone whos ever felt excluded herefor whatever reason, I hope this AMA will be taken as a small token of goodwill.
Similar rules apply as to my previous AMAs:

Only one question per person.
No multi-part questions, or questions that require me to read a document or watch a video and then comment on it.
Questions need not have anything to do with yourunderrepresented group (though they could). Math, science, futurology, academic career advice, etc. are allfine. But please be courteous; anything gratuitouslynosy or hostilewill be left in the moderation queue.
Ill stop taking further questions most likely after 24 hours (Ill post a warning before closing the thread).

Update (Sep. 6): For anyone from the Boston area, or planning to visit it, I have an important piece of advice. Do not ever, under any circumstances, attempt to visit Walden Pond, and tell everyone you know to stay away. After we spent 40 minutes drivingthere with a toddler, the warden literally screamed at us to go away, that the park was at capacity. It wasnt an issue of parking: even if wed parked elsewhere, we just couldnt go. Exceptions were made for the people in front of us, but not for us, the ones with the 2-year-old whod been promised her weekend outing would be to meet her best friend at Walden Pond. Its strangely fitting that what for Thoreau was a place of quiet contemplation, is today purely a site of overcrowding and frustration.
Another Update: OK, no new questions please, only comments on existing questions!  Ill deal with the backlog later today.  Thanks to everyone who contributed.Bluehost sucks

I apologize for my website being down all morning.  Back in the heyday of Bell Labs, they used to engineer telecommunications systems for five-nines availability (that is, 99.999% uptime).  In our vastly more sophisticated Internet age, Id gladly settle for two and a half nines.
So, can anyone recommend a webhosting service that doesnt suck?  If such a service exists, Ill dump Bluehost and encourage others to do the same.Bell inequality violation finally done right

A few weeks ago, Hensen et al., of the Delft University of Technology and Barcelona, Spain,put out a paperreporting the first experiment that violates the Bell inequality in a way that closes off the two main loopholes simultaneously: the locality and detection loopholes. Well, at leastwith~96% confidence. This is big news, not onlybecause of the result itself,but because of the advances in experimental technique needed to achieve it. Last Friday, two renownedexperimentalistsChris Monroe of U. of Maryland and Jungsang Kim of Dukevisited MIT, and in addition to talking about their own exciting ion-trap work, they did a huge amount to help me understand the new Bell test experiment. So OK, let me try to explain this.
While some people like to make it more complicated, the Bell inequality is the following statement. Alice and Bob are cooperating with each other to win a certain game (the CHSH game) with the highest possibleprobability. They can agree on a strategy and share information and particles in advance, but then they cant communicate once the game starts. Alice gets a uniform random bit x, and Bob gets a uniform random bit y (independent of x). Their goal is to output bits, a and b respectively, such that a XOR b = x AND y: in other words, such that a and b are different if and only if x and y are both 1. The Bell inequality says that, in any universe that satisfies the property oflocal realism,no matter which strategy they use,Alice and Bob can win the game at most 75% of the time (for example, by always outputting a=b=0).
What does local realism mean? It means that, after she receives her input x, any experimentAlice can performin her lab has a definite resultthat mightdepend onx, on the stateof her lab, and on whatever information she pre-shared with Bob, but at any rate, not on Bobs input y. If you like: a=a(x,w) is a function of x and of the information w available before the game started, but is nota function of y. Likewise, b=b(y,w) is a function of y and w, but not of x. Perhaps the best way to explain local realism is thatits the thing you believe in, if you believeall the physicists babbling about quantum entanglement justmissed something completely obvious. Clearly, at the moment two entangled particles are created, but before they separate, one of them flips a tiny coin and then says to the other, listen, if anyone asks, Ill be spinning up and youll be spinning down. Then the nave, doofusphysicists measure one particle, find it spinning down, and wonder how the other particle instantly knows to be spinning upoooh, spooky! mysterious! Anyway, if thats how you think it has to work, then you believe in local realism, and you must predict that Alice and Bob can win the CHSH game with probability at most 3/4.
What Bell observedin 1964 is that, even though quantum mechanics doesnt let Alice send a signal to Bob (or vice versa) faster than the speed of light, it still makes a prediction aboutthe CHSH game that conflicts with local realism. (And thus, quantum mechanics exhibits what one might not have realized beforehand was even a logical possibility: it doesnt allow communication faster than light, but simulating the predictions of quantum mechanics in a classical universewould require faster-than-light communication.) In particular, if Alice and Bob share entangled qubits, say $$\frac{\left| 00 \right\rangle + \left| 11 \right\rangle}{\sqrt{2}},$$ then theres a simple protocol that lets them violate the Bellinequality, winning the CHSH game ~85% of the time (with probability (1+1/2)/2 > 3/4). Starting in the 1970s, people did experiments that vindicated the prediction of quantum mechanics, and falsified local realismor so the story goes.
The violation of the Bell inequality has a schizophrenic status in physics. To many of the physicists I know, Natures violating the Bell inequality is so trivial and obviousthat its barely even worth doing the experiment: if people had just understood and believed Bohr and Heisenberg back in 1925, there wouldve been no need for this whole tiresome discussion. To others, however, the Bell inequality violation remains so unacceptable that someway must be found arounditfrom casting doubt on the experiments that have been done, to overthrowing basic presuppositions of science(e.g., our own freedom to generaterandom bits x and y to send to Alice and Bob respectively).
For several decades, there was a relatively conservative way out for local realist diehards, and that was to point to loopholes: imperfections in the existing experiments whichmeant that local realism was still theoretically compatible with the results, at least if one was willing to assume a sufficiently strange conspiracy.
Fine, you interject, but surelyno one literallybelieved these little experimental imperfections would be the thing that would rescue local realism? Not so fast. Right here, on this blog, Ive had people point to the loopholes as a reason to acceptlocal realism and reject the reality of quantum entanglement. See, for example, the numerous comments byTeresa Mendes in myWhether Or Not God Plays Dice, I Dopost. Arguing with Mendes back in 2012, I predictedthat the two main loopholes would both be closed in a single experimentand not merely eventually, but in, like, a decade. I was wrong: achieving this milestonetook only a few years.
Before going further, lets understand what the two main loopholes are (or rather, were).
The locality loophole arises because the measuring process takes time and Alice and Bob are not infinitely far apart. Thus, suppose that, the instant Alice starts measuring her particle, a secret signal starts flying toward Bobs particle at the speed of light, revealing her choice of measurement setting (i.e., the value of x). Likewise, the instant Bob starts measuring his particle, his doing so sends a secret signal flying toward Alices particle, revealing the value of y. By the time the measurements are finished, a few microseconds later, theres been plenty of time for the two particles to coordinate their responses to the measurements, despite being classical under the hood.
Meanwhile, the detection loophole arises because in practice, measurements of entangled particlesespecially of photonsdont always succeed in finding the particles, let alone ascertaining their properties. So one needs to select those runs of the experiment where Alice and Bob both findthe particles, and discard all the bad runs where they dont. This by itself wouldnt be a problem, if not for the fact that the very same measurement that revealswhether the particles are there, is also the one that counts (i.e., where Alice and Bob feed x and y and get out a and b)!
To someone with a conspiratorial mind, this opens up the possibility that the measurements success or failureis somehowcorrelated with its result, in a way that could violate the Bell inequality despite there being no real entanglement. To illustrate, suppose that at the instant theyre created, one entangled particle says to the other: listen, if Alice measures me in the x=0 basis, Ill give the a=1 result. If Bob measures you in the y=1 basis, you give the b=1 result. In any other case, well just evade detection and count this run as a loss. In such a case, Alice and Bob will win the game with certainty, whenever itgets played at allbut thats only because of the particles freedom to choose which rounds will count. Indeed, by randomly varying their acceptable x and y values from one round to the next, the particles can even make it look like x and y have no effect on the probability of a rounds succeeding.
Until a month ago, the state-of-the-art was that there were experiments that closed the locality loophole, and other experiments that closed the detection loophole, but there was no single experiment that closed both of them.
To close the locality loophole, all you need is a fast enough measurement on photons that are far enough apart. That way, even if the vast Einsteinian conspiracy is trying to send signals between Alices and Bobs particles at the speed of light, to coordinate the answers classically, the whole experiment will be done before the signals can possibly have reached their destinations. Admittedly, as Nicolas Gisin once pointed out to me, theres a philosophical difficulty in definingwhat we mean by the experiment being done. To some purists, a Bellexperiment might only be done once the results (i.e., the values of a and b) are registered in human experimenters brains! And given the slowness of human reaction times, this might implythat a real Bell experiment ought tobe carried outwith astronauts on faraway space stations, or with Aliceon the moonand Bob on earth(which, OK, would be cool). If were being reasonable, however, we can grant that the experiment is done once a and b are safely recorded in classical, macroscopic computer memoriesin which case, given the speed of modern computer memories, separating Alice and Bob by half a kilometer can be enough. And indeed, experiments starting in 1998 (see for example here) have done exactly that; the current record, unless Im mistaken,is 18 kilometers. (Update: I was mistaken; its 144 kilometers.) Alas, since these experiments used hard-to-measure photons, they were still open to the detection loophole.
To close the detection loophole, the simplest approach is to use entangled qubitsthat (unlike photons) are slow and heavy and can be measured with success probability approaching 1. Thats exactly what various groups did starting in 2001 (see for example here), withtrapped ions,superconducting qubits, and other systems. Alas, given current technology, these sorts of qubitsarevirtuallyimpossible to move miles apart from each other without decohering them. So the experiments used qubits that were close together, leaving the locality loophole wide open.
So the problem boils down to: how do you create long-lasting, reliably-measurable entanglement between particles that are very far apart (e.g., in separate labs)? There are three basic ideas in Hensen et al.s solution to this problem.
The first idea is to use a hybrid system. Ultimately, Hensen et al. create entanglement between electron spins in nitrogen vacancy centers in diamond (one of the hottestor coolest?experimental quantum information platforms today), in two labs that are about a mile awayfrom each other. To get these faraway electron spins to talk to each other, they make them communicate via photons. If you stimulate an electron, itll sometimes emit a photon with which its entangled. Very occasionally, the two electrons you care about will even emit photonsat the same time. In those cases, by routing those photons into optical fibers and then measuring the photons, its possible to entangle the electrons.
Wait, what? How does measuring the photons entanglethe electrons from whence they came? This brings us to the second idea, entanglement swapping. The latter is a famous procedure to create entanglement between two particles A and B that have never interacted, by merely entangling A with another particle A, entangling B with another particle B, and then performingan entangled measurement on A and B and conditioning on its result. To illustrate, consider the state
$$ \frac{\left| 00 \right\rangle + \left| 11 \right\rangle}{\sqrt{2}} \otimes \frac{\left| 00 \right\rangle + \left| 11 \right\rangle}{\sqrt{2}}$$
and now imagine that we project the first and third qubits onto the state $$\frac{\left| 00 \right\rangle + \left| 11 \right\rangle}{\sqrt{2}}.$$
If the measurement succeeds, you can check that well be left with the state $$\frac{\left| 00 \right\rangle + \left| 11 \right\rangle}{\sqrt{2}}$$ in the second and fourth qubits, even though those qubits were not entangled before.
So to recap: these two electron spins, in labs a mile away from each other, both have some probability of producing a photon. The photons, if produced, are routed to a third site, where if theyre both there, then an entangled measurement on both of them (and a conditioning on the results of that measurement) has some nonzero probability of causing the original electron spins to become entangled.
But theres a problem: if youve been paying attention, all weve done is cause the electron spins to become entangled with some tiny, nonzero probability (something like 6.410-9 in the actual experiment). So then, why is this any improvement over the previousexperiments, which just directly measuredfaraway entangled photons, and also had some small but nonzero probability of detecting them?
This leads to the third idea. The new setup is an improvement because, whenever the photon measurementsucceeds, we know that the electron spins are there and that theyre entangled, without having to measurethe electron spins to tell us that. In other words, weve decoupled the measurement that tells us whether we succeeded in creating an entangled pair, from the measurementthat uses the entangled pair to violate the Bell inequality. And because of that decoupling, we can now just condition on the runs of the experiment where the entangled pair was there, without worrying that that will open up the detection loophole, biasing the results via some bizarrecorrelated conspiracy. Its as if the whole experiment were simply switched off, except for those rare lucky occasionswhen an entangled spinpair gets created (with its creation heralded by the photons). On those rare occasions, Alice and Bob swing into action, measuring their respective spins within the brief window of timeabout 4 microsecondsallowed by the locality loophole, seeking an additional morsel of evidence that entanglement is real. (Well, actually, Alice and Bobswing into action regardless; they only find out later whether this was one of the runs that counted.)
So, those are the main ideas (as well as I understand them); then theres lots of engineering. In their setup, Hensen et al. were able to create just a few heralded entangled pairs per hour. This allowedthem to produce 245 CHSH gamesfor Alice and Bob to play, and to reject the hypothesis of local realism at ~96% confidence. Jungsang Kim explained to me that existing technologies could have produced many more events per hour, andhence, in a similar amount of time, particle physics (5 or more) rather than psychology(2) levels of confidence that local realism is false. But in this type of experiment, everything is a tradeoff. Building not one but two labs for manipulating NV centers in diamond is extremely onerous, and Hensen et al. did what they hadto do to get a significant result.
The basic idea here, of using photons to entangle longer-lasting qubits, is useful for more than pulverizing local realism. In particular, the idea is a majorpart of current proposals for how to build a scalable ion-trap quantum computer. Because of cross-talk, you cant feasibly put more than 10 or so ions in the same trap while keeping all of them coherent and controllable. So the current ideas for scaling up involve having lots of separate trapsbut in that case, one will sometimes need to perform a Controlled-NOT, or some other 2-qubit gate, between a qubit in one trap and a qubit in another. This can be achieved using the Gottesman-Chuang technique of gate teleportation, providedyou have reliable entanglement between the traps. But how do you create such entanglement? Aha: the current idea is to entangle the ions by using photons as intermediaries, very similar in spirit to what Hensen et al. do.
At a more fundamental level, will this experiment finally convince everyonethat local realism is dead, and that quantum mechanics mightindeed be the operating system of reality? Alas, I predict that those who confidently predicted that a loophole-free Bell test could never be done, will simply findsome new way to wiggle out, without admitting the slightest problem for their previous view. This prediction, you might say, is based ona different kind of realism.In support of an academic boycott

Todays topic is one I was hoping I could avoid, since I know that my stance will alienate many of my own supporters.  But after I read the comments on this post by Bill Gasarch, and reflected on all the men, women, and children who were dispossessed of their land while the world did nothing, I realized I could no longer remain silent.
Most of you will know what Im talking about, but for those who dont: I urge the readers of this blog to join me in severing all academic ties with the settler state of New Zealand, until that state makes complete restitution for its historic crimes against the Maori people.  That means no more giving seminars at the University of Auckland.  No more reading papers with ac.nz in the authors email address.  Indeed, no more involvement with any physics or climate research in Antarctica, the flights to which leave from Christchurch.
Some will say my proposed boycott smacks of anti-Kiwi prejudice. But in reality, some of my best friends are Kiwis.  Furthermore, I hope and expect that those Kiwis who care about justice will embrace my proposal, for the chance it affords their rogue state to confront the lies and denial upon which it was founded.
Others will ask: if were going to boycott Kiwi scientists over the dispossession of the Maori, then why not boycott Australian scientists over the aboriginals, Chinese scientists over the Tibetans, or American scientists over the Native Americans, Iraqis, Vietnamese, or Guatemalans?  I trust, however, that sensible people will recognize this question for the Kiwi diversionary tactic that it is. For what could Australia, China, or the US possibly have to do with New Zealand?  Until the Kiwis acknowledge that the issue is them and only them, there is no hope for progress.
Even in a world rife with violence and despair, I can think of no single issue with a greater claim upon our conscience.  And that is why I ask again: who will join me in severing all academic ties with New Zealand?Six announcements

I did a podcast interview with Julia Galeffor her seriesRationally Speaking. See also here for the transcript (which I read rather than having to listen to myself stutter). Theinterview is all about Aumanns Theorem, and whether rational people can agree to disagree. It covers a lotof the same ground as my recent poston the same topic, exceptwith less technical detail about agreement theory and more  well, agreement. At Julias suggestion, were planning to do a follow-up podcast about the particular intractability of online disagreements. I feel confident that well solvethat problem once and for all. (Update: Also check outthis YouTube video, where Julia offers additional thoughts about what we discussed.)
When Julia asked me to recommend a book at the end of the interview, I picked probably my favorite contemporary novel:The Mind-Body Problem by Rebecca Newberger Goldstein. Embarrassingly, I hadnt realized that Rebecca had alreadybeen on Julias show twice as a guest! Anyway, one of the thrills of my life over the last year has been to get to know Rebecca a little, as well as her husband, whos some guy named Steve Pinker. Like, they both live right here in Boston! You can talk to them! I was especially pleased two weeks ago to learn that Rebecca won the National Humanities Medalas I told Julia, Rebecca Goldstein getting a medal at the White House is the sort of thing I imagine happening in my ideal fantasy world, making it a pleasant surprise that it happened in this one. Huge congratulations to Rebecca!
The NSA has released probably its most explicit public statement so far about its plans to move to quantum-resistantcryptography. For more seeBruce Schneiers Crypto-Gram. Hat tip for this item goes to reader Ole Aamot, one of the only people Ive ever encountered whose name alphabetically precedesmine.
Last Tuesday, I got tohear Ayaan Hirsi Ali speak at MIT about her new book, Heretic, and thenspendalmost an hour talking to students who had come to argue with her. I found her clear, articulate, and courageous (as I guess one hasto be in her line of work, even with armed cops on either side of the lecture hall). After the shameful decision of Brandeis in caving in to pressure and cancelling Hirsi Alis commencement speech, I thought it spoke wellof MIT that they letherspeak at all. The bar shouldnt be that low, but it is.
From far away on the political spectrum, I also heard Noam Chomsky talk last week (my first time hearing him live), about the current state of linguistics. Much of the talk, it struck me, could have been given in the 1950s with essentiallyzero change (and I suspect Chomsky would agree), though a few parts of it were newer, such as the speculation that human languages have many of the features they do in order to minimize the amount of computation that the speaker needsto perform. The talk was full of declarations that there had been no useful work whatsoever on various questions (e.g., about the evolutionary function of language), that they were totalmysteries and would perhapsremain totalmysteries forever.
Many of you have surely heard by now that Terry Tao solvedthe Erds Discrepancy Problem, by showing that for everyinfinite sequence of heads and tails and every positive integer C, theres a positive integer k such that, if you look at the subsequence formed by every kth flip, there comes a point where the heads outnumber tails or vice versa by at least C. This resolves a problem thats been open for more than 80 years. For more details, see this post by Timothy Gowers. Notably, Taos proof builds, in part, on a recent Polymath collaborative online effort. It was a big deal last year when Konev and Lisitsa used a SAT-solver to prove that theres always a subsequence with discrepancy at least 3; Taos result now improves on that bound by .aaronson@mit

They rejected me for undergrad.  They rejected me for grad school.  And for reasons best known to them, in July theyre going to let me loose on their campus as an Assistant Professor of Electrical Engineering and Computer Science.
This decision was one of the hardest Ive ever made.   I was lucky to have a half-dozen fantastic offers (apparently, larding your job talk with jokes actually works). I asked myself: can I really see myself as an MIT person?  Can I deal with the pressure, the competitiveness, the non-rectangular Stata Center offices, the winters said to be even worse than Waterloos?  Wouldnt I prefer (for example) to return to my alma mater, and bask in the familiar sunshine of the Peoples Republic of Berkeley  a place whose politics make Cambridge, Massachusetts look like Oklahoma City?
In the end, though, MIT simply refused to cooperate in giving me a good reason to turn it down.  Among the considerations that tilted me toward Cambridge, the most important by far was the high caliber of ice cream available there.  Other factors included the chance to get in some quality arguing time with Ed Farhi; students who solve your open problems before youve even finished stating them; the urge to spread the Gospel of Vazirani I imbibed at Berkeley in relatively virgin territory; and MITs role as a publicly-visible platform from which to pursue my central ambition in life, fighting doofosity wherever and whenever I find it.  And, of course, a strong desire to be closer to Lubo Motl.
But just as I was getting ready to sign the contract, a sticking point emerged that threatened to derail the entire decision.  My brother, David, had already taken the address aaronson@mit.edu.  Luckily for me, though, David graduated just last week with a bachelors in math, and Srini Devadas, MITs Associate Head for Computer Science, has assured me in writing that I can have Davids address as soon as it lapses.  As a new faculty member, I was even formally able to present Davids degree to him:

Let me end this post with a plea to any superstar undergrads who (when youre not procrastinating by reading this blog) are considering applying to grad school in theoretical computer science. Sure, your decision might seem like an obvious one, but please give the unBerkeley a chance.  If you do decide come to Cambridge, MA, there will now be someone around who you can work with  I mean, yknow, besides Demaine, Goemans, Goldwasser, Indyk, Karger, Kelner, Kleitman, Leighton, Lynch, Micali, Mitzenmacher, Rivest, Rubinfeld, Shor, Sipser, Sudan, Vadhan, Valiant, Ordinary Words Will Do

Izabella Laba, a noted mathematician at the University of British Columbia, recently posted some tweets that used me as a bad, cautionary example for how STEM faculty should be less contemptuous of social sciences. Here was the offending comment of mine, from the epic Walter Lewin thread last fall:
[W]hy not dispense with the empirically-empty notion of privilege, and just talk directly about the actual well-being of actual people, or groups of people? If men are doing horrific things to womenfor example, lashing them for driving cars, like in Saudi Arabiathen surely we can just say so in plain language. Stipulating that the torturers are exercising their male privilege with every lash adds nothing to anyones understanding of the evil. Its bad writing. More broadly, it seems to me that the entire apparatus of privilege, delegitimation, etc. etc. can simply be tossed overboard, to rust on the ocean floor alongside dialectical materialism and other theoretical superstructures that were once pompously insisted upon as preconditions of enlightened social discourse. This isnt quantum field theory. Ordinary words will do.
Prof. Laba derisively commented:
Might as well ask you to explain calculus without using fancy words like derivative or continuous. Simple number arithmetic will do.
Prof. Labas tweets were favorited by Jordan Ellenberg, a mathematician who wrote the excellent popular book How Not to Be Wrong. (Ellenberg had also criticized me last year for my strange, nave idea that human relations can be thoughtabout using logic.)
Given my respect for the critics, I guess Imhonor-bound to respond.
For the record, I tend not to think about the social sciencesor for that matter, the natural sciencesas monolithic entities at all. I admire any honest attempt to discoverthe truth about anything. And not being a postmodern relativist, I believe there are deep truths worth discovering in history, psychology, economics, linguistics, possibly even sociology. Reading the books of Steven Pinker underscored for me how much is actually understood nowadays about human naturemuch of it onlyfigured outwithin the last half-century. Likewise, reading the voluminous profundities of Scott Alexander taught me that even in psychiatry, there are truths (and even a few definite cures) to be had for those who seek.
I also believethat the social sciences are harderway harderthan math or physics or CS. Theyre harder because of the tenuousness of the correlations, because of the complexity of each individual human brain (let alone 7 billion of them on the same planet), but most of all, because politics and ideology and the scientists own biases place such powerful thumbs on the scale. This makes it all the more impressive when a social scientist, like (say) Stanley Milgram or Judith Rich Harris or Napoleon Chagnon, teaches the world something important and new.
I will confess to contempt for anything that I regard as pompous obscurantismfor self-referential systems of jargon whose main purposes areto bar outsiders, to mask a lack of actual understanding, and to confer power on certain favoredgroups. And I regardthe need to be alert to such systems, to nip them in the bud before they grow into Lysenkoism,as in some sensethe problem of intellectuallife. Whichbrings meto the most fundamentalasymmetry between thehard and softsciences. Namely, the very fact that its so much harder to nurture new truths to maturityin the socialsciences than it is in math or physics, means that in the former, the jargon-weeds have aneasier time filling the voidand we knowtheyve done it again and again, even in the post-Enlightenment West.
Time for a thought experiment. Suppose you showed up at a university anytime between, lets say, 1910 and 1970, and went from department to department asking (in so many words): whatare you excitedabout this century? Where are your new continents, whats the future of your field? Who should I read to learn aboutthat future?
In physics, the consensus answerwouldve been something like: Planck, Einstein, Bohr, Schrdinger, Dirac.
In psychology, it wouldve been: Freud and Jung (with another faction for B. F. Skinner).
In politics and social sciences, over an enormous swath of academia (including in the West), itwouldve been: Marx, Engels, Trotsky, Lenin.
With hindsight, we now know that the physics advice wouldve been absolute perfection,the psychology and politics advice an unmitigated disaster. Yes, physicists today know more than Einstein, caneven correct himon somepoints, but the continents herevealed to us actually existedindeed, have only become more important since Einsteinstime.
But Marx and Freud? You wouldve done better to leave the campus, andask a random person on the street what she or he thought about economics and psychology. In high school, I remember cringing through a unit on the 1920s, when we learned about howtwo European professors upset a war-weary civilizations established certaintieswith Einstein overturning received wisdom about space and time, and Freud doing just the same for the world of the mind. It was never thought important to add that Einsteins theoriesturned out to be true whileFreuds turned out to be false. Still, at least Freuds ideas led only to decades of bad psychology and hundreds of innocent people sent to jail because of testimony procured through hypnosis, rather than to tens of millions of dead, as with the other social-scientifictheorythat reigned supreme among 20th-century academics.
Marx and Freud builtimpressive intellectual edificessufficiently impressive for a large fraction ofintellectuals to have accepted those men as gurus on par with Darwin and Einstein for almost a century. Yet on nearly every topic they wrote about, we now know that Marx and Freudcouldnt havebeen any more catastrophically wrong. Moreover, their wrongness was knowable at the timeandwas knownto many, though the oneswho knew were typically the ones who theintellectual leaders sneered at, as deluded reactionaries.
Which raises a question: suppose that, in the 1920s, Id taken the social experts advice tostudy Marx and Freud, didnt understand much of what they said(and found nonsensical much of what I did understand),and eventually rejected them as pretentious charlatans. Then why wouldnt I have been just like Prof. Labas ignorant rube, who dismissescalculus because he doesnt understand technical terms like continuous and derivative?
On reflection, I dont think that the two cases are comparable at all.
The hard sciencesneed technicalvocabularies for a simplereason: because theyre about things that normal people dont spend their hours obsessively worryingabout. Yes,Id have a hard time understanding organic chemists or differential geometers, but largelyfor the same reasons Id have a hard time understanding football fans or pirates. Its not justthat I dont understand the arguments;its thatthe arguments are about a world thats alien to me (and that, to behonest, I dont care about as much as I do my world).
Suppose, by contrast, that youre writing about thetopicseveryone spends their time obsessively worrying about: politics, society, the human mind, the relations between theraces and sexes. In other words, suppose youre writing about preciselythe topics for whichthe ordinary English languagehas been honed over centuriesfor which Shakespeare and Twainand Dr. King and so many others deployedthe language to such spectacular effect. In that case, what excuse could you possibly have to writein academese, to pepper your prose with undefined in-group neologisms?
Well, lets be charitable; maybe you have a reason. For example, maybe youre doing a complicated meta-analysis of psychology papers, so you need to talk about r-values and kurtosis and heteroskedasticity. Or maybe youre putting people in an fMRI machine while you ask them questions, soyou need to talk about the temporal resolution in the anterior cingulate cortex. Or maybe youre analyzing sibling rivalriesusing game theory, so you need Nash equilibria. Or youre picking apart sentences using Chomskyan formal grammar. In all these cases, armchair language doesnt suffice because youre not just sitting in your armchair: youre using a newtool to examine the everyday from a differentperspective. For presentpurposes, you might as well be doing algebraic geometry.
The Freudians and Marxists would, of course, claim that theyre doing the exact same thing. Yes, theyd say, you thought you had the words to discussyour own mind or the power structure of society, but really you didnt, because you lackedthe revolutionary theoretical frameworkthat we now possess. (Trotskys writings are suffused with this brandof arrogance in nearly every sentence:for example, when he ridicules the bourgeoisie liberals who whine about human rights violations in the early USSR, yet who are too dense tophrase their objections within the framework of dialectical materialism.)
I submit that, even without the hindsight of 2015, there wouldve been excellent reasons to be skeptical of these claims. Has it ever happened, you might ask yourself, that someone sat in their study andmused about thesame humanquestionsthatoccupied Plato and Shakespeare and Hume, in the same human way they did, and then came up with a new, scientific conclusionthat was asrigorousand secure as relativity or evolution?
Let me know if I missed something, but I cant think of a single example. Sure, it seems to me, there have been geniuses of human nature, who enlarged our visionwithout any recourse to the quantitative methodsof science. But eventhosegeniuses only contributed melodies for other geniuses to answer in counterpoint, rather than stones for everyonewho came laterto build upon. Also, the geniuses usually wrote well.
Am I claiming thatprogress is impossible in the social realm? Not at all. The emancipation of slaves, the end of dueling and blasphemy laws and the divine right of kings, womens suffrage and participation in the workforce, gay marriageallthese strike me as crystal-clear examples of moral progress, as advancesthat will still be consideredprogress a thousand years from now, if theres anyone around then to discuss such things. Evolutionary psychology, heuristics andbiases, reciprocal altruism, and countless other developmentslikewise strike me as intellectual progress within the sciences of human nature. But none of these advances needed recondite language! Ordinary words sufficed for Thomas Paine and Frederick Douglass and John Stuart Mill, as they sufficed for Robert Axelrod and for Kahneman and Tversky. So forgive me for thinking that whatever is true and important in the social world today, should likewisebe defensible to everysmart personin ordinary words, and that this represents a genuinedifference between the social sciences and physics.
Whichbrings us to the central point that Prof. Laba disputedin that comment of mine. I believe there are countlessmoral heroes in our time, as well associal scientists who struggleheroicallyto get the right answers. But as far as I can tell, the people whobuild complexintellectualedificesaround words likeprivilege and delegitimation and entitlement and marginalized are very much the same sort of people who, a fewgenerations ago, built similar edificesaround bourgeoisie and dialectical and false consciousness. In both cases,theres an impressive body of theorythats held up as the equivalent in its domain of relativity, quantum mechanics, and Darwinism, with anyskeptics denounced asscience-deniers. In both cases, enlightenedliberals are tempted to side with the theorists, since the theorists believe in so many of the same causes that the enlightened liberals believe in, andhate so many of the same people who the enlightenedliberals hate. But in both cases, the theorists language seems to alternate between incomprehensible word-saladand fervid, oftenprofanity-laced denunciations, skipping entirely over calm clarity. And in both cases, the only thingthat the impressive theoreticaledifice ever seems to get used for, is to prove over and over that certain favored groups should get more power while disfavored ones should get less.
So Im led to the view that, if you want to rouse peoples angerabout injustice or their pity about preventable suffering, orend arbitrary discrimination codified into law, or give individualsmore freedom to pursue their own happiness, or come up with a new insight about human nature, or simplydescribe the human realities that you see around youfor all these purposes, the words that sufficed for every previous generations great humanists willalso suffice for you.
On the other hand, to restrict freedom and inventnew forms ofdiscriminationand to do it in the name of equality and justicethat takes theory. Youll need a sophisticated framework, for example, to prove that even iftwo adultsbothinsisttheyre consenting to a relationship, really they might not be, because of power structuresin the wider societythat your superior insight lets you see. Youll need advanceddiscourseto assureyou that, even though your gutreaction might be horror at (say) someone who misspoke onceand then had theirlife gleefullydestroyed on social media, your gutis not to be trusted, because itspoisoned by the same imperialist, patriarchalbiases aseverything elseand because what looks like a cruel lynching needs to be understoodin a broader social context (did the victim belong toadominant group, or to a marginalized one?). Finally, youll need oodles of theory (bring out the Marcuse) to explain whythe neoliberal fanaticism aboutfree speech and tolerance and due process and the presumption of innocence is too abstract and simplisticforthose concepts, too, fail to distinguish between a marginalized group thatdeserves societysprotection and a dominant groupthat doesnt.
So I concede to Prof. Laba that the complicated discourse of privilege, hegemony, etc. serves a definite purpose for the people who wield it, just as much as the complicated discourse of quantum field theory serves a purpose for physicists. Its just that the purposes of the privilege-warriors arent my purposes. For my purposeswhich include fighting injustice, advancing every socialand naturalscience as quickly as possible, and helping all well-meaning women and men see eachothers common humanityI said last yearand I say again that ordinary words will do.

Update (Oct. 26): Izabella Laba has written a response to this post, for which Im extremely grateful.  Her reply reveals that she and I have a great deal of common ground, and also a few clear areas of disagreement (e.g., whats wrong with Steven Pinker?).  But my most important objection is simply that, the first time I loaded her blog, the text went directly over the rock image in the background, making it impossible to read without highlighting it.You down with SPP?

Ive been in San Diego all week for the FCRC (Federated Computing Research Conference), which just wrapped up yesterday.  I was here for Complexity2007, but, lawless rebel that I am, I also crashed some of the talks at STOC2007.  Highlights:

Many of my friends wanted to skip the plenary talk on Computer Science: Past, Present, and Future, by past Computing Research Association Chair Ed Lazowska.  But I urged them to go despite the title, since Id met Lazowska when I interviewed at the University of Washington, and immediately concluded that this is the guy we want in charge of our field.  As it turned out,  Lazowska gave the most rousing defense of computer science research Ive ever heard. Heres what I remember: 2004 was the first year that human beings produced more transistors than grains of rice (~10 quintillion). Academic computer science research more than paid for itself over the last two decades by producing at least 15 billion-dollar industries. Computer scientists should be tackling the biggest issues in the world, including climate change and third-world poverty (Lazowska mentioned a project hes involved with to put thousands of sensors under the ocean near the Northwest US, thereby reducing oceanography to a computer science problem, as well as a project of his student Tapan Parikh, to let illiterate farmers in India and Guatemala upload financial records via cellphones with intermittent access). Computer scientists should bring self-driving cars from prototype to reality, thereby saving some of the 45,000 people in the US alone who die in auto accidents every year. The future of theoretical computer science lies in transforming the other sciences (math, physics, economics, biology) via computational thinking.  Had Watson and Crick been computer scientists, they wouldve realized immediately that the real import of their discovery had nothing to do with the biochemical details, and everything to do with the fact that DNA is a digital code. A piece of computer science (P vs. NP) is what many now consider the preeminent open problem in mathematics.  Quantum computing might not work but certainly merits a huge effort.  Our introductory CS courses suck.  Weve been doing a terrible job recruiting women. Update (6/23): Slides for Ed Lazowskas talk, as well as another inspiring talk by Christos Papadimitriou, can be found here.


I gave a talk on my paper with Greg Kuperberg, on quantum versus classical proofs and advice.


I gave another talk on the paper Quantum t-designs, by my colleagues Andris Ambainis and Joe Emerson. Why?  Because Joe couldnt make it to San Diego, and Andris lost his passport.  As I promised Andris, the vast majority of the talk was not delivered in my imitation of his voice.


Sergey Yekhanin gave a talk on his paper Towards 3-query locally decodable codes of subexponential length, which not only won the Danny Lewin Best Student Paper Award but also shared the STOC07 Best Paper Award.  Not to toot my own breakthrough-recognition horn, but  you saw it here first.


Ryan Williams, the pride of Alabama, won the Complexity Best Student Paper Award for his excellent paper Time-space tradeoffs for counting NP solutions modulo integers.  This marks the second time Ryan has won this award, as well as the first time the award has been given twice to a former Cornell undergrad and resident of Telluride House in the late 1990s (no  wait). So what did Ryan prove?  Alright, suppose you have O(n1.8) time and no(1) memory, and you want to count the number of satisfying assignments of a Boolean formula, modulo a prime number p. Then theres at most one prime p for which you can do this. Ryan has no idea which prime, and conjectures in any case that it doesnt exist.  Im not making this up.


Guy Kindler gave a talk on his amazing paper with Uri Feige and Ryan ODonnell, Understanding parallel repetition requires understanding foams.  Read the paper: the title is literally true.


I saw Terence Tao.


Ronald de Wolf and Harry Buhrman are reading this entry over my shoulder right now as I sit in the airport terminal typing.


As I watched the conference regulars  Lance Fortnow, Bill Gasarch, Harry Buhrman (yes, Harry, you got another mention  happy?), Ken Regan, etc.  banter and drink coffee, I realized that the IEEE Conference on Computational Complexity desperately needs an official theme song. The song should have real complexity-theoretic content, but nevertheless be a little edgier than Find the Longest Path.  So without further ado, I present to you a preliminary effort along these lines, due to Troy Lee and myself (aka Nerdy by Nature):
You down with SPP (Yeah you know me)
You down with SPP (Yeah you know me)
You down with SPP (Yeah you know me)
Whos down with SPP (Every last attendee)
(Note: BPP and ZPP also wouldve fit the meter, but those are really more appropriate for STOC than Complexity.)
Update (6/20): We may have a winner, Aaron Sterlings I Just Do Theory.  (Thanks to Bill Gasarch for the pointer.)Mahmoud and me

From the Wikipedia entry on Mahmoud Ahmadinejad, the current President of Iran:
During a World Without Zionism student conference in October 2005, Mahmoud Ahmadinejad  called Israel a disgraceful blot that ought to be wiped off the map. He went on to decry attempts to normalize relations with Israel and condemned all Islamic leaders who recognize Israels existence as acknowledging the surrender and defeat of the Islamic world 
Kofi Annan said he was dismayed by the comments, and reiterated Irans obligations and Israels right of existence under the UN Charter.  The White House responded by saying Ahmadinejads rhetoric showed that it was correct in trying to halt Irans nuclear program.  EU leaders issued a strong condemnation of the Iranian Presidents remarks, stating that [c]alls for violence, and for the destruction of any state, are manifestly inconsistent with any claim to be a mature and responsible member of the international community.
Ahmadinejad reaffirmed his position on 28 October 2005, as supporters chanting death to Israel and death to America, some burning and trampling on Israeli and U.S. flags, marched to a rally in Tehran attended by most of Irans top officials. My words are the Iranian nations words, he said. Westerners are free to comment, but their reactions are invalid.
In an age when soft-pedaling, pussyfooting, and political correctness are the norm, its refreshing to find a leader with genuine convictions  one who says what he means, and refuses to back down at the first whiff of criticism. Say what you like about Mahmoud; the man is not a flip-flopping wuss.A breakthrough on QMA(2)?

Last night, Martin Schwarz posted a preprint to the arXiv that claims to show the new complexity class containment QMA(2) EXP. (See also his brief blog post about this result.) Here QMA(2) means Quantum Merlin-Arthurwith two Merlinsi.e., the set of languages for which a yes answer can be witnessed by two unentangled quantum states, ||, on polynomially many qubits each, which are checked by a polynomial-time quantum algorithmwhile EXPmeans deterministic exponential time. Previously, the best upper boundwe had was the trivialQMA(2)  NEXP (Nondeterministic Exponential Time), which comes from guessing exponential-size classical descriptions of the two quantum proofs.
Whether QMA(2) is contained in EXP is a problemthat had fascinatedme for a decade. With Salman Beigi, Andy Drucker, Bill Fefferman, and Peter Shor, we discussed this problemin our 2008 paper The Power of Unentanglement. That paper(with an additional ingredient supplied by Harrow and Montanaro) shows how to prove that a 3SAT instance of size n is satisfiable, using two unentangled quantum proofs with only(n) qubits each. This implies thatsearching over alln-qubit unentangled proofs must take at least exp(n2) time, unless 3SAT is solvable in 2o(n) time (i.e., unless the Exponential Time Hypothesis is false). However, since EXP is defined as the set of problems solvable in 2p(n) time, for any polynomial p, this is no barrier to QMA(2)  EXP being trueit merely constrains the possible techniques that could prove such a containment.
In trying to proveQMA(2)  EXP, the fundamental difficulty is that you need to optimize over unentangled quantum states only. That might sound easier than optimizing over allstates (including the entangled ones), but ironically, its harder! The reason why its harder is that optimizing over all quantum states (say, to find the one thats accepted by some measurement with the maximum probability) is a convex optimization problem: in fact, it boils down to finding the principal eigenvector of a Hermitian matrix. By contrast, optimizing over only the separable states is a non-convex optimization problem, which is NP-hard to solve exactly (treating the dimension of the Hilbert space as the input size n)meaning that the question shifts to what sorts of approximations are possible.
Last week, I had the pleasure of speaking withMartin in person, when I visited Vienna, Austria to give a public lectureat the wonderful new research institute IST. Martin was then ironing out some finalwrinkles in his proof, and I got to watch him in actionin particular, to see the care and detachmentwith which heexaminedthe possibility that his proof might imply too much(e.g., that NP-complete problemsare solvable inquasipolynomial time). Fortunately, hisproofturned out not to imply anything of the kind.
The reason why it didnt is directly related to the moststriking feature ofMartins proofnamely, that itsnon-relativizing, leaving completely open the question of whether QMA(2)A EXPA relative to all oracles A. To explain how this is possible requires saying a bit about how the proof works. The obvious way to prove QMA(2)  EXPwhat I had assumed from the beginning was the onlyrealistic waywould be to give a quasipolynomial-time approximation algorithm for the so-called Best Separable State or BSS problem. The BSS problem, as defined in this paperby Russell Impagliazzo, Dana Moshkovitz, and myself (see also this one by Barak et al.), is as follows: youre given as input an n2n2 Hermitian matrix A, with all its eigenvalues in [0,1]. Your goal is to find length-n unit vectors, u and w, that maximize
(uTwT)A(uw),
to within an additive error of , for some constant .
Of course, if we just asked for a length-n2 unit vector v that maximized vTAv, wed be asking for the principal eigenvector of A, which is easy to find in polynomial time. By contrast, from the ABDFSand Harrow-Montanaro results, it follows that the BSS problem, for constant , cannot be solved in poly(n) time, unless 3SAT is solvable in 2o(n)time. But this still leaves the possibility that BSS is solvable in nlog(n) timeand that possibility would immediately imply QMA(2)  EXP. So, as I and others saw it, the real challenge here was to finda quasipolynomial-time approximation algorithm for BSSsomething that remained elusive, although Brandao-Christandl-Yard made partial progress towards it.
But now Martin comes along, and proves QMA(2)  EXPin a way that sidesteps the BSS problem. The way he does it is by using the fact that, if a problem is in QMA(2), then we dont merely know a Hermitian operator A corresponding to the measurement of ||: rather, we know an actualpolynomial-size sequence of quantum gates that get multiplied together to produce A. Using that fact, Chailloux and Sattath showed that a natural variant of the QMA-complete Local Hamiltonians problem, which they call Separable Sparse Hamiltonians, is complete for QMA(2). Thus, it suffices for Martin to show how to solve the Separable Sparse Hamiltonians problem in singly-exponential time. This he does by using perturbation theory gadgets to reduce Separable Sparse Hamiltonians to Separable Local Hamiltonians with an exponentially-small promise gap, and then using a result of Shi and Wuto solve the latter problem in singly-exponential time. All in all, given the significance of the advance, Martins paper is remarkably short; a surprising amount of it boils down to deeply understanding some not-especially-well-known results that were already in the literature.
One obvious problem leftopen is whether the full BSS problemrather than just the special case of it corresponding to QMA(2)is solvable in quasipolynomial time after all. A second obvious problem is whether the containment QMA(2)  EXP can be improved to QMA(2)  PSPACE, or even (say) QMA(2)  PP. (By comparison, note that QMA  PP, by a result of Kitaev and Watrous.)

Update (Nov. 10): I thought I should let people know that a serious concern has been raised by an expert about the correctness of the proofand in particular, about the use of perturbation theory gadgets.  Martin tells me that hes working on a fix, and I very much hope hell succeed, but not much to do for now except let the scientific process trundle along (which doesnt happen at blog-speed).Americas nerdiest cities

From Money Magazine, a list of American cities with the highest percentage of residents with graduate degrees.  Cambridge, MA (26.3%) narrowly edges out Palo Alto, CA (25.4%) and Berkeley, CA (24.5%)  but beating them both by a long shot is Arlington, VA, the winner at 35.7%.  It takes a much more educated crowd to unify Iraq and 9/11 than to unify relativity and quantum mechanics.G.  Phi.  Fo.  Fum.

Update (Dec. 14): The long wait is over! Heres Lacis paper on the arXiv. So far, Ive read it only deeply enough to note that it contains the following sentence:
A group G  S() defines the category of G-isomorphisms of strings on the domain ; the natural notation for this category, the central object of study in this paper, would seem to be G-Strings.
With that, I believeLaci himself has outshone evenreddits attempt to mine his breakthrough result for juvenile humor.
See also a nice Quanta article about Lacis algorithm by Erica Klarreich. Theres only one statement in the article that I disagree with: namely that, if graph isomorphism were inherently quasipolynomial time, then it would be the first natural example of such a problem. We know other natural problems, like approximating free games and socially-optimal Nash equilibria, that are solvable in nO(log n) time but that cant be in P unless 3SAT is solvable in ~exp(n) time.
Update (Nov. 17): Video of Lacis first talk is now available.
Breaking News (Nov. 12): Jeremy Kun has written up a phenomenal summary of Babais first lecture. I havent carefully studied all of it, and in any case, there are many missing details to be filled in later (Babai told Kun that the preprint will be available soon, soon!). But from the summary, fourpoints stood out to me:

Babai actually claims a quasipolynomial-time algorithmfor an interestingly more general problem than graph isomorphism, called string isomorphism. This was already in the abstract, but googling didnt reveal what string isomorphism was. So, OK, heres what it is: youre given two strings x and y over some finite alphabet, as well as the generators of a group G of permutations of the string indices. The problem is to determine whether you can transform x to y by applying a permutation in G. Or even more generally: given a string x, find a full set of generators for the subgroup of G that fixes x. See Kuns post for the straightforward reductions from GI to these group-theoretic problems.
As was hinted in the abstract, in Babais analysis ofhis algorithm, theres one step that relies ona statement whose only known proof dependsonthe Classification of Finite Simple Groups. (Thus, its not the algorithm itself requires iterating through all the sporadic simple groups or anything like that; this only shows up inthe correctness proof.) This is not the first-ever computer-scienceapplication of the Classification of Finite Simple Groups (indeed, Babai himself has some previous ones), but its certainly the most dramatic.
In previous work on GI, the Johnson graph emerged over and over as a forehead-banginglyhard case that caused numerous algorithms to fail. In the new work, it looks likeBabais centraltechnical innovation is to show that, in some sense, the Johnson graph is the only obstruction to taking the divide-and-conquer approaches that people that had tried before, and making them run in quasipolynomial time. I.e., in each step of the recursion, either you can find a Johnson graph on a large fraction of the vertices and handle it specially, or elseyou can do something that works whenever theres not a Johnson graph on a large fraction of the vertices. Babai calls this split-or-Johnson.
Babai stressed that in some sense, his new algorithm is the culmination of a program laid out by Eugene Luks in 1982. Now, the Classification of Finite Simple Groups was also more-or-lesscompleted in the early 1980s. To my mind, this raises a fascinating socio-mathematical question: which aspects of the new work, if any, could not have been done in the early 80s, possibly by Babaior Luksthemselves? what is it that neededanother 30 years? If the answer turns out to be nothing, then to me thats an astoundingillustration of the role of the individual in mathematical progress. As in: Laci was niceenough to take a third-of-a-century break between his and Luks workin the early 80s, and the natural next step in their program  andstillno one managed to use that break to beat him to the next step!


Earlier today, I was tipped off towhat might be the theoretical computer science resultof thedecade. My source asked me not to break the news on this blogbut since other theory bloggers(and twitterers) are now covering the story, I guess the graph is out of the Babai.
According to the University of Chicagos theory seminar calendar, on Tuesday of next week (November 10), the legendaryLaszlo Babai will be giving a talk about a new algorithm that solves the graph isomorphism problem in quasipolynomial time. The previous fastest algorithm to decide whether two n-vertex graphs G and H are isomorphicby Babai and Luks, back in 1983ran in exp((n log n)) time. If we credit theannouncement, Babai has now gotten that down to exp(polylog(n)), putting one of the central problems of computer sciencejust barely aboveP. (For years, Ive answered questions on this blog about the status of graph isomorphismwould I bet that its in BQP? in coNP? etc.by saying that, as far as I and many others are concerned, it might as well just be in P. Of course Im happyto reaffirm that conjecture tonight.)
Next week, I assume, Laci will lecture to a packed house; then the expertswill race to unpack the details. Until then, we probably need to sit tight; I dont know any more than whats in the abstract. For now,Im delightedif commenters want to sharegeneral thoughts or questions about graph isomorphism (and Ill try to answer what I can), but Iwontallow uninformed speculations or rumors about the details of the new resultnot until Laci has had a chance to speak.

Update (Nov. 5): While we all wait with bated breath for more details, you can amuse yourself with the talk I gave at Lacis 60th birthday conference five years ago.
Also, a comment of mine that I should probably promote to the main post:
Dana points out to me that non-native English speakers might not get the staggeringly clever pun in this posts title (hey, it was the best I could do on a deadline).
So, alright, fee fi fo fum is what the approaching giant bellows in Jack and the Beanstalk. It means something big is on the horizon. Also, G is a graph, and Phi is an isomorphism.

Update (Nov. 12): So, Laci gave his talk. Video was made but does not appear to be available yet. However, Gabriel Gaster, who was in attendance, graciously live-tweeted everything. Heres a Storify of the live-tweets. (Whats a Storify?)Experimental complexity theory

I just came back from the MIT CSAIL (Computer Science and Artificial Intelligence Lab) annual meeting, which was held at a beach resort in Cape Cod.  No, it isnt California, but for at least a few months a year my coast can put up a respectable showing too:

Out of all the ideas I heard at the CSAIL meeting, the one that made me proudest to have become a professor was this: computer scientists should make a serious effort to address world hunger, deforestation, climate change, and other global crises, because of the significant opportunities to tap funding resources that are becoming available in these areas. Im telling you, if a giant asteroid were going to hit the earth in a week, the first question academics would ask would be how to beat out competing proposals for the $50-million Deflection of Space-Based Objects initiative at NSF.
The meeting ended with a Wild & Crazy Ideas Session, at which I (naturally) spoke.  I briefly considered talking about quantum gravity computing, closed timelike curves, or quantum anthropic postselection, but ultimately decided on something a little less mainstream.  My topic was Experimental Computational Complexity Theory, or why do theoretical physicists get $8-billion machines for the sole purpose of confirming or refuting their speculative ideas, whereas theoretical computer scientists get diddlysquat?  More concretely, my proposal is to devote some of the worlds computing power to an all-out attempt to answer questions like the following: does computing the permanent of a 4-by-4 matrix require more arithmetic operations than computing its determinant?  You can read my slides here.If I cant do math, I dont want to be part of your revolution

1. Emma Goldman, the fiery early-20th-century anarchist, is credited for givingthe world the immortal refrain if I cant dance, I dont want to be part of your revolution (actually its not clear that she ever said it sopithily, but she didexpress such athought). Admittedly, no one would mistake me for either a dancer or an anarchist, but Ive always felt a kinship withGoldman over her terpsichorean line in the sand. The other day, it occurred to methat theres a parallel sentence that sums up my entire political philosophyon the one hand, my default instinct to side with the downtrodden and with the progressive left, but on the other,my dissentfrom any even vaguely anti-STEM, anti-rationality, or anti-nerd undercurrents, and my refusalto joinany popularuprisingthat seems liable (for example) todelay the discovery of aPNP proof, by inconveniencing the people working on one.
So, heres mysentence, which you should feel free to reprint on t-shirts and coffee mugs as desired:
If I cant do math, I dont want to be part of your revolution.
2. Over at Scientific Americans website, John Horgan postedan account of a workshop on Integrated Information Theory, which I attended a couple weeks ago at NYU (along with David Chalmers, Giulio Tononi, Christof Koch, Max Tegmark, and a dozen or so others). I was the official skeptic of the workshop, and gave a talk based on my blog post The Unconscious Expander. I dont reallyagree with what Horgan says about physics and information in general, but I do (of course) join him in his skepticism of IIT, and he gives a pretty accurate summary of what people said at the workshop. (Alas, my joke about my lunch not being poisoned completely bombed with the IIT crowd  as I shouldve predicted!) The workshop itself was lots of fun; thanks so much to David, Giulio, and Hedda Hassel Morch for organizing it.
3. As you might have noticed, Ive created a new category on this blog: Obviously Im Not Defending Aaronson. This categoryreserved for posts that caused at least a hundredpeople to hate mereferstoa peculiar phrase Iencounteredover and over, in the social media threads denouncing me as a horribleperson. The phrase tends tooccur in passageslike: look, obviously Im not defending Aaronson, but its worth pointing outthat, if you carefully reread everythinghe wrote, he never actually said that warorphans should be roasted alive and then eaten for fun. Thats just something we all know that a clueless, arrogant nerd like him would think.
4. Right now Im at the ThinkQ conference at IBM in Yorktown Heights. Here are the PowerPoint slides from my talk yesterday, entitled The Largest Possible Quantum Speedups. Regular readers of this blog willfind a lot thats old and a little thats new.Talk, be merry, and be rational

Yesterday I wrote a statement on behalf ofa Scott Alexander SlateStarCodex/rationalist meetup, whichhappened last night at MIT (in the same room where I teach my graduate class), and which Id really wanted to attend but couldnt. I figuredId share the statement here:
I had been looking forward to attending tonights MIT SlateStarCodex meetup as I hardly ever look forward to anything. Alas, Im now stuck in Chicago, with my flight cancelled due to snow, and with all flights for the next day booked up. But instead of continuing to be depressed about it, Ive decided to be happy that this meetup is even happening at allthat theres a community of people who can read, lets say, a hypothetical debate moderator questioning Ben Carson about what its like to be a severed half-brain, and simply be amused, instead of silently trying to figure out who benefits from the post and which tribe the writer belongs to. (And yes, I know: the answer is the gray tribe.) And you can find this community anywhereeven in Cambridge, Massachusetts! Look, I spend a lot of time online, just getting more and more upset reading social justice debates that are full of people calling each other douchebags without even being able to state anything in the same galactic supercluster as the other sides case. And then what gives me hope for humanity is to click over to the slatestarcodex tab, and to see all the hundreds of comments (way more than my blog gets) by people who disagree with each other but who all basically get it, who all have minds that dont make me despair. And to realize that, when Scott Alexander calls an SSC meetup, he can fill a room just about anywhere  well, at least anywhere I would visit. So talk, be merry, and be rational.
Im now back in town, and told by people who attended the meetup that it was crowded, disorganized, and great. And now Im off to Harvard, to attend the other Scott A.s talk How To Ruin A Perfectly Good Randomized Controlled Trial.

Update (Nov. 24) Scott Alexanders talk at Harvard last night was one of the finest talks Ive ever attended.  He was introduced to rapturous applause as simply the best blogger on the Internet, and as finally an important speaker, in a talk series that had previously wasted everyones time with the likes of Steven Pinker and Peter Singer.  (Scott demurred that his most notable accomplishment in life was giving the talk at Harvard that he was just now giving.)  The actual content, as Scott warned from the outset, was just a small subset of a basic statistics course, but Scott brought each point alive with numerous recent examples, from psychiatry, pharmacology, and social sciences, where bad statistics or misinterpretations of statistics were accepted by nearly everyone and used to set policy.  (E.g., Alcoholics Anonymous groups that claimed an over 95% success rate, because the people who relapsed were kicked out partway through and not counted toward the total.)  Most impressively, Scott leapt immediately into the meat, ended after 20 minutes, and then spent the next two hours just taking questions.  Scott is publicity-shy, but I hope for others sake that video of the talk will eventually make its way online.
Then, after the talk, I had the honor of meeting two fellow Boston-area rationalist bloggers, Kate Donovan and Jesse Galef.  Yes, I said fellow: for almost a decade, Ive considered myself on the fringes of the rationalist movement.  Id hang out a lot with skeptic/effective-altruist/transhumanist/LessWrong/OvercomingBias people (who are increasingly now SlateStarCodex people), read their blogs, listen and respond to their arguments, answer their CS theory questions.  But I was always vaguely uncomfortable identifying myself with any group that even seemed to define itself by how rational it was compared to everyone else (even if the rationalists constantly qualified their self-designation with aspiring!).  Also, my rationalist friends seemed overly interested in questions like how to prevent malevolent AIs from taking over the world, which I tend to think we lack the tools to make much progress on right now (though, like with many other remote possibilities, Im happy for some people to work on them and see if they find anything interesting).
So, what changed?  Well, in the debates about social justice, public shaming, etc. that have swept across the Internet these past few years, it seems to me that my rationalist friends have proven themselves able to weigh opposing arguments, examine their own shortcomings, resist groupthink and hysteria from both sides, and attack ideas rather than people, in a way that the wider societyand most depressingly to me, the enlightened, liberal part of societyhas often failed.  In a real-world test (real-world, in this context, meaning social media), the rationalists have walked the walk and rationaled the rational, and thus theyve given me no choice but to stand up and be counted as one of them.
Have a great Thanksgiving, those of you in the US!

Another Update: Dana, Lily, and I had the honor of having Scott Alexander over for dinner tonight.  I found this genius of human nature, who took so much flak last year for defending me, to be completely uninterested in discussing anything related to social justice or online shaming.  Instead, his gaze was fixed on the eternal: he just wanted to grill me all evening about physics and math and epistemology.  Having recently read this Nature News article by Ron Cowen, he kept asking me things like: you say that in quantum gravity, spacetime itself is supposed to dissolve into some sort of network of qubits.  Well then, how does each qubit know which other qubits its supposed to be connected to?  Are there additional qubits to specify the connectivity pattern?  If so, then doesnt that cause an infinite regress?  I handwaved something about AdS/CFT, where a dynamic spacetime is supposed to emerge from an ordinary quantum theory on a fixed background specified in advance.  But I added that, in some sense, he had rediscovered the whole problem of quantum gravity thats confused everyone for almost a century: if quantum mechanics presupposes a causal structure on the qubits or whatever other objects it talks about, then how do you write down a quantum theory of the causal structures themselves?
Im sure theres a lesson in here somewhere about what I should spend my time on.FOCS36 notification

Dear Mr. Turing,
We regret to inform you that your submission
"On Computable Numbers, With an Application to the Entscheidungsproblem"
was not accepted to appear in FOCS 1936.  The Program Committee received a record 4 submissions this year, many of them of high quality, and scheduling constraints unfortunately made it impossible to accept all of them.
Below please find some reviews on your submission.  The reviews are *not* intended as an explanation for why your paper was rejected.  This decision depended on many factors, including discussions at the PC meeting and competition from other papers.
Best wishes,
FOCS 1936 Program Committee
---------------------------------------- review 1 ----------------------------------------
seems like a trivial modification of godel's result from STOC'31
---------------------------------------- review 2 ----------------------------------------
The author shows that Hilbert's Entscheidungsproblem (given a mathematical statement, decide whether it admits a formal proof) is unsolvable by any finite means.  While this seems like an important result, I have several concerns/criticisms:
1. The author defines a new "Turing machine" model for the specific purpose of proving his result.  This model was not defined in any previous papers; thus, the motivation is unclear.
2. I doubt Hilbert's goal of "automating mathematical thought" was ever really taken seriously by anyone (including Hilbert himself).  Given this, the negative result comes as no surprise -- a positive result would have been much more interesting.
3. It's hard to find any technical "meat" in this paper.  Once the author sets up the problem, the main result follows immediately by a standard diagonalization argument.
4. The whole philosophical discussion in Section 9, about what it means to compute something, is out of place (even slightly embarrassing) and should be deleted entirely.
Summary: While this paper deserves to be published somewhere -- SODA? ICALP? FSTTCS? -- it certainly isn't FOCS caliber.
---------------------------------------- review 3 ----------------------------------------
merge with alonzo church's submission?
---------------------------------------- review 4 ----------------------------------------
while i agree with the other reviewers' concerns about triviality, i confess to liking this paper anyway. one reason is that, along the way to the main result, the author proves a lemma stating that there exists a "universal machine" (a machine able to simulate any other machine given a suitable choice of input).  the claim that this lemma could have "practical" applications is clearly exaggerated -- but even so, it seems like it could be a useful ingredient for other results.
Recommendation: Borderline Accept.Google, D-Wave, and the case of the factor-10^8 speedup for WHAT?

Update (Dec. 16): If youre still following this, please check outan important comment by Alex Selby, the discoverer of Selbys algorithm, which Idiscussed in the post. Selby queries a fewpoints in the Google paper: among other things, he disagrees with their explanation of why his classical algorithm works so well on D-Waves Chimera graph (and with their prediction that it should stop working for larger graphs), and he explains that Karmarkar-Karp is notthe best known classical algorithm for theNumber Partitioning problem. He also questionswhethersimulated annealing is the benchmark against which everything should be compared (on the grounds that everything else requires fine-tuning), pointing out that SA itself typically requires lots of tuning to get it to work well.
Update (Dec. 11): MIT News now has a Q&A with me about the new Google paper. Im really happy with how the Q&A turned out; people who had trouble understanding this blog post might find the Q&A easier. Thanks very much to Larry Hardesty for arranging it.
Meanwhile, I feel good that there seems to have been actual progress in the D-Wave debate! In previous rounds, I had disagreed vehemently with some of my MIT colleagues (like Ed Farhi and Peter Shor) about the best way to respond to D-Waves announcements. Today, though, at our weekly group meeting, there was almost no daylight between any of us. Partly, Im sure, its that Ive learned to express myself better; partly its that the trigger this time was a serious research paper by a group separate from D-Wave, rather than some trash-talking statement from Geordie Rose. But mostly its that, thanks to the Google groups careful investigations, this time pretty much anyone who knows anything agrees about all the basic facts, as I laid them out in this blog post and in the Q&A. All that remains are some small differences in emotional attitude: e.g., how much of your time do you want to spend on a speculative, dirty approach to quantum computing (which is far ahead of everyone else in terms of engineering and systems integration, but which still shows no signs of an asymptotic speedup over the best classical algorithms, which is pretty unsurprising given theoretical expectations), at a time when the clean approaches might finally be closing in on the long-sought asymptotic quantum speedup?
Another Update:Daniel Lidar was nice enough to email me an important observation, and to give me permission to share it here. Namely, the D-Wave 2X has a minimum annealing time of 20 microseconds. Because of this, the observed running times for small instance sizes are artificially forcedupward, making the growth ratein the machines running time look milder than it really is. (Regular readers might rememberthat exactly the same issueplaguedprevious D-Wave vs. classical performance comparisons.) Correcting this would certainly decrease the D-Wave 2Xs predicted speedupover simulated annealing, in extrapolations to larger numbers of qubits than have been tested so far (although Daniel doesnt know by how much). Daniel stresses that hes not criticizing the Google paper, which explicitly mentions the minimum annealing timejust calling attention to something that deserves emphasis.

In retrospect, I shouldve been suspicious, when more than a year went by with no major D-Wave announcements that everyone wanted me to react to immediately. Could it really be that this debate was overor not over, but where it always shouldve been, in the hands of experts who might disagree vehemently but are always careful to qualify speedup claimsthereby freeing up the erstwhile Chief D-Wave Skeptic for more rewarding projects, like charting a middle path through the Internets endless social justice wars?
Nope.
As manyof you will have seen by now, on Mondaya team at Google put out a major paper reporting new experiments onthe D-Wave 2X machine. (See also Hartmut Nevens blog post about this.) The predictable popularizedversionof the resultssee for example hereand hereis that the D-Wave 2X hasnow demonstrateda factor-of-100-millionspeedup over standard classical chips, thereby conclusively putting to rest the question of whether the device istruly a quantum computer. In the comment sections of one my previous posts, D-Wave investor Steve Jurvetson eventriedtoerect a victory stele, by quoting Karl Popper about falsification.
In situations like this, the first thing I do is turn to Matthias Troyer, whos arguably the planets most balanced, knowledgeable, trustworthy interpreter of quantum annealing experiments. Happily, in collaboration with Ilia Zintchenko and Ethan Brown, Matthias was generous enough to write a clear 3-page document putting the new results into context, and to give me permission to share it on this blog. From a purely scientific standpoint, my post could end right here, with a link to their document.
Then again, from a purely scientific standpoint, thepost couldve ended even earlier, with the link to the Google paper itself! For this is not a case where the paper hides some crucial issuethat the skeptics then need to ferret out. On the contrary, the papers authors include some of the most carefulpeople in the business, and the paper explains the caveats as clearly as one could ask. In some sense, then, all thats left for me or Matthias to do is to tell you what youd learnif you read the paper!
So, OK, has the D-Wave 2X demonstrated afactor-108 speedup or not? Heres the shortest answer that I think is non-misleading:
Yes, theres a factor-108 speedup that looks clearly asymptotic in nature, and theres also a factor-108 speedup over Quantum Monte Carlo. But the asymptotic speedup is only if you compare against simulated annealing, while the speedup over Quantum Monte Carlo is only constant-factor, not asymptotic. And in any case, both speedups disappear if you compare against other classical algorithms, like that of Alex Selby. Also, the constant-factor speedup probably has less to do with quantum mechanics than with the fact that D-Wave built extremely specialized hardware, which was then compared against a classical chip on the problem of simulating the specialized hardware itself (i.e., on Ising spin minimization instances with the topology of D-Waves Chimera graph). Thus, while theres been genuine, interesting progress, it remains uncertain whether D-Waves approach will lead to speedups over the best known classical algorithms, let alone to speedups over the best known classical algorithms that are also asymptotic or also of practical importance. Indeed, all of these points also remain uncertain for quantum annealing as a whole.
To expand a bit, there are reallythreeseparate results in the Google paper:

The authors create Chimera instanceswith tall, thin energy barriers blocking the way to the global minimum, by exploitingthe 8-qubit clusters that play such a central role in the Chimera graph. In line with a 2002 theoretical predictionby Farhi, Goldstone, and Gutmann (a predictionweve often discussed on this blog), they then find that on these specialinstances, quantum annealing reachesthe global minimum exponentially faster than classicalsimulated annealing, and that the D-Wave machine realizes this advantage. As far as Im concerned, this completely nails down the case for computationally-relevant collective quantum tunneling in the D-Wave machine, at least within the 8-qubit clusters. On the other hand, the authors point out that there are other classical algorithms, like that ofSelby(building on Hamze and de Freitas), which group together the 8-bit clusters into 256-valued mega-variables, and thereby get rid of the energybarrier that kills simulated annealing. These classical algorithms are found empirically to outperform the D-Wave machine. The authors also match the D-Wave machines asymptotic performance (though not the leading constant) using Quantum Monte Carlo, which (despite its name) is a classical algorithm often used to find quantum-mechanical ground states.
The authors make a case that the ability to tunnel pasttall, thin energy barriersi.e., the central advantage thatquantum annealing has been shown to have over classical annealingmightbe relevant to at least some real-world optimization problems. They do this by studying a classic NP-hard problem called Number Partitioning, where youre given a list of N positive integers, and yourgoal is to partition the integers into two subsets whose sums differ from each other by as little as possible. Through numerical studies on classical computers, they find that quantum annealing (in the ideal case) and Quantum Monte Carlo should both outperform simulated annealing, by roughly equal amounts, on random instances of Number Partitioning. Note thatthis part of the paper doesnt involve any experiments on the D-Wave machine itself, sowe dont knowwhether calibration errors, encoding loss, etc. will kill the theoretical advantage over simulated annealing. But even if not, this still wouldnt yieldatrue quantum speedup, since (again) Quantum Monte Carlo is a perfectly-goodclassical algorithm, whose asymptotics match those of quantum annealingon these instances.
Finally, on the special Chimera instances with the tall, thin energy barriers, the authors find that the D-Wave 2X reaches the global optimum about108times faster than Quantum Monte Carlo running on a single-core classical computer. But, extremely interestingly, they also find that this speedup does not grow with problem size; insteadit simply saturates at ~108. In other words, this is a constant-factor speedup rather than an asymptotic one. Now, obviously, solving a problemonly100 milliontimes faster (rather than asymptotically faster) can still have practical value! But its crucial to remember that this constant-factor speedup is only observed for the Chimera instancesor in essence, for the problem of simulating the D-Wave machine itself! If you wanted to solve somethingof practical importance, youd first need to embed it into the Chimera graph, and it remains unclear whether any of the constant-factor speedup would survive that embedding. In any case, while the paper isnt explicit about this, I gather that the constant-factor speedup disappears when one compares against (e.g.) the Selby algorithm, rather than against QMC.

So then, what do I say to Steve Jurvetson? I sayhappily, not grudgingly!thatthe new Google paper provides the clearestdemonstration so far of a D-Wave devices capabilities. But then I remind himof all the worriesthe QC researchers had from the beginning aboutD-Waves whole approach: the absenceof error-correction; the restriction to finite-temperature quantum annealing (moreover, using stoquastic Hamiltonians), for which we lack clear evidence for a quantum speedup; the rush for more qubits rather than better qubits. And I say: not only do all these worries remain in force, theyve been thrown into sharper relief than ever, now that many of the side issues have been dealt with. The D-Wave 2X is a remarkable piece of engineering. If its still not showingan asymptotic speedup over the bestknown classical algorithmsas the new Google paper clearlyexplainsthat it isntthen the reasons are not boringor trivial ones. Rather, they seem related tofundamentaldesign choicesthat D-Wave made over a decade ago.
The obvious question now is: canD-Wave improve its design, in order to get a speedup thats asymptotic, andthat holds against all classical algorithms (including QMC and Selbys algorithm), and that survives the encoding of a real-world problem into the Chimera graph? Well, maybe or maybe not. The Google paper returns again and again to the subjectof planned future improvements tothe machine, and how they might clear the path to a true quantum speedup. Roughly speaking, if we rule out radical alterations to D-Waves approach, there are four main things one would want to try, to see if they helped:

Lower temperatures (and thus, longer qubit lifetimes, and smaller spectral gaps that can be safely gotten across without jumping up to an excited state).
Better calibration of the qubits and couplings (and thus, ability to encode a problem of interest, like the Number Partitioning problem mentioned earlier, to greater precision).
The ability to apply non-stoquastic Hamiltonians. (D-Waves existingmachinesare all limited tostoquastic Hamiltonians, defined as Hamiltonians all of whose off-diagonal entries are real and non-positive. While stoquastic Hamiltonians are easier from an engineering standpoint, theyre also the easiest kind to simulate classically, using algorithms like QMCso much so that theres no consensus onwhether its even theoretically possible to get a true quantum speedup usingstoquastic quantum annealing. This is a subject of active research.)
Better connectivity among the qubits (thereby reducing the huge lossthat comesfrom taking problems of practical interest, and encoding them in the Chimera graph).

(Note that more qubits is not on this list: if a true quantum speedup is possible at all with D-Waves approach, then the 1000+ qubits that they already have seem like more than enough to notice it.)
Anyway, these are all, of course, things D-Wave knows about and will be working on in the near future. As well they should! But to repeat: even if D-Wave makes all four of these improvements, we still have no idea whether theyll see a true, asymptotic, Selby-resistant, encoding-resistant quantum speedup. We just cant say for sure that they wont see one.
In the meantime, while its sometimeseasy to forget during blog-discussions, the field of experimental quantum computing is a proper superset ofD-Wave, and things have gotten tremendously more exciting on many frontswithinthe last year or two. In particular, the group of John Martinis at Google(Martinis is one of the coauthors of the Google paper) now has superconducting qubits with orders of magnitude better coherence times than D-Waves qubits, and has demonstrated rudimentary quantum error-correction on 9 of them. Theyre now talking about scaling up to ~40 super-high-quality qubits with controllable couplingsnot in theremote future, but in, like, the next few years. If and when they achieve that, Im extremely optimistic that theyll be able to showa clear quantum advantagefor something (e.g., some BosonSampling-like sampling task), if not necessarily something of practical importance. IBM Yorktown Heights, which I visited last week, is also working (with IARPA funding) on integrating superconducting qubits with many-microsecond coherence times. Meanwhile, someof the top ion-trap groups, likeChris Monroes at the University of Maryland, are talking similarlybig about what they expect to be able to do soon. The academic approach to QCwhich one could summarize as understand the qubits, control them, keep them alive, and only then try to scale them upis finally bearing some juicy fruit.
(At last weeks IBM conference, there was plenty of D-Wave discussion; how could there not be? But the physicists in attendanceI was almost the only computer scientist thereseemed much more interested in approaches that aim for longer-laster qubits, fault-tolerance, and a clear asymptotic speedup.)
I still have no ideawhen and if well have a practical, universal, fault-tolerant QC, capable of factoring 10,000-digit numbers and so on. But its now looking likeonly a matter of years until Gil Kalai, and the other quantum computing skeptics,will beforced to admit they were wrongwhich was always the main application I cared about anyway!
So yeah, its aheadytimefor QC,with manythingscoming together faster than Id expected (then again, it was always my personal ruleto err on the side of caution,and thereby avoid contributing to runaway spirals of hype). As we staggeraheadinto this new world of computingbravely, coherently, hopefully non-stoquastically, possiblyfault-tolerantlymy goal onthis blog will remain what its been for a decade:not to prognosticate, not to pick winners, but merelytotry to understand and explain what has and hasnt already been shown.

Update (Dec. 10): Some readers might be interested in an economic analysis of the D-Wave speedup by commenter Carl Shulman.
Another Update:Since apparently some people didnt understand this post, here are some comments from a Y-Combinator thread about the postthat might be helpful:
(1) [T]he conclusion of the Google paper is that we have probable evidence that with enough qubits and a big enough problem it will be faster for a very specific problem compared to a non-optimal classical algorithm (we have ones that are for sure better).
This probably sounds like a somewhat useless result (quantum computer beats B-team classical algorithm), but it is in fact interesting because D-Waves computers are designed to perform quantum annealing and they are comparing it to simulated annealing (the somewhat analogous classical algorithm). However they only found evidence of a constant (i.e. one that 4000 qubits wouldnt help with) speed up (though a large one) compared to a somewhat better algorithm (Quantum Monte Carlo, which is ironically not a quantum algorithm), and they still cant beat an even better classical algorithm (Selbys) at all, even in a way that wont scale.
Scotts central thesis is that although it is possible there could be a turning point past 2000 qubits where the D-Wave will beat our best classical alternative, none of the data collected so far suggests that. So its possible that a 4000 qubit D-Wave machine will exhibit this trend, but there is no evidence of it (yet) from examining a 2000 qubit machine. Scotts central gripe with D-Waves approach is that they dont have any even pie-in-the-sky theoretical reason to expect this to happen, and scaling up quantum computers without breaking the entire process is much harder than for classical computers so making them even bigger doesnt seem like a solution.
(2) DWave machines are NOT gate quantum computers; they call their machine quantum annealing machines. It is not known the complexity class of problems that can be solved efficiently by quantum annealing machines, or if that class is equivalent to classical machines.
The result shows that the DWave machine is asymptotically faster than the Simulated Annealing algorithm (yay!), which suggests that it is executing the Quantum Annealing algorithm. However, the paper also explicitly states that this does not mean that the Dwave machine is exhibiting a quantum speedup. To do this, they would need to show it to outperform the best known classical algorithm, which as the paper acknowledges, it does not.
What the paper does seem to be showing is that the machine in question is actually fundamentally quantum in nature; its just not clear yet that that the type of quantum computer it is is an improvement over classical ones.
(3) [I]t isnt called out in the linked blog since by now Scott probably considers it basic background information, but D-Wave only solves a very particular problem, and it is both not entirely clear that it has a superior solution to that problem than a classical algorithm can obtain and it is not clear that encoding real problems into that problem will not end up costing you all of the gains itself. Really pragmatic applications are still a ways into the future. Its hard to imagine what they might be when were still so early in the process, and still have no good idea what either the practical or theoretical limits are.
(4) The popular perception of quantum computers as doing things in parallel is very misleading. A quantum computer lets you perform computation on a superposed state while maintaining that superposition. But that only helps if the structure of the problem lets you somehow cancel out the incorrect results leaving you with the single correct one. [Theres hope for the world! SA]This ones for the physicists

Yesterday I loaded up my Prius with books, computers, bedsheets, a garbage bag full of underwear, and a summer student named Eyal Dechter, and we drove for twelve hours from Waterloo to MIT.  This drive, while historic, was largely uneventful; the main obstacle we encountered along the way was the state of New York.  Still, it was good to have someone around to share the driving, argue about the survival prospects of the human race, and point out when I left my parking brake on.
In return for helping deliver me to my new job alive, Eyal asked for just one thing: a list of papers in quantum computing and information that make explicit connections to foundational issues in physics, connections that even a physicist could recognize as such.  (If we allowed implicit connections, wed have to include pretty much every quantum computing paper ever written.)
There are many requests I cant satisfy, but this isnt one of them.
[AbramsLloyd] [AharonovJonesLandau] [Bacon] [BlumeKohoutHayden] [BriegelRaussendorf] [CavesFuchsSchack] [vanDam] [FarhiEtAl] [FreedmanKitaevWang] [Fuchs] [GottesmanPreskill] [Hardy] [Hardy] [KitaevMayersPreskill] [LiuChristandlVerstraete] [Lloyd] [Nielsen] [Smolin] [Spekkens] [TerhalDiVincenzo] [TonerBacon] [Vidal]
Notes:

The above list was produced by a rigorous selection process, which consisted of listing 21 papers that popped into my head.  If I missed your favorite, tell me.
I deliberately excluded papers that try to sugarcoat esoteric complexity theorems no one would care about otherwise, by throwing around ill-digested physics buzzwords that the author probably saw in a pop-science magazine (for example, [A.] [A.] [A.] [A.] [A.-Ambainis]).Checkers solved

From Science and NYT.Deep thoughts in shallow lagoons

I just got back from a conference in Reykjavik, Iceland (!), on Foundational Questions in Physics and Cosmology.  Photos and trip report coming soon.  For now, please content yourself with the following remarks, which I delivered to the assembled pontificators after a day of small-group conversation in a geothermally-heated lagoon.
Ive been entrusted to speak for our group, consisting of myself, Greg Chaitin, Max Tegmark, Paul Benioff, Caslav Brukner, and Graham Collins.
Our group reached no firm conclusions about anything whatsoever.
Part of the problem was that one of our members  Max Tegmark  was absent most of the time.  He was preoccupied with more important matters, like posing for the TV cameras.
So, we tried to do the best we could in Maxs absence.  One question we talked about a lot was whether the laws of physics are continuous or discrete at a fundamental level.  Or to put it another way: since, as we learned from Max, were literally living in a mathematical object, does that object contain a copy of the reals?
One of us  me  argued that this is actually an ill-posed question.  For its entirely consistent with current knowledge that our universe is discrete at the level of observables  including energy, length, volume, and so on  but continuous at the level of quantum amplitudes.  As an analogy, consider a classical coin thats heads with probability p and tails with probability 1-p.  To describe p, you need a continuous parameter  and yet when you observe the coin, you get just a single bit of information.  Is this mysterious?  I have trouble seeing why it should be.
We also talked a lot about the related question of how much information is really in a quantum state.  If we consider a single qubit  |0 + |1  does it contain one bit of classical information, since thats how many you get from measuring the qubit; two bits, because of the phenomenon of superdense coding; or infinitely many bits, since thats how many it takes to specify the qubit?
You can probably guess my answer to this question.  You may have heard of the Shut Up and Calculate Interpretation of Quantum Mechanics, which was popularized by Feynman.  I dont actually adhere to that interpretation: I like to discuss things that neither I nor anyone else has any idea about, which is precisely why I came to this wonderful conference in Iceland.  I do, however, adhere to the closely-related What Kind of Answer Were You Looking For? Interpretation.
So for example: if you ask me how much information is in a quantum state, I can show you that if you meant A then the answer is B, whereas if you meant C the answer is D, etc.  But suppose you then say yes, but how much information is really there?  Well, imagine a plumber who fixes your toilet, and explains to you that if the toilet gets clogged you do this; if you want to decrease its water usage you do that, etc.   And suppose you then ask: Yes, but what is the true nature of toilet-ness?  Wouldnt the plumber be justified in responding: Look, buddy, youre paying me by the hour.  What is it you want me to do?
A more subtle question is the following: if we consider an entangled quantum state | of n qubits, does the amount of information in | grow exponentially with n, or does it grow linearly or quadratically with n?  We know that to specify the state even approximately you need an exponential amount of information  that was the point Paul Davies made earlier, when he argued (fallaciously, in my opinion) that an entangled state of 400 qubits already violates the holographic bound on the maximum number of bits in the observable universe.  But what if we only want to predict the outcomes of those measurements that could be performed within the lifetime of the universe?  Or what if we only want to predict the outcomes of most measurements drawn from some probability distribution?  In these cases, recent results due to myself and others show that the amount of information is much less than one would navely expect.  In particular, the number of bits grows linearly rather than exponentially with the number of qubits n.
We also talked about hidden-variable theories like Bohmian mechanics.  The problem is, given that these theories are specifically constructed to be empirically indistinguishable from standard quantum mechanics, how could we ever tell if theyre true or false?  I pointed out that this question is not quite as hopeless as it seems  and in particular, that the issue we discussed earlier of discreteness versus continuity actually has a direct bearing on it.
What is Bohmian mechanics?  Its a theory of the positions of particles in three-dimensional space.  Furthermore, the key selling point of the theory is that the positions evolve deterministically: once youve fixed the positions at any instant of time, in a way consistent with Borns probability rule, the particles will then move deterministically in such a way that they continue to obey Borns rule at all later times.  But if  as were told by quantum theories of gravity  the right Hilbert space to describe our universe is finite-dimensional, one can prove that no theory of this sort can possibly work.  The reason is that, if you have a system in the state |A and its mapped to  (where |A, |B, and |C are all elements of the hidden-variable basis), then the hidden variable (which starts in state |A) is forced to make a random jump to either |B or |C: youve created entropy where there wasnt any before.  The way Bohm gets around this problem is by assuming the wavefunctions are continuous.  But in a finite-dimensional Hilbert space, every wavefunction is discontinuous!
We also talked a good deal about the many-worlds interpretation of quantum mechanics  in particular, what exactly it means for the parallel worlds to exist  but since theres some other branch of the wavefunction where I told you all about that, theres no need to do so in this one.
Oh, yeah: we also talked about eternal inflation, and more specifically the following question: should the many worlds of inflationary cosmology be seen as just a special case of the many worlds of the Everett interpretation?  More concretely, should the quantum state you ascribe to your surroundings be a probabilistic mixture of all the inflationary bubbles that you could possibly find yourself in?
Other topics included Bell inequalities, the definition of randomness, and probably others Ive forgotten about.
Finally, I wanted to take the liberty of mentioning a truly radical idea, which arose in a dinner conversation with Avi Loeb and Fotini Markopoulou.  This idea is so far-out and heretical that I hesitate to bring it up even at this conference.  Should I go ahead?
Moderator: Sure!
Well, OK then.  The idea was that, when were theorizing about the nature of the universe, we might hypothetically want some way of, you know, testing whether our theories are right or not.  Indeed, maybe we could even go so far as to reject the theories that dont succeed in explaining stuff.  As I said,  though, this is really just a speculative idea; much further work would be needed to flesh it out.Ask an unbounded question, get an uncomputable answer

Just when I thought I could relax, as the waters slowly receded from the latestD-Tsunami, my inbox and Facebook feed once again lit up with inquiriesthis time, asking me to confirm or deny thatAParadox at the Heart of Mathematics Makes a Physics Problem Unanswerable.
Uh-oh!
Luckily for my blood pressure, though, this one turned out toreferto something that more-or-lessdeservesthe hype. In particular, its aboutaphenomenal 146-pagepaperby Cubitt, Perez-Garcia, and Wolf, which just appeared this week in Nature(in condensed form, of course). Incidentally, yeah, his name really isToby Cubitt, pronounced like qubit. Hes a good guy.
To thosein quantum computing, Cubitt et al.s breakthrough is old news, having already been on the arXiv for almost a year (weve also had a talk at MIT about it). The arXiv has created a funnyphenomenon, where you learn something new and cool, assimilate it, move on, and then ayear later, everyone is suddenlyasking you have you seenthis thing, is it for real, etc. etc., just because the thing got some rubber stamp likeacceptance to Naturethat caused the press to pick it up. Like, dude, I was into the undecidability of the spectral gap way before it went mainstream.
One more amusing anecdote before we dive into the math. In hisNature News piece popularizing Cubitt et al.s result, the writer Davide Castelvecchi quotes Rebecca Goldstein, the brilliantnovelist and biographer of Kurt Gdel, as saying: Turing thought more clearly about the relationship between physics and logic than Gdel did. Heres what happened: Nature News wrote to Rebeccato ask whatGdels own thoughtswere about the relation between undecidability andphysics. Rebecca passed the request along to me. So I wrote back to her, arguing that they mightjustas well ask what Turing thought, since the Cubitt et al. result is really about Turing-undecidability (with Gdel-undecidability just an automatic corollary), and at any rate:
I also think that Turing thought more clearly about the relationshipbetween logic and physics than Gdel did (indeed, Gdel himself saidthat it was only Turings analysis of the notion of computability, interms of actual physical machines that one could imagine building,that convinced him that computability had been properly defined).
Rebecca passed thatbackto Nature News, agreeing with it, and then at some point the quote became hers. Far from being miffed about this, I consider having my forgettablewords attributed to a genius like Rebecca to be one of the great honors of my life. (By pure coincidence, she and I are having lunch next week; hopefully this will butter her up.)
So, OK, let me restate Cubitt et al.s great theorem in less pop-scienceyterms than Nature Newsused. (You could also just read the papers intro, which is exceedingly clear, but what the hellIm here to serve.)
Suppose you have two-dimensionalmaterial made of a bunch of stationary particles, each with local Hilbert space dimension d, which are arranged on an LL square grid (so, there are L2 particles in all). And suppose theres some fixedd2-dimensionalHamiltonian h, witha local copy hi,j=hacting on eachneighboring pair of particles (i,j). (I.e., the materialis translationally invariant, with the same laws of physicsacting throughout.) Let H be the total Hamiltonian: that is, the sum of the hi,js over all the neighboring (i,j)s.
Then a huge fractionof all of physicsquantum field theory, condensed-matter physics, you name itcan be summarized as, youre trying to figure out the eigenvalues and eigenvectors of H. The lowesteigenvalue, 0, tells you yourmaterialsground energy, while the higher eigenvalues, 1,2,, tell you the next discrete energy levels that the materialcan jump up to. The corresponding eigenvectors tell you which quantum states the materialis sitting in when ithas these energies:the ground state v0, and the excited states v1,v2, Those, in turn, determine basicallyeverything you could want to know about the material: whether it superconducts, etc. etc.
Of course, the eigenvalues and eigenvectors willdepend on the lattice size L. Equally obviously, for any fixed L, you could in principle compute all the eigenvalues and eigenvectors by just diagonalizing some huge-ass matrix. (That matrix beingH.) But physicists are usually more interested in the limiting behavioras L goes to infinity. One of their most basicdistinctions is: the material is gapped if 1-0, the difference between the first excited energy and the ground energy, converges to some positive value or even grows with L as L. Its gapless if 1-0converges to 0 as L. (Actually, Cubitt et al. use more technical definitions of both of these concepts, but well ignore that.)
Cubitt et al.s theorem now says the following: for some fixed, constant local dimension d, there is no algorithm that takes as input the local Hamiltonian h (say, as a d2d2 matrix of algebraic numbers), and that decides whether the material is gapped or gapless. Indeed, you can reducethe halting problem to that problem, in such a way that the material will be gapped if your Turing machine halts, or gapless if it runs forever.
As an immediate corollary, theres some 2Dmaterialcharacterized by a translationally-invariant local Hamiltonian h on particles of local dimension dsuch that whether the material is gapped or gapless is independent of the axioms of ZF set theory, or whatever else your favorite axioms might be. (Proof: build a Turing machine M that halts if and only if it finds an inconsistency in set theory, then run Cubitt et al.sreduction from the halting problem. By Gdel, if set theory is consistent then it cant prove whether M halts or not.)
Cubitt et al. neverbother towork out the local dimension d that suffices for them, but it could be worked out, and its probably at least in the tens of thousands. Thus, their result leaves open the possibility that theresan algorithm to decide gaplessness for 2D lattices of qubits (i.e., the special case d=2), or other reasonably low-dimensional quantum systems. We simply dont know right now. Another tantalizing open question is whether theres an algorithm to decide gaplessness for one-dimensionalspin chainsagain, even in the special case d=2. Right now, the best we have in that direction is a difficult recent result of Bravyi and Gosset, which gives an algorithm to decide gaplessness for one-dimensional, frustration-free chains of qubits. (Here frustration-free, an amusing term that does not well describe this subject as a whole, means that you can minimize the energy H by minimizing the energies of each hi,j individually. Or, if you think of H as a SAT instance, its satisfiable.)
But while the exact value of d where uncomputabilitykicks in is still up for grabs, its extremely important that d is somefixed, universal constant, independent of the Turing machine. Indeed, as Cubitt et al. point out in their paper, this is the onlyfeature that makes their new result not a trivial corollary of the uncomputability of Wang tiling. The latter is a famousresult from 1966, which says that theres no algorithm that takes as input a finite setof tiles, and that tells you whether, usingunlimited copies of each tile, you could cover the entire plane (or equivalently, arbitrarily large finite regionsof the plane). I.e., this is yet another natural math problem that secretly encodes the halting problem.
The fact that d is fixed also means that, in ordertoencode larger and larger Turing machines into the local Hamiltonian h (as you must, if you wantto embed the halting problem), you need to use more and more bits of precision(!) in the ~d4 real numbers that define h. This then raises aquestion: how do you actually extract a description of a Turing machine from the binary expansions of the real numbers that define yourHamiltonian? To do this, Cubitt et al. use Kitaevs phase estimation algorithmwhich, interestingly, is the only part of their construction that usesquantum mechanics in any way. One thing that Id love to understand better is whether the phase estimation is really essential here, or whether the analogous classical question, with the Hamiltonian given by a probability distribution over classical constraints, could also be proved to be undecidable for some fixed value of dthereby showing that Cubitt et al.s discoveryhad nothing to do with quantum mechanics.
(Its possible that the answer to this is obvious; I didnt think about it deeply. Note that if the classical Hamiltonian is also deterministic, then the problem must be decidable for every fixed d, since there are only finitely many possible hs, and we could cache all the answers in a lookup table.)
Anyway, its now my professional duty, as the prickly, curmudgeonly blogger I am, to end the post byshooing you awayfrom two tempting misinterpretations of the Cubitt et al. result.
First, the result does not sayor even suggestthat theres anyreal, finite physical system whose behavior is Gdel- orTuring-undecidable. Thus, it gives nosupport to speculations like Roger Penroses, abouthypercomputing that would exceed the capabilities of Turing machines. The reason, again, is that as soon as you fix a lattice size L, everything becomes computable. TheCubitt et al. resultapplies only to questions about the limiting behavior, as the number of particles goesto infinity. But we already knew lotsofexamples of physical systems for which predicting their behaviorin some infinite limit is at least as hard as the halting problem: for instance, the Wang tiles discussed earlier, or Post rewrite systems, or even Turing machines themselves. Local Hamiltonians are a profound, nontrivial addition to that listone that will be particularly striking to physicists, many of whom calculate the spectral gaps of at least 50 Hamiltoniansbetween dinner and dessert. But in some sense, there was no a-priori reason why a problem this general, about physical systems of unbounded size,ought tohave been computable.
Second, the result does not say that any particularquestion physicists want ananswer tofor example, the million-dollarYang-Mills mass gap problemis Gdel-undecidable. All it says, is that the possibility that some real-world question of that kind could beundecidableisnt totally closed off. The Nature News piece stressesthis latter implication a lotas, admittedly, do Cubitt et al.themselves. But to put things in perspective: four logiciansprovedaround 1970 that theres no algorithm to decide whether an arbitrary polynomial equation has an integer solution, thereby giving a negative solution to Hilberts Tenth Problem. Yet with few exceptions, working number theorists barely even noticed this development, nor was (say)Andrew Wiles dissuaded from proving Fermats Last Theorem, by the absence ofageneral algorithm to do things like what he was trying to do. (Indeed, the absence of a general algorithm was shown even earlierfor equations like FLT, which have variables in the exponent.) So I doubt the mathematical physicists who calculate spectral gaps for a living will be any more terrifiedthan the number theorists were, tolearn that theyve been laboring their entire lives on the shores of the halting problem. Good for us, then! they could rightly reply. Maybeour jobs wont be so easy to automate.
Update (Dec. 20): My colleague Seth Lloyd calls my attention to a PRL paper of his from 1993, which also discusses the construction of physical systems that are gapped if a given Turing machine halts and gapless if it runs forever. So this basic idea has been around for a while. As I explained in the post, the main contribution of the Cubitt et al. paper is just to get undecidability into the sort of systemphysicists could plausibly care about (or for which they couldve plausibly hoped for an analytic solution): in this case, 2D translationally-invariant nearest-neighbor Hamiltonians with bounded local dimension.Sorry, Prof. Guth

but its been discovered by empirical observation that the universe is not, as you famously claimed, the ultimate free lunch.   Rather, the FQxi Conference on Foundational Questions in Physics and Cosmology in Reykjavik, Iceland is the ultimate free lunch.

Speaking of which, above you can see the discoverer of cosmic inflation himself, together with theoretical physicist Lawrence Krauss on his left, chatting on a glacier only minutes after engaging in a snowball fight.

And your humble blogger, who still cant parallel park, hoping hell be able to steer a snowmobile without falling into any 1000-foot crevices.

Here I am with Cosmic Variances Mark Trodden (who blogged earlier about this conference, saving me a good deal of work).

The dirt above is all area where the glacier previously was, but retreated over the last few decades.

To all those who say global warming is a myth: lo, I have watched a glacier melting with mine own eyes.

The geothermally-heated lagoon where part of the conference was held.

And just in case debating unfalsifiable cosmic hypotheses in a lagoon isnt tacky enough, a PBS crew (from a show called Closer to Truth) was there to film it.

This is said to be the official divide between the North American and European tectonic plates.

In North America this would be a major tourist attraction with hotels, casinos, cotton candy shops, etc.  Here its just another waterfall.

Curse me lucky charms, theres no pot o gold!German comedy

I know Ive been a derelict blogger since moving to MIT, allowing far, far too many of you to concentrate on work.  But today Im back with some quality procrastination material.
My colleague (and sometime berliberal commenter on this blog) Aram Harrow points me to a safety video for German forklift-truck drivers, which was posted to YouTube with English subtitles.  As Aram says, it starts slow but is definitely worth watching to the end.
Its funny: just this weekend, I was volunteering with the Cornell Alumni Association at the Greater Boston Food Bank.  My job was to unload 40-pound boxes of canned goods from a forklift truck and place them on a conveyor belt.  (And no, this is not something Id normally do.  Normally Id offer to write a check to pay for ten people stronger than I am to unload boxes for the needy.  Long story short, I was invited to do this by an individual of female persuasion.)
The whole time I was unloading boxes, I too was a bit worried about forklift safety  but, as I now know, not nearly as worried as I should have been.Mahmoud and me (continued)

I woke up this afternoon to find, in the comments section of my previous post, an ongoing debate about whether or not I was being serious when I praised the President of Iran for his resoluteness and conviction. For those who couldnt figure it out, the answer is: of course I was being serious. In fact, right after I finished blogging, I telephoned Mahmoud to ask whether the Iranian army could use the services of a 24-year-old male who speaks fluent English, can do up to two push-ups per day, once fired an actual rifle, loves Persian food, and believes himself able to prove quantum lower bounds under combat conditions.
Mahmoud mulled it over for a while, and then replied that, while my qualifications were certainly impressive, unfortunately I did not meet his needs at the present time. I was devastated  and, I confess, I even started to wonder whether anti-Semitism might be at play. Except  how could he know? Throw in an extra s, and Scott Aaronsson could almost pass for Scandanavian. Then it hit me: like everyone else Ive talked to over the past couple weeks, Mahmoud must be reading my weblog!
OK, look: is it immature to joke about these things, as several posters argued?  Yes, it is immature. The mature response is to deplore evil, to be shocked by it  not to make a movie with Nazis dancing to the tune of Springtime for Hitler in Germany, or Woody Allen standing behind Hitler on a podium as part of his ongoing struggle to fit in. Its just that all that deploring gets monotonous eventually. After a millennium or two, theres nothing else to do except joke.  As the story goes:
In 1936 in Berlin, a Jew is sitting in a cafe, reading Der Strmer.  His friend runs over to him: Herschel, what are you doing?  Dont you realize thats a Nazi paper?
Yeah, but in the Jewish papers, the news is always so depressing. Here its phenomenal: we control the banks, we control the media6.S899 Student Project Showcase!

As 2015 winds down,I thought Id continue my tradition of using this blog to showcase some awesomestudent projects from my graduate class. (For the previous project showcases from Quantum Complexity Theory, see here, here, and here. Also see here for the showcase from Philosophy and Theoretical Computer Science.)
This fall, I taught 6.S899, a one-time Seminar on Physics and Computation that focused on BosonSampling, complexity and quantum gravity, and universality of physical systems. There were also lots of guest lectures and student presentations. Unfortunately, we didnt do anynotes or recordings.
Fortunately, though, the students did do projects, which were literature reviews some of whichventured into original research, and all nine have agreed to share their project reports here! So enjoy, thanks so much to the students for making it a great class, and happy holidays.

Computational Complexity of Spectral Gaps, by Anand Natarajan.
Further Extensions of Clifford Circuits and Their Classical Simulation Complexities, by Dax Koh.
On the Complexity of Stoquastic Hamiltonians, by Ian Kivlichan.
Gravitational Attacks on Relativistic Quantum Cryptography, by Jayson Lynch.
Tensor Networks, Quantum Error Correction, and AdS/CFT, by John Napp.
Computation in a Topological Quantum Field Theory, by Daniel Epelbaum and Raeez Lorgat.
Quantum Complexity, Statistical Physics, and Combinatorial Optimization, by Rolando La Placa.
Building and Bounding Quantum Bernoulli Factories, by Theodore Yoder.


Update (Dec. 23):Here are two conference announcements that Ive been asked to make: Innovations in Theoretical Computer Science (ITCS) 2016, January 14-16 in Cambridge MA, and the Fifth Women in Theory Workshop, at the Simons Institute in Berkeley, May 22-25, 2016.Edging in: the biggest science news of 2015

For years, I was forced to endure life with my nose up against the glass of the Annual Edge Question. What are you optimistic about? Ooh! ooh! Call on me! Im optimistic about someday being able to prove my pessimistic beliefs (like PNP). How is the Internet changing the way you think? Ooh, ooh! I know! Google and MathOverflow are saving me from having to think at all! So then why are they only asking Steven Pinker, Freeman Dyson, Richard Dawkins, David Deutsch, some random other people like that?
But all that has changed. This year, I was invited to participate in Edge for the first time. So, OK, heres the question:
What do you consider the most interesting recent [scientific] news? What makes it important?
My response is here. I wasnt in lovewith the question, because of what I saw as an inherent ambiguity in it: the news thats most interesting to me, that I have a comparative advantage in talking about, and that people probably want to hear me talk about (e.g., progress in quantum computing), is not necessarily what Id regard as the most importantin any objective sense (e.g., climate change). So, I decided to write my answer precisely about my internal tension in what I should consider most interesting: should it be the recent progress by John Martinis and others toward building a quantum computer? Or should it be the melting glaciers, or something else that Im confident will affect the future of the world? Or possibly the mainstream attention nowbeing paid to the AI-risk movement? But if I really want to nerd out, then why notBabais graph isomorphism algorithm? Or if I actuallywant to be honest about what excited me, then why not the superquadratic separations between classical and quantum query complexities for a total Boolean function, by Ambainis et al. and my student Shalev Ben-David? On the other hand, how can I justify even caring about such things while the glaciers are melting?
So, yeah, my response tries to meditate on all those things. My original title was How nerdy do you want it?, but John Brockman of Edge had me change it to something blander (How widely should we draw the circle?), and made a bunch of other changes from my usual style. Initially I chafed at having an editor for what basically amounted to a blog post; on the other hand, Im sure I wouldve gotten in trouble much less often on this blog had I had someone to filter my words for me.
Anyway, of course I wasnt the only person to write about the climate crisis. Robert Trivers, Laurence Smith, and Milford Wolpoff all wrote about it as well(Trivers most chillingly and concisely), while Max Tegmark wrote about the mainstreaming of AI risk. John Naughton even wrote about Babais graph isomorphism breakthrough (though he seems unaware that the existing GI algorithms were already extremely fast in practice, and therefore makes misleading claims about the new algorithms practical applications). Unsurprisingly, no one else wrote about breakthroughs in quantum query complexity: youll need to go to my essay for that! A bit more surprisingly, no one besides me wrote about progress in quantum computing at all (if we dont count the loophole-free Bell test).
Anyway, on reflection, 2015 actuallywas a pretty awesome year for science, no matter how nerdy you want it or how widely you draw the circle. Here are other advances thatI easily couldvewrittenabout but didnt:

PH has finally been proven infinite relative to a random oracle
We finally understand why computing the edit distance between two strings takes nearly-quadratic time
Terry Tao solved the Erds Discrepancy Problem
The loophole-free Bell test that I blogged about here (Anton Zeilinger and Hans Halvorson discussed this in their Edge answers)
Recent progress on the emergence of spacetime from entanglement, and understanding the role of computational complexity in quantum gravity (Lenny Susskind, Amanda Gefter, and Donald Hoffman all discussed these things in their Edge answers)

Ive now read all(more or less) of this years Edge responses. Even though someof the respondents pushed personal hobbyhorses like Id feared, I was impressed by how easyit wasto discern themes:advancesthat kept cropping up in one answer after another and that one might therefore guess are actuallyimportant (or at least, are currently perceived to be important).
Probably at the top of the list was a new gene-editing technique called CRISPR: Randolph Neese, Paul Dolan, Eric Topol, Mark Pagel, and Stuart Firesteinamong others all wrote about this, and about its implications for creating designer humans.
Also widely-discussed was the discovery that most psychology studies fail to replicate (Id long assumed as much, but apparently this was big news in psychology!): Nicholas Humphrey, Stephen Kosslyn, Jonathan Schooler, Ellen Winner, Judith Rich Harris, and Philip Tetlock all wrote about that.
Then there was the Pluto flyby, which Juan Enriquez, Roger Highfield, and Nicholas Christakis all wrote about. (As Christakis, Master of Silliman College at Yale, was so recently a victim of asocial-justice mob, I found it moving how he simply ignored those baying for his head and turned his attention heavenward in his Edge answer.)
Then there was progress in deep learning, including Googles Deep Dream (those images of dogs in nebulae that filled your Facebook wall) and DeepMind (the program that taught itself how to play dozens of classic video games). Steve Omohundro, Andy Clark, Jamshed Bharucha, Kevin Kelly, David Dalrymple, and Alexander Wissner-Gross all wrote about different aspects of this story.
And recent progress in SETI, which Yuri Milner (whos given $100 million for it) and Mario Livio wrote about.
Unsurprisingly, a bunch of high-energy physicistswrote about high-energy physics at the LHC: how the Higgs boson was found (still news?), how nothing other than the Higgs boson was found (the biggest news?), but how theres now the slightesthintof a new particle at 750 GeV. See Lee Smolin, Garrett Lisi, Sean Carroll, and Sarah Demers.
Finally, way out on the Pareto frontier of importance and disgustingness was the recently-discovered therapeutic value of transplanting one persons poop into another persons intestines, which Joichi Ito, Pamela Rosenkranz, and Alan Alda all wrote about (it also, predictably, featured in a recent South Park episode).
Without further ado, here are 27 other answers that struck me in one way or another:

Steven Pinker on happy happy things are getting better (and we can measure it)
Freeman Dyson on the Dragonfly astronomical observatory
Jonathan Haidt onhow prejudice against people of differing political opinions was discovered to have surpassed racial, gender, and religious prejudice
S. Abbas Raza on Pikettys r>g
Rebecca Newberger Goldstein, thoughtful as usual, on the recent study that saidits too simple to say female participation is lower in STEM fieldsrather, female participation is lower in all and only those fields, STEM or non-STEM, whose participants believe(rightly or wrongly) that genius is required rather than just conscientiouseffort
Bill Joy on recent advances on reducing CO2 emissions
Paul Steinhardt on recent observations saying that, not only were the previous B-modes from inflation just galactic dust, but there are noreal B-modes to within thecurrent detection limits, and this poses a problem for inflation (I hadnt heard about this last part)
Aubrey de Grey on new antibiotics that are grown in the soil rather than in lab cultures
John Tooby on the evolutionary rationale for germline engineering
W. Tecumseh Fitch on the coming reality of the Jurassic Park program (bringing back extinct species through DNA splicingthough probably not dinosaurs, whose DNA is too degraded)
Keith Devlin on the new prospect of using massive datasets (from MOOCs, for example) to actually figure out how students learn
Richard Muller on how air pollution in China has become one of the worlds worstproblems(imagine every child in Beijing being force-fed two packs of cigarettes per day)
Ara Norenzayan on thedemographic trends in religious belief
James Croak on amazing advances in battery technology (which were news to me)
Buddhini Samarasinghe on (among other things) the power of aspirin to possibly prevent cancer
Todd Sacktor on a new treatment for Parkinsons
Charles Seife on the imminent availability of data about pretty much everything in our lives
Susan Blackmore on that dress and what it revealed about the human visual system
Brian Keating on experiments that should soon tell us the neutrinos masses (again, I hadnt heard about these)
Michael McCullough on something called reproductive religiosity theory, which posits that the central purpose of religions is to enforcesocial norms around mating and reproduction(for what its worth, Id always regarded that as obvious; its even expounded in the last chapter of Quantum Computing Since Democritus)
Greg Cochran on the origin of Europeans
David Buss on the mating crisis among educated women
Ed Regis on how high-fat diets are better (except, isnt this the principle behind Atkins, and isnt this pretty old news by now?)
Melanie Swan on blockchain-based cryptography, such as Bitcoin (though it wasnt entirely clear to me what point Swan was making about it)
Paul Davies on LIGO getting ready to detect its first gravitational waves
Samuel Arbesman on how weather prediction has gotten steadilybetter (rendering our cultures jokes about the perpetually-wrong weatherman outdated, with hardly anyone noticing)
Alison Gopnik on how the ubiquity of touchscreen devices like the iPad means that toddlers can now master computers, and this is something genuinely new under the sun (I can testify from personal experience that shes onto something)

Then there were three answers for which the progress being celebrated, seemed to me to be progress racing faster into WrongVille:

Frank Tipler on how one can conclude a priorithat there must be a Big Crunch to our future (and hence, the arena for Tiplerian theology) in order to prevent the black hole information paradox from arising, all recent cosmological evidence to the contrarybe damned.
Ross Andersonon an exciting conference whose participantsaim to replace quantum mechanics with local realistic theories. (Anderson, in particular, is totally wrongthat you can get Bell inequality violation from a combination of local action and global correlation, unless the global correlation goes as far as a t-Hooft-like superdeterministic conspiracy.)
Gordon Kane on how the big news is that the LHC shouldsoonsee superparticles. (This would actually be fine except that Kane omitsthe crucial context, that hes been predicting superparticles just around the corner again and againfor the past twenty years and theyve never shown up)

Finally, two responses by old friends that amused me. The science-fiction writerRudy Rucker just became aware of the discovery of the dark energy back in 1998, and considers that to be exciting scientific news (yes, Rudy, so it was!). AndMichael Vassarthe Kevin Bacon or Paul Erds of the rationalist world, the guy who everyones connected to somehowwrites something about a global breakdown of economic rationality, $20 bills on the sidewalk getting ignored, that I had trouble understanding (though the fault is probably mine).Intellectual whack-a-mole

Several readers have now written to me independently, asking for my reaction to the following paper:
An Optical Solution For The Traveling Salesman Problem
Tobias Haist and Wolfgang Osten
Abstract: We introduce an optical method based on white light interferometry in order to solve the well-known NPcomplete traveling salesman problem. To our knowledge it is the first time that a method for the reduction of nonpolynomial time to quadratic time has been proposed. We will show that this achievement is limited by the number of available photons for solving the problem. It will turn out that this number of photons is proportional to NN for a traveling salesman problem with N cities and that for large numbers of cities the method in practice therefore is limited by the signaltonoise ratio. The proposed method is meant purely as a gedankenexperiment.
Look, this is really not hard.  You really dont need a world CompuCrackpotism expert to tell you what to think of this.  If you read carefully, the authors were actually kind enough to explain themselves, right in the abstract, why their proposal doesnt scale.  (This, of course, is entirely to their credit, and puts them above ~98% of their colleagues in the burgeoning intersection of computer science, physics, and non-correctness.)
Hint: If the number of photons scales exponentially with N, and the photons have high enough energies that you can detect them, then the energy also scales exponentially with N. So by the Schwarzschild bound, the volume also scales exponentially with N; therefore, by locality, so does the time.From Boston to Austin

I have some big newswell, not for the world, but for me personally. Starting this summer, Ill be leaving MIT, and starting a new phase of my life, as David J. Bruton Jr. Centennial Professor of Computer Science at the University of Texas at Austin. Ill alsobe the founding director of UT Austins new quantum computing center, whose motto will be Hook em Hadamards, and whose logo will depict a fierce longhorn bull, whose horns are bra and ket signsenclosing an inner product between two quantum states. My brilliant and talented wife, Dana Moshkovitz Aaronson, will also be joining UT Austin, as a tenured Associate Professor of Computer Science. Our current PhD students will remain enrolled at MIT, while also spending as much time as they like in Austin.
Ill deeply miss MIT and Boston. More than anything else, Ill miss the phenomenalstudents at MIT, who Ive had the immense privilege to teach and learn from for nine years. Go Beavers! Im grateful as well to my many friends and colleagues who made my yearsat MIT so rewarding:a time of personal growth, in which I developedfrom a skinny, insecure 26-year-oldnerd, blogging and trying to proveoracle separations, into a pot-bellied, tenured, 34-year-old married-father nerd, still blogging and trying to prove the same oracle separations (but no longer as diligently).
To nipan otherwise-inevitable rumor: I wasnt forced to leave MITover anything here on Shtetl-Optimized. I feel the need to say thisbecause, within the last year, Ive spenthundreds of miserable hoursscrolling throughsocial mediathreads wherein stranger after stranger proclaimedme basically the worlds worst scum(tied, perhaps, with the other Scott A.),and even called on MIT to fire me. Given that experience,it was repeatedly jarring for me to reenter realityanddiscover how irrelevant thisallwas, either to MIT or to any of the universitiesthat recruitedme and Dana. Bizarre as it sounds, CS departments mostly cared about what actualresearch we weredoing and could bring to them! Sostudents and faculty afraid to debateanything controversial online under their real names, however politely,should knowthat even in 2016, the banner of academicfreedom yet waves.
Without further ado, let me listten things that are awesome about Austin and that helped attract me and Dana there.

One of the strongest CS departments andtheory groups in the world. From 1984 until his death in 2002, UT Austin was home to Edsger Dijkstra, who not only discovered Dijkstras algorithm but also pennedthe immortal wordsthat might as well be tattooed onmy stomach:computer science is no more about computers than astronomy is about telescopes. Today, AustinsCS department is rapidly expanding, andjust within theory, ishome to David Zuckerman, Anna Gal, Vijaya Ramachandran, Brent Waters, Eric Price, and Greg Plaxton. With me and Dana there as well, I can say with all due modesty that we intendtocompete against any CS theory program anywhere in the world.
Adam Klivans. The closest Ive had to a mentor in the exceedinglynarrow field of theoretical computer science humor.
An outstanding recent track record withCS theory PhD students. Since the turn of the century, UT Austin has produced Sasha Sherstov, Anup Rao, Allison Bishop Lewko,Seth Pettie, Vladimir Trifonov, Raghu Meka, and other stars of the CS theory world. That record lets me without the slightest hesitation tell hotshot undergrads who want to do classical and/or quantum complexity theory to apply to Austin for grad school.
The opportunity to buildor rather, rebuilda UT presence in quantum computing. While Im excited to help build a new groupand I feel like its the right time in my career to do thatI cant say that this is the first time UT Austin will have a significantpresence inquantum computing. Way back in the late 70s and early 80s, UT was home to most of the (proto) quantum computing research that existed on earth. Its there that John Archibald Wheeler philosophized about It from Bit, that Bryce deWitt popularized the Many-Worlds Interpretation and Hugh Everett gave his only public lecture onthe subject, that David Deutsch did a four-yearpostdoc in which he formed the seeds of the idea of quantum computing, and that Wojciech Zurek, William Wootters, and Benjamin Schumacher (who between them, founded decoherence theory, proved the No-Cloning Theorem, and coined the term qubit) did their PhDs. Im honored to treadin their footsteps.
Money. Texas, as it turns out, has a lot of it. Now, the conventional wisdom would be that Texas wealthis mostly irrelevant to academic scientists, because itscontrolled by reactionaryoilmenfor whom curiosity-drivenresearch is not exactly the toppriority. That might have been true about the administrations of George W. Bush or Rick Perry. But Texascurrent governor, Greg Abbott, while stilla right-wingRepublican, alsopushed through an aggressive $4-billion measure called the Governors University Research Initiative, one of whose centralgoalsis to recruitleading scientists to Texas.
Weather. To a first approximation, Austin is lovelyand pleasant during the academic year (even as the planet warms, this should remain true for at least a few more decades)and while Id sort of vaguely imagined all of Texas as a giant desert, Austin turns out to be lush and green and full of swimming holes. The summers, of course, are hot enough to fuse hydrogen. But for academics like me and Dana, it turns out that theres an elegant solution to that, one unavailable for dealing with New Englandwinters. That solution isto leave town,to use June, July, and Augustformiscellaneous academictravel.
Quality of life. If were being honest, Im not someone likely to spend much timeat indie-rockfestivals, or whatever quirky cultural stuff it is thatsmadeAustin the fastest-growing city in the US. But heres something I do care about: even thoughhighway traffic in Austin is bad and getting worse, that need not affect my life toomuch. Research indicates that, for roughly the price of our current 2-bedroom condo in Cambridge,we could get a lovely4-bedroom with a yard thats in walking distance to the UT campus, as well as to stores, restaurants, good schools, and parks.
Schools. I had a prettymiserable experience growing up. I dont know if Lily (or any future children Dana and I have)will be anything like I was, but given thatshes in an at-risk population for nerdiness,Id loveto live in a place with nerd education optionsthat dont stink. Austin, happily, has two renowned math/science magnet schoolsKealing Middle School and LASA High Schoolwhich admit based on test scores. (By contrast, in most partsin the US, such programs either dont exist or admit purely by lottery.) Austin also has the only elementary school, anywhere, whose admissions director told me that sure, theydlet a student skip a grade if it made sense academically.
Steven Weinberg. I confess: it probably affected me more than it should that arguablythe greatest scientistnow walking the earth, a legend of physics who could go wherever the hell he wanted, has chosen to spend the past thirty-plus years at UT Austin. On our last visit there, Dana, my parents, and I had the honorof having dinner with Weinberg. After wed exchanged stories about Telluride House at Cornell, where Weinberg and I both lived as undergrads (and which apparently changed little betweenthe 1950s and the 1990s), Weinberg sung the praises of Austin for hours. (Admittedly, part of why Weinberg enjoysAustin so much is that there its easy tobe on a first-name basis with the mayor, tech billionaires, and all the other leaders of the cityan advantage that might be Nobel-laureate-specific!)
Adventure. By background and temperament, Im probably one of the least Texan Americansimaginable: a nerdy east-coast Jewish intellectual who enjoyssnow, cant much tolerate spicy food, is bored bycowboy movies and fears physical confrontation. Indeed, until I actually visited the place, my only real associations with Texas were tumbleweeds blowing across a parched desert hellscape, oilmen with giant belt buckles guffawing about so-called global warming, crazed football hooligans filling city-sized stadiums, shotguns, rattlesnakes, and George W. Bush. But then, the contrast between the over-the-top image and the pleasant reality of Austinhad the paradoxical effect of making moving to Texas feel like an adventurean adventurewith an acceptable risk profile. Like, if Im going to uproot at all, why not to a place thats strange and different and interesting?

Even given the above, some people will ask about things theyd consider obvious dealbreakers for moving to Texas. In particular, what about theinfamous new lawthat essentially forces UT Austin to letstudents carry concealed firearmsto class? Well, I oppose that law. Indeed, when I havent been angeringthe social-justice left, Ive been angeringthe right by (for example)blogging about my strong support for gun control. To me, it seems likea terribleideafor the Texas state legislature, which providesonly 14% of the UT systems budget, to force on UT a gun policy that its faculty and students overwhelmingly hate. And I admired Steven Weinbergsannouncementthat he intendsto defythe law in his classroom, and fight it out in court if necessary. (Weinberg also gave, as one reason to oppose the law, how much harder it will make it for UT to recruit faculty.)
But at the same time  Dana is Israeli. For her, its perfectly normal to go outside and see 18-year-old girls chattingand laughing with huge-ass machine guns slung over their shoulders. Having spent a month of each year in Tel Aviv, seeingpassersby with guns has become, if not exactlynormal to me, then not something I fear 2% as much as I fear crashing my car. And indeed, if onetakes a statistical approach to risk, Austin has a much lower per-capita violent crime rate than Boston does.
And yes, I know, the US and Israel have completelydifferent gun cultures: in Israel, for example,the onlypeople carryingaround semiautomatics are trained and monitored conscripts; theres no concept of a private right to such a weapon. And yes, the principle matters. But if one isunwilling to move to any place that has any lawsonedisagrees with, oneshould probably look into faculty positions on offshore barges or Jupiter.
Austin itself, of course, is only slightly less liberal than Portland,the blueberry in the tomato soup as Rick Perry so memorablyput it. Even so, the maps insist thatAustin is in Texas, which means that while there one will probablyencounter Texans. (A friend, on hearing that Dana took aquickliking to Austinwhen she visited, quipped that it was probably because Austin reminded her of Israel: hot and surrounded by hostile territory.)
Now, the actual Texans who Ive met so far have beenfrighteningly warm and hospitable. But the question stands: what will I do if, while living there, I meet (lets suppose) some sun-callousedcattle rancherswhoconsider me an arrogant, effete coastal liberal who patronizes them in blog posts like this one? What if they tell me to scram, headback east,andnevermess with Texas again?
Well, Ive already decided what Id like to do in this hypothetical situation. Id like to invite the ranchers over to my placefor some barbecued beers and ice-cold steaks, or whatever it is you eat in Texas, and tell them all about quantum query algorithms, and ask them about cattlefeed, and try to find common ground, justlike I tried to find common ground withthe other end of the political spectrumwith the folks who called me a clueless, patriarchal, entitled white male douchebro who silenced their already-marginalized voices by not agreeing with everything they said. For Ive increasingly come to theconviction that, while you might fail tofind common ground with someone, youve gotto try, youve gottosteelman theirargumentand learn whatever you can from it. I once, for example, thought about theReligious Rightas purely contemptible, deserving only unthinking snark, and I was completelywrong. Even when I was right on the underlying issues, I was wrong on the epistemology. In Texas, hopefully Ill have a chance to do better.
In summary:

Wherever youre at in your career, if youd like to do quantum informationand/or theoretical computer scienceresearch on the wildfrontierif QMA, QCMA, and BQP/qpoly strike you as little more than wayward calvesto be lassoed inthen please consider joining us at UT Austin. To be concrete: well be looking for distinguished senior faculty to hireunder the Governors University Research Initiative, well be looking for tenure-track junior faculty in bothCSand ECE, well be looking for postdocs, well be looking for grad students, and finally well be looking for undergrads whod like to join the innovative Turing Scholarshonors program.
If youd just like to come for a week andgive a seminar, well have money for that too.
Hook em Hadamards!


Totally Unrelated Update (Feb. 29): Michael Mitzenmacher has asked me to announce that nominations are open for the SIGACT Distinguished Service Prize.  More information is available here.Happy Third Birthday Lily!

Non-Lily-Related Updates (Jan. 22)
Uri Bram posted a cute little article about whether he was justified, as a child, to tell his parents that he wouldnt clean up his room because doing so would only increase the universes entropy and thereby hasten its demise.  The article quotes me, Sean Carroll, and others about that important question.
On Wednesday I gave a TCS+ online seminar about The Largest Possible Quantum Speedups.  If youre interested, you can watch the YouTube video here.





(I promised a while ago that Id upload some examples of Lilys MOMA-worthy modern artworks. So, here are two!)
A fewquotable quotes:
Daddy, when you were little, you were a girl like me!
Im feeling a bit juicy [thirsty for juice].
Saba and Safta live in Israel. Theyre mommys friends! [Actuallytheyre mommys parents.]
Me: Youre getting bigger every day!
Lily: But Im also getting smaller every day!
Me: Then Goldilocks tasted the third bowl, which was Baby Bears, and it was just right! So she ate itall up. Then Goldilocks went
Lily: No, then Goldilocksate some cherries in the kitchen before shewent to the bedroom. And blueberries.
Me: Fine, so she ate cherries and blueberries. Then she went to the bedroom, and she saw that there were three beds
Lily: No, four beds!
Me: Fine, four beds. So she laid in the first bed, but she said, this bed is too hard.
Lily: No, it was too comfortable!
Me: Too comfortable? Is she some kind of monk?
Me [pointing to a taxidermed black bear in a museum]: Whats that?
Lily: A bear!
Me: Is it Winnie the Pooh?
Lily: No, its a different kind of bear.
Me [pointing to a tan bear in the next case]: So what about that one? Is that Winnie?
Lily: Yes! Thats Winnie the Pooh!
[Looking at it more closely] No, its a different kind of Winnie.
Lily: Why is it dark outside?
Me: Because its night time.
Lily: Why is it night time?
Me: Because the sun went to the other side of the world.
Lily: It went to China!
Me: Yes! It did in fact go to China.
Lily: Why did the sun go to China?
Me: Well, more accurately, it only seemed to go there, because the world that were on is spinning.
Lily: Why is the world spinning?
Me: Because of the conservation of angular momentum.
Lily: Why is the  consibation of amomomo?
Me: I suppose because of Noethers Theorem, and the fact that our laws of physics are symmetric under spatial rotations.
Lily: Why is
Me: Thats enough for today Lily!Death to Verizon

Needing a token of my years in Waterloo, I figured it was finally time to trade in my Pleistocene Nokia phone for a BlackBerry.  So I used some of my startup funds to buy a BlackBerry 8830 World Edition from Verizon.  What particularly excited me about this model was that it was advertised as having a built-in GPS receiver  meaning (or so I thought) that Id be able to pull up Google Maps wherever I was, and never get lost again.
Well, today the phone arrived, and I found out that Verizon has disabled the GPS (see here, here, and here).  The reason, apparently, is that at some unknown time in the future, it plans to sell an inferior navigation service for $10/month, and doesnt want people getting for free what it will later rip them off for.
Ive been having fun imagining the conversation between Mike Lazaridis (the founder of Research in Motion, the Waterloo-based company that makes BlackBerries) and Verizon:
Lazaridis: Its an abomination!  As long as I draw breath, Ill never agree to your crippling my invention!
Verizon CEO (breathing heavily): Young Lazaridis, come over to the Dark Side.
Lazaridis (pause): Actually, how much are you offering?  Ive been needing cash, ever since blowing all those millions on the Perimeter Institute and the Institute for Quantum Computing
Some will say Im a sucker, buyer beware, etc.  The more sympathetic will call me a victim of false advertising  indeed, of the exact sort of corporate behavior that my best friend Alex Halderman and his adviser Ed Felten have battled for years with some spectacular successes.
Recently I attended a talk by the legendary free-software activist Richard Stallman, who thundered like an Old Testament prophet about human beings inalienable right to understand, modify, and share the technology they own.  At the time I agreed with Stallman intellectually but found him a bit obsessive.  Now I have my own dog in this fight.
Ive always known that American cell phone companies are evil: they have shitty, unreliable networks, enormous advertising budgets, and miniscule R&D budgets.  But Verizon has taken things to a level even I wouldnt have predicted.
Were not living in anything close to the efficient market dreamed of by my economist friends like Robin Hanson.  The invisible hand has palsy and four missing fingers.  And the proof is that, when a company like Verizon pulls a Monty Burns, theres almost no risk it runs  almost nothing it fears.  Indeed, about the only risk it does run is that some of its customers might have blogs  and that some of the savvier readers of those blogs might figure out how to hack the crippled phones and share that information with the worldMarvin Minsky

Yesterday brought the sad news that Marvin Minsky passed away at age 88. I never met Minsky (I wish I had); I just had one email exchange with him back in 2002, about Stephen Wolframs book. But Minsky was my academic great-grandfather (through Manuel Blum and Umesh Vazirani), and he influenced me in many other ways. For example, in his and Paperts 1968book Perceptronsnotorious for killing neural net research for a decade, because of its mis- or over-interpreted theorems about the representational limitations of single-layer neural netsthe way Minsky and Papert proved those theorems was by translating questions about computation into questions about the existence or nonexistence of low-degree polynomials with various properties, and then answering the latter questions using MATH. Their polynomial method is now a mainstay of quantum algorithmsresearch (having been brought to the subject by Beals et al.), and in particular, has been a mainstay of my own career. Hardly Minskys best-known contribution to human knowledge, but that even such a relatively minor partof his oeuvre could have legs half a century lateris a testament to his impact.
Im sure readers will have other thoughts to share about Minsky, so please do so in the comments section. Personal reminiscences are especially welcome.My Favorite Growth Rates

Update (8/17): Believe it or not, this blog actually led to something (scroll down to comment #52 if the link doesnt work).Heres some video of me spouting about Deep Questions

In January 2014, I attended anFQXi conference on Vieques island in Puerto Rico. While there, Robert Lawrence Kuhn interviewed me for his TV programCloser to Truth, which deals with science and religion and philosophy and you get the idea. Alas,myinterview was at the very end of the conference, and we lost track of the timeso unbeknownst to me, a plane full of theorists was literallysitting on the runway waiting for me to finish philosophizing! This was the second time Kuhn interviewed me for his show; the first time was on a cruise ship near Norway in 2011. (Thankless hero that I am, theres nowhere I wont travel for the sake of truth.)
Anyway, after a two-year wait, the videos from Puerto Rico arefinallyavailable online. While my vignettes cover what, for most readers of this blog, will be very basic stuff, Im sort ofhappy with how they turned out: I still stutter and rock back and forth, but not as much as usual. For your viewing convenience, here are the new videos:

The black hole information paradox, firewalls, and Harlow-Hayden argument (6 minutes)
Physics and free will (8 minutes 24 seconds)
Which entities are conscious? (6 minutes 3 seconds)
Quantum mechanics, the predictability of nature, the Bell inequality, and Einstein-certified randomness (5 minutes 12 seconds)
Whats the value of philosophy, and can it make progress? (3 minutes 42 seconds)
Newcombs Paradox (4 minutes 13 seconds)
Gdels Theorem and the definiteness of mathematical truth (8 minutes 20 seconds)

I had one other vignette, about why the universe exists, but they seem to have cut that one. Alas, if I knew why the universe existed in January 2014, I cant remember any more.
One embarrassing goof: I referred to the inventor of Newcombs Paradox as Simon Newcomb. Actually it was William Newcomb: a distant relative of Simon Newcomb, the 19th-century astronomer who measured the speed of light.
At their website, you can also see my older 2011 videos, and videos from others who might be known to readers of this blog, likeMarvin Minsky, Roger Penrose, Rebecca Newberger Goldstein, David Chalmers,Sean Carroll, Max Tegmark, David Deutsch, Raphael Bousso, Freeman Dyson,Nick Bostrom,Ray Kurzweil, Rodney Brooks, Stephen Wolfram, Greg Chaitin, Garrett Lisi, Seth Lloyd, Lenny Susskind, Lee Smolin, Steven Weinberg, Wojciech Zurek, Fotini Markopoulou, Juan Maldacena, Don Page, andDavid Albert. (No, I havent yet watched most of these, but now that I linked to them, maybe I will!)
Thanks very much to Robert Lawrence Kuhn and Closer to Truth (and my previous self, I guess?) for providing Shtetl-Optimized content so I dont have to.

Update: Andrew Critch of CFAR asked me to post the following announcement.
Were seeking a full time salesperson for the Center for Applied Rationality in Berkeley, California. Weve streamlined operations to handle large volume in workshop admissions, and now we need that volume to pour in. Your role would be to fill our workshops, events, and alumni community with people. Last year we had 167 total new alumni. This year we want 120 per month. Click here to find out more.Why does the universe exist?  finally answered (or dissolved) in this blog post!

In my previouspost, I linked to seven Closer to Truth videos of me spouting about free will, Gdels Theorem, black holes, etc. etc. I also mentioned that there was a segmentof me talking about why the universe exists that for some reason they didnt put up. Commenter mjgeddes wrote, Would have liked to hear your views on the existence of the universe question, so I answered in another comment.
But then I thought about it some more, and it seemed inappropriate to me that my considered statement about why the universe exists shouldonly be available as part ofa comment thread on my blog. At the very least, I thought, such a thingought tobe a top-level post.
So, without further ado:
My view isthat, if we want to make mental peace with the Why does the universe exist? question, the keything we need to do is forget about the universe for a while, and just focus on the meaning of the word why. I.e., when we ask a why-question, what kind of answer are we looking for, what kind of answer would make us happy?
Notice, in particular, that there are hundreds of other why-questions, not nearly as prestigious as the universe one, yet that seem just as vertiginously unanswerable. E.g., why is 5 a prime number? Why does cat have 3 letters?
Now, the best account of whyand of explanation and causalitythat I know about is the interventionist account, as developed for example in Judea Pearls work. In that account, to ask Why is X true? is simply to ask: What could we have changed in order to make X false? I.e., in the causal network of reality, what are the levers that turn X on or off?
This question can sometimes make sense even in pure math. For example: Why is this theorem true? Its true only because were working over the complex numbers. The analogous statement about real numbers is false. A perfectly good interventionist answer.
On the other hand, in the case of Why is 5 prime?, all the levers you could pull to make 5 composite involve significantly more advanced machinery than is needed to pose the question in the first place. E.g., 5 is prime because were working over the ring of integers. Over other rings, like Z[5], it admits nontrivial factorizations. Not really an explanation that would satisfy a four-year-old (or me, for that matter).
And then we come to the question of why anything exists. For an interventionist, this translates into: what causal lever could have been pulled in order to make nothing exist? Well, whatever lever it was, presumably the lever itself was somethingand so you see the problem right there.
Admittedly, suppose there were a giant red button, somewhere within the universe, that when pushed would cause the entire universe (including the button itself) to blink out of existence. In that case, we could say: the reason why the universe continues to exist is that no one has pushed the button yet. But even then, that still wouldnt explain why the universe had existed.Toads, lower bounds vie for control of Australia

What better way to procrastinate than to hear an Australian radio show interview me about the quantum query complexity of the collision problem, public-key cryptography, interactive proofs, computational intractability as a law of physics, and my great love for my high school?  The first part of the program is about Australias population of cane toads (or rather, tie-oads).  Then at 32:40, they start in with a report on the FQXi conference in Iceland, and interviews with Max Tegmark, Fred Adams, and Simon Saunders.  Im from 39:10 to 46:50.
A few comments/corrections:

The interviewer, Pauline Newman, asks me about the practical implications of the collision lower bound, and then cuts to me talking about how quantum computers could break the RSA cryptosystem.  Of course, the connection is only an indirect one (the collision lower bound is what gives hope that one could design collision-resistant hash functions that, unlike RSA, are secure even against quantum attacks).


I said that, when trying to solve jigsaw puzzles or schedule airline flights, there doesnt seem to be anything one can do thats fundamentally better than trying every possibility.  I should have added, in the worst case.


The reason I mentioned how old I was when IP=PSPACE was proved is not that Im a narcissist (though I am), but because in a section that was cut, Pauline asked me if I proved IP=PSPACE, and I was trying to make it clear that I didnt.  The theorem was proved by Shamir, building on work of Lund, Fortnow, Karloff, and Nisan.


Paulines assertion that I took off on a snowmobile without [my] passenger and left a distinguished physicist stranded on a glacier is a gross exaggeration.  What happened was, I waited and waited for someone  anyone  to climb onto my snowmobile.  When no one did (maybe because everyone was scared by my abysmal driving ability), I figured I should just go.

Anyway, at least the ums and uhs seem to have been under control, compared to my interview with Lance two years ago.The universe has a high (but not infinite) Sleep Number

As everyone knows, this was a momentousweek in the history of science. And I dont need to tell you why: the STOC and CCC accepted paper lists finally came out.
Haha, kidding! I meant,we learned this week that gravitational waves were directly detected for the first time, a hundred years after Einstein first predicted them (he then reneged on the prediction, then reinstated it, then reneged again, then reinstated it a second timesee Daniel Kenneficks articlefor some of the fascinating story).
By now, we all know some of the basic parameters here: a merger of two black holes, ~1.3 billion light-years away, weighing ~36 and ~29 solar masses respectively, which (when they merged) gave off 3 solar masses worth of energy in the form of gravitational wavesin those brief 0.2 seconds, radiating more watts of powerthan all the stars in the observable universe combined. By the time the waves reached earth, they were only stretching and compressing space by 1 part in 41021thus, changing the lengths of the 4-kilometer arms of LIGO by 10-18 meters (1/1000 the diameter of a proton). But this was detected, in possibly the highest-precision measurement ever made.
As I read the historic news, theres one question that kept gnawing at me: how close would you need to have been to the merging black holesbefore you could, you know, feel the distortion of space? I made a guess, assuming the strength of gravitational waves fell off with distance as1/r2. Then I checked Wikipedia and learned that the strength falls off only as 1/r, which completely changes the situation, and implies that the answer to my question is: youd needto be veryclose. Even if you were only as far from the black-hole cataclysm as the earth is from the sun, I get that youd bestretched and squished by a mere ~50 nanometers (this interview with Jennifer Ouellette and Amber Stuversays 165 nanometers, but as a theoretical computer scientist, I try not to sweat factors of 3). Even if you were 3000 miles from the black holesNew-York/LA distanceI get that the gravitational waves would only stretch and squish you by arounda millimeter. Would you feel that? Not sure. At 300 miles, it would be maybea centimeterthough presumablythe linearized approximation is breaking down bythat point. (See also this Physics StackExchange answer, which reaches similar conclusions, though again off from mine by factors of 3 or 4.) Now, the black holes themselves were orbiting about 200 miles from each other before they merged. So, the distance at which you could safelyfeel their gravitational waves, isnt too far from the distance at which theyd rip you to shreds and swallow you!
In summary, to stretch and squeeze spacetime by just a few hundred nanometers per meter, along the surface of a sphere whoseradius equals our orbit around the sun, requires more watts of power than all the stars in the observable universe give off as starlight. People often say that the message of general relativity is that matter bends spacetime as if it were a mattress. But they should add that the reason it took so long for humans to notice this, is that its a really friggin firmmattress, one that you need to bounce up and downon unbelievably hard before it quivers, and would probably never want to sleep on.
As if I needed to say it, this post is an invitation for experts to correct whatever I got wrong. Public humiliation, Ive found, is a very fast and effective way to learn an unfamiliar field.Does it come with a 14-Gyr warranty?

As many of you probably saw, John Tierney of the New York Times thinks theres a ~50% chance were living in a computer simulation, having been persuaded by Nick Bostroms infamous simulation argument.
(This argument, incidentally, is something that occurred to me as a teenager, and Im guessing to many others of nerdly leanings as well.  I didnt consider it a profound metaphysical discovery, just a sign I needed to get out more.)
Peter Woit feels strongly that debates about whether the universe is a computer are not science and therefore have no place in the Times science section.  Robin Hanson retorts that rather than complain that something is not science, or not philosophy, it is much better to just say more specifically what it is that you dont like about it.  Peter Shor points out that if were living in a simulation, then the incompatibility of quantum mechanics with general relativity might simply be a bug, in which case the universe will crash when the first black hole evaporates.
As for me, I tend to side with Woody Allen: yes, the universe might be a simulation, but where else can you get a decent steak?
The last word, however, goes to Bender Bending Rodriguez of Futurama.
Bender: If that stuff wasnt real, how can I be sure anything is real? Is it not possible, nay, probable that my whole life is just a product of my or someone elses imagination?
Clerk: No, get out. Next!
(Click here for the audio clip.)What Google Wont Find

While I rummage around the brain for something more controversial to blog (thats nevertheless not too controversial), here, for your reading pleasure, is a talk I gave a couple weeks ago at Google Cambridge.  Hardcore Shtetl-Optimized fans will find little here to surprise them, but for new or occasional readers, this is about the clearest statement Ive written of my religio-ethico-complexity-theoretic beliefs.
What Google Wont Find
As I probably mentioned when I spoke at your Mountain View location two years ago, its a funny feeling when an entity that knows everything that ever can be known or has been known or will be known invites you to give a talk  what are you supposed to say?
Well, I thought Id talk about What Google Wont Find.   In other words, what have we learned over the last 15 years or so about the ultimate physical limits of search  whether its search of a physical database like Googles, or of the more abstract space of solutions to a combinatorial problem?
On the spectrum of computer science, Im about as theoretical as you can get.  One way to put it is that I got through CS grad school at Berkeley without really learning any programming language other than QBASIC.  So it might surprise you that earlier this year, I was spending much of my time talking to business reporters.  Why?  Because there was this company near Vancouver called D-Wave Systems, which was announcing to the press that it had built the worlds first commercial quantum computer.
Lets ignore the commercial part, because I dont really understand economics  these days, you can apparently make billions of dollars giving away some service for free!  Lets instead focus on the question: did D-Wave actually build a quantum computer?  Well, they apparently built a device with 16 very noisy superconducting quantum bits (or qubits), which they say theyve used to help solve extremely small Sudoku puzzles.
The trouble is, weve known for years that if qubits are sufficiently noisy  if they leak a sufficient amount of information into their environment  then they behave essentially like classical bits.  Furthermore, D-Wave has refused to answer extremely basic technical questions about how high their noise rates are and so forth  they care about serving their customers, not answering nosy questions from academics.  (Recently D-Wave founder Geordie Rose offered to answer my questions if I was interested in buying one of his machines.  I replied that I was interested  my offer was $10 US  and I now await his answers as a prospective customer.)
To make a long story short, its consistent with the evidence that what D-Wave actually built would best be described as a 16-bit classical computer.  I dont mean 16 bits in terms of the architecture; I mean sixteen actual bits.  And theres some prior art for that.
But thats actually not what annoyed me the most about the D-Wave announcement.  What annoyed me were all the articles in the popular press  including places as reputable as The Economist  that said, what D-Wave has built is a machine that can try every possible solution in parallel and instantly pick the right one.  This is what a quantum computer is; this is how it works.
Its amazing to me how, as soon as the word quantum is mentioned, all the ordinary rules of journalism go out the window.  No one thinks to ask: is that really what a quantum computer could do?
It turns out that, even though we dont yet have scalable quantum computers, we do know something about what they could do if we did have them.
A quantum computer is a device that would exploit the laws of quantum mechanics to solve certain computational problems asymptotically faster than we know how to solve them with any computer today.  Quantum mechanics  which has been our basic framework for physics for the last 80 years  is a theory thats like probability theory, except that instead of real numbers called probabilities, you now have complex numbers called amplitudes.  And the interesting thing about these complex numbers is that they can interfere with each other: they can cancel each other out.
In particular, to find the probability of something happening, you have to add the amplitudes for all the possible ways it could have happened, and then take the square of the absolute value of the result.  And if some of the ways an event could happen have positive amplitude and others have negative amplitude, then the amplitudes can cancel out, so that the event doesnt happen at all.  This is exactly whats going on in the famous double-slit experiment: at certain spots on a screen, the different paths a photon couldve taken to get to that spot interfere destructively and cancel each other out, and as a result no photon is seen.
Now, the idea of quantum computing is to set up a massive double-slit experiment with exponentially many paths  and to try to arrange things so that the paths leading to wrong answers interfere destructively and cancel each other out, while the paths leading to right answers interfere constructively and are therefore observed with high probability.
You can see its a subtle effect that were aiming for.  And indeed, its only for a few specific problems that people have figured out how to choreograph an interference pattern to solve the problem efficiently  that is, in polynomial time.
One of these problems happens to be that of factoring integers.  Thirteen years ago, Peter Shor discovered that a quantum computer could efficient apply Fourier transforms over exponentially-large abelian groups, and thereby find the periods of exponentially-long periodic sequences, and thereby factor integers, and thereby break the RSA cryptosystem, and thereby snarf peoples credit card numbers.  So thats one application of quantum computers.
On the other hand  and this is the most common misconception about quantum computing Ive encountered  we do not, repeat do not, know a quantum algorithm to solve NP-complete problems in polynomial time.  For generic problems of finding a needle in a haystack, most of us believe that quantum computers will give at most a polynomial advantage over classical ones.
At this point I should step back.  How many of you have heard of the following question: Does P=NP?
Yeah, this is a problem so profound that its appeared on at least two TV shows (The Simpsons and NUMB3RS).  Its also one of the seven (now six) problems for which the Clay Math Institute is offerring a million-dollar prize for a solution.
Apparently the mathematicians had to debate whether P vs. NP was deep enough to include in their list.  Personally, I take it as obvious that its the deepest of them all. And the reason is this: if you had a fast algorithm for solving NP-complete problems, then not only could you solve P vs. NP, you could presumably also solve the other six problems.  Youd simply program your computer to search through all possible proofs of at most (say) a billion symbols, in some formal system like Zermelo-Fraenkel set theory.  If such a proof existed, youd find it in a reasonable amount of time.  (And if the proof had more than a billion symbols, its not clear youd even want to see it!)
This raises an important point: many people  even computer scientists  dont appreciate just how profound the consequences would be if P=NP.  They think its about scheduling airline flights better, or packing more boxes in your truck. Of course, it is about those things  but the point is that you can have a set of boxes such that if you could pack them into your truck, then you would also have proved the Riemann Hypothesis!
Of course, while the proof eludes us, we believe that PNP.  We believe theres no algorithm to solve NP-complete problems in deterministic polynomial time.  But personally, I would actually make a stronger conjecture:
There is no physical means to solve NP-complete problems in polynomial time  not with classical computers, not with quantum computers, not with anything else.
You could call this the No SuperSearch Principle.  It says that, if youre going to find a needle in a haystack, then youve got to expend at least some computational effort sifting through the hay.
I see this principle as analogous to the Second Law of Thermodynamics or the impossibility of superluminal signalling.  That is, its a technological limitation which is also a pretty fundamental fact about the laws of physics.   Like those other principles, it could always be falsified by experiment, but after a while it seems manifestly more useful to assume its true and then see what the consequences are for other things.
OK, so what do we actually know about the ability of quantum computers to solve NP-complete problems efficiently?  Well, of course we cant prove its impossible, since we cant even prove its impossible for classical computers  thats the P vs. NP problem!  We might hope to at least prove that quantum computers cant solve NP-complete problems in polynomial time unless classical computers can also  but even that, alas, seems far beyond our ability to prove.
What we can prove is this: suppose you throw away the structure of an NP-complete problem, and just consider it as an abstract, featureless space of 2n possible solutions, where the only thing you can do is guess a solution and check whether its right or not.  In that case its obvious that a classical computer will need ~2n steps to find a solution.  But what if you used a quantum computer, which could guess all possible solutions in superposition?  Well, even then, youd still need at least ~2n/2 steps to find a solution.  This is called the BBBV Theorem, and was one of the first things learned about the power of quantum computers.
Intuitively, even though a quantum computer in some sense involves exponentially many paths or parallel universes, the single universe that happened on the answer cant shout above all the other universes: hey, over here!  It can only gradually make the others aware of its presence.
As it turns out, the 2n/2 bound is actually achievable.  For in 1996, Lov Grover showed that a quantum computer can search a list of N items using only N steps.  It seems to me that this result should clearly feature in Googles business plan.
Of course in real life, NP-complete problems do have structure, and algorithms like local search and backtrack search exploit that structure.  Because of this, the BBBV theorem cant rule out a fast quantum algorithm for NP-complete problems.  It merely shows that, if such an algorithm existed, then it couldnt work the way 99% of everyone whos ever heard of quantum computing thinks it would!
You might wonder whether theres any proposal for a quantum algorithm that would exploit the structure of NP-complete problems.  As it turns out, theres one such proposal: the quantum adiabatic algorithm of Farhi et al., which can be seen as the quantum version of simulated annealing.  Intriguingly, Farhi and his collaborators proved that, on some problem instances where classical simulated annealing would take exponential time, the quantum adiabatic algorithm takes only polynomial time.  Alas, we also know of problem instances where the adiabatic algorithm takes exponential time just as simulated annealing does.  So while this is still an active research area, right now the adiabatic algorithm does not look like a magic bullet for solving NP-complete problems.
If quantum computers cant solve NP-complete problems in polynomial time, it raises an extremely interesting question: is there any physical means to solve NP-complete problems in polynomial time?
Well, there have been lots of proposals.  One of my favorites involves taking two glass plates with pegs between them, and dipping the resulting contraption into a tub of soapy water.  The idea is that the soap bubbles that form between the pegs should trace out the minimum Steiner tree  that is, the minimum total length of line segments connecting the pegs, where the segments can meet at points other than the pegs themselves.  Now, this is known to be an NP-hard optimization problem.  So, it looks like Nature is solving NP-hard problems in polynomial time!
You might say theres an obvious difficulty: the soap bubbles could get trapped in a local optimum thats different from the global optimum.  By analogy, a rock in a mountain crevice could reach a lower state of potential energy by rolling up first and then down  but is rarely observed to do so!
And if you said that, youd be absolutely right.  But that didnt stop two guys a few years ago from writing a paper in which they claimed, not only that soap bubbles solve NP-complete problems in polynomial time, but that that fact proves P=NP!  In debates about this paper on newsgroups, several posters raised the duh-obvious point that soap bubbles can get trapped at local optima.  But then another poster opined that thats just an academic party line, and that hed be willing to bet that no one had actually done an experiment to prove it.
Long story short, I went to the hardware store, bought some glass plates, liquid soap, etc., and found that, while Nature does often find a minimum Steiner tree with 4 or 5 pegs, it tends to get stuck at local optima with larger numbers of pegs.  Indeed, often the soap bubbles settle down to a configuration which is not even a tree (i.e. contains cycles of soap), and thus provably cant be optimal.
The situation is similar for protein folding.  Again, people have said that Nature seems to be solving  an NP-hard optimization problem in every cell of your body, by letting the proteins fold into their minimum-energy configurations.  But there are two problems with this claim.  The first problem is that proteins, just like soap bubbles, sometimes get stuck in suboptimal configurations  indeed, its believed thats exactly what happens with Mad Cow Disease.  The second problem is that, to the extent that proteins do usually fold into their optimal configurations, theres an obvious reason why they would: natural selection!  If there were a protein that could only be folded by proving the Riemann Hypothesis, the gene that coded for it would quickly get weeded out of the gene pool.
So: quantum computers, soap bubbles, proteins  if we want to solve NP-complete problems in polynomial time in the physical world, whats left?  Well, we can try going to more exotic physics.  For example, since we dont yet have a quantum theory of gravity, people have felt free to speculate that if we did have one, it would give us an efficient way to solve NP-complete problems.  For example, maybe the theory would allow closed timelike curves, which would let us solve NP-complete and even harder problems by (in some sense) sending the answer back in time to before we started.
In my view, though, its more likely that a quantum theory of gravity will do the exact opposite: that is, it will limit our computational powers, relative to what they wouldve been in a universe without gravity.  To see why, consider one of the oldest extravagant computing proposals: the Zeno computer.  This is a computer that runs the first step of a program in one second, the second step in half a second, the third step in a quarter second, the fourth step in an eighth second, and so on, so that after two seconds its run infinitely many steps.  (It reminds me of the old joke about the supercomputer that was so fast, it could do an infinite loop in 2.5 seconds.)
Question from the floor: In what sense is this even a proposal?
Answer: Well, its a proposal in the sense that people actually write papers about it!  (Google hypercomputation.)  Whether they should be writing those papers a separate question
Now, the Zeno computer strikes most computer scientists  me included  as a joke.  But why is it a joke?  Can we say anything better than that it feels absurd to us?
As it turns out, this question takes us straight into some of the frontier issues in theoretical physics.  In particular, one of the few things physicists think they know about quantum gravity  one of the few things both the string theorists and their critics largely agree on  is that, at the so-called Planck scale of about 10-33 centimeters or 10-43 seconds, our usual notions of space and time are going to break down.  As one manifestation of this, if you tried to build a clock that ticked more than about 1043 times per second, that clock would use so much energy that it would collapse to a black hole.  Ditto for a computer that performed more than about 1043 operations per second, or for a hard disk that stored more than about 1069 bits per square meter of surface area.  (Together with the finiteness of the speed of light and the exponential expansion of the universe, this implies that, contrary to what you might have thought, there is a fundamental physical limit on how much disk space Gmail will ever be able to offer its subscribers)
To summarize: while I believe what I called the No SuperSearch Principle  that is, while I believe there are fundamental physical limits to efficient computer search  I hope Ive convinced you that understanding why these limits exist takes us straight into some of the deepest issues in math and physics.  To me thats so much the better  since it suggests that not only are the limits correct, but (more importantly) theyre also nontrivial.
Thank you.Quantum.  Crypto.  Things happen.  I blog.

1. A bunchof peopleemailedmeto ask about the paper Realization of a scalable Shor algorithm: a joint effort by the groups of my MIT colleagueIke Chuang and of Innsbrucks Rainer Blatt. The paper has been on the arXiv since July, but last weekeveryone suddenly noticed it becauseitappearedin Science. See also thearticles inMIT Newsand IEEE Spectrum.
Briefly, the newworkuses Kitaevs version of Shors factoring algorithm, running on an ion-trap quantum computer with five calcium ions, to provethat,with at least 90% confidence, 15 equals 35. Now, one might object that the 15=35 theorem has by now been demonstrated many timesusing quantum computing(indeed, Chuang himself was involved in the historic first such demonstration, with Neil Gershenfeld in 1997). Furthermore, if one counts demonstrations notbased on quantum computing, some people have claimed even earlier precedents for that theorem.
Nevertheless, as far as I can tell, the new work is a genuinemilestone in experimental QC, because it dispenses with most of the precompilation tricks that previous demonstrations of Shors algorithm used. Precompilation tricks are a fanciertermfor cheating: i.e., optimizing a quantum circuit in ways that would only make sense if you already assumedthat 15 was, indeed, 35. So, whats new is that a QC has now factored 15 scalably: that is, with muchless cheating than before.
Of course, as Im sure the authors would acknowledge, the word scalable in their titleadmits multiple interpretations, rather like the word possible. (Its possible to buy strawberry Mentos, and its also possible to convert the Sun into computronium, but for different senses of possible.) As I wrote in the comments section of my last post:
There are still all the difficulties of integrating a huge number of qubitswhich, in ion-trap implementations, would almost certainly mean having many traps that can communicate with each other using gate teleportationas well as implementing quantum fault-tolerance (meaning: doing 2-qubit gates at the fault-tolerance threshold, moving qubits around to the right places, pumping in fresh qubits, pumping out dirty ones, etc). Those all remain major engineering problems for the future.
See also this comment by Vaughan Pratt, who remarks: the MIT press release would appear to have translated [scalable]to mean that RSA was now approaching its best-by date, although the paper itself makes no such claim.
In any case, regardless of how long it takes until we can factor enormous numbers like 91, congratulations to the MIT and Innsbruck groups on whats certainlyprogresstoward scalable ion-trap QC!
2. Other people wrote to ask about a strikingrecent preprintof Kaplan, Leurent, Leverrier, and Naya-Plasencia, whichpoints out how Simons algorithmi.e., the forerunner of Shors algorithmcanbe used to break all sorts of practical private-key authentication schemes in quantum polynomial time, assumingthe adversarycanquery the scheme being attacked on a coherent superposition of inputs. In practice, this assumption is unlikely to hold, unlessthe adversary gets the actual obfuscated code of the scheme being attacked (in which case itholds). Also, this is not the first time Simons algorithm has beenused to attack cryptography; previous work in the same spirit by Kuwakado and Morii showed how to use Simons algorithm to break the 3-round Feistel scheme and the Even-Mansour scheme, again if we assumesuperposition queries.
Even so, Kaplan et al.seem to pretty dramatically expand the range of practical cryptosystemsthat are known to be vulnerable to Simon attacks in the superposed-query model. I suspect this will force a revision in how we talk about Simons algorithm: from useless, but theoretically important, and historically important because it led to Shors algorithm to actually maybe notthat useless. (See here for a previous attempt of mine to give an interesting explicit problem that Simons algorithm solves in polynomial time, but thats classically hard. Alas, my candidate problem turned out to be classically easy.) This is analogous to the revision that Einstein-certified randomness and the RUV theoremrecently forced in how we talk about Bells inequality: we can no longer tell studentsthat Bells workwas important because of the conceptual point it proved about local hidden variables, and because of all the other stuffit led to, even though it obviously has no applications in and of itself. Now it does have applications in and of itself.
To a quantum complexity theorist like me, who doesnt know nearly as much appliedcrypto as he should, the realnews in the Kaplan et al. paperis not that Simons algorithm can break the sorts of systems they study. Rather, its that so manysystems that are vulnerable to Simon attackexist and are usedin the first place! Once people understandthe problem, I doubt it willbehard to design schemes of similar efficiencythat remainquantum-secure even in the superposed-query model (under some plausible assumption, like that an underlying one-way function is quantum-secure). Indeed, recent work of Boneh and Zhandry, among others, has already taken significant steps in that direction. So the situation doesnt seem asbad as it was with public-key crypto, where once Shors algorithm comes along, the plausibly quantum-secure alternatives that we currently know (like lattice-based crypto and quantum key distribution) are either much less efficient than RSA and Diffie-Hellman, or else require new hardware. Still, the new observationsabout Simons algorithm show us how the history of quantum computingcould haveunfolded differently: rather than Simon Shor everyone gets excited (because their crypto is now vulnerable), people couldve gotten cryptographically excited immediately after Simon.
3. Speaking of Diffie-Hellman, belated congratulations to Whitfield Diffie and Martin Hellman for an extremely well-deserved Turing Award!
4. At MITs weekly quantum information group meeting, Aram Harrow spoke about his new paper with Ed Farhi, Quantum Supremacy through the Quantum Approximate Optimization Algorithm. Using the samearguments developed around 2010 by meand Alex Arkhipov, and (independently) by Bremner, Jozsa, and Shepherd, this paper shows that, even though the recently-developed QAOA/Quinoa quantum optimization algorithm turns out not to beat the best classical algorithms on the Max E3LIN2 problem (see here and here)still, whatever that algorithm does do, at least theres no polynomial-time classical algorithm that samples from the same distribution over outputs, unless the polynomial hierarchy collapses.
In other words: even if the algorithm fails at its originalgoal, its still hard for a classical computer to reproduce its exact pattern of failure! Hence: Quantum Supremacy.
A secondary goal of Aram and Eddies paper is to makethe Aaronson-Arkhipov and Bremner et al. arguments more accessibleto physicists, by decreasing the amountof weird complexity theory invoked. (I suppose Ive asked for thisfor physicists to de-complexify complexity theoryby telling everyone for years how easy quantum mechanics becomes once you take away the physics!) Ill leave it to physicists to judge how well Aram and Eddie succeed at their pedagogical goal, but Im thrilledby any such effort to communicate across fields. Arams talk would surelyhave served that same educational purpose,had it not gottenderailed partway throughby Donald Trump jokes from the audience. (My contribution: Aram, will you disavow support from quantum supremacists?)

Unrelated Update: Some people might be interested in this brief interview with Michael Cerullo, who read The Ghost in the Quantum Turing Machine and wanted to ask me about the relevance of quantum mechanics to brain preservation, uploading, and identity.Whats going down in AarTown

Taking a cue from the Pontiff, I thought Id provide three quick updates on my personal life (no, not my personal personal life; thats none of your business).

Last week I bought and moved into a condo in East Cambridge, a 10-minute walk from campus, with lovely views of Boston, the Charles River, and the Red Line T going over the bridge: 
 
(Thats mom on the sofa.)  I cant stress enough how fundamentally my life has changed now that Im a homeowner.   For example, instead of paying rent each month, I now pay something called a mortgage, and instead of going to a landlord, it goes to a bank.  Also I get a massive tax break for some reason.
The students showed up this week, and the semester is here.  No, Im not teaching this fall, but theres still plenty to do, from organizing a theory lunch to deciding what kind of whiteboard should go in my office.  (With a border or without?  How big a tray for pens?  These are serious decisions.) On Wednesday I went to an orientation for new MIT faculty, at which I got to tell President Susan Hockfield about quantum lower bounds, the prospects for practical quantum computers, and how her fine institution rejected me twice.  Along with the usual pleasantries, Hockfield said one thing that deeply impressed me: I know its gone out of fashion in many places, but youre still allowed to use the word truth here.
Besides moving, besides getting oriented, Ive also been distracted from my blogging career by involvement with some  whats it called?  actual research. Sorry about that; I assure you its just a temporary aberration.A postdoc post

I apologize that this announcement is late in this years hiring season, but here goes. Imseekingpostdocs in computational complexity and/orquantum information science to join me at UT Austin starting in Fall of 2016. As I mentioned before, theres a wonderful CS theory group at UT that you can work with and benefit from, including Adam Klivans, David Zuckerman, Anna Gal, Vijaya Ramachandran, Brent Waters, Eric Price, Greg Plaxton, and of course my wife Dana Moshkovitz, who will be joining UT as well. If youre interested, please email me a CV and a short cover letter, and ask your PhD adviser and one or two others to email me recommendation letters. The postdoc would be for two years by default.

Update (March 26): If you want to be considered for next year, please get your application to me by March 31st.
Another Update: Im very honored, along with fourteen others, to have received a 2016 US National Security Science and Engineering Faculty Fellowship (NSSEFF), which supports unclassified basic research related in some way to DoD interests.  My project is called Paths to Quantum Supremacy.  Now that my Waterman award has basically been spent down, this is where much of the funding for quantum computing initiatives at UT Austin will come from for the next five years.My take on the Koblitz affair

Now that Luca, Michael Mitzenmacher, Jonathan Katz, and Oded Goldreich have all weighed in on Neal Koblitzs critique of modern cryptography in the Notices of the AMS, I can no longer bear to be left out of the action.
My reaction is simple: we computer scientists should feel honored that the mathematicians have finally bestowed on us the level of contempt they once reserved for the physicists.
Update (9/6): If you want to understand whats actually involved in this controversy, the best starting point Ive found is this paper by Ivan Damgrd.Black-hole complexity theory: from joke to science

One of the most fun arXiv preprints Ive read in a while:
Black holes as mirrors: quantum information in random subsystems
by Patrick Hayden and John Preskill
Abstract: We study information retrieval from evaporating black holes, assuming that the internal dynamics of a black hole is unitary and rapidly mixing, and assuming that the retriever has unlimited control over the emitted Hawking radiation. If the evaporation of the black hole has already proceeded past the half-way point, where half of the initial entropy has been radiated away, then additional quantum information deposited in the black hole is revealed in the Hawking radiation very rapidly. Information deposited prior to the half-way point remains concealed until the half-way point, and then emerges quickly. These conclusions hold because typical local quantum circuits are efficient encoders for quantum error-correcting codes that nearly achieve the capacity of the quantum erasure channel. Our estimate of a black holes information retention time, based on speculative dynamical assumptions, is just barely compatible with the black hole complementarity hypothesis.
Many of this papers arguments depend on speculative assumptions about quantum gravity, and might very well be wrong.  Whats nice is simply that theyre not not even wrong!    This is an 18-page paper about the Planck-scale dynamics of black hole horizons where I never once found myself wondering what the authors were trying to say, or how their ideas would in principle be tested.
When I used to spout off about the complexity of retrieving information from a black hole as a function of the Schwarzschild radius rS, people assumed I was just fishing for laughs.  And they were basically right.    But even then, I felt sure that actual physicists would eventually say something real about this question, unapologetically using the language of quantum computing and information.  Like Alice with her k qubits, I didnt have to wait as long as Id thought.Buck, buck, buck

Like a masked chicken of the darkness, the anonymous commenter deposits his ad hominem attack and then flees the scene, as though repelled by the malodorous stench of his own words.  Alright, Im not Stephen King.  But the point is that, if you leave an anonymous comment that doesnt contribute anything, from now on Im going to feel free to delete it.  I will never delete signed comments, unless theyre completely off-topic, or reveal the coordinates of nuclear missiles being transported across South Dakota, or something like that.  Oh yeah: and tomorrow night, if youre going to egg any houses or toilet-paper any trees, sign your work.Sellin out to the Man

Alright, its time to tell you: in a couple of days, Shtetl-Optimized will cease its two-year independent existence, and become a part of MIT Technology Review.  Please check out the new shtetl at technologyreview.com and let me know in the comments section, here or there, if anything is amiss.  (Note: You have to register at technologyreview.com before you can post a comment there, but that should be pretty quick and painless.)  If everythings OK, then well start redirecting the scottaaronson.com URLs to point to the new location.
Naturally, selling out to an MIT subsidiary is not a step I took lightly.  The following considerations are what finally induced me to say yes:

Id already sold my soul to MIT, so why not my blog too?


As explained earlier, Bluehost (my current hosting provider) sucks: the sites they host routinely stop working, and when they do its always your fault and never theirs.  Indeed, every webhosting company Ive dealt with strikes me as basically a scam operation that does a tiny bit of hosting on the side.  So when TR told me that they would be that at which the buck stops  and that if anything went wrong I could walk the two blocks to their East Cambridge office and yell at them in person  their pitch fell on receptive ears.


From now on, TRs expert staff will manage all technical aspects of the blog for me, leaving me free to concentrate on deeper, biting-vagina-related matters.  This will be particularly welcome as the demands on my time shift from the severe to ludicrous range.


The Benjamins.  As explained earlier, as a matter of principle I accept bribes and kickbacks from absolutely anyone, trusting that the money from competing groups will cancel each other out, thereby leaving my overall judgment unbiased.  Plus I can actually use the dough, now that I have a mortgage to pay.


Ill now be under contractual obligation to blog at least twice a week on average.  I actually welcome this change, since its the only remedy I can think of for the blog-procrastination (i.e., work) thats often afflicted me in the past.


If this experiment doesnt work, Im allowed to back out on two weeks notice, retaining all the rights to my blog.  Of course, I hope and expect that itll work.


Most importantly, Jason Pontin, the editor-in-chief and publisher of Technology Review, has personally assured me that I will have complete intellectual freedom to blog about anything I want, exactly as I did when the blog was independent.  You can rest assured that Jason will come to regret his guarantee in the days and weeks ahead.  (TR does have a policy of fact-checking blog entries, but as I explained to them, the very concept of fact-checking is not particularly relevant to Shtetl-Optimized.)

Indeed, the only real disadvantage I could see to hosting the blog on TR was the amount of screen space taken up by ads.  Sorry about that!  Fortunately, the ads look pretty ignorable to me.Barriers to proving P!=NP and moving this blog

Thanks, everyone, for your patience, and your numerous complaints about the Technology Review site!  Currently, the folks at TR say they can do all the minor things people asked for, like adding permalinks to the titles and letting people include their URLs with their comments.  On the other hand, they cant make it so you can post comments without logging in, and they cant decrease the size of the ad bar.  (I suggested that they at least turn my sidebar into drop-down menus, thereby increasing the screen width available for the entries; they said theyd look into that.) Also, they cant provide the full text in RSS (since God forbid, that might let people read the blog without seeing ads), although they can give the first 150 words or so.
As you can imagine, TRs response has put me in a difficult position.  From their perspective, theyve been bending over backwards to accommodate me; from my perspective (and I gather from most readers), their offer still falls short of acceptable.  When I originally agreed to let them host me, I imagined that the blog would look just as it does now, with maybe a few unobtrusive ads here or there.  I didnt even think to ask about the RSS feed or the screen width available for entries.
And so, after weeks of introspection (well, mostly being tied up with other work), Ive reached a decision: I will continue to host my blog right here, on Bluehost, until TR comes up with something that both parties can live with.   I like the TR people and appreciate their interest, but Im not in any particular hurry to move, especially if it means crippling this blog so that no will read it.   Its true that Bluehost sucks, and that I no longer have time to be a webmaster  but once I get grant money, maybe I can pay someone to take care of these things for me.
Finally, since all this self-referentiality gets tiresome, here are the PowerPoint slides for a talk I gave at MIT last week, about recent joint work with Avi Wigderson on a new barrier to proving PNP.  (Note: The day before the talk, PowerPoint trashed my file, and I had to recreate the entire presentation from memory.  Always make backup copies!  Excellent advice, in my opinion.)
Abstract:
Algebrization: A New Barrier in Complexity Theory
Any proof of PNP will have to overcome two barriers: relativization and natural proofs. Yet over the last decade, we have seen circuit lower bounds (for example, that PP does not have linear-size circuits) that overcome both barriers simultaneously. So the question arises of whether there is a third barrier to progress on the central questions in complexity theory.
In this talk we present such a barrier, which we call algebraic relativization or algebrization. The idea is that, when we relativize some complexity class inclusion, we should give the simulating machine access not only to an oracle A, but also to the low-degree extension of A over a finite field or ring.
We systematically go through basic results and open problems in complexity theory to delineate the power of the new algebrization barrier. We first show that all known non-relativizing results  both inclusions such as IP=PSPACE and MIP=NEXP, and separations such as MAEXPP/poly  do indeed algebrize. We next show that most open problems  including P versus NP, P versus BPP, and NEXP versus P/poly  will require non-algebrizing techniques, of which we currently have not a single example. In some cases algebrization seems to explain exactly why progress stopped where it did: for example, why we have superlinear circuit lower bounds for PromiseMA but not for NP.
We also exhibit a surprising connection between algebrization and communication complexity. Using this connection, we give an MA-protocol for the Inner Product function with O(n log(n)) communication (essentially matching a lower bound of Klauck), and describe a pure communication complexity conjecture whose truth would imply PNP.
Comments welcome.  Well hopefully have a writeup soon.On drugs, mammoths, and Mahmoud

I was, of course, delighted that Columbia University invited my good friend Mahmoud to speak there, and dismayed only by the tedious introduction by President Lee Bollinger.   (Having demonstrated conclusively that todays featured speaker is a murderous tyrant with no more right to partake in the civilized world than Genghis Khan or Attila the Hun, let me now, without further ado)  However long your speakers list of achievements, crimes against humanity, etc. might be, I think talk introductions should be two minutes tops.
But since this particular event has already been covered on more blogs than the Monster has subgroups, today I thought Id roll out an occasional new Shtetl-Optimized feature  in which, for want of anything better to blog about, I discuss some books Ive read recently.
The Truth About The Drug Companies: How They Deceive Us and What To Do About It by Marcia Angell.
Like many in the US, I once knew that drug companies have to charge such absurd prices here because otherwise they wouldnt be able to fund their R&D.   This book reveals the hilarious truth about what drug company R&D actually consists of.   My favorite examples: coloring Prozac pink instead of green, marketing it for premenstrual dysphoric disorder instead of depression, and charging three times as much for it. Inventing new drugs for high blood pressure that are less effective than diuretics available since the 1950s, but have the advantage of being patentable. Proving in clinical trials that a new drug works better than an old one, as long as you compare 40mg of the one to 20mg of the other.
The book paints a picture of the pharmaceutical industry as, basically, an organized crime syndicate thats been successful in co-opting the government.  It trumpets the free market but depends almost entirely for its existence on bad patent laws that it helped write; it bribes doctors to prescribe worse expensive drugs instead of better cheap ones; it waits for government-funded university researchers to discover new drugs, then bottles them up, makes billions of dollars, and demands credit for its life-saving innovations.
Among the arguments put forward by the rare negative reviewers of this book on Amazon, the following was my favorite (Ill let you supply a counterargument):

Who do you folks think are paid higher, scientists in the Unis and government programs, or scientists in the industry?  Marcia saying the Universities and the NIH are more innovative in developing drugs than the Pharma Industry is like saying (using sports analogy) Minor League baseball is better than the MLB. Which players do you think are paid more? Common sense my friends.

The World Without Us by Alan Weisman.
This book has received a lot of attention lately, and deserves all of it.  The topic is: if humans disappeared tomorrow, how long would it take for the worlds forests and coral reefs to regenerate, garbage to decompose, excess CO2 to wash out of the sky, giant land mammals to reappear in North America, etc.?  Of course this is just a different way of asking: exactly how badly have humans screwed up the planet?  Weismans key insight, though, is that its less depressing to read about the world regenerating itself than about its being destroyed.
Its hard to identify a clear thesis in this book, just lots of interesting observations: for example, that African elephants werent hunted to extinction whereas woolly mammoths probably were because only the former evolved to fear humans; and that, if North and South Korea ever reunite, it will be a disaster for the dozens of endangered species that now survive only in a four-mile-wide demilitarized strip between the two.  The prose is beautiful throughout, and sometimes reaches heights rarely seen in environmental writing.  After explaining the role of volcanoes in climate change, Weisman says: the problem is, by tapping the Carboniferous Formation and spewing it up into the sky, weve become a volcano that hasnt stopped erupting since the 1700s.On Deutsches, Shors, and Vaziranis

My friend Robin Hanson kvetches that scientific contrarians dont get no respect: even if they ultimately turn out to be right, its the more cautious, Johnny-come-lately conservative radicals who get the lions share of the credit.    (Like many of Robins posts, this one is written in a purely descriptive mode that nevertheless leaves no doubt where his sympathies lie.)  And so, as a firmly-entrenched pillar of the hidebound scientific establishment, I thought Id tell you our side of the story.
In the US, there are companies whose business it is to patent (or buy patents for) every obvious idea they can think of, then sit around and do nothing with those ideas, wait for some other company to build a successful business around one of them, and sue that company for patent infringement.  (The textbook example is NTPs lawsuit against Research In Motion.)
In science, one occasionally sees the intellectual equivalent of these patent-holding companies: people who publish one flaky idea after another with no data or calculations to back them up; and then if, after years of painstaking research, one of their speculations turns out to be right (or even 10% right), scream they stole my idea!
But in my experience  and happily for all concerned  the truth usually lies between this extreme and the opposite extreme described in Robins post.    To illustrate, lets consider the example of Robins that I know best: that of David Deutsch and quantum computing.
Unlike the patent-holding firms, David Deutsch really was a scientific pioneer, thinking deeply about quantum physics and the Church-Turing Thesis back when basically no one else was.    His philosophical insights led him to define the quantum Turing machine model, prove its universality, and realize it might have implications for complexity theory.  But his one concrete example of a quantum algorithm  how shall I say?  sucked.  In particular, he gave an algorithm to compute the XOR of two bits (and know one has done so) using one quantum query and with success probability 1/2.  (Later it was realized that success probability 1 is achievable, but thats still only a factor-2 speedup compared to classical computers.)  If this was all youd seen of quantum computing, you would rightly file it away with dozens of other promising ideas that hadnt led anywhere.
Unless, that is, you were Ethan Bernstein and Umesh Vazirani.  These conservative radicals from Berkeley decided to put quantum computing under the microscope of theoretical computer science.   The result of their labor  besides a bounteous harvest of complexity theorems like BPP  BQP  P#P  was the first example of a black-box problem for which quantum computers gave a superpolynomial speedup over classical randomized ones.  Shortly afterward, another conservative, Dan Simon, set out to prove that the speedup of quantum computing was illusory  and ended up with strong evidence (now called Simons algorithm) for exactly the opposite conclusion.  A year later, yet another conservative   an expert on combinatorics and discrete geometry by the name of Peter Shor  took a close look at Simons algorithm, and realized that if you changed the underlying group from (Z2)n to the cyclic group ZN, then you could efficiently compute the period of a black-box function, and thereby factor integers, and thereby break the RSA cryptosystem, and thereby change the world.
A Hansonian might downplay these later achievements  arguing that, were it not for Shor, some other mainstream mathematician (a strange description of him!) wouldve sooner or later discovered the factoring algorithm.   But its equally true that, were it not for Deutsch, some other renegade physicist would have come up with quantum Turing machines (and indeed Feynman and Benioff were close).  My own judgment is that Deutsch and Shor both made creative scientific contributions of the highest order, and are both deservedly celebrated for them.  Indeed, if anyone gets short-shrifted in the usual popular accounts, I think its the people in between  like Bernstein, Vazirani, and Simon.
So yes, lets remember the first person who struck gold, but also the first to realize it wasnt fools gold and the first to figure out how to mine it.  Science is a big place; theres plenty of room for Deutsches, Shors, and even a Vazirani or two.Australian actresses are plagiarizing my quantum mechanics lecture to sell printers

I tried to think of a witty, ironic title for this post, but in the end, I simply couldnt.  The above title is a literal statement of fact.
A reader named Warren Smith informs me of an Australian TV commercial (which you can watch on YouTube), in which two fashion models have the following conversation:
Model 1: But if quantum mechanics isnt physics in the usual sense  if its not about matter, or energy, or waves  then what is it about?
Model 2: Well, from my perspective, its about information, probabilities, and observables, and how they relate to each other.
Model 1: Thats interesting!
The commercial then flashes the tagline A more intelligent model, followed by a picture of a Ricoh printer.
More intelligent, or simply more shameless?   Ladies and gentlemen of the jury, allow me to quote from Lecture 9 of my Quantum Computing Since Democritus notes:
But if quantum mechanics isnt physics in the usual sense  if its not about matter, or energy, or waves, or particles  then what is it about?  From my perspective, its about information and probabilities and observables, and how they relate to each other.
For almost the first time in my life, Im at a loss for words.  I dont know how to respond.  I dont know which of 500,000 possible jokes to make.   Help me, readers.  Should I be flattered?  Should I be calling a lawyer?
Update (10/3): [Sydney Morning Herald] [The Age] [Slashdot] [BoingBoing] [AdNews] [Scientific American blog] (Let me know if you find others) (Im actually in Riga, Latvia, where its 8:30am, and just woke up to find all this.  Im going to take a shower now.)
Also: Please let me know if you get any more CPU quota exceeded errors.  I just enabled an option to speed up PHP scripts, which might or might not solve the problem.  Bluehost sucks  never use them for anything!
Update (10/4): Thanks, everyone, for the free legal advice! From half of you Ive learned that Id be an arrogant, stereotypically-American jerk to pursue this case further; from the other half Ive learned that Id be a nave idiot not to. The longer I blog, the more I despair of ever achieving my central goal in life, namely for everyone to like me.
Also: Many commenters seem to assume the pilfered quote is just my expression of the conventional wisdom.   Well, it should be, and I wish it were!  But as Avi Wigderson pointed out to me, the idea that quantum mechanics is about information rather than waves or particles is still extremely non-standard, and would have been considered insane fifteen years ago.
Update (10/5): This is not to say its my idea (as other commenters assumed I was saying)!  If any entity can claim ownership of the idea, I would think its the entire quantum computing and information community.  The longer I blog, the more I despair of ever achieving my secondary goal in life, namely for everyone to understand me.Procrastinating on the sidelines of history

I wasnt born to be a blogger.   I cant respond to events in real-time.    When history happens, I might or might not be there to react.  To give one example: I still dont have any update to share about the Australian models.  (Hopefully soon.)
To give another example: last week Al Gore  the most famous American politician to think in complete sentences since Abraham Lincoln  won the Nobel Peace Prize, and where was I?  At a workshop in Germany, wondering how it could be that if UNSAT many-one reduces to a set of subexponential density then NP is in coNP/poly.  (More on that another time.)
So, Al Gore.  Look, I dont think it reflects any credit on him to have joined such distinguished pacifists as Henry Kissinger and Yasser Arafat.  I think it reflects credit on the prize itself.  This is one of the most inspired choices a Nobel Peace Prize committee ever made, even though  ironically it has nothing directly to do with peace.
With the release of An Inconvenient Truth and The Assault on Reason, its become increasingly apparent that Gore is the tragic hero of our age: a Lisa among Cletuses, a Jeffersonian rationalist in the age of Coulter and OReilly.  If I havent said so more often on this blog, its simply because the mention of Gore brings up such painful memories for me.
In the weeks leading up to the 2000 US election, I could almost feel the multiverse splitting into two branches of roughly equal amplitude that would never again interact.   In both branches, our civilization would continue racing into an abyss, the difference being that in one branch wed be tapping the brakes while in the other wed be slamming the accelerator.  I knew that the election would come down to Florida and one or two other swing states, that the margin in those states would be razor-thin (of course no one couldve predicted how thin), and that, in contrast to every other election Id lived through, in this one every horseshoe and butterfly would make a difference.  I knew that if Bush got in, Id carry a burden of guilt the rest of my life for not having done more to prevent it.
The question was, what could a 19-year-old grad student at Berkeley do with that knowledge? How could I round up tens of thousands of extra Gore votes, and thereby seize what might be my only chance in life to change the course of history?   I quickly ruled out trying to convince Bush voters, assuming them beyond persuasion.   (I later found out I was wrong, when I met people whod voted for Bush in 2000 but said they now regretted their decision.  To me, it was as if theyd just noticed the blueness of the sky.)
And thus my attention shifted to the Rights #1 friend and ally throughout history: the Far Left.  All over Berkeley I was seeing Ralph Nader placards.  At the lunch table, I even heard the strange argument that if Nader caused Bush to win, it would ultimately be for the best, since it would finally force everyone to see how bad things were: an update of the old Marxist doctrine of heightening the contradictions.  (I wondered: if Nader supporters truly believed that, then why didnt they just forget about Nader and vote for Bush outright?)
Yet it seemed to me that most Nader supporters were still sane enough that, conditioned on Nader losing (i.e. conditioned on 2+2=4), they would prefer Gore over Bush. The problem was this: how to convince Nader supporters in swing states of something that, were they convincable, they wouldve been convinced of already?  Thats when I read about an idea due to law professor Jamin Raskin, called Nadertrading.  The idea was simple: Nader supporters in swing states (like Florida and Pennsylvania) would vote for Gore, having arranged for a Gore supporter in a safe state (like New York or Texas) to vote for Nader on their behalf, thereby helping Nader get the 5% hed need to qualify for federal funds in 2004.  Two separate irrationalities of the US election system  (1) the Electoral College, and (2) the lack of something like Approval Voting to handle three or more candidates  would be played against each other.
Almost as soon as Raskin published his idea, websites arranging the swaps were set up and were being used.  Nadertrading clearly appealed to a nontrivial fraction of Nader supporters, possibly even enough to tip the scales of fate.  Yet in magazine articles and message boards, I repeatedly saw fallacious arguments against the idea: for example, that Bush supporters could game the system; that you shouldnt agree to a vote swap if you think theres any nonzero chance of the other person reneging; that trading a vote has the same moral status as selling it.
So I set up a little web page called In Defense of Nadertrading, to make the moral and game-theoretic case for Raskins idea.  The next morning, I was surprised to find myself an expert on the topic: getting Slashdotted, deluged with email, woken up by a call from CNN, etc.  I also got a fair amount of hate mail, some of which I posted on the site and ridiculed: good experience for my blogging career.
The Nadertrading movement took a hit when, in a few states, the sites arranging the vote swaps (which didnt include mine) were shut down by state attorneys-general (all of whom happened to be Republicans), over the protests of civil libertarians.   But sites hosted in other states remained up and running.
In the end, though, the Nadertrading movement simply failed to reach enough of its target audience. The websites put up by me and others apparently induced at least 1,400 Nader supporters in Florida to vote for Gore  but 97,000 Floridians still voted for Nader.  And as we know, Bush ended up winning the state by 537 votes.
After the hanging-chad circus and Gores withdrawal, I tried to bury myself in quantum complexity classes and worry as little as possible about the future of civilization.  My main news sources became The Daily Show and The Onion.  Yet much as Ive wanted to forget, for seven years Ive carried certain questions on my conscience like a sack of stones:
Why does the US have a failed oilman for president rather than the Churchill of climate change?  Why was the president vacationing in Texas when bin Ladens plans to strike the US came up in a daily briefing?   Why are we stuck in Iraq?
There are, of course, many correct answers to these questions, but theres one correct answer I keep coming back to: because I didnt make a good enough website.  Because my prose wasnt tight enough and my jokes werent funny enough.   Because I spent too much time procrastinating when I shouldve been pounding away at my keyboard.What every math talk should be like

Watch a sphere get turned inside out with no cuts or creases.  Hat tip: John Baez.Cant blog too much pain

Im bedridden with a sore throat, and on enough painkillers to knock out an elephant (well, a very small elephant). I assume the String Theory God is punishing me. Ive been repenting to all five of His manifestations  Type I, Type IIA, Type IIB, Heterotic SO(32), and Heterotic E8xE8  and hopefully Ill be back in a couple days.  Happy Halloween.Dead-blogging FOCS2007

For the past few days Ive been at FOCS2007 in Providence, Rhode Island, where apparently Im supposed to have been live-blogging the conference.   This came as news to me.  (One of the organizers wrote to ask if Id be posting live updates.  I replied that I might post something eventually.)
The trouble is, I still have tons of backblog from my previous trip to Latvia and Germany.  And so, in the hopes of someday catching up, without further ado I hereby post some photos from Europe.

The Latvian countryside.

Sure, I support moderate-to-liberal Democrats  as a temporary measure until zee vorkers take over zee vorl  [laughs maniacally]
(The above photos were taken in an underground bunker a couple hours from Riga, which the Soviets secretly built in the 70s, and to which top Communist party officials planned to retreat in case of a nuclear war.  Of course, no provisions were made for the rest of the population.   Apparently the Soviets built shelters like these all over Latvia.  Most of them were converted to bowling alleys or library storage space, but one was preserved for tourists.)

My gracious hosts in Latvia: longtime colleague (and sometime Shtetl-Optimized commenter) Andris Ambainis, Andriss Ambai-niece Ilze, and Ilzes husband Girts.

When I think about Munich, Germany, so many mental associations spring immediately into my mind: the fine baroque architecture, the nearby Bavarian alps, the freshly-baked pretzels that are a Munich specialty, the open spaces perfect for rallies and demonstrations of all kinds  but most of all, of course, I think of Oktoberfest!   Here you see me drinking genuine bier served by a genuine bier wench (not pictured) with my gracious hosts from the Max-Planck-Institut fr Quantenoptik: Norbert Schuch, Ignacio Cirac, and Michael Wolf.Halloween Special: My Inbox

Most Respected Profeser Sir Dr. Scot Andersen: I wish to join your esteemed research group.  I have taken two courses in Signal Processing at the Technical College of Freedonia; thus, it is clear that I would be a perfect fit for your laboratory at MIT. Please respond immediately with a specific date for the commencement of my studiesUniversity takes unfortunate stance on existence of quantum algorithm

The homepage of Bristol University now prominently features a photograph with the words NP  BQP, but the proof is too small to fit on this blackboard.   Hat tip to Aram Harrow, whos also the apparent culprit behind this embarrassment to his employer.The Aaronson $25.00 Prize

[Update]
For those of you whove been living in a non-wifi-enabled cave, four days ago Stephen Wolfram awarded a $25,000 prize to a 20-year-old undergraduate named Alex Smith, for proving that a particular two-state, three-symbol Turing machine is universal.    The prize was to celebrate the fifth anniversary of Wolframs paradigm-smashing, foundation-shaking masterpiece, A New Kind of Science.  (More from Bill Gasarchs blog, Nature, and Scientific American.)
Smith sounds like a swell guy who entered this contest for exactly the right reasons: he was at his parents place over summer break and had nothing better to do.  He deserves the money, and I sincerely hope the CS theory community hasnt heard the last from him.
Predictably, though, as soon as this story broke I started getting emails from journalists asking me about the far-reaching scientific implications of the new universality proof.  In trying to give them an honest answer  one that wouldnt be misunderstood, or spun to support a pre-existing storyline with which I disagreed  I inevitably came off like an ornery old sourpuss.  From Scientific American:
Of course, there may be a reason the problem languished. Finding the smallest universal [Turing machines] is a neat recreational pursuit, quantum computation researcher Scott Aaronson of the Massachusetts Institute of Technology says, but its no longer seen as connected to the central questions of the field. 
The impact of NKS on all the areas of computer science and physics Im familiar with has been basically zero, he says. As far as I can tell, the main impact is that people now sometimes use the adjective Wolframian to describe breathtaking claims for the trivial or well-known.  [Martin] Davis offers a sunnier take: The book has a lot of beautiful pictures.
And from Nature:
The solution isnt hugely relevant to modern computer science, says Scott Aaronson, a computer scientist at the Massachusetts Institute of Technology (MIT) in Cambridge, Massachusetts. Most theoretical computer scientists dont particularly care about finding the smallest universal Turing machines, he wrote in an e-mail. They see it as a recreational pursuit that interested people in the 60s and 70s but is now sort of retro.
Having partially degrumpified, in the remainder of this post I wish to offer something positive.
But first some background: a month after NKS came out, I wrote a review of it for the journal Quantum Information and Computation, in which I examined Wolframs claims about quantum mechanics and computational complexity, and explained what I saw as the problems with them.  (Rather than rehash the review, Ill just point you there if youre interested.)
Today Id like to celebrate the fifth anniversary of my critical review of NKS, by offering a $25 prize for stodgy, conventional work in the field of quantum complexity theory.
The Aaronson $25.00 Challenge
In NKS, Wolfram places himself among those computer scientists and physicists who doubt the possibility of quantum computers, not for any practical reason but as a consequence of their disbelieving quantum mechanics itself.  As he writes on page 771:
Indeed within the usual formalism [of quantum mechanics] one can construct quantum computers that may be able to solve at least a few specific problems exponentially faster than ordinary Turing machines.  But particularly after my discoveries in Chapter 9 [Fundamental Physics], I strongly suspect that even if this is formally the case, it will still not turn out to be a true representation of ultimate physical reality, but will instead just be found to reflect various idealizations made in the models used so far.
Here, then, is the challenge:
If a quantum computer can efficiently solve a problem, can it also efficiently convince Wolfram that the solution is correct?  More formally, does every language in the class BQP admit an interactive protocol where the prover is in BQP and the verifier is in BPP?
In other words: can quantum computers always show their work?  Its obvious, for example, that if a quantum computer spit out the factors of a 5,000-digit number, you wouldnt have to believe quantum mechanics (or even know what it was) to check whether the answer was right.  Im asking whether every problem solvable by a quantum computer has the same property.  And to make things fair to the quantum computer, Ill let it give not just a static proof but also an interactive protocol, by which a distrustful polynomial-time classical verifier could become convinced, to arbitrarily high confidence, that the quantum computer knows the right answer.
(An example for the uninitiated: suppose you had two graphs G and H, and suppose you picked one of the graphs at random, randomly permuted its vertices, and gave the result to a quantum computer. And suppose the quantum computer could unfailingly tell you which graph you started with.  Clearly this should convince you that G and H are not isomorphic  since if they were isomorphic, then the quantum computer couldnt have done better than guessing!  And this is true even though you never received a proof of non-isomorphism that you could hand to someone else.)
Ill award $25 either for a proof that every quantum computation can be counter-Wolframized, or for an oracle relative to which some quantum computation provably cant be. If both problems are solved then Ill award $25 for each.  Every serious submission will be reviewed by a Prize Committee consisting of me.   The Committee may also choose to award smaller prizes for partial results.
Note: Much as Id like to pull a Wolfram, the beautiful question above was (to my knowledge) first asked by Daniel Gottesman, at a conference in February 2004.  Also, the idea of a $25 prize was suggested to me by Mike Mosca.
Update (10/30): A commenter pointed me to this thread  in the Foundations of Mathematics (FOM) mailing list, which contains an actual technical discussion of Smiths universality proof.  Of particular interest:

an argument by Vaughan Pratt that Smiths universality proof is wrong,
a response by Todd Rowland of Wolfram Research,
a post from Wolfram himself, which, though written in his trademark way, comes the closest Ive seen of anything by him to addressing actual hard questions about the definition of universality, and
this comment from John McCarthy: In the 1950s I thought that the smallest possible (symbol-state product) universal Turing machine would tell something about the nature of computation.  Unfortunately, it didnt.  Instead as simpler universal machines were discovered, the proofs that they were universal became more elaborate, and [so] did the encodings of information.

In judging the correctness of Smiths proof, the key question is what counts as universality.  As I explained to the journalists who emailed me, the rules of Wolframs prize left a huge gray area by explicitly refusing to specify this.  In particular: what kinds of input and output encodings are allowed?  How do we make sure the real computational work is done by the Turing machine itself and not the encoding procedures?  Does the tape have to be filled with 0s initially, or can it be filled with other patterns, and if so which ones? Since the two-state Turing machine in question has no halt state, what external conditions can we impose to determine when the machine has halted?
Still, I decided not to make a fuss about such things in my original post, since it seemed clear from Smiths writeup that (1) he was aware of these issues, and (2) there was some nontrivial sense in which he proved universality.  I wasnt going to lose sleep over which sense, for the simple reason that Id never lost sleep over the (2,3) universality question itself!Unparadox Contest

In a recent talk at MIT, Umesh Vazirani appealed to the famous Birthday Paradox to say that two random subsets of {1,,N}, each of size o(N), probably wouldnt intersect each other.  Of course we all understood what he meant, but it occurred to me that Umesh was actually appealing to the Birthday Unparadox: If you put three people in a room, chances are no two of them will have the same birthday.
Once I realized that, I started seeing unparadoxes everywhere I looked:
The Banach-Tarski Unparadox: If you cut an orange into five pieces using a standard knife, then put them back together, the result will have exactly the same volume as the original orange.
Braess Unparadox: If you add an extra lane to a highway, one possible result will be to decrease congestion.
Hempels Unparadox: If you observe a bunch of ravens and find that all of them are black, this might increase your likelihood for the statement All ravens are black.
Russells Unparadox: The set of all sets that contain themselves as a member, might or might not contain itself as a member (either way is fine).
In the spirit of my highly-successful Best Umeshism and Best Anthropicism contests (remember those?), I now open the floor to you: come up with the best unparadox!  The winner will receive absolutely nothing.  (If you have to ask what the point is, this contest isnt for you.)Lev R.s question answered at last; fate of humanity revealed

Almost two years ago, a reader named Lev R. won my Best Anthropicism Contest with the following gem:
why arent physicists too interested in computational complexity? because if they were, theyd be computer scientists.
As the champion, Lev won the right to ask any question and have me answer it on this blog.  Here was Levs question:
I like your Earth Day, Doomsday, and Chicken Little post, but you dodged the big question. Will the world end (humans go extinct) anytime soon? Or do you think that despite our best efforts, well somehow end up not destroying ourselves?
In general, I despise being asked to make predictions, even about infinitely less weighty topics  especially when theres a chance of my being wrong, and people looking back Nelson-Muntz-like and saying ha ha, Scott was wrong!  Thats one of only several reasons why I could never be a physicist.
An answerable question would be one that asked me to clear up a misconception, or render a moral judgment, or discuss the consequences of a given assumption.  (Unanswerable: When will we see useful quantum computers?  Answerable: Didnt that company in Vancouver already build one?)  Questions about relationships between complexity classes or other unsolved math problems are also fine.  But as for the universe, how am I supposed to know what itll decide to do, among all the things it could do within reasonable bounds of physics and logic?  How am I even supposed to have a prior?  As a CS theorist, Im trained to think not about whats likely to happen, but about the very worst that could happen  within stated assumptions, of course.  Among the practical consequences of this attitude, I never gamble and I never play the stock market (and not only because, while there are many things I want, almost none of them can be traded for money).   I also dont worry about being put out of a job by prediction markets.  Where the Bayesian stops,  and says every question beyond these is trivial or meaningless, thats where Im just getting started.
But despite everything Ive said, after years of diligent research into the future of the human race  reading hundreds of trillions of books and articles about climate change, overpopulation, Peak Oil, nuclear proliferation, transhumanism, AI, and every other conceivably relevant topic (what do you think I was doing, writing CS papers?)  I am finally prepared, this somber April 1st, to answer Levs question with the seriousness it deserves.  Obviously my predictions can only be probabilistic, and obviously I cant give you the deep reasons behind them  those would take years to explain.  I shall therefore present the human future, circa 2100, in the form of a pie chart.Deoxyribononapproximability

[Updates]
Alright, heres a problem for all you bioinformatistas and inapproximabistas out there, which was inspired by this post of Eliezer Yudkowsky at Overcoming Bias (see also the comments there).
Let a DNA sequence be an element of {A,C,G,T}*, and suppose were allowed the following primitive operations: (1) insert a base pair anywhere we want, (2) delete any substring, (3) reverse any substring, and (4) copy any substring into any other part of the string.  Then given a DNA sequence S, how hard is it to estimate the minimum number of operations needed to produce S starting from the empty string?
Closely related is the following problem: by starting from the empty string and applying o(n) operations, can we produce a pseudorandom DNA sequence of length n  that is, a sequence that cant be distinguished in polynomial time from a uniform random one?
(Note 1: For both problems, we might also want to stipulate that every intermediate sequence should have size at most polynomial in n.  Or better yet, maybe one can prove that such an assumption is without loss of generality.)
(Note 2: Im also very interested in what happens if we disallow the powerful operation of reversal.)
For all I know, these problems might have trivial (or at any rate, known) answers; I just came up with them and havent thought them through.
What the problems are really getting at is this: is the effective number of bits in your genome (that is, the number of bits from a polynomial-time algorithms perspective) limited by how many ancestors youve had since life on Earth began?  Or can it be vastly greater?
Update (11/4):  Rereading the last few paragraphs of Eliezers post, I see that he actually argues for his central claim  that the human genome cant contain more than 25MB of meaningful DNA  on different (and much stronger) grounds than I thought!  My apologies for not reading more carefully.
In particular, the argument has nothing to do with the number of generations since the dawn of time, and instead deals with the maximum number of DNA bases that can be simultaneously protected, in steady state, against copying errors.  According to Eliezer, copying a DNA sequence involves a ~10-8 probability of error per base pair, which  because only O(1) errors per generation can be corrected by natural selection  yields an upper bound of ~108 on the number of meaningful base pairs in any given genome.
However, while this argument is much better than my straw-man based on the number of generations, theres still an interesting loophole.  Even with a 10-8 chance of copying errors, one could imagine a genome reliably encoding far more than 108 bits (in fact, arbitrarily many bits) by using an error-correcting code.  Im not talking about the local error-correction mechanisms that we know DNA has, but about something more global  by which, say, copying errors in any small set of genes could be completely compensated by other genes.   The interesting question is whether natural selection could read the syndrome of such a code, and then correct it, using O(1) randomly-chosen insertions, deletions, transpositions, and reversals.  I admit that this seems unlikely, and that even if its possible in principle, its probably irrelevant to real biology.  For apparently there are examples where changing even a single base pair leads to horrible mutations.  And on top of that, we cant have the error-correcting code be too good, since otherwise well suppress beneficial mutations!
Incidentally, Eliezers argument makes the falsifiable prediction that we shouldnt find any organism, anywhere in nature, with more than 25MB of functional DNA.  Does anyone know of a candidate counterexample?  (I know there are organisms with far more than humans 3 billion base pairs, but I have no idea how many of the base pairs are functional.)
Lastly, in spite of everything above, Id still like a solution to my pseudorandom DNA sequence problem.  For if the answer were negative  if given any DNA sequence, one could efficiently reconstruct a nearly-optimal sequence of insertions, transpositions, etc. producing it  then even my original straw-man misconstrual of Eliezers argument could put up a decent fight!
Update (11/5): Piotr Indyk pointed me to a paper by Ergn, Muthukrishnan, and Sahinalp from FSTTCS2003, which basically solves my problem in the special case of no reversals.   It turns out that you can estimate the number of insert, delete, and copy operations needed to produce a given DNA sequence to within a factor of 4, by just applying Lempel-Ziv compression to the sequence.  Thanks, Piotr!
Another Update (11/5): Andy Drucker has pointed out that, in the case where reversals are allowed, we can approximate the number of insert, delete, copy, and reverse operations needed to produce a given DNA sequence to within a factor of 16, by combining the Lempel-Ziv approach of Ergn et al. with a clever trick: maintain both the sequence and its reversal at all times!  Interestingly, though, this trick doesnt seem to work for transforming one sequence into another (a more general problem than I asked about, and the one considered by Ergn et al).MIT sues Frank Gehry over Stata Center

When I first saw the headline, I assumed it was from The Onion or (more likely) some local MIT humor publication.  But no, its from the Associated Press.Tis the week before deadline

and at least over here
Not a blogger is stirring
The reason is clearCold logic

Everyone knows that if you have a cold, the most important thing (besides chicken soup) is to get plenty of sleep. Sleep is when your white blood cells stop reading The Onion and watching Simpsons reruns, and start snacking on viruses.
But what if your cold is so severe that you cant sleep, not even for an hour or two? What do you do then? Not knowing the answer  but knowing readers of your blog will be getting increasingly antsy  you go see a doctor. The doctor says to take NyQuil to sleep.
The problem is that NyQuil tastes worse than Vegemite, and (another Catch-22) you can barely force a drop of it down your swollen throat. So you mix a Coke and NyQuil, on the rocks. But this merely converts a small disgusting green beverage into a large disgusting greenish-brown one.
So you go back to the drugstore, where youre relieved to learn that NyQuil is also sold in capsule form. You take two capsules. Hours later, youre still not asleep. So you take a third. An hour later youre still not asleep, and your throat is in indescribable pain.  So you take two Advils.  The pain doesnt go away, so you take a third Advil.
At this point you start hallucinating and feeling dizzy. Your skin is pale, your pupils are dilated, and youre sweating profusely. Uh-oh. What was in those pills, anyway? In each NyQuil: Dextromethorphan HBr 15mg, Pseudoephedrine HCl 30mg, Acetaminophen 325mg, Doxylamine succinate 6.25mg. In each Advil Cold & Sinus: Ibuprofen 200mg, Pseudoephedrine HCl 30mg. So, youve now ingested 180mg of Pseudoephedrine HCl, whatever the hell that is.
In case of accidental overdose contact a physician or poison control centre immediately, even if there are no symptoms.
Staggering over to your computer, you read that overdosing on antihistamines and decongestants can be fatal, and that indeed, the proper thing to do would be to get your stomach pumped as soon as possible. But its 4AM, and for better or worse, you decide to leave the 9-1-1 operator alone, and trust that three billion years of Darwinian natural selection werent for bleaaaarrrrrgghhhhhhhhh
The Moral: Never assume that, just because a single dose of a drug doesnt help you, a double or triple dose isnt going to kill you.
It actually gets even more nauseating, but Ill cut to the end: after more than a week, I can eat again. I can blog again. I can lower-bound again. I can even talk again, though I wont be playing female leads in Broadway musicals anytime soon.
Its good to be back.Thanksgiving Special: D-Wave at MIT

Some people think I have a vendetta against D-Wave Systems and its questionable quantum computer claims (see here, here, here, here, here, here, here, here, here for context). But actually, nothing could be further from the truth. I keep trying and trying to change the subject! Wouldnt you all rather hear about Wolfram, I say? Or unparadoxes? Or my #1 topic du jour, nothing whatsoever?
Apparently you wouldnt. From my inbox to my comments section to the hallway, the masses have spoken, and what they want to know is: did I attend D-Waves presentation at MIT on Monday, and if so what did I think?
Yes, I attended, in body though not in mind. You see, Monday was also the day of the STOC deadline, so if our guests from D-Wave (Mohammad Amin and Andrew Berkley) were expecting a ferocious skeptic, they instead got a bleary-eyed zombie with visions of MAEXP, P/poly, and 7:59PM EST cavorting in his head.
This meant that Ed Farhi, Isaac Chuang, Peter Shor, and Lorenza Viola had to do most of the questioning. As it turned out, they did a vastly better job than I could have.
As others have pointed out in stronger terms, Im not a physicist. (On the other hand, the gentleman linked to in the previous sentence is not correct about my being paid by the NSA to discredit Canadian quantum computing efforts: its actually the GCHQ and the Mossad.) As such, I cant directly evaluate D-Waves central claim to have built an adiabatic quantum computer, nor have I ever tried to do so. All I can do is point out the many things D-Wave has said to the press (about NP-complete problems, for example) that I know are false, its history of making dramatic announcements without evidence, and its contemptuous attitude toward scientists who have asked for such evidence. For me, thats more than enough to destroy D-Waves credibility on the claims I cant directly evaluate. After all, the burden of proof is not on me; its on them.
However, other people have not been satisfied with this line of argument. We dont care who the burden the proof is on, they say. We just care whether D-Wave built an adiabatic quantum computer.
But my physicist colleagues dont suffer from the same argumentative limitations that I do. At the group meeting preceding the talk, Farhi announced that he didnt care what the press releases said, nor did he want to discuss what problems quantum computers can solve (since we academics can figure that out ourselves). Instead he wanted to focus on a single question: is D-Waves device a quantum computer or not?
What followed was probably the most intense grilling of an invited speaker Ive ever seen.
It quickly emerged that D-Wave wants to run a coherent quantum computation for microseconds, even though each of their superconducting qubits will have completely decohered within nanoseconds. Farhi had to ask Amin to repeat this several times, to make sure hed gotten it right.
Amins claim was that what looks like total decoherence in the computational basis is irrelevant  since for adiabatic quantum computation, all that matters is what happens in the basis of energy eigenstates. In particular, Amin claimed to have numerical simulations showing that, if the temperature is smaller than the spectral gap, then one can do adiabatic quantum computation even if the conventional coherence times (the t1 and t2) would manifestly seem to prohibit it.
The physicists questioned Amin relentlessly on this one claim. I think its fair to say that they emerged curious but severely skeptical, not at all convinced by the calculations Amin provided, and determined to study the issue for themselves.
In other words, this was science as it should be. In contrast to their bosses, Amin and Berkley made a genuine effort to answer questions. They basically admitted that D-Waves press releases were litanies of hype and exaggeration, but nevertheless thought they had a promising path to a quantum computer. On several occasions, they seemed to be struggling to give an honest answer that would still uphold the company line.
Two other highlights:

I asked Amin and Berkley whether they could give any evidence for any sort of speedup over classical simulated annealing. They laughed at this. Its sixteen qubits! they said. Of course youre not going to see a scaling effect with sixteen qubits.I said I understood perfectly well (though I wondered silently whether the dozens of journalists covering D-Waves demo understood the same). But, I continued, surely you should be able to see a scaling effect by the end of 2008, when your business plan calls for 1024 qubits?Well, thats what it says in the press release, they said.
Forget about the press release, Farhi interjected. How many qubits are you actually going to make?
Amin and Berkley shrugged; they said theyd just try to make as many qubits as they could.


Even though it hadnt exhibited any sort of speedup, Amin and Berkley steadfastly maintained that their 16-qubit device was indeed a quantum computer. Their evidence was that simulations of its behavior that took quantum mechanics into account gave, they said, a better fit to the data than simulations that didnt. On the other hand, they said they were not able to test directly for the presence of any quantum effect such as entanglement. (They agreed that entanglement was a non-negotiable requirement for quantum computing.)There was a Feynmanesque moment, when Ike Chuang asked Amin and Berkley an experimental question so simple even I understood it. Ike said: if youre indeed seeing quantum effects, then by running your computer at higher and higher temperatures, at some point you should see a transition to classical behavior. Have you tried this simple control experiment?Amin and Berkley said that they hadnt, but that it sounded like a good idea.

For a theorist like me  accustomed to talks ending with if there are no questions, then lets thank the speaker again  this was exciting, heady stuff. And when it was over, I still had almost three hours until the STOC deadline.Mistake of the Week: Explain Everything (Or Dont Bother Explaining Anything)

In todays post I was going to announce the winners of my Unparadox Contest.  But then I noticed the Lake Wobegon unparadox: if the total winnings are zero, then no ones winnings are below average and in that sense, everyones a winner!
So instead of that, I thought Id contribute to the general shnoodification of humankind, by discussing the same thing every other science bloggers discussing: Paul Daviess New York Times op-ed.
Over the years I have often asked my physicist colleagues why the laws of physics are what they are. The answers vary from thats not a scientific question to nobody knows. The favorite reply is, There is no reason they are what they are  they just are.  The idea that the laws exist reasonlessly is deeply anti-rational.  After all, the very essence of a scientific explanation of some phenomenon is that the world is ordered logically and that there are reasons things are as they are.  If one traces these reasons all the way down to the bedrock of reality  the laws of physics  only to find that reason then deserts us, it makes a mockery of science.
Now, I know Paul Davies: he took me out to a nice dinner in Iceland, and even quoted me next to Ludwig Wittgenstein in the epigraph of one of his papers.  And I know for a fact that his views are much more nuanced than youd think, if the above passage was all you were going on.  I can assure you that, if his claim that physics without metaphysics is a mockery of science reminds you of those hooded monks from Monty Python and the Holy Grail, pounding their heads with wooden boards in between mystic incantations, then youve read his piece too superficially and have failed to grasp its subtler message.
But even so, reading his op-ed made me wonder: when did we, as a civilization, have a similar conversation before?  Then I remembered: the early 1600s!
Galileo: Hey, Ive discovered that Jupiter has moons!  And that objects in free fall follow parabolic trajectories!  And that
Jesuit schoolmen: Ah, foolish one, but you have told us nothing about the underlying causes of motion, or what it is that imbues the lunar bodies with their lunarity.   Of what use are your so-called explanations if they rest on a foundation that is itself unexplained?  One can hardly build a pyramid on sand!
One imagines the schoolmen feeling sorry for the nave Galileo, with his rampant scientism and countless unexamined presuppositions.   In their minds, if Galileo hadnt explained everything then he hadnt really explained anything  and hence they themselves (who had explained nothing) were the wiser by far.
Four hundred years after the scientific revolution, most people still think like the Jesuit schoolmen did:
How does a toaster work?
By converting electrical energy into heat.
But what is electricity?
The movement of electrons through a wire.
But what are electrons?
Fundamental particles with spin 1/2, negative charge, mass of 10-27 grams
But why do particles exist?  Why does anything exist?
Well, those are excellent and profound questions, and you see
Aha!  Aha!  So science doesnt have all the answers!  Ultimately, then, science is just another form of faith!
The schoolman glances at the intermediate steps  how a toaster works, what electricity is, what electrons are  and is not only profoundly unimpressed, but baffled and annoyed that anyone thinks he should be impressed.  What are these so-called answers but irrelevant distractions from the Answer?  What are they but the build-up to the punchline, stepping-stones on the road to the metaphysical abyss?
Science, in the schoolmans mind, is just a massive con game: an attempt to distract people from the ultimate questions of essence by petty conjuring tricks like curing diseases or discovering the constituents of matter.   Even pure math is part of the con: all Wiles did was reduce Fermats Last Theorem to some supposedly self-evident axioms.   But why bother with such a reduction, if you cant justify the axioms or the laws of logic themselves?
I frequently encounter the schoolmen even in my little corner of the world.   People will ask: isnt computational complexity theory a colossal failure, since all you ever do is prove this problem is as hard as that other one, or this problem is hard relative to an oracle, and never really prove anything is hard?
Lets leave aside the factual misunderstandings  we can prove certain problems are hard, etc. etc.  and concentrate on the subtext, which is:
Dont waste my time with the accumulated insights of the last half-century.  If you havent solved the P versus NP problem  and you havent, right?  then arent you, ultimately, just as ignorant about computation as I am?
Of course, does P=NP? differs from where do the laws of physics come from? in that we know, at least philosophically, what an answer to the former question would look like.   And yet, if complexity theorists ever do prove PNP, Im guessing the schoolmen will switch immediately to saying that that was merely a technical result, and that it doesnt even touch the real question, which is something else entirely.
The schoolmens philosophy leads directly to a fatalist methodology.  What causes polio? If you say a virus, then you also have to explain what viruses are, and why they exist, and why the universe is such that viruses exist, and even why the universe itself exists.  And if you cant answer all of these questions, then your so-called knowledge rests on a foundation of arbitrariness and caprice, and youre no better off than when you started.   So you might as well say that polio is caused by demons.
Yet so long as the schoolmen are careful  and define the ultimate explanation for X in such a way that no actual discovery about X will ever count  their position is at least logically consistent.   Ill even confess to a certain sympathy with it.   Ill even speculate that most scientists have a smidgen of schoolman inside.
All I really object to, then, is the notion that tracing every question down to what Davies calls the bedrock of reality represents a new, exciting approach to gathering knowledge  one at the cutting edge of physics and cosmology.  Say whatever else you want about the schoolmans way, its neither new nor untried.  For most of human history, its the only approach that was tried.Entanglement for peace and freedom

A reader named Prempeh writes in the comments section of my last post:
Im really no happier because of knowing that a phenomenon called quantum entanglement exist [sic]. Now, you say, this phenomenon has the potential to enable super-powerful computing, teleportation,  I say, until science helps me with a comprehensive, provable, repeatable methodology for using its [sic] results to make me (and everyone who wants to be) happy, I really do not see it as significantly more helpful than faith.
NB: Any chance that a unification theory could help the poor stave off devastating climate change caused in part by the profligacy of the west? End the brutality of war? Stop child sexual exploitation? Remove corruption, greed, racism, 
This is not a rhetorical question
A few quick non-rhetorical answers:

At the least, thinking about quantum entanglement doesnt exacerbate problems like war and climate change (if we neglect o(1) terms like the jet fuel needed to fly to conferences).  The same cant be said for many other human endeavors.
The scientific revolution 400 years ago led directly to a doubling of the human lifespan, the birth of democracy and its subsequent spread across the world (Galileo, Newton  Spinoza, Hume, Locke  Paine, Jefferson  ), and the cessation of practices such as witch-burning.  Its true that those few lucky enough to have been tribal chieftains with large harems probably wouldnt want to trade places with a modern; and also true that Hitler and Stalin managed to surpass the already-impressive brutality of the ancients.  But on the whole, it seems to me that the human condition improved once we started understanding how the universe works.    And given the number of utopian ideas that managed to do nothing but drench this vale of tears in new tears of their own, I dont see the relative success of curiosity-driven science as anything to sneeze at.
I do try to do my tiny part to raise awareness of climate change and other threats to civilization.  Of course, every time I do so, Im attacked in the comments section by hordes of denialists who tell me I should stick to what I know about (like quantum entanglement).  Theres just no pleasing everyone.
I see the central problem facing humanity  much more central than climate change, greed, racism, or anything else you mentioned  as collective stupidity.  If we, as a species, werent so collectively stupid, wed have error-correcting mechanisms that checked the other problems before they spiraled out of control.I also maintain the possibly-nave hope that, if people could just understand basic conceptual points about how the world works  like why quantum entanglement doesnt allow faster-than-light communication, but is still not the same as classical correlation  some tiny contribution might be made to fighting the collective stupidity of our species and thereby helping to ensure its continued survival.  That, and not the prospect of teleportation or super-powerful computing, is what really motivates me.Review of Mermins book

By now, maybe a half-dozen people have asked me what I thought of David Mermins new book Quantum Computer Science: An Introduction; many seemed surprised when I told them I hadnt read it.  Since I aim to please, I finally cracked open my review copy on a train this weekend, and am pleased to report that  yes, its quite good.  Indeed, the biggest problem is just Mermins infamous insistence on spelling qubit Qbit.   (At this point, one might as well decide to spell quark Qork.  A language consists of shared, often highly-irrational conventions that cannot be changed unilaterally.)
Mermins book is, one might say, radically limited in scope.  Theres nothing about physical implementation, not a mixed state or POVM in sight, not a word on the provable limitations of quantum computers, no mention of P, NP, or BQP, and pretty much nothing about any development after 1995.  The sole aim is to cover the quantum canon  Hadamards and Toffolis, Shor and Grover, quantum error-correction, the BB84 key distribution protocol, etc.  while dispelling various misconceptions along the way.  But at that limited task, Mermin  whos an extremely gifted expositor  does a better job than almost anyone.
He certainly does a better job than I would have.  Ill admit that, when the Mike&Ike book came out seven years ago, I navely imagined that the quantum textbook problem (or more precisely, the good quantum textbook problem) had been solved.  From now on, there would be a single place where everyone could go to learn the quantum canon.  And because anyone could know all that twentieth-century material by reading a single book, I could readily assume that anyone who was interested did know it, and could take that as shared background knowledge (like, say, the existence of the Roman Empire) when discussing newer topics like quantum lower bounds, the adiabatic algorithm, or BQP/qpoly.
Of course I couldnt have been more wrong.  In the years since Mike&Ike came out, the total amount of confusion in the world about the |A|B|Cs of quantum computing (as well as the total number of books that try to address that confusion) has increased exponentially.  And so its good to have a distinguished physicist like Mermin patiently telling readers the following:
To understand how to build a quantum computer  you must indeed have many years of experience in quantum mechanics and its applications under your belt.  But if you only want to know what such a device is capable in principle of doing once you have it, then there is no reason to get involved in the really difficult physics of the subject. (page xiii)
This means that all traces of the amplitudes x characterizing the input state have vanished from the output state.  The only role they have played in the measurement is to determine the probability of a particular output. (page 25)
Small alterations in the phases produce small alterations in the probabilities of getting that extremely precise digital information, but not the precision of the information itself, once it is acquired. (page 85)
Personally, I find it hard to remember that anyone needs to be told these things  and even when I do tell them, they dont believe me (probably because Im waving my arms too wildly).   They think Im making it up.  But Mermin dispels the common misconceptions with a calm air of gravity.
Ill end with two quibbles.
First, while Mermin talks a great deal about quantum black-box algorithms, he never once mentions the crucial distinction between the black-box world  the world where one can prove unconditionally both that quantum computers can solve certain problems exponentially faster than classical computers, and that they cant solve certain other problems any faster than classical ones  and the non-black-box world, where all such statements are necessarily conjectural.  The one time he does touch on this distinction, he gets it wrong:
The best known classical algorithms for finding the period r of such a function take a time that grows faster than any power of the number n of bits of r (exponentially with n1/3). (page 63)
The best classical algorithm for period-finding provably takes time that grows exponentially with n/2.   The best known classical algorithms for factoring take time that grows exponentially with n1/3.  But the latter algorithms (necessarily) use deeper properties of the factoring problem than just its reducibility to period-finding.
I found this an uncharacteristic omission for Mermin  whose tendency is to examine whatever he brings up from all possible angles  though perhaps it can be understood in terms of a decision to avoid any mention of complexity theory.
The second quibble is that there are no exercises.Australian educators are using my $5,000 plagiarism settlement to sell schoolkids (on science)

Two months ago, you might remember, the gods of humor and blogging saw fit to bestow on me an unexpected gift:

Model 1: But if quantum mechanics isnt physics in the usual sense  if its not about matter, or energy, or waves  then what is it about?
Model 2: Well, from my perspective, its about information, probabilities, and observables, and how they relate to each other.
Model 1: Thats interesting!
For almost the first time in my life, I wrote then, Im at a loss for words  Help me, readers. Should I be flattered? Should I be calling a lawyer?
Almost three hundred comments later, your answer was clear.  Half of you thought Id be a stereotypical American jerk, epitomizing everything wrong with modern society, if I sought any redress for the blatant plagiarism of my quantum mechanics lecture.  The other half thought Id be a nave moron if I didnt seek redress. However, there did seem to be a rough consensus on two topics: first, that as part of any settlement I should date the models (at least a hundred people made some joke to that effect, each one undoubtedly thinking it highly creative); and second, that it was probably okay to try to get something from either Ricoh (the printer company) or Love Communications (the ad agency), as long as the proceeds went to charity and I didnt directly benefit.   Since, like any public figure, I now make all decisions by polling my base, I finally had a warrant for action.
After talking things over informally with Warren Smith  the guy who discovered the Ricoh ad in the first place, who just happens (in one of the many ironies of this case) to be studying Australian intellectual property law, and to whom Im deeply indebted  I next contacted a lawyer from a well-known Australian law firm.  Talking to her confirmed my suspicion that many of the armchair legal theories offered in my comments section were simply mistaken.  In Australian copyright law, as in American law, you cant just take someones words and use them for commercial purposes without permission or attribution, regardless of any subjective judgments about the uniqueness or specialness of those words.   I was on strong legal ground. But there was also a key difference between the Australian and American legal systems:  Australian lawyers are prohibited from taking cases on a contingency basis.  If I wanted the law firm to pursue the case, then I would have to pay them up-front.
Disregarding the pleas of my relatives  who at this point were begging me to sue  I instead wrote to Love Communications directly, proposing a settlement to be donated (for example) to a mutually-agreed-upon Australian science outreach organization. We eventually agreed to a settlement of AUS$5,000.  Considering the value of Love Communications Ricoh account  which the Sydney Morning Herald reported as more than AUS$1,000,000  I thought the ad agency was getting off incredibly easily, but at least I wouldnt have to write any more letters or deal with lawyers.
The one remaining problem was to find a suitable Australian science outreach organization to which to donate the $5,000, and that would also be amusing to blog about.  As I chewed on this problem, my mind wandered back to my visit to Brisbane in December 2005, and to a conversation Id had there with Jennifer Dodd  then of the University of Queensland and now of the Perimeter Institute in Waterloo.   In that conversation, Jen had told me about a popular-science lecture series in Brisbane shed founded, called BrisScience.  Id immediately asked her to repeat the name.
BrisScience, she said.
Spell it? I asked.
B-r-i-s-Science.  Why, is there something funny about the name?
No, no, it shouldnt be a big deal in Australia.
Aha!  I now emailed Jen to ask whether BrisScience had continued its cutting-edge outreach programs in her absence. Jen replied that yes, it had, and she put me in touch with Joel Gilmore, BrisSciences current director.  Joel told me that not only was BrisScience still going strong (with the next lecture, by Bill Phillips, being about quantum mechanics), but that he (Joel) also directed another science outreach program called the Physics Demo Troupe, which does hands-on science shows for schoolkids in Brisbane and rural areas.  Joel proposed that we donate $2,000 of the settlement to BrisScience and $3,000 to the Physics Demo Troupe, the latter supporting a visit to the Torres Strait Islands in North Queensland.  I agreed, and Love Communications agreed as well.
I am, of course, gratified that this sordid southern-hemisphere tale of sex, plagiarism, quantum mechanics, and printers could be resolved to everyones satisfaction, without the need for a courtroom battle, and that schoolkids in Torres Strait Island might even learn some physics as a result.  But is there one sentence with which to conclude this saga, one sublimely fatuous thought that sums up my feelings toward the entire affair?  Wait for it wait for it
Thats interesting.Its science if it bites back

Is math a science? What about computer science? (A commenter on an earlier post repeated the well-known line that no subject calling itself a science is one.)
These are, at the same time, boring definitional disputes best left to funding agencies, and profound mysteries worthy of such intellects as Plato, Leibniz, and Gdel. In a recent comment on Peter Woits blog, the physicist John Baez  as usual  went straight to the heart of the matter:
The problem of course is that in the standard modern picture, science is empirical, based on induction, and tends to favor a materialistic ontology, while mathematics is non-empirical, based on deduction, and tends to favor a Platonist/Pythagorean ontology yet somehow they need each other! So, mathematics is not only the queen and handmaiden of the sciences  its the secret mistress as well, a source of romantic fascination but also some embarrassment.
That 17 is prime strikes us as absolutely certain, yet theres nothing in the physical world we can point to as the source of that certainty. (Seventeen blocks that cant be arranged into a rectangle? Give me a break.) In that respect, math seems more like subjective experience than science: you might be wrong about the sky being blue, but you cant be wrong about your seeing it as blue. Maybe this has something to do with mathematicians much-noted mystical tendencies: Pythagoras sacrificing a hundred oxen because the square root of 2 was irrational; Cantor naming infinite cardinalities using the Hebrew letter aleph, which represents the infinite greatness of God in Kabbalah; Erds forswearing earthly pleasures to devote his life to the Book; Gdel updating St. Anselms proof of the existence of God; Penrose speculating that quantum gravity gives rise to consciousness. My favorite novel about mathematicians, Rebecca Goldsteins The Mind-Body Problem, gets much of its mileage from this ancient connection. (For empirical types: according to a 1997 survey by Larson and Witham, ~40% of mathematicians say they believe in God, compared to 20% of physicists and 30% of biologists.)
And yet, if mathematicians are mystics during those rare late-night epiphanies when they first apprehend (or believe theyve apprehended) a timeless thought of God, then theyre scientists through and through when it comes time to LaTeX that thought and post it to the arXiv. What makes me so sure of that? Mostly, that my 10th-grade chemistry teacher claimed the opposite.
To give you some background, this is a teacher whose hatred of curiosity and independent thought was renowned throughout the school district  whod give her students detentions for showing up fifteen seconds after the bell  whod flunk me on exams, even when I got the answers right, because I refused to write things like (1 mol)/(1 g) = 1 mol/g. Immediately after enduring her class, I dropped out of high school and went straight to college, picking up a G.E.D. along the way. For I had sworn to myself, while listening to this woman lecture, that the goal of my life was to become her antithesis: the living embodiment of everything she detested. Ten years later, I still havent wavered from that goal.
Which brings me to the term project in her class.  We were supposed to interview a scientist  any scientist  and then write a detailed report about his or her work. I chose a mathematician at Bell Labs who did operations research. After Id interviewed the guy and finished my project, the teacher ordered me to redo it from scratch with a different interviewee. Why? Because mathematicians arent real scientists. (To give some context, the teacher did accept a pharmacist, a physical therapist, and an architect as real scientists.)
Now, is it possible that my views about the epistemological status of mathematics are hopelessly colored by enmity toward my chemistry teacher? Yes, it is. But as far as I can tell, the refusal to count math and CS among the sciences has done some real damage, even outside the intellectual prison known as high school. Lets consider a few examples:

The New York Times hardly ever runs a story about math or CS theory, but it runs the same story about cosmology and string theory every two weeks.


We all know the recipe for getting a paper published in Science or Nature: first gather up all your analytical results, and bury them in your yard. Then make some multicolored charts of Experimental Data, which suggest (at a 2 level) the same conclusions you previously reached via the forbidden method of proving them true.


Philosophers like Wittgenstein have gotten away with saying arbitrarily dumb things, like Mathematical propositions express no thoughts. As my adviser Umesh Vazirani pointed out to me, the proper response to anyone who says that is: Indeed, the mathematical propositions that you know express no thoughts.


Many people seem to have the idea that, whereas scientists proceed by proposing theories and then shooting them down, mathematicians somehow proceed in a different, alien way. Which raises the question: what other way is there? Whenever I hear someone claim that quantum computers are really just analog computers, or all cellular automata that arent obviously simple are Turing-complete, Im reminded that Poppers notion of falsifiability is just as important in math and CS as in any other sciences.


Saddest of all, many mathematicians and computer scientists seem to reason that, because they can write their results up with something approaching Platonic rigor, it follows that they should. Thus we have the spectacle of math/CS papers that, were they chemistry papers, would read something like this: First I took the test tube out of the cabinet. Then I rinsed it. Then I filled it with the solution. Then I placed it on the bunsen burner For whom are such papers written? The authors high-school teacher? God? I would think it obvious that the goal of writing a math paper should be to explain your results in  just enough detail that your colleagues can replicate them  not in their labs or their computers, but in their minds.

The bottom line, of course, is that math and CS are similar to biology and physics in the most important sense: they bite back.  Granted, you might be sitting in your armchair when you do them, but at least youre probably leaning forward in the armchair, scribbling on a piece of paper and willing to be surprised by what you find there.
This seems like an appropriate time to quote the distinguished American philosopher Dave Barry.
Here is a very important piece of advice: be sure to choose a major that does not involve Known Facts and Right Answers. This means you must not major in mathematics, physics, biology, or chemistry, because these subjects involve actual facts. If, for example, you major in mathematics, youre going to wander into class one day and the professor will say: Define the cosine integer of the quadrant of a rhomboid binary axis, and extrapolate your result to five significant vertices. If you dont come up with exactly the answer the professor has in mind, you fail. The same is true of chemistry: if you write in your exam book that carbon and hydrogen combine to form oak, your professor will flunk you. He wants you to come up with the same answer he and all the other chemists have agreed on. Scientists are extremely snotty about this.
And, since I cant resist, heres a classic joke.
The dean summons the physics department chair to his office. You people are bankrupting us! he fumes. Why do you need all this expensive equipment? All the mathematicians ever ask for is pencils, paper, and erasers. And the philosophers are better still: they dont even ask for erasers!Special entry for you, my friend

Happy New Year and all that.  Recently I got back from a two-week journey to India (to attend the QIP conference in New Delhi and, of course, liveblog from the Taj) as well as England (to meet up with family in London and make a religious pilgrimage to Bletchley Park).
Even though my travel entries typically get fewer comments than anything else, I nonetheless feel a historic responsibility to record my first visit to a subcontinent with one-sixth of the worlds population  the birthplace not only of my adviser and so many other great theoretical computer scientists, but also of Gandhi, Ramanujan, the Buddha, and commenter Nagesh Adluru.     But where do I even start?     Writing anything open-ended has always been a chore for me, and its only getting harder with time.
So Ill tell you what: Ill just post some photos with commentary.  Then ask me whatever you want in the comments section:  Were there any good talks at QIP?  Were you brave enough to sample the strange, exotic North Indian dishes, like naan and samosas and chicken curry? Having spent a full week in India, to what extent, if any, do you think the Bhutto assassination will destabilize Indo-Pakistani relations?

India: where every imaginable entity with wheels, feet, or hooves can be found on the road, making deafening noises while swerving to kill you; the waters not even safe for toothbrushing; the beggars have their own beggars; and the cellphone network is more reliable than anything in the US.

These are students and religious pilgrims at the Dayalbagh colony near Agra, the headquarters of one branch of the Radha Soami sect of Hinduism.  Theyre laboring in the fields at dawn, before coming in to hear me and others give quantum computing talks.  Im not making this up.
When I agreed to give a talk at the Dayalbagh Educational Institute, all I knew about my hosts is that they were computer scientists near Agra who would take me on a guided tour of the Taj Mahal and arrange the logistics.  I had no idea that my hosts  and their self-supporting agricultural commune of about 20,000 people, led by religious scholars fascinated by quantum computing theory  would turn out to be considerably more interesting than the Taj itself.
For my talk, I was going to present some recent results with Peter Shor, Salman Beigi, and Bill Fefferman on the complexity class QMA(k) (Quantum Merlin-Arthur with multiple unentangled Merlins).  But then I learned that over 200 people would be attending.  I panicked: there arent 200 people on Earth who would care about this talk, let alone 200 people on a Hindu kibbutz near Agra!  So I quickly substituted my usual dog-and-polynomial show about the limits of quantum computers.
I was surprised that the guru of the sect, Prof. P. S. Satsangi, actually came to my talk.  Everyone stood at attention when he entered the room, and then he sat in a special chair surrounded by flowers at the front of the lecture hall.  He did not ask questions.
In the end, while I couldnt assent to the Radha Soamis mystical beliefs (as they were explained to me), I found much in their way of life to recommend it.   I had fun imagining, say, a Kansas farmtown where a quantum computing workshop would be a major public event, attended by the mayor and every local dignitary.

This is where I stayed in New Delhi: at the Islamic Cultural Centre Guest House.  I chose to stay here because (1) as someone whos occasionally blogged about the Israeli/Palestinian conflict, I felt a historic responsibility to make a bold peace gesture, and (2) it was the only place in walking distance to the conference center.
As you can see from the Christmas tree out in front, the Islamic Centre was happily not averse to ecumenicism.  As explained to me by my friend at the guest house (the guy who knocked on my door every fifteen minutes to see if I needed anything, before asking me for a tip), here in India there is no you Hindu, you Muslim, you Buddhist, you Sikh.  All are brothers, you understand?  Tip?

Dorit Aharonov and Barbara Terhal passionately debating some adiabatic something-or-other near the Qutb Minar, a twelfth-century minaret.

Need Grovers algorithm tailored to solve the element distinctness problem in n2/3 queries?   I know just the guy for such jobs

If you cant read it, the sign says MADHUSUDAN MOTORS.

Our guides: cmon, move along, nothing to see here  just a stray monkey 

The obligatory photo.  Not Photoshopped, I promise.

Here we shift the scene from India to its former colonialist ruler (now a quaint, scone-intensive island in the North Atlantic). Im standing in front of the Bletchley Park mansion, an hour and a half by train from London.  In the early nineties, this site was apparently going to be demolished to make way for housing developments.  Then someone pointed out that, by current estimates, the cryptanalysis done at Bletchley Park probably shortened World War II by at least two years and saved about twenty million lives.  So they made it into a museum.   Next time youre in London, I strongly recommend making the pilgrimage (just beware that the place closes at 4PM).

This is a Bombe.

Alan Turings office in Hut 8.Im liveblogging from the Taj Mahal

No particular news to report  its about the same as it was 400 years ago, I guess.  I just wanted to liveblog from the Taj Mahal, is all.  (Jonathan Walgate is the one who suggested it.). Now Ill go back to looking at it.Volume 4 is already written (in our hearts)

Today is the 70th birthday of Donald E. Knuth: Priest of Programming, Titan of Typesetting, Monarch of MMIX,  intellectual heir to Turing and von Neumann, greatest living computer scientist by almost-universal assent  alright, you get the idea.
That being the case, Jeff Shallit proposed to various CS bloggers that we should all band together and present the master with a birthday surprise: one post each about how his work has inspired us.  The posts are now in!  Readers who dont know about Knuths work (are there any?) should start with this post from Luca.  Then see this from David Eppstein, this from Doron Zeilberger, this from Jeff, this from Bill Gasarch, and this from Suresh.
Knuths impact on my own work and thinking, while vast, has not been directly through research: his main influence on my BibTeX file is that if not for him, I wouldnt have a BibTeX file.   (One reason is that Im one of the people Doron Zeilberger attacks for ignoring constant factors, and supporting what he calls the ruling paradigm in computational complexity theory, with its POL vs. EXP dichotomy.)  So I decided to leave Knuths scientific oeuvre to others, and to concentrate in this post on his contributions to two other fields: mathematical exposition and computational theology.
Knuths creation of the TeX typesetting system  his original motivation being to perfect the layout of his own Art of Computer Programming books  was remarkable in two ways.  First, because scientific typesetting is of so little interest to industry, its not clear if something like TeX would ever have been invented if not for one man and his borderline-neurotic perfectionism. Second, TeX is one of the only instances I can think of when a complicated software problem was solved so well that it never had to be solved again (nor will it for many decades, one hazards to guess).  At least in math, computer science, and physics, the adoption of TeX has been so universal that failure to use it is now a reliable crackpot indicator.
From Wikipedia:
Since version 3, TeX has used an idiosyncratic version numbering system, where updates have been indicated by adding an extra digit at the end of the decimal, so that the version number asymptotically approaches . This is a reflection of the fact that TeX is now very stable, and only minor updates are anticipated. The current version of TeX is 3.141592; it was last updated in December 2002  Even though Donald Knuth himself has suggested a few areas in which TeX could have been improved, he indicated that he firmly believes that having an unchanged system that will produce the same output now and in the future is more important than introducing new features. For this reason, he has stated that the absolutely final change (to be made after my death) will be to change the version number to , at which point all remaining bugs will become features.
But Knuths interest in scientific exposition goes far beyond typesetting.  His 1974 Surreal Numbers: How Two Ex-Students Turned on to Pure Mathematics and Found Total Happiness, which he wrote in one week, was weirdness at the highest possible level: the Beatles White Album of math.  Its said to represent the only occasion in history when a new mathematical theory (Conways theory of surreal numbers) was introduced in the form of a novel.    (Though admittedly, with the exception of one sex scene, this is a novel whose plot development mostly takes the form of lemmas.)
Those seeking to improve their own writing should consult Mathematical Writing (available for free on the web), the lecture notes from a course at Stanford taught by Knuth, Tracy Larrabee, and Paul Roberts. Like a lot of Knuths work, Mathematical Writing has the refreshing feel of an open-ended conversation: we get to see Knuth interact with students, other teachers, and visiting luminaries like Mary-Claire van Leunen, Paul Halmos, Jeff Ullman, and Leslie Lamport.
Since Ive blogged before about the battle over academic publishing, I also wanted  to mention Knuths remarkable and characteristically methodical 2003 letter to the editorial board of the Journal of Algorithms.   Knuth asks in a postscript that his letter not be distributed widely  but not surprisingly, it already has been.
In the rest of this post, Id like to talk about Things A Computer Scientist Rarely Talks About, the only book of Knuths for which I collected one of his coveted $2.56 prizes for spotting an error.   (Nothing important, just a typo.)
Things is based on a series of lectures on computer science and religion that Knuth gave in 1997 at MIT.  (At the risk of oversimplifying: Knuth practices Christianity, but in a strange form less interested in guns and gays than in some business about universal compassion.)  Perhaps like most readers, when I bought Things I expected yet another essay on non-overlapping magisteria, a famous scientists apologia justifying his belief in the Virgin Birth and the Resurrection. But Knuth likes to surprise, and what he delivers instead is mostly a meditation on the typography of Bible verses [sic]. More precisely, Things is a metabook: a book about the lessons Knuth learned while writing and typesetting an earlier book, one I havent yet read, that analyzed verse 3:16 of every book of the Bible.
But this being a lecture series, Knuth also fields questions from the audience about everything from sin and redemption to mathematical Platonism.  He has a habit of parrying all the really difficult questions with humor; indeed, he does this so often one comes to suspect humor is his answer.  As far as I could tell, theres only one passage in the entire book where Knuth directly addresses what atheists are probably waiting for him to address.  From one of the question periods:
Q: How did you become so interested in God and religion in the first place?
A: It was because of the family I was born into.  If I had been born in other circumstances, my religious life would no doubt have been quite different. (p. 155)
And then on to the next question.
To me, whats remarkable about this response is that Knuth without any hesitation concedes what skeptics from Xenophanes to Richard Dawkins have held up as the central embarrassment of religion.  This, of course, is the near-perfect correlation between the content of religious belief and the upbringing of the believer.    How, Dawkins is fond of asking, could there possibly be such a thing as a Christian or Hindu or Jewish child?  How could a four-year-old already know what he or she thinks about profound questions of cosmogony, history, and ethics  unless, of course, the child were brainwashed by parents or teachers?
My Bayesian friends, like Robin Hanson, carry this argument a step further. For them, the very fact that Knuth knows his beliefs would be different were he born to different parents must, assuming hes rational, force him to change his beliefs.  For how can he believe something with any conviction, if he knows his belief was largely determined by a logically-irrelevant coin toss?
And yet, openly defying the armies of Bayes arrayed against him, here we have Knuth saying, in effect: yes, if I know that if I were some other person my beliefs would be different, but Im not that other person; Im Knuth.
So, readers: is Knuths response a cop-out, the understandable yet ultimately-indefensible defense of an otherwise-great scientist who never managed to free himself from certain childhood myths?   Or is it a profound acknowledgment that none of us ever escape the circumstances of our birth, that we might as well own up to it, that tolerance ought not to require a shared prior, that the pursuit of science and other universal values can coexist with the personal and incommunicable?
Taking a cue from Knuth himself, Im going to dodge this question.  Instead, I decided to end this post by quoting some of my favorite passages from Chapter 6 of Things A Computer Scientist Rarely Talks About.
On computer science and God: When I talk about computer science as a possible basis for insights about God, of course Im not thinking about God as a super-smart intellect surrounded by large clusters of ultrafast Linux workstations and great search engines.  Thats the users point of view. (p. 168)
I think its fair to say that many of todays large computer programs rank among the most complex intellectual achievements of all time.  Theyre absolutely trivial by comparison with any of the works of God, but still theyre somehow closer to those works than anything else we know. (p. 169)
On infinity: Infinity is a red herring.  I would be perfectly happy to give up immortality if I could only live Super K years before dying [Super K being defined similarly to an Ackermann number].  In fact, Super K nanoseconds would be enough. (p. 172)
On the other hand: I once thought, if I ever had to preach a sermon in church, I would try to explain Cantors theorem to my non-mathematical friends so that they could understand something about the infinite. (p. 172)
On God and computational complexity: I think its fair to say that God may well be bound by the laws of computational complexity  But I dont recommend that theologians undertake a deep study of computational complexity (unless, of course, they really enjoy it).  (p. 174)
On quantum mechanics: Several years ago, I chanced to open Paul Diracs famous book on the subject and I was surprised to find out that Dirac was not only an extremely good writer but also that his book was not totally impossible to understand.  The biggest surprise, however  actually a shock  was to learn that the things he talks about in that book were completely different from anything I had ever read in Scientific American or in any other popular account of the subject.  Apparently when physicists talk to physicists, they talk about linear transformations of generalized Hilbert spaces over the complex numbers; observable quantities are eigenvalues and eigenfunctions of Hermitian linear operators.  But when physicists talk to the general public they dont dare mention such esoteric things, so they speak instead about particles and spins and such, which are much less than half the story.  No wonder I could never really understand the popular articles. (p. 181)
The extra detail that gets suppressed when quantum mechanics gets popularized amounts to the fact that, according to quantum mechanics, the universe actually consists of much more data than could ever be observed. (p. 182)
On free will and the problem of evil: I can design a program that never crashes if I dont give the user any options.  And if I allow the user to choose from only a small number of options, limited to things that appear on a menu, I can be sure that nothing anomalous will happen, because each option can be foreseen in advance and its effects can be checked.  But if I give the user the ability to write programs that will combine with my own program, all hell might break loose.  (In this sense the users of Emacs have much more free will than the users of Microsoft Word.)  I suppose we could even regard Figure 5 [a binary tree representing someones choices] as the Tree of the Knowledge of Good and Evil. (p. 189-190)Ten Signs a Claimed Mathematical Breakthrough is Wrong

Yesterday several people asked my opinion of a preprint claiming to solve the Graph Isomorphism problem in deterministic polynomial time.  I responded:
If I read all such papers, then I wouldnt have time for anything else. Its an interesting question how you decide whether a given paper crosses the plausibility threshold or not. For me personally, the AKS PRIMES in P paper somehow crossed it whereas this one somehow doesnt.
Of course, Id welcome an opinion from anyone whos actually read the paper.
Three commenters wrote in to say the paper looked good.   Then the author found a bug and retracted it.
Update (1/5): Laci Babai writes in to tell me thats not quite what happened.  See here for what did happen, and here for an argument that Friedlands approach would if sound have implied P=NP.
My purpose here is not to heap embarrassment on the author: hes a serious mathematician who had a well-defined and interesting approach, and who (most importantly) retracted his claim as soon as a bug was discovered.  (Would that everyone did the same!)  Though the stakes are usually smaller, similar things have happened to most of us, including me.
Instead I want to explore the following metaquestion: suppose someone sends you a complicated solution to a famous decades-old math problem, like P vs. NP.  How can you decide, in ten minutes or less, whether the solution is worth reading?
For a blogger like me  whose opinions are both expected immediately and googlable indefinitely  this question actually matters.  Err in one direction, and Ill forever be known as the hidebound reactionary who failed to recognize some 21st-century Ramanujan.  Err in the other direction, and Ill spend my whole life proofreading the work of crackpots.
A few will chime in: but if everyone wrote out their proofs in computer-checkable form, thered be no need for this absurd dilemma!  Sure, and if everyone buckled up thered be fewer serious accidents.  Yet heres the bloodied patient, and here we are in the emergency room.
In deciding whether to spend time on a paper, obviously the identity of the authors plays some role.  If Razborov says he proved a superlinear circuit lower bound for SAT, the claim on our attention is different than if Roofus McLoofus says the same thing.   But the danger of elitism is obvious here  so in this post, Ill only be interested in what can be inferred from the text itself.
Inspired by Sean Carrolls closely-related Alternative-Science Respectability Checklist, without further ado I now offer the Ten Signs a Claimed Mathematical Breakthrough is Wrong.
1. The authors dont use TeX.  This simple test (suggested by Dave Bacon) already catches at least 60% of wrong mathematical breakthroughs.  David Deutsch and Lov Grover are among the only known false positives.
2. The authors dont understand the question.  Maybe they mistake NPcoNP for some claim about psychology or metaphysics.  Or maybe they solve the Grover problem in O(1) queries, under some notion of quantum computing lifted from a magazine article.  Ive seen both.
3. The approach seems to yield something much stronger and maybe even false (but the authors never discuss that). Theyve proved 3SAT takes exponential time; their argument would go through just as well for 2SAT.
4. The approach conflicts with a known impossibility result (which the authors never mention). The four months I spent proving the collision lower bound actually saved me some time once or twice, when I was able to reject papers violating the bound without reading them.
5. The authors themselves switch to weasel words by the end. The abstract says we show the problem is in P, but the conclusion contains phrases like seems to work and in all cases we have tried.  Personally, I happen to be a big fan of heuristic algorithms, honestly advertised and experimentally analyzed.   But when a proof has turned into a plausibility argument by page 47  release the hounds!
6. The paper jumps into technicalities without presenting a new idea. If a famous problem could be solved only by manipulating formulas and applying standard reductions, then its overwhelmingly likely someone wouldve solved it already.  The exceptions to this rule are interesting precisely because theyre rare (and even with the exceptions, a new idea is usually needed to find the right manipulations in the first place).
7. The paper doesnt build on (or in some cases even refer to) any previous work. Math is cumulative.  Even Wiles and Perelman had to stand on the lemma-encrusted shoulders of giants.
8. The paper wastes lots of space on standard material.  If youd really proved PNP, then you wouldnt start your paper by laboriously defining 3SAT, in a manner suggesting your readers might not have heard of it.
9. The paper waxes poetic about practical consequences, deep philosophical implications, etc. Note that most papers make exactly the opposite mistake: they never get around to explaining why anyone should read them.  But when it comes to something like PNP, to motivate your result is to insult your readers intelligence.
10. The techniques just seem too wimpy for the problem at hand.  Of all ten tests, this is the slipperiest and hardest to apply  but also the decisive one in many cases.   As an analogy, suppose your friend in Boston blindfolded you, drove you around for twenty minutes, then took the blindfold off and claimed you were now in Beijing. Yes, you do see Chinese signs and pagoda roofs, and no, you cant immediately disprove him  but based on your knowledge of both cars and geography, isnt it more likely youre just in Chinatown?  I know its trite, but this is exactly how I feel when I see (for example) a paper that uses category theory to prove NLNP.  We start in Boston, we end up in Beijing, and at no point is anything resembling an ocean ever crossed.
Obviously, there are just some heuristics Ive found successful in the past.  (The nice thing about math is that sooner or later the truth comes out, and then you know for sure whether your heuristics succeeded.)  If a paper fails one or more tests (particularly tests 6-10), that doesnt necessarily mean its wrong; conversely, if it passes all ten that still doesnt mean its right.  At some point, there might be nothing left to do except to roll up your sleeves, brew some coffee, and tell your graduate student to read the paper and report back to you.Science: the toroidal pyramid

Chad Orzel gripes about this months Scientific American special issue on The Future of Physics  which is actually extremely good, but which turns out to be exclusively about the future of high-energy particle physics.  Not surprisingly, the commenters on Chads blog reignite the ancient debate about which science is more fundamental than which other one, and whether all sciences besides particle physics are stamp collecting.
I started writing a comment myself, but then I realized I hadnt posted anything to my own blog in quite some time, so being nothing if not opportunistic, I decided to put it here instead.
To me, one of the most delicious things about computer science is the way it turns the traditional pyramid of sciences on its head.  We all know, of course, that math and logic are more fundamental than particle physics (even particle physicists themselves will, if pressed, grudgingly admit as much), and that particle physics is in turn more fundamental than condensed-matter physics, which is more fundamental than chemistry, which is more fundamental than biology, which is more fundamental than psychology, anthropology, and so on, which still are more fundamental than grubby engineering fields like, say, computer science  but then you find out that computer science actually has as strong a claim as math to be the substrate beneath physics, that in a certain sense computer science is math, and that until you understand what kinds of machines the laws of physics do and dont allow, you havent really understood the laws themselves  and the whole hierarchy of fundamental-ness gets twisted into a circle and revealed as the bad nerd joke that it always was.
That was a longer sentence than I intended.
Note (Jan. 25): From now on, all comments asking what I think of the movie Teeth will be instantly deleted.  Im sick of the general topic, and regret having ever brought it up.  Thank you for your understanding.Geordie Rose at MIT

While there are many, many things in this world that Im bent on destroying, D-Wave Systems has never been one of them.  Ideally, Id simply let the D-Wave folks do their thing (namely, try to build an adiabatic quantum computer) while I do my thing (namely, study the fundamental limits of quantum computers).  It was only when, in connection with D-Wave, cringe-worthy claims about quantum computing started appearing all over the press that I felt a professional obligation to say something.
Now that Im involved, though, I also need to keep you ablog of any notable further developments.  And presumably, D-Wave founder Geordie Rose coming to MIT to meet with our quantum information group counts as notable.
Two months ago, youll recall, we were graced by a visit from D-Waves Mohammad Amin and Andrew Berkley, but Id never before had the pleasure of meeting Geordie.  At least formally, the reason for his visit was not to defend D-Wave, but to present four hard problems for us to solve.  These problems were as follows:

Find a practical adiabatic factoring algorithm.  Because of the equivalence of adiabatic and standard quantum computing, we know that such an algorithm exists, but the running time you get from applying the reduction is something like O(n11).  Geordie asks for an O(n3) factoring algorithm in the adiabatic model.  It was generally agreed (with one dissent, from Geordie) that reducing factoring to a 3SAT instance, and then throwing a generic adiabatic optimization algorithm at the result, would be a really, really bad approach to this problem.
Find a fault-tolerance threshold for adiabatic quantum computing, similar to the known threshold in the circuit model. Geordie asserted that such a threshold has to exist, because of the equivalence of adiabatic and standard quantum computing.  However, others immediately pointed out that this is not so: the equivalence theorem is not known to be fault-tolerance-preserving.  This is a major open problem that many people have worked on without success.
Prove upper and lower bounds on the adiabatic algorithms performance in finding exact solutions to hard optimization problems.
Prove upper and lower bounds on its performance in finding approximate solutions to such problems.  (Ed Farhi described 3 and 4 as so much harder than anything else weve failed to solve.)

While none of these problems are new to the quantum computing community, theyre all extremely good ones, and all (indeed) extremely hard.
Of course, we did also discuss some controversial, red-meat, did-D-Wave-build-a-quantum-computer sorts of questions, so I owe it to you to provide a few highlights from that discussion.
Seth Lloyd, whos been more sympathetic to D-Wave than most of us, correctly pointed out that D-Wave has a credibility problem in the scientific community.  He discussed in great detail the experiments D-Wave ought to be doing to convince scientists that theyre really seeing quantum effects.  I strongly agreed with Seth, adding that Id rather see two coherent qubits than thousands of incoherent ones.  Of course, even if D-Wave could demonstrate two-qubit entanglement (and Geordie says its the next thing on the list), there would still remain the enormous issues of scalability and of the limitations of the adiabatic algorithm in solving hard optimization problems.  But at least we could be more comfortable in saying that what they currently have is a tiny quantum computer.
Geordie conceded that, so far, D-Wave has no direct evidence for entanglement among two or more qubits.  He nevertheless argued that they have indirect evidence (basically, that their data are better fit by a simple quantum model than a simple classical one), and that the lack of direct evidence is solely due to the difficulty of performing the requisite measurements.  Seth replied that, despite the difficulty, D-Wave would do itself a big favor by performing the measurements.
Seth also mentioned D-Waves claims to the popular press  for example, about the ability of quantum computers to solve NP-complete problems  as a major factor in its scientific credibility problem.  Geordie admitted that some of D-Waves publicity was (here he paused for a few seconds) not inaccurate, but verging on inaccurate.
Note: Geordie now says that he was only talking about the reporting on D-Wave; in his words, I stand by 100% anything Ive ever said to anyone about these machines.  At the time, I understood him quite clearly to be talking about D-Waves own publicity; its strange that he would have hesitated to admit that reporters have misunderstood things.  But I freely admit that I might have misheard or misinterpreted him.
I asked Geordie about the result of Bansal, Bravyi, and Terhal that the planar Ising spin graph problem admits an efficient classical approximation algorithm  thus calling into question D-Waves whole strategy of solving other NP approximation problems by mapping them onto Ising spin graph instances.  Geordie replied, first, that their machine can handle many non-planar links, and second, that Bansal et al.s algorithm merely trades an exponential dependence on n for an exponential dependence on 1/.  I agreed that their algorithm isnt practical, but argued that its mere existence would have to be dealt with in any attempt to convert approximate solutions of the Ising spin graph problem into approximate solutions of the original optimization problems.
So, where do we stand?  Heres my attempt at a fair summary:

The people at D-Wave are not conscious frauds; they genuinely believe in what theyre doing.


On the other hand, much of the publicity surrounding D-Wave can be safely rejected.  To some academics, even one or two public misrepresentations are enough to destroy a companys credibility.  Others, however, prefer to ignore press releases  seeing hype, exaggeration, and even outright falsehoods as just a necessary part of raising money  and to concentrate solely on a companys communications with experts.  Where you fall between these extremes probably depends on your personality more than anything else.


In the past, I criticized D-Wave (rightly, I think) for failing to share information with the scientific community in a good-faith manner. To their credit, theyre now making more of an effort to communicate.


Thus far, by Geordies own account, theres no direct evidence that D-Waves machine actually produces entanglement at any stage of its operation (which all agree is a non-negotiable requirement for quantum computing).  Geordie says that producing such evidence will be the next thing on the list.  The Sudoku stunt was worthless from a scientific perspective; it did not answer any of the questions that physicists need answered.


Even if D-Wave managed to build (say) a coherent 1,024-qubit machine satisfying all of its design specs, its not obvious it would outperform a classical computer on any problem of practical interest.  This is true both because of the inherent limitations of the adiabatic algorithm, and because of specific concerns about the Ising spin graph problem.  On the other hand, its also not obvious that such a machine wouldnt outperform a classical computer on some practical problems.  The experiment would be an interesting one!   Of course, this uncertainty  combined with the more immediate uncertainties about whether D-Wave can build such a machine at all, and indeed, about whether they can even produce two-qubit entanglement  also means that any talk of lining up customers is comically premature.Great Ideas In Theoretical Computer Science Lecture 1

For those whove stopped following the Democritus series, theres another train leaving the station today: the first lecture of my new undergraduate course (Great Ideas In Theoretical Computer Science) is now available.
After whetting the appetite by describing how theoretical computer science has finally let humankind achieve one of its noblest aspirations (playing roulette over the Internet), the lecture then goes back to antiquity, and covers the hottest results in the computing world circa 300BC: Euclids GCD algorithm and the straightedge-and-compass model of computation.
(One word of warning: the lecture notes were written by my teaching assistant, Yinmeng Zhang, and do not faithfully reflect what I said in class. Theyre much better than what I said in class.   She even had the gall to improve my jokes.)
To preempt the inevitable questions, two remarks about the courses title:

I considered calling it just Great Ideas In Computer Science, but then I realized it would have to be a week longer.  (Har har, just kidding!  Cue cymbals.)
Any relation to the famous CMU course designed by Steven Rudich (Great Theoretical Ideas In Computer Science) is obviously a coincidence.  The philosophies behind the two courses are every bit as different as their names.Scientific American article is out!

After three years of procrastination and delays, my 8-page feature article on The Limits of Quantum Computers has finally appeared in the March issue of Scientific American. Once I get permission, Ill post a plain-text version on my website. In the meantime, you can buy the online issue for US$5.00 from SciAms website, in which case you get colorful sidebars and graphics (including a bearded, white-lab-coated cartoon scientist holding quantum computers and complexity class inclusion diagrams), as well as an interview with Jeff Kimble about the unfortunate movie Jumper, and other articles about the end of cosmology, prediction markets (Robin Hanson and his futarchy get a mention), and the disastrous overfishing of the bluefin tuna (the kind used for toro sushi).
Update (2/18): By popular demand, Im posting a rough early draft (PDF) of my article online.  Read at your own risk!
So, what was it like to write for Scientific American?  Exhausting, excruciating, and ultimately worth it.  As a general rule, SciAm (probably like all large-circulation magazines) rewrites articles so extensively that the person listed in the byline is less the writer than the content consultant.  Almost every sentence in my article bears the scars of battle (some that I won, more that I didnt).  Yet I have to concede that, when something was really cringe-inducingly wrong, SciAm was willing to listen and make changes  and besides, they did a great job with the cartoons.  Im happy with the end result.  Thanks to George Musser, the editor who solicited the article and gave me lots of feedback in the early stages, and to Graham Collins, who finally saw it into print.
A few specific comments for your amusement:

In an earlier draft, the cartoons adorning my article were all balding white guy, all the time (supposedly, because of the need to keep a consistent character throughout the article).   I demanded some sort of cartoon-diversity.  After a heated discussion among the editors  in which, Im told, the name of Larry Summers was invoked  they finally agreed to add a cartoon black woman.  To those who think Im a male chauvinist pig: how many brownie points do I get?


No, the crystal ball with floating s and s, mounted atop a keyboard, is not an accurate depiction of what a quantum computer would look like.   Having toured some actual QC labs, though, I had to admit it worked better graphically than a lab table piled high with tinfoil, lasers, and assorted pipes.


The topic label of the article is Information Technology. I pleaded with them to change the topic to Computer Science, but to no avail.  Apparently the problem was that in the table of contents, the previous two articles were labeled Prediction Science and Brain Science.


The complexity class inclusion diagram on page 67 was a key concession I did win. (Apparently some editors felt a Venn diagram with P, NP, BQP, and PSPACE would be way too complicated, even for readers who regularly gobble down heaping helpings of M-theory.)  As you can imagine, exposing people to this stuff seemed pretty important to me: this is apparently the first time P, NP, and NP-completeness have been explained at any length in Scientific American since articles by Knuth and by Lewis and Papadimitriou in the 1970s.


In the author bio on page 67, the description of me as a high school dropout is a slight exaggeration, but theres no other short term for what I am (see here for more).


I had nothing to do with the sidebar on page 68, about Vernor Vinges novel A Fire Upon the Deep.  Ive never read that (or anything else by Vinge for that matter).


My original draft included explanations of both the polynomial and adversary methods for quantum lower bounds, with references to BBCMdW and Ambainis.  Shockingly, all of that was cut, while the part about time machines was greatly expanded.

During the hairiest parts of editing process, I was reminded of a passage in Anita and Solomon Fefermans biography of the great logician Alfred Tarski, which described Tarskis writing of an article for Scientific American (the only popular article he ever wrote).
Usually the Scientific American articles are heavily edited; many are rewriteen and some even ghostwritten, but Wisnovsky [Tarskis editor] knew better than to tamper with Tarskis work and did not  except for his usage of which and that.  It seemed to him that Tarski did a 180-degree reversal of these words, so he changed every which to that and every that to which and sent the proofs to Tarski, who changed everything back to the way it had been.  Wisnovsky got out Fowlers Dictionary of Modern English Usage, the house bible, and called Tarski on the telephone.  I asked if I could read him the relevant passage on that and which and he said, yes.  It goes on for pages, but he listened very patiently until I finished.  Then he said, Well, you see, that is Fowler.  I am Tarski.  The minute he said that I caved in.  I felt cut off at the knees and I gave up trying to make any changes at all.
Yet, while the Tarski approach to magazine writing is a tempting one, heres the final irony.  I looked up Tarskis actual article from 1969, and it badly needed an editor.Dude, its like you read my mind

Newcombs Problem, for those of you with social lives, is this. A superintelligent Predictor puts two opaque boxes on a table. The first contains either $1,000,000 or nothing, while the second contains $1,000. You have a choice: you can either open the first box or both boxes. Either way, you get to keep whatever you find.
But (duhhh) theres a catch: the Predictor has already predicted what youll do. If he predicted youll open both boxes, then he left the first box empty; if he predicted youll open the first box only, then he put $1,000,000 in the first box. Furthermore, the Predictor has played this game hundreds of times before, with you and other people, and has never once been wrong.
So what do you do?  As Robert Nozick wrote, in a famous 1969 paper:
To almost everyone, it is perfectly clear and obvious what should be done. The difficulty is that these people seem to divide almost evenly on the problem, with large numbers thinking that the opposing half is just being silly.
Actually, people confronted with Newcombs Problem tend to split into three camps: the one-boxers, the two-boxers, and the Wittgensteins.
The one-boxers figure they might as well trust the Predictor: after all, hes never been wrong. According to the prediction, if you open the first box youll get $1,000,000, while if you open both youll only get $1,000. So its a no-brainer: you should open only the first box.
But thats stupid! say the two-boxers. By the time youre making the choice, the $1,000,000 is either in the first box or it isnt. Your choice cant possibly change the past. And whatever youd get by opening the first box, youll get $1,000 more by opening both.  So obviously you should open both boxes.
(Incidentally, dont imagine you can wiggle out of this by basing your decision on a coin flip! For suppose the Predictor predicts youll open only the first box with probability p. Then hell put the $1,000,000 in that box with the same probability p. So your expected payoff is 1,000,000p2 + 1,001,000p(1-p) + 1,000(1-p)2 = 1,000,000p + 1,000(1-p), and youre stuck with the same paradox as before.)
The Wittgensteins take a third, boring way out. The whole setup is contradictory! they say. Its like asking what happens if an irresistable force hits an immovable object. If the Predictor actually existed, then you wouldnt have free will, so you wouldnt be making a choice to begin with. Your very choice implies that the Predictor cant exist.
I myself once belonged to the Wittgenstein camp. Recently, however, I came up with a new solution to Newcombs Problem  one that I dont think has ever been discussed in the literature. (Please correct me if Im wrong.) As I see it, my solution lets me be an intellectually-fulfilled one-boxer: someone who can pocket the $1,000,000, yet still believe the future doesnt affect the past. I was going to write up my solution for a philosophy journal, but what fun is that? Instead, I hereby offer it for the enlightenment and edification of Shtetl-Optimized readers.
Well start with a definition:
You are anything that suffices to predict your future behavior.
I know this definition seems circular, but it has an important consequence: that if some external entity could predict your future behavior as well as you could, then wed have to regard that entity as instantiating another copy of you. In other words, just as a perfect simulation of multiplication is multiplication, Im asserting that a perfect simulation of you is you.
Now imagine youre standing in front of the boxes, agonizing over what to do.  As the minutes pass, your mind wanders:
I wonder what the Predictor thinks Ill decide? Predictor! What a pompous asshole. Thinks he knows me better than I do. Hes like that idiot counselor at Camp Kirkville  what was his name again? Andrew. I can still hear his patronizing voice: You may not believe me now, but someday youll realize you were wrong to hide those candy bars under the bed. And I dont care if you hate the cafeteria food! What about the other kids, who dont have candy bars? Didnt you ever think of them? Well, you know what, Predictor? Lets see how well you can track my thoughts. Opening only one box would be rather odd, wouldnt you say? Camp Kirkville, Andrew, candy bar  thats 27 letters in total. An odd number. So then that settles it: one box.
Whats my point? That reliably predicting whether youll take one or both boxes is you-complete, in the sense that anyone who can do it should be able to predict anything else about you as well. So by definition, the Predictor must be running a simulation of you so detailed that its literally a copy of you. But in that case, how can you possibly know whether youre the real you, or a simulated version running inside the Predictors mind?
But thats silly! you interject. Here, Ill prove Im the real me by pinching myself! But of course, your simulated doppelganger says and does exactly the same thing. Lets face it: the two of you are like IP and PSPACE, water and H2O, Mark Twain and Samuel Clemens.
If you accept that, then the optimal strategy is clear: open the first box only. Sure, you could make an extra $1,000 by opening both boxes if you didnt lead a double life inside the Predictors head, but you do. That, and not backwards-in-time causation, is what explains how your decision can affect whether or not theres $1,000,000 in the first box.
An important point about my solution is that it completely sidesteps the mystery of free will and determinism, in much the same way that an NP-completeness proof sidesteps the mystery of P versus NP. What I mean is that, while it is mysterious how your free will could influence the output of the Predictors simulation, it doesnt seem more mysterious than how your free will could influence the output of your own brain! Its six of one, half a dozen of the other. Or at least, thats what the neural firings in my own brain have inexorably led me to believe.The Nerderer

Alas, this weekend I became engrossed by the OJ Simpson trial for nerds: the ongoing trial of Hans Reiser (the famous Linux file system developer and supposedly-brilliant high-school accelerant) for the murder of his ex-wife Nina.  What makes the case interesting is that Reisers defense largely consists of the claim that he was too nerdy and Aspbergerish, too lacking in basic social skills, to realize that doing innocuous things in the weeks following Ninas disappearance like

removing the passenger seat of his car, soaking the floorboards, and hiding the car several miles from his house,
not returning calls from numerous friends and family members searching for his ex-wife (except to tell one that he needed to talk to his lawyer),
hiding his hard disks, and
telling his mother (in a wiretapped phone conversation) why he was happy his ex-wife went missing

might lead non-nerds to suspect he was guilty.
Like the Twinkie defense, Reisers nerd defense is an invitation to parody.  But my feeling is that in this case, even the nerd characterization of Reiser itself is open to question.  For one thing, Reiser has a blackbelt in judo and appears to have been obsessed with cultivating physical aggressiveness, both in himself and in his eight-year-old son.  For another, it seems the reason he was able to attract Nina in the first place was his swaggering confidence.  So while portraying Reiser as a nerdy nebbish might be convenient both for journalists and for Reisers defense team, he seems to me to be much closer to an aggressive narcissist.
(Of course that doesnt imply hes guilty.  But I have to say that, thus far in the trial, Reiser and his defense lawyer have done an excellent job of convincing me that he is.  Certainly the defense theory  that in an elaborate frame-up of Hans, Nina suddenly abandoned her two children, friends, and new job, left her car by the side of the road with the groceries to rot in the back, and went into hiding in an unspecified former Soviet state with a fake identity and passport  is difficult for a sane person to accept.  And unfortunately for Hans, the fact that Nina was far from a perfect specimen of humanity  sleeping with Hanss best friend, embezzling his companys money, and divorcing him as soon as she got her US citizenship  only adds to the prima facie likelihood that her body is currently rotting somewhere in the Sierra Nevadas.)
On the other hand, Reiser was certainly wise to hide his hard disks rather than relying on disk encryption.  For this week a team of nine researchers at Princeton and elsewhere  including my friends Alex Halderman and Nadia Heninger  released a paper showing how to take a DRAM chip out of one computer, put it into another computer, and read its contents even though the chip had no power in the interim.  (One hint: use canned-air spray dusters as a cheap alternative to liquid nitrogen for cryopreserving the chip.)  The story made it to the Science Times, although they failed to mention most of the authors by name.
But, you ask, how else have I been procrastinating this weekend?  Ah.  Peter Woit links to a remarkable set of oral histories from people who were involved with the Princeton math department in the 1930s.  Read Alonzo Church (he of the Church-Turing Thesis) list his graduate students and forget to mention Alan Turing, and Nathan Jacobson talk about the disgusting food that Mrs. Einstein would bring to department receptions.  In the midst of possibly the greatest concentration of intellect the world has ever seen or will see, and on the eve of perhaps the greatest calamity the world has ever seen, what is it that people worried about?  The oak paneling in Fine Hall, and other trivialities completely different from the sorts of things we academics would worry about today.
Oh right: at the behest of you, my loyal readers, Im now more than halfway through Vernor Vinges A Fire Upon The Deep, an entertaining novel that depicts a far future with malevolent AI beings, faster-than-light travel, and (possibly the nerdiest science-fiction premise of all time) Usenet newsgroups spanning the galaxy, whose flamewars play a major role in the rise and fall of civilizations.  Vinges estimate of how much longer Usenet would stay relevant was off by a factor of only about 10,000.Sourkatz

A reader named Hernan asked me for my opinion of a well-known rant by Jonathan Katz of Washington University, about why young people shouldnt go into academic science since there are so few jobs and the jobs that there are stink anyway.  I posted my response in the comments section, but since it seems to be of general interest I thought Id make a proper entry of it.
Katz is correct that opportunities in academic science (at least in the US) are much scarcer than they were during the Cold War; I think government shortsightedness deserves a huge part of the blame for that. On the other hand, countless would-be grad students have already followed the invisible hand and taken Katzs advice, and are doing quite well in Wall Street, Silicon Valley, etc. So the ones going to grad school are mostly the ones willing to assume the (by now well-known) risks: if they werent, they wouldnt be there.
My fundamental disagreement with Katz is that I think PhD work is increasingly excellent preparation for industry careers. Of course, in some cases (e.g. a quantum computing PhD going to work for an Internet startup), its hard to argue that the PhD provides much beyond general skills like analytical thinking, teamwork, project completion, etc., and that those skills couldnt just as well be obtained elsewhere. But even in those cases, I think a PhD at least wont hurt your chances in industry these days (notwithstanding Phil Greenspuns PhD expunging service).  So what the PhD does is to give many people an opportunity to spend six years advancing human knowledge and doing something they enjoy, before switching to something thats actually rewarded by the economy. (One corollary is that, if youre not enjoying grad school, then you shouldnt be there. But this is just an instance of a general rule: dont choose a career option that causes you years of suffering in the hope that the suffering will end later; it probably wont.)
Furthermore, if there used to be a stigma attached to leaving grad school for industry, I think thats basically vanished, and that now many PhD programs even see training students for industry as a fundamental part of their mission.
I cant comment on the rest of Katzs complaints (the need for conformity, the burden of writing grant proposals, etc.), except to say that so far, my own experience has been more positive.  Maybe the worst is ahead!
Incidentally, my comments apply most clearly to computer science PhD programs, which are what Im most familiar with, but I believe they also apply to physics and other sciences. As for humanities PhDs  dude, youre on your own.Penroses Gdel argument in rap

About as logically sound as the original, and with a better backbeat (link to MP3).  From computer science grad student / hip-hop artist MC Plus+.Long-dreaded politics post

Until today, I have failed to uphold one of the most sacred responsibilities of the guild of bloggers: that of weighing in on the Democratic primary.  This is not because of any desire to keep politics out of this blog: Ive never succeeded in keeping anything out of this blog.  Rather, its because I find the question genuinely difficult.
The general election is so damn easy by comparison.  There, the only questions I need to ask myself are, do I prefer the Enlightenment or the Dark Ages that preceded it?  Is the Earth 4.6 billion years old or 10,000?  Do anti-gay laws spring from a less repugnant part of human nature than Jim Crow laws?  While I look forward to the day when my answers to such questions wont determine my vote, so far they unfailingly have  thereby eliminating the need for me to adjudicate more complicated social and economic issues that I dont really understand.
In other words, my view of Democrats and Republicans couldnt possibly be further from that of (say) Eliezer Yudkowsky, who sees the general US election as a meaningless, Kang vs. Kodos popularity contest. Like Yudkowsky, I can easily imagine two political parties fighting over nothing  but what I see in reality is a clearly-identifiable neo-Union and neo-Confederacy, who every four years re-fight the Civil War.  As many others have pointed out, even the geographic boundary between Americas two subcountries has barely changed since the 1860s; the one real irony is that the party of Lincoln now represents the Confederate side.  (And yes, if the free-market/libertarian wing of the Republican Party ever broke free of the medieval wing, then this correspondence would break down.  Im only talking about things as they currently stand.)
On the other hand, as Clinton and Obama debated their subtly-different proposals for health insurance, subprime lending reform, etc., I realized that, in a race between Democrats (or a general election in a more normal country), my go with the Enlightenment approach can only take me so far.  Faced with two non-lunatic candidates, you almost have to, like, know something about policy or economics to make a sensible choice.
So being an ignorant computer scientist, what can I say?  Lets start with the obvious: that after seven years of Bush, to ask whether Id prefer Hillary or Obama is like asking a drowning person surrounded by sharks which of two lifeboats he prefers to be rescued by (and adding, in case its helpful, that one lifeboat is rowed by a woman and the other by a half-Kenyan).  Its a shame we cant elect both of them, and then send one back in time to have been president for the last eight years.  As the next best option, I wish the candidates would just agree right now to choose the winner by an Intrade-weighted coin flip, and thereby save money for defeating the religious-right-courting hypocrite McCain.
But of course they wont do that, and hence the question of whom to prefer.  Until recently I had a mild preference for Hillary, my reasons being as follows:

Because shes been despised for so many years by so many people who I despise (and the worse they say about her, the better she seems).
Because shes been doing better than Obama in crucial swing states like Florida.
Because with her you get all the advantages of her husband but with considerably less chance of a sex scandal.
Because on one issue that I actually follow  ending the Republicans war on science  her position paper is full of excellent specifics, whereas (so far as I know) Obama has only said much vaguer things in the same direction.

Recently, though, Ive been tilting more toward Obama, for five reasons:

Because hes winning (still, after last night).   This, of course, would be an important piece of evidence about his likelihood of winning the general election, even if it werent also a prerequisite to winning.
Because unlike Hillary, hes clearly stated his position on the inefficiency of bubblesort.
Because Im told that some Americans now supplement their reading of text by the viewing of YouTubes and tele-vision boxes  and in those settings, Obama clearly does better.  His jokes succeed where Hillarys fail.
Because the 2000 and 2004 elections suggest that experience is now a severe liability: it simply translates into more stuff that an opponent will twist against you.
Because people whose judgment I respect, and who follow politics more closely than I do, seem to prefer Obama by a wide margin. As in Aumanns Agreement Theorem, the mere fact of these other peoples opinions ought to change my own opinion if Im a rational agent.  Whether for rational reasons or not, it has.

Incidentally, so far as I can tell, the accusations of anti-Semitism against Obama that have filled the right-wing blogosphere are completely baseless. The assumption underlying these accusations is that admiration is a transitive predicate: that is, if x admires y and y admires z (where, say, z=Farrakhan), then x must admire z, even if x claims to reject and denounce z.  But its easy to think of counterexamples: I admire Sakharov who admired Stalin (at least for part of his life), I admire Bertrand Russell who admired all sorts of thugs and poseurs, etc.  Of course its impossible to know Obamas heart about these matters, but I dont think one needs to: its enough to know his brain.Statement on conceptual contributions in theory

About six months ago, a group of theoretical computer scientists started raising concerns about what they saw as a growing problem in our field.  (My parody post FOCS36 notification was one attempt to explain what this problem is.)  The group has now put together a statement, which I was happy to sign, and which is meant to serve as a starting point for further discussion at the STOC08 business meeting.  If you support this statement and want add your name to it, please say so in the comments section! Of course criticism is welcome too. SA
We, the undersigned, are concerned about two related attitudes that seem to be increasingly prevalent in the TCS community, and in particular, are affecting its program committees and their decisions.  The goal of this statement is to attempt to recognize and reverse this trend.  We are happy to note that the STOC08 PC made a conscious effort to move in the direction of this proposal. The trends that worry us are the followingGreat Ideas In Theoretical Computer Science Lectures 2-7

For those who missed it on the sidebar, we now have six more GITCS lecture notes available:
Lecture 2: Logic
Lecture 3: Circuits and Finite Automata

Lecture 4: Turing Machines
Lecture 5: Reducibility and Gdel
Lecture 6: Minds and Machines
Lecture 7: Complexity
More are on the way  compared to the Democritus notes, its so much easier with others doing the writing!  These notes were prepared almost entirely by the students, with only minor editing from me and Yinmeng.  In general, I think the students have been doing a fantastic job.  On the other hand, if you rely on these notes to build a Turing-machine-controlled jumbo jet which then crashes in the Himalayas, its entirely possible that it wasnt my fault.Mistake of the Week: But even an X says so!

Consider the following less-than-hypothetical scenarios:

Joseph Weizenbaum (who passed away two weeks ago), the MIT computer scientist who created the ELIZA chatbot in the 1960s, spent the rest of his career decrying the evils of computer science research, holding (perhaps strangely) both that almost everything thats done with computers could be done just as well without them, and that computers have made possible terrible things like missile guidance systems that now threaten our civilization.


Distinguished mathematician Doron Zeilberger argues that mathematicians are wasting their time pursuing chimeras like beauty and elegance, and that within the near future, mathematics will be entirely the domain of computers.


Ayaan Hirsi Ali, who was born into a Muslim family in Somalia, and who escaped from an arranged marriage after being forced to undergo FGM, tells Westerners theyre deluding themselves if they think current Islamic practices are compatible with Enlightenment values.


John Browne, the Chief Executive of BP, tells the world that urgent action is needed on global warming.


A former atheist stumps for Christianity (or vice versa).

The obvious question in all these cases is: how much extra credence does a person gain by belonging, or having once belonged, to the group he or she is criticizing?  From a strict rationalist standpoint, the answer would seem to be zero: surely all that matters is the soundness of the arguments!  Who cares if the keynote speaker at the anti-widget rally also happens to be past president of the Widget Club?
I can think of three possible reasons for giving extra credence to attacks from insiders:

The insider might simply know more about the realities of the situation than an outsider, or be less able to ignore those realities.
One assumes the insider is someone whos at least grappled with the best arguments from her own side before rejecting them.  (In FantasyLand, one could assume that anyone making an argument had first grappled with the best arguments from the opposing side, but FantasyLandEarth.)
When someone relentlessly attacks a single group of people  seeming to find them behind every perfidy on earth  history says to assume the worst about their motivations, and not to accept the refrain Im only criticizing them for their own good! However, its possible that members of the group themselves should merit a pass in this regard.  (Though even here there are exceptions: for example, if the person has renounced all ties with the despised group, or, as in the case of Bobby Fischer, refuses to accept the reality of his membership in it.)

On the other hand, I can think of five reasons why not to give extra credence to attacks from insiders:

Given any exotic mixture of beliefs and group affiliations, theres almost certainly someone on earth who fits the description  and is even available for a fee to speak at your next event.  If you want an accomplished scientist who sees science as an expensive sham or tool of the military, you can find one.  If you want a former Republican hardliner whos now a Naderite, you can find one.  If you want a Jew who renounces Jews or Israel, you can find a stadium of them. So you cant conclude anything from the mere existence of such people  at most, you can possibly learn something from their number.
Any group of people  computer scientists, CEOs, Israelis, African-Americans  will consist (to put it mildly) of multiple factions, some of whom might seek to gain an advantage over the other factions by blasting their group as a whole before the outside world. So one cant simply accept someones presentation of himself as a lone, courageous whistleblower, without first understanding the internal dynamics of the group he comes from and is criticizing.
The very fact that people within a group feel free to criticize it can in some cases speak well about the groups tolerance for dissent, and thereby undermine some of the critics central claims.  (Of course, one has to verify that the tolerated dissenters arent just a sham maintained by the ruling faction, as in Communist regimes throughout their history.)
Some people simply enjoy dissenting from their peers, as a way of proving their independence or of drawing attention to themselves.
Just as most people like to toot their own groups horn, a few are masochistically biased toward the opposite extreme.  We can all think of people who, for whatever deep psychological reasons, feel a constant need to repent the sins of themselves or their group, in a manner wildly out of proportion to any actual guilt. Granted, anyone can understand the conflict a physicist might feel over having participated in the Manhattan Project.  On the other hand, when the invention youre renouncing is the ELIZA chatbot, the question arises of whether youve earned the right to Faust-like penitence over the unspeakable evil youve unleashed.

So whats my verdict?  Belonging to the group youre criticizing can give you one or two free starting chips at the table of argument, entitling you to a hearing where someone else wouldnt be so entitled.  But once youve sat down and entered the game, from then on you have to play by the same rules as everyone else.Veiled humor

I just finished Marjane Satrapis Persepolis, the most astonishing comic book Ive ever seen.  Persepolis tells the story of Satrapis childhood in Iran, during which she witnessed the repressive regime of the Shah, then the takeover by Khomeini (who made the Shah look like Mr. Rogers), then the war with Iraq.  What makes the story so compelling is not the horrors  next-door neighbors killed by an Iraqi missile, relatives tortured and executed for counterrevolutionary activities, etc.  but Satrapi and her friends absurd attempts to enjoy a normal childhood while all of this was going on.  She describes how the girls in her school, suddenly forced to wear veils, would put them on backwards and pretend to be monsters of the darkness; how her dad brought her an Iron Maiden poster from Turkey by weaving it into his suit, lurching through airport security like Frankensteins monster; how a food shortage that emptied the supermarkets of everything but kidney beans provided an occasion for fart jokes.  For me, reading this book only deepened the mystery of Iran: namely, how could such a funny, literate, humane country be conquered so completely by fundamentalist thugs?  On reflection, I guess its happened before.  And I guess I should be grateful that in the US, our secular institutions are strong enough that even Bush hasnt destroyed them entirely.
Persepolis raises pointed questions about the navet of intellectuals, like the Iranian Marxists who refused to see the Islamists for what they were until it was too late.  To any intellectuals still in Iran, I can only second Eldars advice, in the comments to a previous post: Get out!  Get out now!  And to everyone else, set aside a couple hours (which is all it takes) to read Persepolis.  It might be the first comic book to win a Nobel Prize in Literature.Great Ideas in Theoretical Computer Science Lectures 8-11

A few more lectures, hot off the Turing machine tape:

Lecture 8: Polynomial Time
Lecture 9: P and NP
Lecture 10: NP-completeness
Lecture 11: NP-completeness in Practice

Yeah, its all standard material, but if you dont know it  well, this is one more place you can learn.
Apropos of computer science education, some of you may have heard the sad news that the College Board is killing the AP Computer Science AB test [Slashdot] [Pontiff].  The reasons they gave were that (1) not enough students were taking it and (2) of those who were, not enough were underrepresented minorities.
I took the AB test in 96, despite not having taken the course (my high school didnt offer it) and not knowing Pascal (the language they still used, before they switched to C++ and then Java).  I did read a book to prepare, and thats where I got my first exposure to O-notation, linked lists, and other crumbs from the feast table of theory.  I devoured it all like a hungry dog licking the floor.
It goes without saying that high school students (including underrepresented minorities) wont take an AP course if it isnt offered, or if their schools or the colleges theyre applying to dont take it seriously.   Computer science education is a threat to many peoples pet ideas about the world: that CS is not a real subject and is devoid of intellectual content. That everything having to do with computers is mundane and technical, and should (for that reason) be outsourced to China and India. That if we must teach CS, we should at least focus on applications, and get rid of any math or logical thought. That CS is pass, a 20th-century relic that was long ago superseded by the life sciences (havent computer scientists gotten the message yet?).  Against this backdrop, its not surprising that the AB test is being killed: whats surprising is that it lasted so long.
Blogging will continue to be sporadic, as I have a cold.
Update (4/10): Lenore Blum just gave a talk here at MIT about the future of CS education, in which she echoed several themes of this post, but also argued (among other things) that the cancellation of APCSAB is good news given the courses obsessive focus on the details of the programming language du jour, and given high schools refusal to treat it as a real academic subject, instead grouping it with electives like woodshop and metalworking.  She held out hope that the US will someday develop a reasonable K-12 computer science curriculum, pointing to successful models from Israel and New Zealand.   Needless to say, I have mixed feelings about canceling the mediocre (AB), keeping the truly bad (A), and hoping for the distant good.Open thread

Ive had a miserable week (only partly because of the headaches and coughing fits that have been keeping me up all night), and feel a need to be of use to some other human being without leaving my apartment. So this thread is for you to ask about whatevers on your mind  complexity classes, philosophy, grad school advice, anteaters  anything asked in earnest will be responded to, in considerably less than the two years it took me for Lev R.
Update (4/13): Having spent a good part of the weekend answering 57 questions about everything from quantum computing to painting elephants, I think its time to call it quits. Thanks to everyone who submitted; it really cheered me up! Well do this again sometime.Great Ideas in Theoretical Computer Science Lectures 12-15

Yeah, yeah, I know.  Combination of the end of the semester and family matters.  But Im back with four more GITCS lectures:

Lecture 12: Space Complexity and More


Lecture 13: Randomness


Lecture 14: Probabilistic Complexity Classes


Lecture 15: Derandomization / Crypto Double Feature

Comments welcome as always.The bullet-swallowers

Question for the day: what do libertarianism and the Many-Worlds Interpretation of quantum mechanics have in common?  Interest in the two worldviews seems to be positively correlated: think of quantum computing pioneer David Deutsch, or several prominent posters over at Overcoming Bias, or  oh, alright, my sample size is admittedly pretty small.
Some connections are obvious: libertarianism and MWI are both grand philosophical theories that start from premises that almost all educated people accept (quantum mechanics in the one case, Econ 101 in the other), and claim to reach conclusions that most educated people reject, or are at least puzzled by (the existence of parallel universes / the desirability of eliminating fire departments).  Both theories seem to have a strong following with nerds who read science fiction and post to Internet discussion groups, but a relatively poorer following with both John Q. Public and Alistair K. Intellectual.    (Needless to say, these stereotypes tell us almost nothing about the theories validity.)
My own hypothesis has to do with bullet-dodgers versus bullet-swallowers.  A bullet-dodger is a person who says things like:
Sure, obviously if you pursued that particular line of reasoning to an extreme, then youd get such-and-such an absurd-seeming conclusion.  But that very fact suggests that other forces might come into play that we dont understand yet or havent accounted for.  So lets just make a mental note of it and move on.
Faced with exactly the same situation, a bullet-swallower will exclaim:
The entire world should follow the line of reasoning to precisely this extreme, and this is the conclusion, and if a consensus of educated opinion finds it disagreeable or absurd, then so much the worse for educated opinion!  Those who accept this are intellectual heroes; those who dont are cowards.
In a lifetime of websurfing, I dont think Ive ever read an argument by a libertarian or a Many-Worlds proponent that didnt sound like the latter.
We know plenty of historical examples where the bullet-swallowers were gloriously right: Moores Law, Darwinism, the abolition of slavery, womens rights.  On the other hand, at various points within the last 150 years, extremely smart people also reasoned themselves to the inescapable conclusions that aether had to exist for light to be a wave in, that capitalism was reaching its final crisis, that only a world government could prevent imminent nuclear war, and that space colonies would surely exist by 2000.  In those cases, even if you couldnt spot any flaws in the arguments, you still wouldve been wise to doubt their conclusions.  (Or are you sure you would have spotted the flaws where Maxwell and Kelvin, Russell and Einstein did not?)
Heres a favorite analogy.  The world is a real-valued function thats almost completely unknown to us, and that we only observe in the vicinity of a single point x0.  To our surprise, we find that, within that tiny vicinity, we can approximate the function extremely well by a Taylor series.
Aha! exclaim the bullet-swallowers.  So then the function must be the infinite series, neither more nor less.
Not so fast, reply the bullet-dodgers.  All we know is that we can approximate the function in a small open interval around x0.  Who knows what unsuspected phenomena might be lurking beyond it?
Intellectual cowardice! the first group snorts.  Youre just like the Jesuit schoolmen, who dismissed the Copernican system as a mere calculational device!  Why cant you accept what our best theory is clearly telling us?
So whos right: the bullet-swallowing libertarian Many-Worlders, or the bullet-dodging intellectual kibitzers?  Well, that depends on whether the function is sin(x) or log(x).Floating in Platonic heaven

In the comments section of my last post, Jack in Danville writes:
I may have misunderstood [an offhand comment about the irrelevance of the Continuum Hypothesis]  Intuitively Ive thought the Continuum Hypothesis describes an aspect of the real world.
I know weve touched on similar topics before, but something tells me many of you are hungerin for a metamathematical foodfight, and Jacks perplexity seemed as good a pretext as any for starting a new thread.
So, Jack: this is a Deep Question, but let me try to summarize my view in a few paragraphs.
Its easy to imagine a physical process whose outcome could depend on whether Goldbachs Conjecture is true or false.  (For example, a computer program that tests even numbers successively and halts if it finds one thats not a sum of two primes.)  Likewise for P versus NP, the Riemann Hypothesis, and even considerably more abstract questions.
But can you imagine a physical process whose outcome could depend on whether theres a set larger than the set of integers but smaller than the set of real numbers?  If so, what would it look like?
I submit that the key distinction is between

questions that are ultimately about Turing machines and finite sets of integers (even if theyre not phrased that way), and
questions that arent.

We need to assume that we have a direct intuition about integers and finite processes, which precedes formal reasoning  since without such an intuition, we couldnt even do formal reasoning in the first place.  By contrast, for me the great lesson of Gdel and Cohens independence results is that we dont have a similar intuition about transfinite sets, even if we sometimes fool ourselves into thinking we do.  Sure, we might say were talking about arbitrary subsets of real numbers, but on closer inspection, it turns out were just talking about consequences of the ZFC axioms, and those axioms will happily admit models with intermediate cardinalities and other models without them, the same way the axioms of group theory admit both abelian and non-abelian groups.  (Incidentally, Gdels models of ZFC+CH and Cohens models of ZFC+not(CH) both involve only countably many elements, which makes the notion that theyre telling us about some external reality even harder to understand.)
Of course, everything Ive said is consistent with the possibility that theres a truth about CH floating in Platonic heaven, or even that a plausible axiom system other than ZFC could prove or disprove CH (which was Gdels hope).  But the truth of CH is not going to have consequences for human beings or the physical universe independent of its provability, in the same way that the truth of P=NP could conceivably have consequences for us even if we werent able to prove or disprove it.
For mathematicians, this distinction between CH-like questions and Goldbach/Riemann/Pvs.NP-like questions is a cringingly obvious one, probably even too obvious to point out.   But Ive seen so many people argue about Platonism versus formalism as if this distinction didnt exist  as if one cant be a Platonist about integers but a formalist about transfinite sets  that I think its worth hammering home.
To summarize, Kronecker had it backwards. Man and Woman deal with the integers; all else is the province of God.The array size of the universe

Ive been increasingly tempted to make this blog into a forum solely for responding to the posts at Overcoming Bias.  (Possible new name: Wallowing in Bias.)
Two days ago, Robin Hanson pointed to a fascinating paper by Bousso, Harnik, Kribs, and Perez, on predicting the cosmological constant from an entropic version of the anthropic principle.   Say what you like about whether anthropicology is science or not, for me theres something delightfully non-intimidating about any physics paper with anthropic in the abstract.  Sure, you know its going to have metric tensors, etc. (after all, its a physics paper)  but you also know that in the end, its going to turn on some core set of assumptions about the number of sentient observers, the prior probability of the universe being one way rather than another, etc., which will be comprehensible (if not necessarily plausible) to anyone familiar with Bayes Theorem and how to think formally.
So in this post, Im going to try to extract an anthropic core of Bousso et al.s argument  one that doesnt depend on detailed calculations of entropy production (or anything else)  trusting my expert readers to correct me where Im mistaken.  In defense of this task, I can hardly do better than to quote the authors themselves.  In explaining why they make what will seem to many like a decidedly dubious assumption  namely, that the number of observations in a given universe should be proportional to the increase in non-gravitational entropy, which is dominated (or so the authors calculate) by starlight hitting dust  they write:
We could have  continued to estimate the number of observers by more explicit anthropic criteria.  This would not have changed our final result significantly.  But why make a strong assumption if a more conservative one suffices? [p. 14]
In this post Ill freely make strong assumptions, since my goal is to understand and explain the argument rather than to defend it.
The basic question the authors want to answer is this: why does our causally-connected patch of the universe have the size it does?  Or more accurately: taking everything else we know about physics and cosmology as given, why shouldnt we be surprised that it has the size it does?
From the standpoint of post-1998 cosmology, this is more-or-less equivalent to asking why the cosmological constant  ~ 10-122 should have the value it has.  For the radius of our causal patch scales like
1/ ~ 1061 Planck lengths ~ 1010 light-years,
while (if you believe the holographic principle) its maximum information content scales like 1/ ~ 10122 qubits. To put it differently, there might be stars and galaxies and computers that are more than ~1010 light-years away from us, and they might require more than ~10122 qubits to describe.  But if so, theyre receding from us so quickly that well never be able to observe or interact with them.
Of course, to ask why  has the value it does is really to ask two questions:
1. Why isnt  smaller than it is, or even zero?  (In this post, Ill ignore the possibility of its being negative.)
2. Why isnt  bigger than it is?
Presumably, any story that answers both questions simultaneously will have to bring in some actual facts about the universe. Lets face it: 10-122 is just not the sort of answer you expect to get from armchair philosophizing (not that it wouldnt be great if you did).  Its a number.
As a first remark, its easy to understand why  isnt much bigger than it is.  If it were really big, then matter in the early universe wouldve flown apart so quickly that stars and galaxies wouldnt have formed, and hence we wouldnt be here to blog about it.  But this upper bound is far from tight.  Bousso et al. write that, based on current estimates,  could be about 2000 times bigger than it is without preventing galaxy formation.
As for why  isnt smaller, theres a naturalness argument due originally (I think) to Weinberg, before the astronomers even discovered that >0.  One can think of  as the energy of empty space; as such, its a sum of positive and negative contributions from all possible scalar fields (or whatever else) that contribute to that energy. That all of these admittedly-unknown contributions would happen to cancel out exactly, yielding =0, seems fantastically unnatural  if you choose to think of the contributions as more-or-less random.  (Attempts to calculate the likely values of , with no anthropic correction, notoriously give values that are off by 120 orders of magnitude!)  From this perspective, the smaller you want  to be, the higher the price you have to pay in the unlikelihood of your hypothesis.
Based on the above reasoning, Weinberg predicted that  would have close to the largest possible value it could have, consistent with the formation of galaxies.  As mentioned before, this gives a prediction thats too big by a factor of 2000  a vast improvement over the other approaches, which gave predictions that were off by factors of 10120 or infinity!
Still, cant we do better?   One obvious approach to pushing  down would be to extend the relatively-uncontroversial argument explaining why  cant be enormous.  After all, the tinier we make , the bigger the universe (or at least our causal patch of it) will be.  And hence, one might argue, the more observers there will be, hence the more likely well be to exist in the first place!  This form of anthropicizing  that were twice as likely to exist in a universe with twice as many observers  is what philosopher Nick Bostrom calls the Self-Indication Assumption.
However, two problems with this idea are evident.  First, why should it be our causal patch of the universe that matters, rather than the universe as a whole? For anthropic purposes, who cares if the various civilizations that arise in some universe are in causal contact with each other or not, provided they exist?  Bousso et al.s response is basically just to stress that, from what we know about quantum gravity (in particular, black-hole complementarity), it probably doesnt even make sense to assign a Hilbert space to the entire universe, as opposed to some causal patch of it.  Their Causal-Patch Self-Indication Assumption still strikes me as profoundly questionable  but lets be good sports, assume it, and see what the consequences are.
If we do this, we immediately encounter a second problem with the anthropic argument for a low value of : namely, it seems to work too well!  On its face, the Self-Indication Assumption wants the number of observers in our causal patch to be infinite, hence the patch itself to be infinite in size, hence =0, in direct conflict with observation.
But wait: what exactly is our prior over the possible values of ?  Well, it appears Landscapeologists typically just assume a uniform prior over  within some range.  (Can someone enlighten me on the reasons for this, if there are any?  E.g., is it just that the middle part of a Gaussian is roughly uniform?)  In that case, the probability that  is between  and 2 will be of order   and such an event, we might guess, would lead to a universe of size 1/, with order 1/ observers.  In other words, it seems like the tiny prior probability of a small cosmological constant should precisely cancel out the huge number of observers that such a constant leads to  (1/)=1  leaving us with no prediction whatsoever about the value of .  (When I tried to think about this issue years ago, thats about as far as I got.)
So to summarize: Bousso et al. need to explain to us on the one hand why  isnt 2000 times bigger than it is, and on the other hand why its not arbitrarily smaller or 0.  Alright, so are you ready for the argument?
The key, which maybe isnt so surprising in retrospect, turns out to be other stuff thats known about physics and astronomy (independent of ), together with the assumption that that other stuff stays the same (i.e., that all were varying is ).  Sure, say Bousso et al.: in principle a universe with positive cosmological constant  could contain up to ~1/ bits of information, which corresponds  or so a computer scientist might estimate!  to ~1/ observers, like maybe ~1/ observers in each of ~1/ time periods.  (The 1/ comes from the Schwarzschild bound on the amount of matter and energy within a given radius, which is linear in the radius and therefore scales like 1/.)
But in reality, that 1/ upper bound on the number of observers wont be anywhere close to saturated.   In reality, what will happen is that after a billion or so years stars will begin to form, radiating light and quickly increasing the universes entropy, and then after a couple tens of billions more years, those stars will fizzle out and the universe will return to darkness.  And this means that, even though you pay a  price in prior probability for a universe with 1/ information content, as  goes to zero what you get for your money is not ~1/ observers in each of ~1/ time periods (hence ~1/ observers in total), but rather just ~1/ observers over a length of time independent of  (hence ~1/ observers in total).  In other words, you get diminishing returns for postulating a bigger and bigger causal patch, once your causal patch exceeds a few tens of billions of light-years in radius.
So thats one direction.  In the other direction, why shouldnt we expect  to be 2000 times bigger than it is (i.e. the radius of our causal patch to be ~45 times smaller)?  Well,  could be that big, say the authors, but in that case the galaxies would fly apart from each other before starlight really started to heat things up.  So once again you lose out: during the very period when the stars are shining the brightest, entropy production is at its peak, civilizations are presumably arising and killing each other off, etc., the number of galaxies per causal patch is minuscule, and that more than cancels out the larger prior probability that comes with a larger value of .
Putting it all together, then, what you get is a posterior distribution for  thats peaked right around 10-122 or so, corresponding to a causal patch a couple tens of light-years across.  This, of course, is exactly whats observed.  You also get the prediction that we should be living in the era when  is just taking over from gravity, which again is borne out by observation.  According to another paper, which I havent yet read, several other predictions of cosmological parameters come out right as well.
On the other hand, it seems to me that there are still few enough data points that physicists ability to cook up some anthropic explanation to fit them all isnt sufficiently surprising to compel belief.  (In learning theory terms, the measurable cosmological parameters still seem shattered by the concept class of possible anthropic stories.)  For those of us who, unlike Eliezer Yudkowsky, still hew to the plodding, non-Bayesian, laughably human norms of traditional science, it seems like whats needed is a successful prediction of a not-yet-observed cosmological parameter.
Until then, Im happy to adopt a bullet-dodging attitude toward this and all other proposed anthropic explanations.  I assent to none, but wish to understand them all  the more so if they have a novel conceptual twist that I personally failed to think of.Great Ideas in Theoretical Computer Science Lectures 16-19

In the next-to-last GITCS installment, we cover some of the greatest hits of the 70s and 80s.

Lecture 16: Private-Key Cryptography


Lecture 17: Public-Key Cryptography


Lecture 18: Cryptographic Protocols (including: how computer scientists date!)


Lecture 19: Interactive Proofs / Machine Learning

(Something tells me Lecture 18 is going to get more hits than the other three combined)
The course itself ended two weeks ago; last week was the final exam. Thanks so much to all of my students for signing up for a brand-new course, asking probing questions, enduring my excruciating jokes, and doing a fantastic job with the notes.   (Of course, thanks also to my eagle-eyed readers for spotting errors.)  Thanks above all to my TA, Yinmeng Zhang, who went way beyond her job description to work with students individually, tell me when I was being a doofus, etc.  Because of the input of everyone who participated, this course will be better when I teach it the second time around.
Also, for anyone who might want to teach a similar course, the recipe is simple (much simpler than I expected, actually):

Start with a standard, off-the-shelf, undergraduate computability and complexity theory course.
Cut out the most boring parts, like pushdown automata, context-free grammars, and 105000 NP-completeness reductions.  (Yes, I know these things can be taught in a non-boring way, but why make it hard on yourself?)
Fill in the gaps with more interesting material, like zero-knowledge proofs, computational learning theory, or quantum computing.
Add a pinch (to taste) of mindblowing results that cant be covered in detail, like the PCP Theorem, the independence of the Continuum Hypothesis, or cosmological limits on computation.

Serves 10-100.First we assume a circular CD

Over at Freedom to Tinker, Alex Halderman and his adviser Ed Felten have been causing headaches for SunnComm, the makers of broken technology designed to prevent the copying of music CDs. Alex is the Princeton graduate student who enjoyed worldwide media attention two years ago, when he showed that SunnComms MediaMax anti-copying software could be disabled by holding down the Shift key while inserting a CD into your computer. Alexs paper about this was downloaded over a hundred thousand times, and caused SunnComms stock to lose $10,000,000 in a week. By comparison, my paper Quantum Lower Bound for Recursive Fourier Sampling has (I think) been downloaded at least twice, and would have driven Recursive Fourier Sampling In 2o(h) Queries Incorporated out of business, had it existed.
Now Alex and Ed are reporting that SunnComm has continued to innovate. It seems that the latest version of MediaMax, which is included with several Sony/BMG music CDs,

secretly installs itself even before you accept the End User License Agreement,
remains installed even if you decline the agreement, and
secretly phones home to SunnComm with information about your activities, despite assurances to the contrary.

Alex and I met in seventh grade at Newtown Junior High School. I had just transferred from a parochial school, and was so low in the social hierarchy that, when kids beat me up, I was grateful for the attention. My one consolation was that, out of all the kids in the school, I  and I alone  knew that dx3/dx=3x2 and that t=t/(1-(v/c)2).  Most importantly, I alone knew how to program in GW-BASIC.
So you can imagine the existential shock when I heard there was another kid in seventh grade who was already writing Windows applications and marketing them as shareware. Clearly I had to meet this guy, see if he was for real. After I found out that he was  and repaired the gaping holes in my ego  Alex and I became best friends. We remain so twelve years later.
Even in junior high, Alex was obsessed with security issues: his bestselling program, if I remember correctly, was an encryption utility. At the same time, he was obviously a white hat. Rather than getting himself into trouble by hacking the school computers, hed simply make the teachers utterly reliant on his expertise, then ask them for administrator privileges.
One day in the cafeteria, Alex excitedly brought me a book he was reading, which described a bizarre-sounding encryption system called RSA. Supposedly, with this system you could send someone secret messages without ever having met them to agree on a key.
But thats obviously impossible, I explained. I was proud that, for once, I could use my superior mathematical knowledge to set Alex straight.
Eventually Alex and I both ended up in academic computer science, albeit on opposite sides of it. Perhaps the difference between us is best summarized as follows. For Alex, the impossibility of making digital information copy-proof is a central truth of our age: something to be explained, and then re-explained, to judges, reporters, and businesspeople, in amicus curiae briefs and interviews on NPR. For me, it follows from the fact that the set of n-bit strings constitutes an orthogonal basis for Hilbert space.How George W. Bush is changing my life for the better

Ill give you a hint: its not from the rebate checks.
Let me put it this way: from now on, I am going to exercise at least twice a week.  Im going to post the remaining Quantum Computing Since Democritus lectures.  Im going to finish writing up several papers that Ive been procrastinating on for years.  Im going to get involved in more non-work-or-blog-related social activities.  And Im going to do all of these things (and have friends and family members vouch for it) because if I dont, then money Ive already placed in escrow will be donated to the George W. Bush Presidential Library, as well as to the National Rifle Association.
Yeah, I signed up for the commitment contract service stickK.com, which was started in January by Yale economics professors Dean Karlan and Ian Ayres and student Jordan Goldberg.  You get to choose the anti-charities to which your money gets donated if you dont achieve your stated goals; surprisingly, stickK itself doesnt take a cut (it seems to get all its money from ad revenue).  The idea is obvious in retrospect; whats amazing is that it took this long for anyone to build a company around it.  So far it seems to be working.  For example, I jogged on Tuesday and went swimming this morning, despite not having exercised for the previous six months.  What remains to be seen is whether W. can inspire me to new heights of research productivity.
An enormous hat tip to Michael Nielsen.Quantum Computing Since Democritus Lecture 13: How Big Are Quantum States?

A year and a half after the actual course, the remaining Democritus lecture notes are finally being transcribed and posted  thanks to my new summer student, Chris Granade.  In Lecture 13, you can read about why QMA, QCMA, and BQP/qpoly are not merely complexity classes but battlefields, where competing visions of what quantum states really are face each other off in conflicts that we as theorists intentionally provoked.  (Work with me here.)Quantum Computing Since Democritus Lecture 14: Skepticism of Quantum Computing

I just came from Brookhaven National Lab, where I gave my standard colloquium talk on the limits of quantum computers, and got driven around the RHIC accelerator ring by physicist Rob Pisarski.  I knew the lab was big; what I hadnt quite appreciated before getting there is that its an entire town, with its own police department, restaurants, etc.  In many ways it looks like lots of small towns across America, except that this ones primary business is smashing gold ions into each other at relativistic speeds and measuring properties of the resulting quark-gluon plasmas.
When I talk to physicists like the ones at BNL, they often find it faintly ridiculous that anyone would doubt quantum mechanics.  But people certainly do  even when they dont admit that thats what theyre doing  when the alternative is accepting that integers are efficiently factorizable in the physical world.  Which brings us to QCSD Lecture 14, on eleven skeptical objections to quantum computing and what can be said in response to them.  And yeah, if youve been reading this blog for years, a lot of the material wont be new to you.  Its just one more hunk of meat to throw into the tigers den.Better safe than sorry

After reading these blog posts dealing with the possibility of the Large Hadron Collider creating a black hole of strangelet that would destroy the earth  as well as this report from the LHC Safety Assessment Group, and these websites advocating legal action against the LHC  I realized that I can remain silent about this important issue no longer.
As a concerned citizen of Planet Earth, I demand that the LHC begin operations as soon as possible, at as high energies as possible, and continue operating until such time as it is proven completely safe to turn it off.
Given our present state of knowledge, we simply cannot exclude the possibility that aliens will visit the Earth next year, and, on finding that we have not yet produced a Higgs boson, find us laughably primitive and enslave us.  Or that a wormhole mouth or a chunk of antimatter will be discovered on a collision course with Earth, which can only be neutralized or deflected using new knowledge gleaned from the LHC.  Yes, admittedly, the probabilities of these events might be vanishingly small, but the fact remains that they have not been conclusively ruled out.  And that being the case, the Precautionary Principle dictates taking the only safe course of action: namely, turning the LHC on as soon as possible.
After all, the fate of the planet might conceivably depend on it.Quantum Computing Since Democritus Lecture 15: Learning

Lektur iz heer.
This week I explain Valiants PAC-learning model (previously covered in GITCS Lectures 19, 20, 21), and also  in response to a question from the floor  take a swipe at Bayesian fundamentalism. When you only know one formalism to describe some phenomenon (in this case, that of choosing hypotheses to fit data), its easy to talk yourself into believing that formalism is the Truth: to paraphrase Caliph Omar, if it agrees with Bayesianism, it is superfluous; if it disagrees, it is heresy. The antidote is to learn other formalisms. Enter computational learning theory: an account of learning thats clear, mathematically rigorous, useful, nontrivial, and completely different from the Bayesian account (though of course they have points of contact). The key idea is to jettison the notoriously-troublesome notion of a prior, replacing it by a concept class (about which one makes no probabilistic assumptions), as well as a probability distribution over sample data rather than hypotheses.
Incidentally, Id say the same thing about complexity theory. If you think (for example) that Turing machines are the only way to reason about computational efficiency, then youre overdue for a heaping helping of communication complexity, circuit complexity, query complexity, algebraic complexity
Ah yes, complexity. This week I was at the Conference on Computational Complexity at the beautiful University of Maryland in College Park: home of the Terrapins, as one is reminded by signs placed roughly every three inches. I heard some great talks (ask in the comments section if you want details), gave two talks myself, and during the business meeting, was elected to the CCC Steering Committee. This being a complexity conference, my declared campaign motto was No We Cant! It was inspiring to see how this simple yet hopeful motto united our community: from derandomization to circuit lower bounds, from quantum computing to proof complexity, we might have different backgrounds but we all worry about shrinking grant sizes and the rising costs of conference registration; we all face common challenges to which we want to prove that no solutions exist. Rest assured, I will treat my duties as a steering committee member (mostly helping to select PC chairs, who in turn select the program committees who select the conference papers) with the awesome gravity they deserve.Arithmetic natural proofs theory is sought

This post will be longer and more technical than most  but what can I say?  Sometimes you need to get something technical off your chest.  The topic is something my student, Andy Drucker, and I (along with several interested others) have been thinking about on and off for months, and if were not going to get a paper out of it, at least well have this blog post.
Complexity theory could be defined as the field concerned with deep, nontrivial, mathematically-sophisticated justifications for failure.  For example, we cant solve NP-complete problems in polynomial time, but maybe thats not so bad, since we conjecture there is no solution (PNP).  Of course, we also cant prove PNP  but maybe thats not so bad either, since we have good explanations for why the problem is so hard, like relativization, natural proofs, and algebrization.
On the other hand, consider the problem of showing that the Permanent of an nxn matrix requires arithmetic circuits of more than polynomial size.  (Given a field Fwhich well assume for this post is finitean arithmetic circuit over F is a circuit whose only allowed operations are addition, subtraction, and multiplication over F, and that doesnt have direct access to the bit representations of the field elements.)
The problem of circuit lower bounds for the Permanent is currently at the frontier of complexity theory.  As we now know, its intimately related both to derandomizing polynomial identity testing and to the  problem of Blum, Cucker, Shub, and Smale.  Alas, not only can we not prove that PermAlgP/poly (which is the street name for this conjecture), we dont have any good excuse for why we cant prove it!  Relativization and algebrization dont seem to apply here, since no one would think of using diagonalization-based techniques on such a problem in the first place.  So that leaves us with natural proofs.
The theory of natural proofs, which was developed by Razborov and Rudich in 1993 and for which they recently shared the Gdel Prize, started out as an attempt to explain why its so hard to prove NPP/poly (i.e., that SAT doesnt have polynomial-size circuits, which is a slight strengthening of PNP).  They said: suppose the proof were like most of the circuit lower bound proofs that we actually know (as a canonical example, the proof that Parity is not in AC0).  Then as a direct byproduct, the proof would yield an efficient algorithm A that took as input the truth table of a Boolean function f, and determined that either:

f belongs to an extremely large class C of random-looking functions, which includes SAT but does not include any function computable by polynomial-size circuits, or
f does not belong to C.

(The requirement that A run in time polynomial in the size of the truth table, N=2n, is called constructivity.  The requirement that C be a large class of functions  say, at least a 2-poly(n) fraction of functions  is called largeness.)
Razborov and Rudich then pointed out that such a polynomial-time algorithm A could be used to distinguish truly random functions from pseudorandom functions with non-negligible bias.  As follows from the work of Hstad-Impagliazzo-Levin-Luby and Goldreich-Goldwasser-Micali, one could thereby break one-way functions in subexponential time, and undermine almost all of modern cryptography!  In other words, if cryptography is possible, then proofs with the property above are not possible.  The irony  we cant prove lower bounds because lower bounds very much like the ones we want to prove are true  is thick enough to spread on toast.
Now suppose we tried to use the same argument to explain why we cant prove superpolynomial arithmetic circuit lower bounds for the Permanent, over some finite field F.  In that case, a little thought reveals that what wed need is an arithmetic pseudorandom function family over F.  More concretely, wed need a family of functions gs:FnF, where s is a short random seed, such that:

Every gs is computable by a polynomial-size, constant-depth (or at most log-depth) arithmetic circuit, but
No polynomial-time algorithm, given oracle access to gs (for a randomly-chosen s), is able to distinguish gs from a random low-degree polynomial over F with non-negligible bias.

Its important not to get so hung up on definitional details that you miss the substantive issue here.   However, three comments on the definition seem in order.
Firstly, we restrict gs to be computable by constant or log-depth circuits, since thats the regime were ultimately interested in (more about this later).  The Permanent is a low-degree polynomial, and well-known depth reduction theorems say (roughly speaking) that any low-degree polynomial thats computable by a small circuit, is also computable by a small circuit with very small depth.
Secondly, we say that no polynomial-time algorithm should be able to distinguish gs from a random low-degree polynomial, rather than a random function.  The reason is clear: if gs is itself a low-degree polynomial, then it can always be distinguished easily from a random function, just by picking a random line and doing polynomial interpolation!  On the other hand, its reasonable to hope that within the space of low-degree polynomials, gs looks randomand thats all we need to draw a natural proofs conclusion.  Note that the specific distribution over low-degree polynomials that we simulate doesnt really matter: it could be (say) the uniform distribution over all degree-d polynomials for some fixed d, or the uniform distribution over polynomials in which no individual variable is raised to a higher power than d.
Thirdly, to get a close analogy with the original Razborov-Rudich theory, we stipulated that no ordinary (Boolean) polynomial-time algorithm should be able to distinguish gs from a random low-degree polynomial.  However, this is not essential.  If we merely knew (for example) that no polynomial-size arithmetic circuit could distinguish gs from a random low-degree polynomial, then wed get the weaker but still interesting conclusion that any superpolynomial arithmetic circuit lower bound for the Permanent would have to be arithmetically non-naturalizing: that is, it would have to exploit some property of the Permanent that violates either largeness or else arithmetic constructivity.  Theres a smooth tradeoff here, between the complexity of the distinguishing algorithm and the strength of the natural proofs conclusion that you get.
Theres no question that, if we had an arithmetic pseudorandom function family as above, it would tell us something useful about arithmetic circuit lower bounds.  For we do have deep and nontrivial arithmetic circuit lower bounds  for example, those of Nisan and Wigderson (see also here), Razborov and Grigoriev, Grigoriev and Karpinski, Shpilka and Wigderson, Raz (see also here), Raz, Shpilka, and Yehudayoff, Raz and Yehudayoff, and Mignon and Ressayre.  And as far as I can tell, all of these lower bounds do in fact naturalize in the sense above.  (Indeed, they should even naturalize in the strong sense that there are quasipolynomial-size arithmetic circuits for the relevant properties.)  Concretely, most of these techniques involve looking at the truth table (or rather, the value table) of the function g:FnF to be lower-bounded, constructing so-called partial-derivatives matrices from that truth table, and then lower-bounding the ranks of those matrices.  But these operationsin particular, computing the rankare all polynomial-time (or quasipolynomial-time for arithmetic circuits).  Thus, if we could construct arithmetic pseudorandom functions, we could use them to argue that no techniques similar to the ones we know will work to prove superpolynomial arithmetic circuit lower bounds for the Permanent.
So the problem is merely one of constructing these goddamned arithmetic pseudorandom functions.  Not surprisingly, its easy to construct arithmetic function families that seem pseudorandom (concrete example coming later), but the game were playing is that you need to be able to base the pseudorandomness of your PRF on some accepted or established computational intractability assumption.  And here, alas, the current toolbox of complexity theory simply doesnt seem up for the job.
To be sure, we have pseudorandom function families that are computable by constant-depth Boolean threshold circuits  most famously, those of Naor and Reingold, which are pseudorandom assuming that factoring Blum integers or the decisional Diffie-Hellman problem are hard.  (Both assumptions, incidentally, are false in the quantum world, but thats irrelevant for natural proofs purposes, since the proof techniques that we know how to think about yield polynomial-time classical algorithms.)  However, the Naor-Reingold construction is based on modular exponentiation, and doing modular exponentiation in constant depth crucially requires using the bit representation of the input numbers.  So this is not something thats going to work in the arithmetic circuit world.
At the moment, it seems the closest available result to whats needed is that of Klivans and Sherstov in computational learning theory.  These authors show (among other things) that if the n1.5-approximate shortest vector problem is hard for quantum computers, then learning depth-3 arithmetic circuits from random examples is intractable for classical computers.  (Here quantum computing actually is relevantsince by using techniques of Regev, its possible to use a quantum hardness assumption to get a classical hardness consequence!)
This result seems like exactly what we needso then whats the problem?  Why arent we done?  Well, its that business about the random examples.  If the learner is allowed to make correlated or adaptive queries to the arithmetic circuits truth table  as we need to assume it can, in the arithmetic natural proofs setting  then we dont currently have any hardness result.  Furthermore, there seems to me to be a basic difficulty in extending Klivans-Sherstov to the case of adaptive queries (though Klivans himself seemed more optimistic).  In particular, theres a nice idea due to Angluin and Kharitonov, which yields a generic way (using digital signatures) for converting hardness-of-learning results against nonadaptive queries to hardness-of-learning results against adaptive queries.  But interestingly, the Angluin-Kharitonov reduction depends essentially on our being in the Boolean world, and seems to break down completely in the arithmetic circuit world.
So, is this all Andy and I can saythat we tried to create an arithmetic natural proofs theory, but that ultimately, our attempt to find a justification of failure to find a justification of failure was itself a failure?  Well, not quite.  Id like to end this post with one theorem, and one concrete conjecture.
The theorem is that, if we dont care about the depth of the arithmetic circuits (or, more-or-less equivalently, the degree of the polynomials that they compute), then we can create arithmetic pseudorandom functions over finite fields, and hence the arithmetic natural proofs theory that we wanted.  Furthermore, the only assumption we need for this is that pseudorandom functions exist in the ordinary Boolean world  about the weakest assumption one could possibly hope for!
This theorem might seem surprising, since after all, we dont believe that theres any general way to take a polynomial-size Boolean circuit C that operates on finite field elements x1,,xn represented in binary, and simulate C by a polynomial-size arithmetic circuit that uses only addition, subtraction, and multiplication, and not any bit operations.  (The best such simulation, due to Boneh and Lipton, is based on elliptic curves and takes moderately exponential time.)  Nevertheless, Andy and I are able to show that for pseudorandomness purposes, unbounded-depth Boolean circuits and unbounded-depth arithmetic circuits are essentially equivalent.
To prove the theorem: let the input to our arithmetic circuit C be elements x1,,xn of some finite field Fp (Ill assume for simplicity that p is prime; you should think of p as roughly exponential in n).  Then what C will do will be to first compute various affine functions of the input:
y1=a0+a1x1++anxn, y2=b0+b1x1++bnxn, etc.,
as many such functions as are needed, for coefficients ai, bi, etc. that are chosen at random and then hardwired into the circuit.  C will then raise each yi to the (p-1)/2 power, using repeated squaring.  Note that in a finite field Fp, raising y0 to the (p-1)/2 power yields either +1 or -1, depending on whether or not y is a quadratic residue.  Let zi=(yi+1)/2.  Then we now have a collection of 0/1 bits.  Using these bits as our input, we can now compute whatever Boolean pseudorandom function we like, as follows: NOT(x) corresponds to the polynomial 1-x, AND(x,y) corresponds to xy, and OR(x,y) corresponds to 1-(1-x)(1-y).  The result of this will be a collection of pseudorandom output bits, call them w1,,wm.  The final step is to convert back into a pseudorandom finite field element, which we can do as follows:
Output = w1 + 2w2 + 4w3 + 8w4 +  + 2m-1wm.
This will be pseudorandom assuming (as we can) that 2m is much larger than p.
But why does this construction work?  That is, assuming the Boolean circuit was pseudorandom, why is the arithmetic circuit simulating it also pseudorandom?  Well, this is a consequence of two basic facts:

Affine combinations constitute a family of pairwise-independent hash functions.   That is, for every pair (x1,,xn)(y1,,yn), the probability over a0,,an that a0+a1x1++anxn=a0+a1y1++anyn is only 1/p.  Furthermore, the pairwise independence can be easily seen to be preserved under raising various affine combinations to the (p-1)/2 power.
If we draw f from a family of pseudorandom functions, and draw h from a family of pairwise-independent hash functions, then f(h(x)) will again be a pseudorandom function.  Intuitively this is obvious: after all, the only way to distinguish f(h(x)) from random without distinguishing f from random would be to find two inputs x,y such that h(x)=h(y), but since h is pairwise-independent and since the outputs f(h(x)) arent going to help, finding such a collision should take exponential time.  A formal security argument can be found (e.g.) in this paper by Bellare, Canetti, and Krawczyk.

Now for the conjecture.  I promised earlier that Id give you an explicit candidate for a (low-degree) arithmetic pseudorandom function, so here it is.  Given inputs x1,,xnFp, let m be polynomially related to n, and let L1(x1,,xn),,Lm^2(x1,,xn) be affine functions of x1,,xn, with the coefficients chosen at random and then hardwired into our circuit, as before.  Arrange L1(x1,,xn),,Lm^2(x1,,xn) into an mxm matrix, and take the determinant of that matrix as your output.  Thats it.
(The motivation for this construction is Valiants result from the 1970s, that determinant is universal under projections.  That might suggest, though of course it doesnt prove, that breaking this function should be as hard as breaking any other arithmetic pseudorandom function.)
Certainly the output of the above generator will be computable by an arithmetic circuit of size mO(log m)n.  On the other hand, I conjecture that if you dont know L1,,Lm^2, and are polynomial-time bounded, then the output of the generator will be indistinguishable to you from that of a random polynomial of degree m.  Im willing to offer $50 to anyone who can prove or disprove this conjectureor for that matter, who can prove or disprove the more basic conjecture that there exists a low-degree arithmetic pseudorandom function family!  (Here, of course, prove means prove modulo some accepted hardness assumption, while disprove means disprove.)
But please be quick about it!  If we dont hurry up and find a formal barrier to proving superpolynomial lower bounds for the Permanent, someone might actually roll up their sleeves and prove oneand we certainly dont want that!Quantum Computing Since Democritus Lecture 16: Interactive Proofs

In which I try to give a non-rigorous taste of the interactive proofs revolution that rocked the complexity world in the 1990s, as well as its consequences for circuit lower bounds.  I argue that these results matter because they offer a tiny glimpse of how one can exploit the structure of problems like 3SAT to prove lower boundssomething we know will eventually be needed for the P vs. NP question.  If you got off the train before its latest tour through the Complexity Badlands, dont worry: it will double back into Philosophers Valley (where everyone has an opinion and no one has a result) by Lecture 17 (Fun With Anthropic Principles).Scott A., disbeliever in Darwinism

Sorry for the delay! I was procrastinating all week by doing real work, but Ive finally put my foot down and resolved that blogging must come first.
I lost a lot of respect for Dilbert cartoonist Scott Adams after flipping through this compilation, which offers a tedious and redundant explanation for every cartoon. But, not content to rest on his laurels, Adams has recently come out as undecided on the question of Darwinism versus ID.
Whenever I encounter an online mudfight about this issue, Im struck by how few commenters  even the ones on our side  really grasp the crucial point: that ID is scientifically worthless, not because its religiously-motivated, or unfalsifiable, or even necessarily wrong, but rather because its boring.
Among elephant seals, 4% of the males account for 88% of the copulations. The other 96%, the ones without harems, almost never get laid. This is puzzling: why do the seals bother to produce all those males who tax the communitys food supply, yet who are destined to become the seal equivalents of computer science grad students?
The answer is that a 50-50 sex ratio is the only evolutionarily stable strategy. Think about it: if every child gets half its genes from a mother and half from a father, then males and females must pass on the same total number of genes, even if the variance is higher for males. So if youre a female elephant seal, then you can either play it safe by having a daughter, or shoot for the genetic jackpot by having a son. In expectation, both strategies will do equally well. But if there were more girls than guys in the population, then the expected number of grandchildren per son would become greater than the expected number of grandchildren per daughter. So the advantage would shift in favor of having a son, and would continue to do so until a 50-50 equilibrium was reestablished. Mystery solved. (The example comes from Dawkins, one of the few writers who consistently presents Darwinism as a way to actually explain things. The explanation itself comes from Fisher.)
On the airplane of science, nontrivial explanations are not the beverage cart or the in-flight movie  theyre the wings. If you think something was designed, but cant explain why the designer chose to make it one way rather than some other way, then it doesnt matter if youre right or not: you dont have a result.  Theres no STOC/FOCS paper.
This, I suspect, is what underlies the disconnect between scientists and almost everyone else on this issue. The business of judging ideas by their explanatory power, and rejecting the ones that dont have any, is remarkably new in human history. Even in the hard sciences, it wasnt until Galileo that it really caught on. So maybe it shouldnt surprise anyone that, in K-12 science education, its still a bizarre and heretical idea.
Why do things fall?  Because gravity makes them fall.
How does a car work?  By using energy.
Why do we need to sleep?  To rest ourselves.
Who designed us?  A designer did.Quantum Computing Since Democritus Lecture 17: Fun With The Anthropic Principle

Here it is.  There was already a big anthropic debate in the Lecture 16 comments  spurred by a homework exercise at the end of that lecture  so I feel absolutely certain that theres nothing more to argue about.  On the off chance Im wrong, though, youre welcome to restart the debate; maybe youll even tempt me to join in eventually.
The past couple weeks, I was at Foo Camp in Sebastopol, CA, where I had the opportunity to meet some wealthy venture capitalists, and tell them all about quantum computing and why not to invest in it hoping for any short-term payoff other than interesting science.  Then I went to Reed College in Portland, OR, to teach a weeklong course on The Complexity of Boolean Functions at MathCamp2008.  MathCamp is (as the name might suggest) a math camp for high school students.  I myself attended it way back in 1996, where some guy named Karp gave a talk about P and NP that may have changed the course of my life.
Alas, neither camp is the reason I havent posted anything for two weeks; for that I can only blame my inherent procrastination and laziness, as well as my steadily-increasing, eminently-justified fear of saying something stupid or needlessly offensive (i.e., the same fear that leads wiser colleagues not to start blogs in the first place).The Routerhead: a fable

Inspired by: reading Naomi Kleins The Shock Doctrine this week alongside Ludwig von Misess The Anti-Captialistic Mentality.
Addendum (7/28): Heres my review of The Shock Doctrine. If you want to know what I thought of the book, you should probably just read the review and ignore the dumb fable that follows.
I tried unplugging the router and plugging it back in, messing around with my DHCP settings  everything I could think of. Still no Internet.  Hours passed, then a day. In desperation, I finally called the tech support number for my Internet service provider, Laissez-Faire Solutions. After putting me hold for an hour with Brahms and Beethoven, Ayn finally picked up the phone.I dont know what to tell you, she said curtly, after Id explained the situation.  Your connection ought to be working perfectly.The Pareto curve of freedom

Inspired by the discussion of my fable, and specifically a comment of Ronald de Wolf, today I decided to do some amateur political science.  Specifically, I created a scatterplot that ranks 156 of the worlds countries (those for which data was available) along two axes:

Their political freedom, as rated by Freedom Houses 2008 Freedom in the World survey.  This is a 0-to-100 scale, which includes 60 points for various civil liberties (such as freedom of speech and freedom of religion) and 40 points for various political rights (such as transparent elections).  (Note that I used the raw scores, rather than the less informative 1-to-7 rankings.)
Their economic freedom, as rated by the Heritage Foundation and Wall Street Journals 2008 Index of Economic Freedom.  This is also a 0-to-100 scale, which ranks the sorts of things libertarians and laissez-faire economists love: free trade, deregulation, privatization, low taxes and tariffs, low or nonexistent minimum wage, etc.

The motivation was simple.  Among educated people, political freedom is universally acknowledged as both good and important, whereas economic freedom (as defined by Heritage and the Wall Street Journal) is not.  Indeed, a huge fraction of the disagreement between liberals and conservativesat least over economicsseems to boil down to a single question: Is economic freedom (again, as defined by Heritage/WSJ) the friend or enemy of political freedom?
On one side of this question, we have Milton Friedman:
Historical evidence speaks with a single voice on the relation between political freedom and a free market. I know of no example in time or place of a society that has been marked by a large measure of political freedom that has not also used something comparable to a free market to organize the bulk of economic activity. (From Capitalism and Freedom, quoted by Wu and Davis)
On the other side we have anti-globalization activists like Naomi Klein (author of The Shock Doctrine), who say that economic freedom simply means the freedom of multinational corporations to exploit the public, and as such is incompatible with political freedom. Klein argues that free-market economic policies almost never win democratically, and hence the ruling elites have had to force these policies on unwilling populations using strong-arm tactics of the World Bank and IMF, cynical exploitation of wars, hurricanes, and other disasters, and (when all else fails) state-sponsored torture and murder.
My modest goal was to use the available cross-country data to test these two hypotheses.  But before we get to that, a few caveats.
Caveat #1: I know full well that the questions Im talking about have already been studied in great detail by professional political scientists. Google Scholar turned up Lundstrm 2005 doing a correlational study between the Freedom House index and various components of the Economic Freedom of the World index (which is similar to the Heritage index), as well as Wu and Davis 1999, Wu and Davis 2005, Berggren 2003, Carbone 2007, and lots more.  (Though see also Doucouliagos 2005 for evidence of publication bias in this area.) So why bother to reinvent the wheel? A few answers:

This project was really just a way to procrastinate.
I like making charts.
My methods were somewhat different from those in the published literature.  Rather than using the accepted methodology of the social scienceswhich consists of reducing all questions to chi-squared significance testsI felt free to use my own Doofus Methodology, which consists of staring at graphs and seeing if something pops out at me.  After careful deliberation, I decided on the latter methodology for three reasons.  First, ultimately I only care about correlations that are strong enough to be obvious to the naked eye.  Second, I might actually know something about some of the countries in questiontheyre not just interchangeable data pointsand given how informal this study was anyway, I saw no reason to jettison that knowledge. Third, as well see, when were asking about the best forms of government, doing regression analysis on all the countries that happen to exist today can be seriously misleading. To put it bluntly, the majority of countries are so abysmal in terms of both economic freedom and political freedom, that trying to gain insight from them into a hypothesized tradeoff between the two freedoms is like studying a remedial class of second-graders to find out whether algebraic or geometric insight is more important for winning the Fields Medal. Its the outlier countries, the Singapores and Icelands, that should interest us at least as much as the pack.

Caveat #2: The problems with the Freedom House and Heritage surveysand for that matter, any surveys that try to rank countries on some linear scale of freedomare evident.  Indeed, reading the survey methodologies, I found plenty of things to complain about, as Im sure you would as well.  Nevertheless, both surveys struck me as (1) having reasonably consistent methodologies, (2) being reasonably well-accepted by social scientists, and (3) giving results that agree pretty well with intuition, for most of the countries I know something about. So lacking a better alternative, I decided to go along with these indices. Just to double-check, I also looked at the Freedom House index versus the Economic Freedom of the World index, and the plot was extremely similar to the one versus the Heritage index.
Caveat #3: A major limitation of my scatterplot is that it only looks at the world of 2008, and disregards a vast wealth of historical examples (Chile under Pinochet, the US under Reagan). Future research by amateur procrastinating bloggers should clearly take the available historical data into account as well.
Granting all of this, what can we potentially learn?
1. Political and economic freedom are correlated. Any doofus could have predicted this, and lo and behold, its apparent from even a glance at the data.  Looking at the countries in question, it seems clear that part of this correlation is due to both freedoms being correlated with economic development, i.e. having your national shit together. In a country like Denmark, you can criticize the government and start a business.  In a country like North Korea, you can neither criticize the government nor start a business, at least without being shot.  The studies I linked to above claim some evidence that this obvious correlation has a causal component, as follows: by and large, economic freedom helps make countries richer, and being richer helps make them more politically free. Assuming that claim is correct, score one for Milton Friedman.
2. A wide range of economic freedom levels is compatible with a near-maximal level of political freedom.  Lets look only at the countries on the far right of the scatterplotthose with US-or-above levels of political freedom (Australia, Austria, Bahamas, Barbados, Belgium, Canada, Chile, Cyprus, Czech Republic, Denmark, Estonia, Finland, Germany, Iceland, Ireland, Luxembourg, Malta, Netherlands, New Zealand, Norway, Portugal, Spain, Sweden, Switzerland, UK, US, and Uruguay).  Here the correlation between economic and political freedom seems to disappear entirely, or even become slightly negative.  The economic freedom scores of these countries range from 64.3 to 82.4, which is almost half of the total spread across all countries on earth (excepting a few dictatorships like North Korea, Cuba, and Zimbabwe).  More to the point, this list includes countries commonly regarded as socialist in contemporary political debate (like the Scandinavian countries), and countries regarded as capitalist (like Australia, Chile, and the US). Thus, the idea that countries that already have a high level of political freedom, would increase their political freedom even more by lowering taxes, privatizing industries, etc., does not seem to be borne out by this dataset.
3. There might be a Pareto curve of freedom: that is, a basic tension between economic and political freedom that prevents them from being maximized simultaneously.   Ill admit that the evidence on this point is inconclusive. Firstly, there arent enough data points; secondly, the lack of any example of a country maximizing both freedoms is obviously not an impossibility proof. A true believer in Ayn Rands utopia, like a true believer in Marxism, could always disregard any empirical finding by saying that the right experiment has never been tried yet, and would self-evidently succeed if it were.
However, if we do construct the Pareto curve of freedom for the Freedom House/Heritage data, what we find is this:

Iceland, with economic freedom score of 76.5 and political freedom score of 100
Canada, with economic freedom score of 80.2 and political freedom score of 99
Ireland, with economic freedom score of 82.4 and political freedom score of 97
Singapore, with economic freedom score of 87.4 and political freedom score of 49

(The US is conspicuously not on the Pareto curve, though wounded patriots can console themselves that its the only country of anywhere near its population size that comes close.)
Note that Hong Kong is not in this dataset, since as part of China, it isnt ranked separately by Freedom House.  However, Heritage  gives Hong Kong an economic freedom score of 90.3, which is the highest in the world (Singapore is #2).  The political freedom score for China itself is a dismal 18. So, if we assigned Hong Kong the point (18,90.3), that would be a fifth point on the Pareto curve.
To check the robustness of the Pareto curve, I recalculated it using the Economic Freedom in the World index in place of the Heritage index.  The result was basically similar: clustered on the right we find Finland, Iceland, and Luxembourg maximizing political freedom, then Canada, then Switzerland, then New Zealand, and then, as before, Singapore way off on its own maximizing economic freedom.
To confirm the hypothesis of a tradeoff between economic freedom and political freedom, what wed need in the dataset are more Singaporesor better yet, some countries that interpolated between the Western democracies and Singapore. Conversely, to disprove the tradeoff hypothesis, all it would take is a single country that dominated the rest of the world on both axes, with the political freedom of Scandinavia and the economic freedom of Singapore. I find it interesting that no such country seems to exist, not even a small city-state or island.
Incidentally, the tradeoff idea is not necessarily rejected by libertarians. Friedman himself stressed that political freedom, once established, has a tendency to destroy economic freedom. To put it bluntly, if poor people can vote, one of the main things they vote for is to redistribute money to themselves. There are then three possibilities: either redistribution takes place (and economic freedom as defined by Heritage and the Wall Street Journal goes down), or the poor majority is violently suppressed (and political freedom goes down), or the government is overthrown. Amusingly, Friedman and Klein seem to be in complete agreement on this central point: its just that one of them laments it while the other relishes it.
In summary, I conjecture that the relationship between economic freedom and political freedom is similar to that between jogging and health.  In general, we expect people to be healthier the more they jog, with at least part of the relationship being causal.  But it doesnt follow that jogging 20 hours per day is healthier than jogging one hour; indeed the former might even be detrimental.
Of course, people could accept all this (even find it plunkingly obvious), and still vehemently disagree about the quantitative aspect: exactly how far out is the Pareto curve? How much jogging is too much? As usual, its the complexity-theoretic questions that are the interesting ones. The tragedy is that you never even get to those questions if youre too hung up on computability.Quantum Computing Since Democritus Lecture 18: Free Will

If you dont like this latest lecture, please dont blame me: I had no choice!  (Yeah, yeah, I know.  You presumably have no choice in criticizing it either.  But it cant hurt to ask!)
Those of you whove been reading this blog since the dark days of 2005 might recognize some of the content from this post about Newcombs Paradox, and this one about the Free Will Theorem.Quantum Computing Since Democritus Lecture 19: Time Travel

A visitor from the year 2006, this time travel lecture appears before you now due to a blip in the space/time/procrastination continuum. No grandfathers were harmed in the writing of it. Im looking backward to your comments.
(Alas, these forehead-bangingly obvious lines can now never be unwritten  or can they?)The Singularity Is Far

In this post, I wish to propose for the readers favorable consideration a doctrine that will strike many in the nerd community as strange, bizarre, and paradoxical, but that I hope will at least be given a hearing. The doctrine in question is this: while it is possible that, a century hence, humans will have built molecular nanobots and superintelligent AIs, uploaded their brains to computers, and achieved eternal life, these possibilities are not quite so likely as commonly supposed, nor do they obviate the need to address mundane matters such as war, poverty, disease, climate change, and helping Democrats win elections.
Last week I read Ray Kurzweils The Singularity Is Near, which argues that by 2045, or somewhere around then, advances in AI, neuroscience, nanotechnology, and other fields will let us transcend biology, upload our brains to computers, and achieve the dreams of the ancient religions, including eternal life and whatever simulated sex partners we want. (Kurzweil, famously, takes hundreds of supplements a day to maximize his chance of staying alive till then.) Perhaps surprisingly, Kurzweil does not come across as a wild-eyed fanatic, but as a humane idealist; the text is thought-provoking and occasionally even wise. I did have quibbles with his discussions of quantum computing and the possibility of faster-than-light travel, but Kurzweil wisely chose not to base his conclusions on any speculations about these topics.
I find myself in agreement with Kurzweil on three fundamental points. Firstly, that whatever purifying or ennobling qualities suffering might have, those qualities are outweighed by sufferings fundamental suckiness. If I could press a button to free the world from loneliness, disease, and deaththe downside being that life might become banal without the grace of tragedyId probably hesitate for about five seconds before lunging for it. As Tevye said about the curse of wealth: may the Lord strike me with that curse, and may I never recover!
Secondly, theres nothing bad about overcoming nature through technology. Humans have been in that business for at least 10,000 years. Now, its true that fanatical devotion to particular technologiessuch as the internal combustion enginemight well cause the collapse of human civilization and the permanent degradation of life on Earth. But the only plausible solution is better technology, not the Kaczynski/Flintstone route.
Thirdly, were there machines that pressed for recognition of their rights with originality, humor, and wit, wed have to give it to them. And if those machines quickly rendered humans obsolete, I for one would salute our new overlords. In that situation, the denialism of John Searle would cease to be just a philosophical dead-end, and would take on the character of xenophobia, resentment, and cruelty.
Yet while I share Kurzweils ethical sense, I dont share his technological optimism. Everywhere he looks, Kurzweil sees Moores-Law-type exponential trajectoriesnot just for transistor density, but for bits of information, economic output, the resolution of brain imaging, the number of cell phones and Internet hosts, the cost of DNA sequencing  you name it, hell plot it on a log scale. Kurzweil acknowledges that, even over the brief periods that his exponential curves cover, they have hit occasional snags, like (say) the Great Depression or World War II. And hes not so nave as to extend the curves indefinitely: he knows that every exponential is just a sigmoid (or some other curve) in disguise. Nevertheless, he fully expects current technological trends to continue pretty much unabated until they hit fundamental physical limits.
Im much less sanguine. Where Kurzweil sees a steady march of progress interrupted by occasional hiccups, I see a few fragile and improbable victories against a backdrop of malice, stupidity, and greedthe tiny amount of good humans have accomplished in constant danger of drowning in a sea of blood and tears, as happened to so many of the civilizations of antiquity. The difference is that this time, human idiocy is playing itself out on a planetary scale; this time we can finally ensure that there are no survivors left to start over.
(Also, if the Singularity ever does arrive, I expect it to be plagued by frequent outages and terrible customer service.)
Obviously, my perceptions are as colored by my emotions and life experiences as Kurzweils are by his. Despite two years of reading Overcoming Bias, I still dont know how to uncompute myself, to predict the future from some standpoint of Bayesian equanimity. But just as obviously, its our duty to try to minimize bias, to give reasons for our beliefs that are open to refutation and revision. So in the rest of this post, Id like to share some of the reasons why I havent chosen to spend my life worrying about the Singularity, instead devoting my time to boring, mundane topics like anthropic quantum computing and cosmological Turing machines.
The first, and most important, reason is also the reason why I dont spend my life thinking about P versus NP: because there are vastly easier prerequisite questions that we already dont know how to answer. In a field like CS theory, you very quickly get used to being able to state a problem with perfect clarity, knowing exactly what would constitute a solution, and still not having any clue how to solve it. (In other words, you get used to P not equaling NP.) And at least in my experience, being pounded with this situation again and again slowly reorients your worldview. You learn to terminate trains of thought that might otherwise run forever without halting. Faced with a question like How can we stop death? or How can we build a human-level AI? you learn to respond: Whats another question thats easier to answer, and that probably has to be answered anyway before we have any chance on the original one? And if someone says, but cant you at least estimate how long it will take to answer the original question? you learn to hedge and equivocate. For looking backwards, you see that sometimes the highest peaks were scaledFermats Last Theorem, the Poincar conjecturebut that not even the greatest climbers could peer through the fog to say anything terribly useful about the distance to the top. Even Newton and Gauss could only stagger a few hundred yards up; the rest of us are lucky to push forward by an inch.
The second reason is that as a goal recedes to infinity, the probability increases that as we approach it, well discover some completely unanticipated reason why it wasnt the right goal anyway. You might ask: what is it that we could possibly learn about neuroscience, biology, or physics, that would make us slap our foreheads and realize that uploading our brains to computers was a harebrained idea from the start, reflecting little more than early-21st-century prejudice? Unlike (say) Searle or Penrose, I dont pretend to know. But I do think that the argument from absence of counterarguments loses more and more force, the further into the future were talking about. (One can, of course, say the same about quantum computers, which is one reason why Ive never taken the possibility of building them as a given.) Is there any example of a prognostication about the 21st century written before 1950, most of which doesnt now seem quaint?
The third reason is simple comparative advantage. Given our current ignorance, there seems to me to be relatively little worth saying about the Singularityand what is worth saying is already being said well by others. Thus, I find nothing wrong with a few people devoting their lives to Singulatarianism, just as others should arguably spend their lives worrying about asteroid collisions. But precisely because smart people do devote brain-cycles to these possibilities, the rest of us have correspondingly less need to.
The fourth reason is the Doomsday Argument. Having digested the Bayesian case for a Doomsday conclusion, and the rebuttals to that case, and the rebuttals to the rebuttals, what I find left over is just a certain check on futurian optimism. Sure, maybe were at the very beginning of the human story, a mere awkward adolescence before billions of glorious post-Singularity years ahead. But whatever intuitions cause us to expect that could easily be leading us astray. Suppose that all over the universe, civilizations arise and continue growing exponentially until they exhaust their planets resources and kill themselves out. In that case, almost every conscious being brought into existence would find itself extremely close to its civilizations death throes. Ifas many believewere quickly approaching the earths carrying capacity, then wed have not the slightest reason to be surprised by that apparent coincidence. To be human would, in the vast majority of cases, mean to be born into a world of air travel and Burger King and imminent global catastrophe. It would be like some horrific Twilight Zone episode, with all the joys and labors, the triumphs and setbacks of developing civilizations across the universe receding into demographic insignificance next to their final, agonizing howls of pain. I wish reading the news every morning furnished me with more reasons not to be haunted by this vision of existence.
The fifth reason is my (limited) experience of AI research. I was actually an AI person long before I became a theorist. When I was 12, I set myself the modest goal of writing a BASIC program that would pass the Turing Test by learning from experience and following Asimovs Three Laws of Robotics. I coded up a really nice tokenizer and user interface, and only got stuck on the subroutine that was supposed to understand the users question and output an intelligent, Three-Laws-obeying response. Later, at Cornell, I was lucky to learn from Bart Selman, and worked as an AI programmer for Cornells RoboCup teaman experience that taught me little about the nature of intelligence but a great deal about how to make robots pass a ball. At Berkeley, my initial focus was on machine learning and statistical inference; had it not been for quantum computing, Id probably still be doing AI today. For whatever its worth, my impression was of a field with plenty of exciting progress, but which has (to put it mildly) some ways to go before recapitulating the last billion years of evolution. The idea that a field must either be (1) failing or (2) on track to reach its ultimate goal within our lifetimes, seems utterly without support in the history of science (if understandable from the standpoint of both critics and enthusiastic supporters). If I were forced at gunpoint to guess, Id say that human-level AI seemed to me like a slog of many more centuries or millennia (with the obvious potential for black swans along the way).
As you may have gathered, I dont find the Singulatarian religion so silly as not to merit a response. Not only is the Rapture of the Nerds compatible with all known laws of physics; if humans survive long enough it might even come to pass. The one notion I have real trouble with is that the AI-beings of the future would be no more comprehensible to us than we are to dogs (or mice, or fish, or snails). After all, we might similarly expect that there should be models of computation as far beyond Turing machines as Turing machines are beyond finite automata. But in the latter case, we know the intuition is mistaken. There is a ceiling to computational expressive power. Get up to a certain threshold, and every machine can simulate every other one, albeit some slower and others faster. Now, its clear that a human who thought at ten thousand times our clock rate would be a pretty impressive fellow. But if thats what were talking about, then we dont mean a point beyond which history completely transcends us, but merely a point beyond which we could only understand history by playing it in extreme slow motion.
Yet while I believe the latter kind of singularity is possible, Im not at all convinced of Kurzweils thesis that its near (where near means before 2045, or even 2300). I see a world that really did change dramatically over the last century, but where progress on many fronts (like transportation and energy) seems to have slowed down rather than sped up; a world quickly approaching its carrying capacity, exhausting its natural resources, ruining its oceans, and supercharging its climate; a world where technology is often powerless to solve the most basic problems, millions continue to die for trivial reasons, and democracy isnt even clearly winning over despotism; a world that finally has a communications network with a decent search engine but that still hasnt emerged from the tribalism and ignorance of the Pleistocene. And I cant help thinking that, before we transcend the human condition and upload our brains to computers, a reasonable first step might be to bring the 18th-century Enlightenment to the 98% of the world that still hasnt gotten the message.Home of the thirsty and brave

Happy Thanksgiving to my American readers! I arrived last night at my parents place in Pennsylvania. After Ive digested enough to walk again, Im off to Cambridge (the England one), then Brisbane, Australia, then back to America before Christmas Eve (which I do celebrate, with Alex Haldermans family).
For all the academic traveling Ive done, this will be my first time circumnavigating the globe. I cant wait to find out whether its really round, or whether thar be dragons at the end.
Yet wherever I go, Ill always be an American.  In Torontos Pearson airport, I came across a Macleans (roughly, Canadas Time or Newsweek), whose cover depicted a smirking Bush holding a glass of water.  The headline (which Im not making up):
America is thirsty
Lets sell them our water before they take it
Sure, we might be chipping away at that land of the free part, but were still the home of the brave.Quantum Computing Since Democritus Lecture 20: Cosmology and Complexity

Come watch me attempt to explain the implications of a positive cosmological constant for computational complexity theory. If this blog is about anything, its about me talking about subjects I dont understand sufficiently well and thereby making a fool of myself. But its also about experts taking the time to correct me. The latter is the primary saving grace.Can we?

I was in a miserable mood for weeksregular readers will know that, for whatever reason, I go through these moods from time to timeand, strangely enough, a key to getting out of it seems to have been watching the Democratic convention and reading Obamas two books. Im not saying this ought to have helped, only that it did. Why? Well, I can think of three possible reasons:
Firstly, its a truism that the cure for misery is to find something greater than yourself to worry about. (Quantum complexity research used to fill that role for me, and will hopefully do so again in the near future.) For someone whos spent so much of his life inside his own head, its fascinating to watch people actually going out and doing something that while often corny and cringe-inducing also bears some recognizable relation to the public good. What a strange, novel idea! Whats even stranger, they might even succeed this year. Of course, theres a paradox at the heart of this philosophy: if you only worry about something greater than yourself because it distracts you from the tragedy of your own existence, then are you really worried about it in the first place? But this is no more paradoxical than so much else about the human condition. The hope is that caring about something greater than yourself will become a self-fulfilling prophecy.
Secondly, theres the fact that a man whose writing demonstrates a finely-developed capacity for introspection, self-criticism, and doubt might become the Leader of the Free World in two months. Reading Obamas books, this introspectivenesswhich is difficult to fake, and which probably doesnt help him with most voters anywaystruck me as his most endearing quality. (Of course, Obama also possesses a finely-developed capacity to suppress his capacity for introspection. If he didnt, then hed still be an obscure instructor at the University of Chicago rather than a rock-star messiah.) Ill freely confess to bias in this matter. Im sure part of the reason why Ive never been able to identify with the Republican Right, the Chomskyan Far Left, or the Libertarian Outwardsbesides my actual disagreement with those philosophieshas been the serene confidence of those philosophies major proponents. Any worldview that isnt wracked by self-doubt and confusion over its own identity is not a worldview for me.
Thirdly, seeing President Clinton in his stride always cheers me up a little.
Given the above, Id like propose the following question: what non-obvious things can nerds who are so inclined do to help the Democrats win in November? Im not talking about voting, donating money, licking envelopes, or standing on street corners Baracking the vote: the first two are easy and obvious while the second two are unsuitable for nerds. The sorts of ideas Im looking for are ones that (1) exploit nerds nerdiness, (2) go outside the normal channels of influence, (3) increase nerds effective voting power by several orders of magnitude, (4) are legal, (5) target critical swing states, and (6) can be done as a hobby.
Do such ideas exist? Well, the prototype for such an idea is Nadertrading, which I was involved with in the 2000 election cycle (see here). Before the main Nadertrading sites were shut down by Republican state attorneys-general (on doubtful legal grounds), we Nadertraders had convinced several hundred Nader supporters in Florida to commit to voting for Gore, in exchange for Gore supporters in safe states voting for Nader on their behalf. Had Nadertrading been allowed to continue just a couple weeks longer, it might have prevented Bush from taking power and thereby changed the history of the world. Im looking for the Nadertrading of 2008, and I havent found it yet.
A few possibilities:

Nadertrading Redux. Ralph is running again, and it might be worthwhile to try and reduce his influence in swing states once more. The trouble is that, after 2000, anyone who would still vote for Nader is likely beyond the reach of any outcomes-based consideration.


Lobbyists for McCain. In 2004, I participated in a Billionaires for Bush march in NYC, and can testify that it was a blast. It seems the 2008 analogue is Lobbyists for McCain. Downsides: (1) this joke has been done before, and (2) its not clear to me that satire, even when amusing and well-executed, actually changes anyones mind about anything.
Publicize and correct voting machine flaws. Researchers have demonstrated that a voting machine virus would be almost trivial to install and could go completely undetected by poll workers. And while some might find such a scenario implausible, it does seem likely that more mundane voting machine problemssystem crashes, dropped and lost votes, confusing interfaces, etc.will determine the outcome this year, exactly as they did in 2000 and possibly in 2004. These irregularities have, for whatever reasons, been far more likely to favor Republicans than Democrats. To their credit, computer scientists have been at the forefront of studying and publicizing these voting machine flaws, and have even succeeded in improving election procedures in California. The downsides? Firstly, its probably already too late to do much before November; secondly, computer scientists have been screaming about these problems for years and yet depressingly little has changed in the swing states.


Build a database and/or statistical model for identifying problem precincts. Wouldnt it have been helpful if, before the 2000 election, prominent Democrats had known about Theresa LePore, and the possibility that her butterfly ballots flapping their wings in Florida would cause the destruction of New Orleans five years later? Or if before the 2004 election, theyd known to concentrate their monitoring efforts on particular counties in Ohio? (A side note: improving the Democrats ability to challenge results after the election is over strikes me as a complete waste of time. Whoever the networks announce as the presumptive winner on election eve, thats who the winner is going to be.) I dont know how to predict 2008s likely trouble zones, and even if I did, I dont know what I would do about them. But this still strikes me as the most promising of the four listed directions.Quantum Computing Since Democritus Lecture 21: Ask Me Anything

In the final Democritus installment, I entertain students questions about everything from derandomization to the complexity class for creativity to the future of religion. (In this edited version, I omitted questions that seemed too technical, which surprisingly was almost half of them.) Thanks to all the readers whove stuck with me to this point, to the students for a fantastic semester (if they still remember it) as well as their scribing help, to Chris Granade for further scribing, and to Waterloos Institute for Quantum Computing for letting me get away with this. I hope youve enjoyed it, and only wish Id kept my end of the bargain by getting these notes done a year earlier.
A question for the floor: some publishers have expressed interest in adapting the Democritus material into book form. Would any of you actually shell out money for that?On mathematicians and mountains

Luca and Terry Tao have already reported the tragic loss of the brilliant probabilist Oded Schramm in a hiking accident. I didnt know Oded, but I knew some of his great results and was deeply saddened by the news. My heartfelt condolences go out to his friends and family.
It was two years ago that we lost Misha Alekhnovich, who I did know, in a whitewater rafting accident. Other mathematicians and scientists lost in similar ways have included Heinz Pagels, Jacques Herbrand, Raymond Paley, Krzysztof Galicki, and Erik Rauch. The teenage Einstein very nearly died while hiking on a mountain near Zurich. I have more than one irreplaceable colleague whos repeatedly courted death on the ski slopes.
Id like to issue a plea to any mathematicians and scientists who might be reading: please go easier on the extreme outdoor activities. Let those who live for such things demonstrate their daring by gambling their lives; those who live for the ages can find safer recreations. The world needs more nerds, not fewer.Open thread #2

Alright, no more politics for a while. Im sick of it.
Given the relative success of Open thread #1, I thought Id give you the readers a second opportunity to ask about whatevers on your minds, except politics. Quantum complexity classes and painting elephants are definitely fair game.
(Update: One question at a time, please!)
(Update: Thanks for the questions, everyone! The open thread is now closed. Well do this again!)With electronic voting machines, its entirely plausible

Heres what I saw the last time I went to Intrade (yes, Ive been checking about 200,000 times per day):

I understand that in this situation, the Constitution dictates that the selection of a President goes to the IEEE 754R Technical Committee.
Joke-Killing Explanation for Non-Nerds: NaN is Not a Number, an error code in floating-point arithmetic for expressions like 0/0. Evidently theres a bug in Intrades script to add the expected electoral college votes.The Bloggour hath returneth

Picture this: its my first visit to Cambridge  Ground Zero of the scientific revolution, a place thats probably contributed more to human knowledge than any other on Earth. Within walking distance are the original manuscripts of Newtons Principia; the halls where Darwin, Maxwell, and Russell dined as undergraduates; the Cavendish Laboratory where Rutherford bombarded nuclei and Crick and Watson unravelled nucleic acids; and architecture dating back to the 1200s, much of it among the finest in Europe. I ought to be taking in the splendor (sorry, splendour) by day, and blogging about it by night.
So where have I been? Hunkered in an office, trying to finish a paper with Greg Kuperberg about QMA versus QCMA in time for the Complexity06 submission deadline. Happily, by Saturday it had become obvious that, try though we might, we werent gonna make it. So I put it off till the next conference, and contented myself with submitting two papers to this years Complexity conference instead of three. As Douglas Adams, another Cambridge alum, put it: I love deadlines. I like the whooshing sound they make as they fly by.
So what can I tell you about Cambridge? First of all, when people refer to the various colleges  Kings, Trinity, and so on  theyre not just being eccentric and British. These colleges actually exist. Each one is basically a walled-off compound, with a few grand-looking entrances that get locked at night, thereby making Cambridge even harder to navigate than the average campus. (It doesnt help that the streets change names constantly: St. Johns becomes Trinity becomes Kings Parade becomes Trumpington Street within a couple of blocks.)
Im staying at Kings, pictured below:



Last week my host at Kings, Artur Ekert, invited me to High Table. For you non-Oxbridge doofuses, High Table is a fancy dinner at which people still wear robes, non-ironically as far as I could tell. Or rather, Fellows must wear robes when dining at their own college, though not when dining at a different college. (Makes sense, huh?) Afterwards, the Fellows and their guests retire to another room for wine, cheese, and academic gossip.
All these dining rooms are lined with portraits of illustrious Kings alumni from centuries past  but amazingly, theres still no portrait of the greatest Kings man of all time. Who was it? Let me give you a few hints. He proved the unsolvability of the Entscheidungsproblem. He was queer in more than one way. He had a Machine and a Test named after him. He may have played a bigger role than Churchill in winning the Second World War.
To his great credit, Artur told me that he almost threatened to resign his Fellowship if no portrait of Alan Mathison Turing F.R.S. was hung in the halls. The relevant authorities have promised to rectify the situation, though they havent done so yet. (Admittedly, the computer help center at Kings is called the Turing Centre. One imagines Turings ghost managing the DHCP servers, so that the real scholars can get on with their work.)
To my mind, the central question is this: did Cambridge become the worlds scientific superpower for 300 years in spite of all this idiosyncratic formality, or because of it? I have mixed feelings. On the one hand, the amount of red tape here, and the importance attached to ones status, is like something out of Victorian England (oh, wait). Fellows and their guests are allowed to walk on the grass; all others are not. Even though theres an ethernet jack right in my room, I wasnt allowed to use it, being merely a visitor. (After I complained, Artur was kind enough to give me his IP address.)
On the other hand, I like High Table and similar traditions. I like how they acknowledge and celebrate something thats always been obvious to me: that being an academic isnt a job like other jobs, but a way of life. This doesnt necessarily mean that academics have no lives; what it means is that they dont distinguish between work and life the way most people do.
Have you ever been to one of those roadside diners where you can pick an entree plus two sides, but a few of the entrees are marked complete, meaning you dont get any sides with them? Well, at Cambridge theyve understood for centuries that academia is one of lifes complete entrees. Not that a Cambridge man would know anything about roadside diners.Nerds and theorists, our honor is at stake

Today Sean Carroll emailed various bloggers, defying us to participate in the DonorsChoose Blogger Challenge 2008. Heres how it works: we (the bloggers) pick projects that we like in underfunded public schools. Then we beg our readers to donate small amounts of money to make those projects happen. Any blogger whose readers cant or wont contribute is revealed as weak, pathetic, and inadequateas are the readers themselves.
Now, do I seem like the sort of pusillanimous coward who would back down from such a direct challenge to his bloghood? Who would cede the moral high ground to a physicist?
I do?
Then let the word echo from the mountaintops and RSS feeds. I, Scott Aaronson, am now seeking to raise up to $7000 for public school teachers trying to:

Help gifted students, meaning those blessed with the gifts of awkwardness, alienation, and solitude. (Note that in the US, less than 0.02% of the federal education budget goes to this lucky group.)
Teach evolution.
Buy Art Spiegelmans Maus (the acclaimed graphic novel about the Holocaust, and an astonishingly un-P.C. work for the classroom).
Buy Twains Huckleberry Finn, the classic and oft-censored howl against doofosity.

Twain, incidentally, was the one who wrote that in the first place, God made idiots. That was for practice. Then He made school boards. The genius of DonorsChoose is that it bypasses those pinnacles of Gods handiwork, letting you route money directly to deserving teachers.
So: if, in your time reading Shtetl-Optimized, youve enjoyed one entry, I ask you to go here and donate $10 to a featured project of your choice. If youve enjoyed ten entries, I ask you to donate $25 (you get the bulk discount). If youve enjoyed every entry (!), I ask you to donate $50 (thats the Platinum Elite Package).
If youre currently a student or Wall Street broker, you can of course scale down your donation appropriately.
And no, this wont save the world or even swing the election. But  sniff  maybe Sean Carroll will finally respect me.
Update (Oct. 6): Thanks so much, everyone! So far weve raised $2,049 (counting my own small contribution).Opening for a summer student

Im seeking a talented student for summer of 2009, to work with me in developing and experimenting with a new open-source web application. Im open to students from anywhere, though MIT students will receive special consideration for funding reasons.
The web app  tentatively called Worldview Manager  is intended to help people ferret out hidden contradictions in their worldviews. Think of a kindly, patient teacher in a philosophy seminar who never directly accuses students of irrationality, but instead uses Socratic questioning to help them clarify their own beliefs.
The idea is extremely simple (as of course it has to be, if this app is to attract any significant number of users). The user selects a topic from a list, which might include the following at the beginning:
Climate Change
The Singularity
Libertarianism
Computational Complexity
Interpretation of Quantum Mechanics
Quantum Computing
Gay Rights
Israel
Gifted Education
Foundations of Mathematics
Strong AI and Philosophy of Mind
Utilitarian Ethics
Animal Rights
Art and Aesthetics
Users will also be able to contribute their own topic files. (The above list is biased toward those topics about which I feel like I could write a topic file myself.)
After choosing a topic, the user will be presented with a sequence of statements, one at a time and in a random order. For example, if the topic is Foundations of Mathematics, the statements might include the following:
Math is a cultural construct.
Math privileges male, linear thinking over female, intuitive thinking.
The Continuum Hypothesis is either true or false, even if humans will never know which.
Theres a sense in which integers, real numbers, and other mathematical objects existed before humans were around to name them, and will continue to exist after humans are gone.
The user can indicate her level of agreement with each statement by dragging the cursor.
Now the topic file, in addition to the statements themselves, will also contain lists of pairs or sometimes triples of statements that appear (at least to the writer of the topic file) to be in tension with one another. From time to time, the program will search the users previous responses for beliefs that appear to be in tension, point out the tension, and give the user the opportunity to adjust one or more beliefs accordingly. For example, the user might get a message like the following:
 You indicated substantial agreement with the statement
If a scientific consensus on climate change existed, then society would have to act accordingly.
and also substantial agreement with the statement
 The so-called consensus on climate change simply reflects scientists liberal beliefs, and therefore does not necessitate action.
These views would seem to be in tension with each other. Would you like to adjust your belief in one or both statements accordingly?
Thats about all there is to it. No Bayesianism, no advanced math of any kind (or at least none that the user sees).
As you may have gathered, the writing of topic files is not a value-neutral activity: the choice of statements, and of which statements are in tension with which other ones, will necessarily reflect the writers interests and biases. This seems completely unavoidable to me. The goal, however, will be to adhere as closely as is practical to Wikipedias NPOV standard. And thus, for example, any well-written topic file ought to admit multiple equilibria; that is, multiple points of view that are genuinely different from one another but all more-or-less internally consistent.
The students responsibilities for this project will be as follows:

 Write, debug, and document the web app. This sounds straightforward, but itll be important to get the details right. Im not even sure which development tools would be beste.g., whether we should use Java or JavaScript, do all computation on the server side, etc.and will rely on you to make implementation decisions.
Write topic files. I can create many of the files myself, but it would be great if you could pitch in with your own ideas.
Help run experiments with real users.
Help write up a paper about the project.

If theres time, we could also add more advanced functionality to Worldview Manager. Your own ideas are more than welcome, but here are a few possibilities:

 Present statements to the user in a non-random order that more rapidly uncovers tensions.
Allow users to register for accounts, and save their worldviews to work on later.
Give users the ability to compare worldviews against their friends, with large disagreements flagged for special consideration.
Give users the ability to use a local search or backtrack algorithm to decrease the total tension in their worldviews, while changing their stated beliefs by the minimum possible amount.
Enable adaptive follow-up questions. That is, once two beliefs in tension have been uncovered, the user can be queried more specifically on how she wants to resolve the apparent contradiction.

Im looking for someone smart, curious, enthusiastic, and hard-working, who has experience with the development of web applications (a work sample is requested). Grad students, undergrads, high school students, nursery school students  its what you can do that interests me.
I expect the internship to last about three months, but am flexible with dates. Note that in the year or so since I started at MIT, Ive already worked with six undergraduate students, and three of these interactions have led or will lead to published papers.
If youre interested, send a cover letter, cv, and link to a work sample to aaronson at csail mit edu. If you want to tell me why the Worldview Manager idea is idiotic and misguided, use the comments section as usual.
Update (10/15): In a somewhat related spirit, Eric Schwitzgebel at UC Riverside points me to a study that he and a colleague are conducting, on whether professional philosophers respond differently than laypeople to ethical dilemmas. Shtetl-Optimized readers are encouraged to participate.Keeping cool

Update (10/27): Peter Norvig at Google points me to his Election FAQ, for those who feel they havent yet spent enough time reading about the election. Ive just been perusing it, and its an unbelievably good source of informationreaching the same conclusions as I did on just about every particular, yet also calm, reasoned, and professional.

1. Thats my mom at an Obama office in Sarasota, FL. For once, I find myself kvelling to strangers about her.
2. Im at FOCS2008 in Philadelphia right now. Yesterday morning I gave a tutorial on The Polynomial Method in Quantum and Classical Computing, and was delighted by how many people showed up  I wouldnt have woken up for my talk. (And before you ask: yes, the PowerPoint slides for this talk include photographs of both Bill Ayers and Joe the Plumber.)
3. Heres the FOCS conference program  tons of good stuff, as you can see for yourself. If theres a talk you want to know more about, say so in the comments section and Ill try to find someone who attended it.
Note: I was a program committee member, and therefore know much more than usual about the talksbut my objectivity and license as a journalist are also severely compromised. If unvarnished opinion is what you seek, ask my friend and roommate Rahul Santhanam, whos also reporting live from the conference over at Lances blog. (As you can see, we CS theorists manage our conflicts of interest roughly as well as the Alaska governors office)
4. I apologize that I havent had much to say recently. Against my better judgment, I find myself transfixed by the same topic everyone else is transfixed by, and its hard to find anything to say about it that hasnt been said better by others. If you want to enter my world, dont read Shtetl-Optimized; read Andrew Sullivan or FiveThirtyEight.com. Following the election is, of course, not all that different from following a football game, except for the added dash of excitement that the future of civilization might hinge on the outcome.
(Years congruent to 0 mod 4 are pretty much the only times when I understand what its like to be a sports fan. Speaking of which, I heard there was some sort of Worlds Series in Philadelphia last nightprobably in basketballand something called the Phillies won? I might be wrong, though. Maybe it was the Flyers  or is that a volleyball team? Keep in mind, I only lived in this area for the first 15 years of my life.)
5. For a congenital pessimist like me, I confess its been difficult to deal with the fact that my team (I mean the Democrats, not the Eagles or whatever theyre called) is winning. I simply dont know how to react; its so far outside my emotional range. Since when has the universe worked this way? When did reason and levelheadedness start reaping earthly rewards, or incompetence start carrying a cost? Im sure Nov. 4 will bring something to console me, though: maybe Al Franken will lose the Senate race in Minnesota, or the homophobe proposition will pass in California
6. Writing blog posts in numbered lists is easier; I should do it more often. I dont have to pretend all the little things I want to say are part of an overarching narrative, rather than standing in the relation and that reminds me of  which in turn reminds me of
7. Theres another psychological question inspired by the election thats fascinated me lately: how does one become more obamalike in temperament?
Ive written before about Obamas penchant for introspection and respect for expertise, which of course are qualities with which I strongly identify. But Obama also has a crucial quality I lack: as the whole world has marveled, nothing rattles him. Placed for two years under the brightest glare on earth, besieged by unexpected events, he simply sticks to a script, Buddha-like in his emotional control (although not in his quest for power in the temporal world). His nerves are of carbon nanotube fiber.
When he briefly slipped behind after the Republican convention, I panicked: I felt sure hed lose if he didnt completely change his approach. Sean Carroll recommended chilling out. I now face the indignity of admitting that I was wrong while a physicist was right.
What struck me most, during the debates, was how again and again Obama would pass up the chance to score pointschoosing instead to let his opponent impale himself with his own words, and use his time to hammer home his message for the benefit of any voters just emerging from their caves. (As an example, consider his pointed refusal in the third debate to say anything bad about Palinthe subtext being, isnt it obvious?) Its almost as if he thought his goal was winning the election, not proving the other guy wrong.
I have (to put it mildly) not always exhibited the same prudent restraint, least of all on this blog. So for example, whenever theres been bait dangling in front of me in the comments section, Ive tended to bite, often ending up with a hook through my cheek.
But no more. As the first exercise in my newfound quest for the Zen-like equanimity and balance of our soon-to-be-president, I now present to you two excerpts from the comments on my previous post, with no reaction whatsoever from me. 
Have you considered the possibility that, in the same way a logical deduction is being equated with truth, understanding a thing is just an illusion? If a thing is logical, that only means that it appeals to the reasoning facility of the brain, not that its the truth.
Mathematics is just a place where it becomes clear how a human may think. Computers only go for the calculable. And the mathematical truths a computer can produce are at most countable infinite. But there are uncountable infinite truths.Should you vote?

(Assuming youre eligible?)
An argument I came up with a while ago is that, in an election with N voters, the probability of your vote swaying the outcome could be expected to scale like 1/Nbut the utility to the world if your vote does sway the outcome could be expected to scale like N. Under those assumptions, the expected utility of your vote for the world scales like N (or -N, depending which candidate you vote for). So if you care about the world even ~1/N as much as you care about yourself, you should probably vote, even though your vote almost certainly wont change the outcome. Indeed, the case is even stronger in the US (at least if you live in a swing state), both because the electoral college amplifies the probability of your vote mattering (see the Majority-Is-Stablest Theorem), and because of the USs disproportionate influence on the world.
A version of the above argument was discovered independently by Peter Norvig, whoappropriately for an applied rather than theoretical computer scientistplugs in some actual numbers, rather than considering the asymptotics as the number of voters goes to infinity. Norvig finds an expected value of your vote to the United States of about $1 million (or $6 trillion divided by a 1 in 6 million chance of your vote mattering). Another version of the argument was given by Andrew Gelman, who points out that other peoples votes are actually not well-modeled by unbiased coin flips (unless you live in Florida, I guess)but that even under a more realistic prior, your vote still has a constant expected value to society (i.e., it doesnt decrease with the number of voters N).
Im aware, of course, that the above is merely a nerdy, rational argument, of a sort thats probably never actually convinced anyone in the entire history of the world, with the possible exception of Robin Hanson. So let me raise the stakes a little. Let me give you an emotional argument.
Did you see WALL-E? My favorite scene in that predictably-excellent moviea scene I confess almost brought me to tearsactually had nothing to do with WALL-E or his robo-love-interest EVE. It was the scene aboard the spaceship Axiom, where the leaf symbol starts flashing overhead, indicating that the earth is once again able to support life, and the fat, coddled human passengers actually have to make a decision about whether to return to earth or not. For the first time in 700 years, the spaceships course is not on autopilot. Like children away from their parents, the humans face the terrifying realization that theres no longer any higher authority to tell them what to do. Or rather, their robot masters are trying to tell them what to do, but the humans are not obliged to listen.
See? Just like an election.
Your vote almost certainly wont change the outcome; indeed, thanks to the wonders of technology, theres probably no way to verify itll even be counted. But on the one day when that leaf is flashing  to have to tell posterity you were too busy finishing a problem set?
Naturally, I also think I know which way you should vote. But even if youre one of the humans who thinks the spaceship carrying the last remnant of humanity should remain floating in spacesince although (and here Im embellishing the movie) the spaceships power will soon run out, leaving all the humans dead, its conceivable that the power could be extended a few years by drilling a nearby asteroid (drill, baby, drill!)even if thats your belief system, still I think you should vote. Why? Because of my newfound Zen-like equanimity, combined with the belief that your candidates going to lose anyway.
Then, after youve voted, go into the comments section and ask me a question about whats new in computational complexity. As a commenter on my last post helpfully opined, its time to start tending my garden again.

Yes We Can. Prove We Cant.The unfamiliar burden of victory

On balance? Ill take it.Sundry and Various

1. Theres now a popular article by Lisa Zyga at physorg.com, about my paper with John Watrous on quantum computing with closed timelike curves. On the whole, I think Zyga did an excellent job at getting the facts (such as they are) correct.
2. Challenged ballots in the Coleman vs. Franken race: you be the judge!
3. One of the unfortunate things about not updating your blog often, I find, is that people assume youre still obsessed with the last thing you blogged about, weeks after youve all but forgotten about it. As it happens, Ive now fully recovered from the joy of the election, and am back to my normal angst-ridden equilibrium. On the other hand, Ive not yet recovered from the STOC deadline.
4. My quest to become more obamalike in temperament is now officially a failure.  I should try it again sometime.Wanted: Better Wikipedia coverage of theoretical computer science

A year ago, a group of CS theoristsincluding Eli Ben-Sasson, Andrej Bogdanov, Anupam Gupta, Bobby Kleinberg, Rocco Servedio, and your humble blogger, and fired up by the evangelism of Sanjeev Arora, Christos Papadimitriou, and Avi Wigdersonagreed to form a committee to improve Wikipedias arguably-somewhat-sketchy coverage of theoretical computer science. One year later, our committee of busy academics has done, to a first approximation, nothing.
In considering this state of affairs, Im reminded of the story of Wikipedias founding. Before Wikipedia there was Nupedia, where the articles had to be written by experts and peer-reviewed. After three years, Nupedia had produced a grand total of 24 articles. Then a tiny, experimental adjunct to Nupediaa wiki-based peanut gallery where anyone could contributeexploded into the flawed, chaotic, greatest encyclopedia in the history of the world that we all know today.
Personally, Ive never understood academics (and there are many) who sneer at Wikipedia. Ive been both an awestruck admirer of it and a massive waster of time on it since shortly after it came out. But I also accept the reality that Wikipedia is fundamentally an amateur achievement. It will never be an ideal venue for academicsnot only because we dont have the time, but because were used to (1) putting our names on our stuff, (2) editorializing pretty freely, (3) using original research as a compliment and not an accusation, and (4) not having our prose rewritten or deleted by people calling themselves Duduyat, Raul654, and Prokonsul Piotrus.
So this Thanksgiving weekend, at the suggestion of my student Andy Drucker, Im going to try an experiment in the spirit of Wikipedia. Im going to post our wish-list of theoretical computer science topics, and invite youmy interested, knowledgeable readersto write some articles about them. (Of course youre welcome to add your own topics, not that youd need permission.) Dont worry if youre not an expert; even some stubs would be helpful. Let us know in the comments section when youve written something.
Thanks, and happy Thanksgiving!
Research areas not defined on Wikipedia


Property testing
Quantum computation (though Quantum computer is defined)
Algorithmic game theory
Derandomization
Sketching algorithms
Propositional proof complexity (though Proof complexity is defined)
Arithmetic circuit complexity
Discrete harmonic analysis
Streaming algorithms
Hardness of approximation

Research areas ill-defined on Wikipedia


Algorithmic mechanism design  extend beyond 4 sentences, and create link from Mechanism design article of Wikipedia
Circuit complexity
Online Algorithms

Basic terms not defined on Wikipedia


Sparsest cut
Metric embedding  also create link from Embedding article on Wikipedia
Price of anarchy
Combinatorial auction
Glauber dynamics
Locally testable code
Locally decodable code (but the closely related Private information retrieval is defined)
Average case complexity
Worst case complexity
Polynomial identity testing
Unique games conjecture
Primal-dual approximation algorithm

Basic terms ill-defined on Wikipedia


Conductance (probability)  extend beyond 3 sentences
Probabilistically checkable proofs
Polynomial-time hierarchy
Algorithms for matrix multiplication
Max-flow min-cut
Zero knowledge proof
Model of computation
List-decoding

Well-known theoretical computer scientists without Wikipedia pages


No, Im not going to make that list  but you can.

Update (11/30): A big shout-out and thank-you to those theorists, such as David Eppstein, whove actually been contributing to Wikipedia and not just theorizing about it!Time: Different from space

Over at Cosmic Variance, I learned that FQXi (the organization that paid for me to go to Iceland) sponsored an essay contest on The Nature of Time, and the submission deadline was last week. Because of deep and fundamental properties of time (at least as perceived by human observers), this means that I will not be able to enter the contest. However, by exploiting the timeless nature of the blogosphere, I can now tell you what I would have written about if I had entered.(Warning: I cant write this post without actually explaining some standard CS and physics in a semi-coherent fashion. I promise to return soon to your regularly-scheduled programming of inside jokes and unexplained references.)
Ive often heard it saidincluding by physicists who presumably know betterthat time is just a fourth dimension, that its no different from the usual three dimensions of space, and indeed that this is a central fact that Einstein proved (or exploited? or clarified?) with relativity. Usually, this assertion comes packaged with the distinct but related assertion that the passage of time has been revealed as a psychological illusion: for if it makes no sense to talk about the flow of x, y, or z, why talk about the flow of t? Why not just look down (if thats the right word) on the entire universe as a fixed 4-dimensional crystalline structure?
In this post, Ill try to tell you why not. My starting point is that, even if we leave out all the woolly metaphysics about our subjective experience of time, and look strictly at the formalism of special and general relativity, we still find that time behaves extremely differently from space. In special relativity, the invariant distance between two points p and qmeaning the real physical distance, the distance measure that doesnt depend on which coordinate system we happen to be usingis called the interval. If the point p has coordinates (x,y,z,t) (in any observers coordinate system), and the point q has coordinates (x,y,z,t), then the interval between p and q equals
(x-x)2+(y-y)2+(z-z)2-(t-t)2
where as usual, 1 second of time equals 3108 meters of space. (Indeed, its possible to derive special relativity by starting with this fact as an axiom.)
Now, notice the minus sign in front of (t-t)2? That minus sign is physics way of telling us that time is different from spaceor in Sesame Street terms, one of these four dimensions is not like the others. Its true that special relativity lets you mix together the x,y,z,t coordinates in a way not possible in Newtonian physics, and that this mixing allows for the famous time dilation effect, whereby someone traveling close to the speed of light relative to you is perceived by you as almost frozen in time. But no matter how you choose the t coordinate, theres still going to be a t coordinate, which will stubbornly behave differently from the other three spacetime coordinates. Its similar to how my up points in nearly the opposite direction from an Australians up, and yet we both have an up that wed never confuse with the two spatial directions perpendicular to it.
(By contrast, the two directions perpendicular to up can and do get confused with each other, and indeed its not even obvious which directions were talking about: north and west? forward and right? If you were floating in interstellar space, youd have three perpendicular directions to choose arbitrarily, and only the choice of the fourth time direction would be an obvious one for you.)
In general relativity, spacetime is a curved manifold, and thus the interval gets replaced by an integral over a worldline. But the local neighborhood around each point still looks like the (3+1)-dimensional spacetime of special relativity, and therefore has a time dimension which behaves differently from the three space dimensions. Mathematically, this corresponds to the fact that the metric at each point has (-1,+1,+1,+1) signaturein other words, its a 44 matrix with 3 positive eigenvalues and 1 negative eigenvalue. If space and time were interchangeable, then all four eigenvalues would have the same sign.
But how does that minus sign actually do the work of making time behave differently from space? Well, because of the minus sign, the interval between two points can be either positive or negative (unlike Euclidean distance, which is always nonnegative). If the interval between two points p and q is positive, then p and q are spacelike separated, meaning that theres no way for a signal emitted at p to reach q or vice versa. If the interval is negative, then p and q are timelike separated, meaning that either a signal from p can reach q, or a signal from q can reach p. If the interval is zero, then p and q are lightlike separated, meaning a signal can get from one point to the other, but only by traveling at the speed of light.
In other words, that minus sign is what ensures spacetime has a causal structure: two events can stand to each other in the relations before, after, or neither before nor after (what in pre-relativistic terms would be called simultaneous). We know from general relativity that the causal structure is a complicated dynamical object, itself subject to the laws of physics: it can bend and sag in the presence of matter, and even contract to a point at black hole singularities. But the causal structure still existsand because of it, one dimension simply cannot be treated on the same footing as the other three.
Put another way, the minus sign in front of the t coordinate reflects what a sufficiently-articulate child might tell you is the main difference between space and time: you can go backward in space, but you cant go backward in time. Or: you can revisit the city of your birth, but you cant (literally) revisit the decade of your birth. Or: the Parthenon could be used later to store gunpowder, and the Tower of London can be used today as a tourist attraction, but the years 1700-1750 cant be similarly repurposed for a new application: theyre over.
Notice that were now treating space and time pragmatically, as resourcesasking what theyre good for, and whether a given amount of one is more useful than a given amount of the other. In other words, were now talking about time and space like theoretical computer scientists. If the difference between time and space shows up in physics through the (-1,+1,+1,+1) signature, the difference shows up in computer science through the famous
P  PSPACE
conjecture. Here P is the class of problems that are solvable by a conventional computer using a reasonable amount of time, meaning, a number of steps that increases at most polynomially with the problem size. PSPACE is the class of problems solvable by a conventional computer using a reasonable amount of space, meaning a number of memory bits that increases at most polynomially with the problem size. Its evident that P  PSPACEin other words, any problem solvable in polynomial time is also solvable in polynomial space. For it takes at least one time step to access a given memory locationso in polynomial time, you cant exploit more than polynomial space anyway. Its also clear that PSPACE  EXPthat is, any problem solvable in polynomial space is also solvable in exponential time. The reason is that a computer with K bits of memory can only be 2K different configurations before the same configuration recurs, in which case the machine will loop forever. But computer scientists conjecture that PSPACE  Pthat is, polynomial space is more powerful than polynomial timeand have been trying to prove it for about 40 years.
(You might wonder how P vs. PSPACE relates to the even better-known P vs. NP problem. NP, which consists of all problems for which a solution can be verified in polynomial time, sits somewhere between P and PSPACE. So if PNP, then certainly PPSPACE as well. The converse is not knownbut a proof of PPSPACE would certainly be seen as a giant step toward proving PNP.)
So from my perspective, its not surprising that time and space are treated differently in relativity. Whatever else the laws of physics do, presumably they have to differentiate time from space somehowsince otherwise, how could polynomial time be weaker than polynomial space?
But you might wonder: is reusability really the key property of space that isnt shared by timeor is it merely one of several differences, or a byproduct of some other, more fundamental difference? Can we adduce evidence for the computer scientists view of the space/time distinctionthe view that sees reusability as central? What could such evidence even consist of? Isnt it all just a question of definition at best, or metaphysics at worst?
On the contrary, Ill argue that the computer scientists view of the space/time distinction actually leads to something like a prediction, and that this prediction can be checked, not by experiment but mathematically. If reusability really is the key difference, then if we change the laws of physics so as to make time reusablekeeping everything else the same insofar as we canpolynomial time ought to collapse with polynomial space. In other words, the set of computational problems that are efficiently solvable ought to become PSPACE. By contrast, if reusability is not the key difference, then changing the laws of physics in this way might well give some complexity class other than PSPACE.
But what do we even mean by changing the laws of physics so as to make time reusable? The first answer that suggests itself is simply to define a time-traveling Turing machine, which can move not only left and right on its work tape, but also backwards and forwards in time. If we do this, then weve made time into another space dimension by definition, so its not at all surprising if we end up being able to solve exactly the PSPACE problems.
But wait: if time is reusable, then when does it get reused? Should we think of some secondary time parameter that inexorably marches forward, even as the Turing machine scuttles back and forth in the original time? But if so, then why cant the Turing machine also go backwards in the secondary time? Then we could introduce a tertiary time parameter to count out the Turing machines movements in the secondary time, and so on forever.
But this is stupid. What the endless proliferation of times is telling us is that we havent really made time reusable. Instead, weve simply redefined the time dimension to be yet another space dimension, and then snuck in a new time dimension that behaves in the same boring, conventional way as the old time dimension. We then perform the sleight-of-hand of letting an exponential amount of the secondary time elapse, even as we restrict the original time to be polynomially bounded. The trivial, uninformative result is then that we can solve PSPACE problems in polynomial time.
So is there a better way to treat time as a reusable resource? I believe that there is. We can have a parameter that behaves like time in that it never changes direction, but behaves unlike time in that it loops around in a cycle. In other words, we can have a closed timelike curve, or CTC. CTCs give us a dimension that (1) is reusable, but (2) is also recognizably time rather than space.
Of course, no sooner do we define CTCs than we confront the well-known problem of dead grandfathers. How can we ensure that the events around the CTC are causally consistent, that they dont result in contradictions? For my money, the best answer to this question was provided by David Deutsch, in his paper Quantum Mechanics near Closed Time-like Lines (unfortunately not online). Deutsch observed that, if we allow the state of the universe to be probabilistic or quantum, then we can always tell a consistent story about the events inside a CTC. So for example, the resolution of the grandfather paradox is simply that youre born with 1/2 probability, and if youre born you go back in time and kill your grandfather, therefore youre born with 1/2 probability, etc. Everythings consistent; theres no paradox!
More generally, any stochastic matrix S has at least one stationary distributionthat is, a distribution D such that S(D)=D. Likewise, any quantum-mechanical operation Q has at least one stationary statethat is, a mixed state  such that Q()=. So we can consider a model of closed timelike curve computation where we (the users) specify a polynomial-time operation, and then Nature has to find some probabilistic or quantum state  which is left invariant by that operation. (There might be more than one such in which case, being pessimists, we can stipulate that Nature chooses among them adversarially.) We then get to observe , and output an answer based on it.
So what can be done in this computational model? Long story short: in a recent paper with Watrous, we proved that
PCTC = BQPCTC = PSPACE.
Or in English, the set of problems solvable by a polynomial-time CTC computer is exactly PSPACEand this holds whether the CTC computer is classical or quantum. In other words, CTCs make polynomial time equal to polynomial space as a computational resource. Unlike in the case of secondary time, this is not obvious from the definitions, but has to be proved. (Note that to prove PSPACE  PCTC  BQPCTC  EXP is relatively straightforward; the harder part is to show BQPCTC  PSPACE.)
The bottom line is that, at least in the computational world, making time reusable (even while preserving its directionality) really does make it behave like space. To me, that lends some support to the contention that, in our world, the fact that space is reusable and time is not is at the core of what makes them different from each other.
I dont think Ive done enough to whip up controversy yet, so let me try harder in the last few paragraphs. A prominent school of thought in quantum gravity regards time as an emergent phenomenon: something that should not appear in the fundamental equations of the universe, just like hot and cold, purple and orange, maple and oak dont appear in the fundamental equations, but only at higher levels of organization. Personally, Ive long had trouble making sense of this view. One way to explain my difficulty is using computational complexity. If time is merely an emergent phenomenon, then is the presumed intractability of PSPACE-complete problems also an emergent phenomenon? Could a quantum theory of gravitya theory that excluded time as not fundamental enoughtherefore be exploited to solve PSPACE-complete problems efficiently (whatever efficiently would even mean in such a theory)? Or maybe computation is also just an emergent phenomenon, so the question doesnt even make sense? Then what isnt an emergent phenomenon?
I dont have a knockdown argument, but the distinction between space and time has the feel to me of something that needs to be built into the laws of physics at the machine-code level. Ill even venture a falsifiable prediction: that if and when we find a quantum theory of gravity, that theory will include a fundamental (not emergent) distinction between space and time. In other words, no matter what spacetime turns out to look like at the Planck scale, the notion of causal ordering and the relationships before and after will be there at the lowest level. And it will be this causal ordering, built into the laws of physics, that finally lets us understand why closed timelike curves dont exist and PSPACE-complete problems are intractable.
Ill end with a quote from a June 2008 Scientific American article by Jerzy Jurkiewicz, Renate Loll and Jan Ambjorn, about the causal dynamical triangulations approach to quantum gravity.
What could the trouble be? In our search for loopholes and loose ends in the Euclidean approach [to quantum gravity], we finally hit on the crucial idea, the one ingredient absolutely necessary to make the stir fry come out right: the universe must encode what physicists call causality. Causality means that empty spacetime has a structure that allows us to distinguish unambiguously between cause and effect. It is an integral part of the classical theories of special and general relativity.
Euclidean quantum gravity does not build in a notion of causality. The term Euclidean indicates that space and time are treated equally. The universes that enter the Euclidean superposition have four spatial directions instead of the usual one of time and three of space. Because Euclidean universes have no distinct notion of time, they have no structure to put events into a specific order; people living in these universes would not have the words cause or effect in their vocabulary. Hawking and others taking this approach have said that time is imaginary, in both a mathematical sense and a colloquial one. Their hope was that causality would emerge as a large-scale property from microscopic quantum fluctuations that individually carry no imprint of a causal structure. But the computer simulations dashed that hope.
Instead of disregarding causality when assembling individual universes and hoping for it to reappear through the collective wisdom of the superposition, we decided to incorporate the causal structure at a much earlier stage. The technical term for our method is causal dynamical triangulations. In it, we first assign each simplex an arrow of time pointing from the past to the future. Then we enforce causal gluing rules: two simplices must be glued together to keep their arrows pointing in the same direction. The simplices must share a notion of time, which unfolds steadily in the direction of these arrows and never stands still or runs backward.
By building in a time dimension that behaves differently from the space dimensions, the authors claim to have solved a problem thats notoriously plagued computer simulations of quantum gravity models: namely, that of recovering a spacetime that behave[s] on large distances like a four-dimensional, extended object and not like a crumpled ball or polymer. Are their results another indication that time might not be an illusion after all? Time (hopefully a polynomial amount of it) will tell.N n n

At least three people have now asked my opinion of the paper Mathematical Undecidability and Quantum Randomness by Paterek et al., which claims to link quantum mechanics with Gdelian incompleteness. Abstract follows:
We propose a new link between mathematical undecidability and quantum physics. We demonstrate that the states of elementary quantum systems are capable of encoding mathematical axioms and show that quantum measurements are capable of revealing whether a given proposition is decidable or not within the axiomatic system. Whenever a mathematical proposition is undecidable within the axioms encoded in the state, the measurement associated with the proposition gives random outcomes. Our results support the view that quantum randomness is irreducible and a manifestation of mathematical undecidability.
Needless to say, the paper has already been Slashdotted. I was hoping to avoid blogging about it, because I doubt I can do so without jeopardizing my quest for Obamalike equanimity and composure. But similar to whats happened several times before, I see colleagues who I respect and admire enormouslyin this case, several who have done pioneering experiments that tested quantum mechanics in whole new regimesmaking statements that can be so easily misinterpreted by a public and a science press hungry to misinterpret, that I find my fingers rushing to type even as my brain struggles in vain to stop them.
Briefly, what is the connection the authors seek to make between mathematical undecidability and quantum randomness? Quantum states are identified with the axioms of a formal system, while measurements (technically, projective measurements in the Pauli group) are identified with propositions. A proposition is decidable from a given set of axioms, if and only if the requisite measurement produces a determinate outcome when applied to the state (in other words, if the state is an eigenstate of the measurement). From the simple fact that no one-qubit state can be an eigenstate of the x and z measurements simultaneously (in other words, the Uncertainty Principle), it follows immediately that no axiom system can decide every proposition. The authors do some experiments to illustrate these ideas, which (not surprisingly) produce the outcomes predicted by quantum mechanics.
But does this have anything to do with undecidability in the mathematical sense, and specifically with Gdels Theorem? Well, its not an illustration of Gdels Theorem to point out that, knowing only that x=5, you cant deduce the value of an unrelated variable y. Nor is it an illustration of Gdels Theorem to point out that, knowing only one bit about the pair of bits (x,y), you cant deduce x and y simultaneously. These observations have nothing to do with Gdels Theorem. Gdels Theorem is about statements that are undecidable within some formal system, despite having definite truth-valuessince the statements just assert the existence of integers with certain properties, and those properties are stated explicitly. To get this kind of undecidability, Gdel had to use axioms that were strong enough to encode the addition and multiplication of integers, as well as the powerful inference rules of first-order logic. By contrast, the logical deductions in the Paterek et al. paper consist entirely of multiplications of tensor products of Pauli matrices. And the logic of Pauli matrix multiplication (i.e., is this matrix in the subgroup generated by these other matrices or not?) is, as the authors point out, trivially decidable. (The groups in question are all finite, so one can just enumerate their elementsor use Gaussian elimination for greater efficiency.)
For this reason, I fear that Paterek et al.s use of the phrase mathematical undecidability might mislead people. The papers central observation can be re-expressed as follows: given an N-qubit stabilizer state |, the tensor products of Pauli matrices that stabilize | form a group of order 2N. On the other hand, the total number of tensor products of Pauli matrices is 4N, and hence the remaining 4N-2N tensor products correspond to undecidable propositions (meaning that theyre not in |s stabilizer group). These and other facts about stabilizer states were worked out by Gottesman, Knill, and others in the 1990s.
(Incidentally, the paper references results of Chaitin, which do interpret variants of Gdels Theorem in terms of axiom systems not containing enough information to decide Kolmogorov-random sentences. But Chaitins results dont actually deal with information in the technical sense, but rather with Kolmogorov complexity. Mathematically, the statements Chaitin is talking about have zero information, since theyre all mathematical truths.)
So is there a connection between quantum mechanics and logic? There isand it was pointed out by Birkhoff and von Neumann in 1936. Recall that Paterek et al. identify propositions with projective measurements, and axioms with states. But in logic, an axiom is just any proposition we assume; otherwise it has the same form as any other proposition. So it seems to me that we ought to identify both propositions and axioms with projective measurements. States that are eigenstates of all the axioms would then correspond to models of those axioms. Also, logical inferences should derive some propositions from other propositions, like so: any state that is an eigenstate of both X and Y is also an eigenstate of Z. As it turns out, this is precisely the approach that Birkhoff and von Neumann took; the field they started is called quantum logic.
Update (Dec. 8): Ive posted an interesting response from Caslav Brukner, and my response to his response.Get off that shoulder  its my giant!

Yesterday I visited the Wren Library, which houses many of Newtons old books.  Notably, they have a first edition of Principia Mathematica, with Newtons handwritten corrections for the second edition. So what did Ike see fit to correct? Well, the title page of the first edition listed him as a Fellow of the Royal Society. Sir Isaac crossed that out: he was now the President of the Royal Society! As Jonathan Oppenheim pointed out to me, its weirdly reassuring to see a guy at the vertiginous top of the academic ladder, grasping in vain for the nonexistent rung above.Four announcements

I arrived in Tempe, Arizona yesterday for a workshop on The Nature of the Laws of Physics, kindly hosted by Paul Davies Beyond Center. Im treating this as a much-needed end-of-semester vacationwith warm desert air, eccentric personalities, talks without theorems, and the sort of meandering philosophical debate I get inexplicably cranky if I havent had for a month. Just one problem: I was hoping Cosmic Variances Sean Carroll would arrive to provide much-needed positivist reinforcement against the gangs of metaphysical ruffians, but the California Clarifier backed outleaving the remaining skeptics to dodge relentless volleys of ill-posed questions only three hours drive from the O.K. Corral.


My graduate course 6.896 Quantum Complexity Theory ended last week, with ten amazing student project presentations. Thanks so much to the students, and to my TA Yinmeng Zhang, for making this a great course (at least for me). Almost all of the scribe notes are now available on the course website. But be warned: not only did I not write these notes, not only did I not edit them, for the most part I havent read them yet. Use entirely at your own risk.


Want to do graduate study in quantum information at MIT? Yes? Then my colleague Jeff Shapiro asks me to point you to the new website of iQUiSE, our Interdisciplinary Quantum Information Science & Engineering program (motto: Further Depleting the Supply of Quantum Funding-Related Acronyms Containing the Letters Q and I). If youre interested, you apply to a traditional department (such as physics, math, EECS, or mechanical engineering), but specify in your application that youre interested in iQUiSE. The application deadline is todaybut if for some strange reason 17 hours isnt enough to write your application, theres always another year.


Dmitry Gavinsky asks me to throw the following piece of meat to the comment-wolves: What exactly should count as a new quantum algorithm?How long could a black hole remain in the center of the earth?

The above question came up in conversation with Michael Vassar and some other nerds in New York City yesterday (before I went with relatives to see Gimpel Tam, an extraordinarily dark and depressing musical performed entirely in Yiddish). Look, I know a massive black hole would swallow the earth extremely quickly, and I also know that a microscopic black hole would quickly evaporate as Hawking radiation. So suppose we chose one of intermediate size so as to maximize the earths survival timehow long a time could we achieve? (Does the answer depend on the viscosity of the magma or whatever else is in the earths core?) Sure, I could try to calculate an answer myself, but why bother when so many physicists read this blog? Pencils out!What can first-order logic do for your self-esteem?

Whereas nerds stand to benefit, even more than normal people, from becoming more assertive, outgoing, optimistic, obamalike in temperament, and all those other good things,
Whereas the fundamental problem with nerds is that theyre constantly overthinking everything,
Whereas this means nerds are regularly beaten in life by people who think less than they do,
Whereas it also means that nerds cant read self-help books without coming up with dozens of (generally sound) reasons why everything theyre reading is a load of crap,
Whereas theres therefore a large unmet need for self-esteem-boosting, personality-improving materials that would somehow fly under nerds radar, disarming the rational skeptical parts of their brains,
This holiday season, as my present to all my nerd readers, Ive decided to start an occasional series entitled Nerd Self-Help.
Todays installment: What should you do when you find yourself asking whether you have any right to exist?
Pondering the problem this morning, I hit upon a solution: Ask yourself whether the integer 8 has any right to exist.
In first-order logic, existence is not even a property that can be predicated of objects. Given a universe of objects, you can ask about properties of those objects: for example, is there a perfect cube which is one less than a perfect square? But its simply assumed that when you use a phrase like is there, youre quantifying over everything that exists. (As many of you know, this was the basic insight behind Kants refutation of Anselms ontological proof of the existence of God: the notion of a being that wouldnt be perfect without the added perfection of existence, said Kant, is gobbledygook.)
Similarly, I claim that if you were to formulate a theory of human rights in first-order logic in any natural way, then whether you have a right to exist is not even a question that would arise within that theory. Such a theory might include your right to not be murdered, to get a fair trial, to engage in consensual sexual activities, to own property, etc., but not your right to exist: that right, to the extent it even made sense, would simply be presupposed by your being part of the universe of persons that the theory of rights was quantifying over. In other words, the sequence of words do I have the right to exist? seems to me to dissolve on analysis, an ill-formed non-question.
Now, I dont doubt that there are plenty of logical, metaphysical, and legal objections that might be raised against the above argument. But heres the key: dont think about it too much! Just trust that theres a rational-sounding argument for why you shouldnt doubt your right to exist, and be happy.
Merry Christmas, everyone!Two links

1. The CRAs Computing Community Consortium, chaired by national treasure Ed Lasowska of the University of Washington, recently put up a website with fifteen brief essays about Computing Research Initiatives for the 21st Century. These essays will apparently be reviewed by the science policy staff at the Obama transition office. Dave Bacon and I wrote the essay on quantum computingor rather, Dave wrote it with his inimitable enthusiasm, and then I tried in vain to moderate it slightly. (When Dave told me that President-elect Obama needed my help with quantum computing policy, what was I going to say? Sorry, Im doing my laundry this weekend?)
2. Lee Gomes of Forbes magazine wrote a fun article about the Worldview Manager project that I blogged about a while ago. (For some reason, Lee wasnt deterred by my pointing out to him that the project hasnt even started yet.)The T vs. HT (Truth vs. Higher Truth) problem

From a predictably-interesting article by Freeman Dyson in Notices of the AMS (hat tip to Peter Woit):
The mathematicians discovered the central mystery of computability, the conjecture represented by the statement P is not equal to NP. The conjecture asserts that there exist mathematical problems which can be quickly solved in individual cases but cannot be solved by a quick algorithm applicable to all cases. The most famous example of such a problem is the traveling salesman problem, which is to find the shortest route for a salesman visiting a set of cities, knowing the distance between each pair. All the experts believe that the conjecture is true, and that the traveling salesman problem is an example of a problem that is P but not NP. But nobody has even a glimmer of an idea how to prove it. This is a mystery that could not even have been formulated within the nineteenth-century mathematical universe of Hermann Weyl.
At a literal level, the above passage contains several howlers (Ill leave it to commenters to point them out), but at a deeper poetic level, Dyson happens to be absolutely right: P versus NP is the example par excellence of a mathematical mystery that human beings lacked the language even to express until very recently in our history.
Speaking of P versus NP, Im currently visiting Sasha Razborov at his new home, the University of Chicago. (Yesterday we had lunch at Baracks favorite pizza place, and walked past Baracks favorite bookstore. Were they really his favorites? At a deeper poetic level, sure.)
One of the highlights of my trip was meeting Ketan Mulmuley for the first time, and talking with him about his geometric approach to the P vs. NP problem. Ketan comes across in person as an almost mythological figure, like a man who flew too close to the sun and was driven nearly to ecstatic obsession by what he saw. This is someone wholl explain to anyone in earshot, for as long as he or she cares to listen, that hes glimpsed the outlines of a solution of the P vs. NP problem in the far frontiers of mathematics, and it is beautiful, and it is elegantsomeone who leaps from Ramanujan graphs to quantum groups to the Riemann Hypothesis over finite fields to circuit lower bounds in the space of a single sentence, as his hapless listener struggles to hold on by a fingernailsomeone whose ideas seem to remain obstinately in limbo between incoherence and profundity, making just enough sense that you keep listening to them.
Now, I get emails every few months from people claiming to have proved PNP (not even counting the P=NP claimants). Without exception, they turn out to be hunting polar bears in the Sahara: they dont even grapple with natural proofs, or relativization, or algebrization, or the lower bounds/derandomization connection, or any the other stuff we know already about why the problem is hard. Ketan, by contrast, might be searching for polar bears with a kaleidoscope and trying to hunt them with a feather, but hes in the Arctic all right. I have no idea whether his program will succeed within my lifetime at uncovering any of the truth about the P vs. NP problem, but it at least clears the lower hurdle of reflecting some of the higher truth.Perspective

Ive been suffering from terrible bronchitis for two weeks. I can barely talk. I had to cancel a planned colloquium. Im not even gonna try to describe what Ive been coughing up. The doctor couldnt figure out if it was viral or bacterial, but gave me antibiotics anyway.
My laptop broke, the day before I had to give my time travel talk at QIP2009 in Santa Fe (if you want to know what actually happened at the conference, see Daves blog or ask in the comments section). First the fan started acting upcausing the machine to overheat and shut itself off whenever the computations got too complex; then the G and H keys became unreliable; and finally the hard disk went, taking much of my data along with it (though I recovered the most important stuff). So I ran out and bought a new Toshiba laptop, which of course came preinstalled with Vista, which is not just said by everyone to suck but truly does suck. (Though if you spend a day disabling all the new features, you can make it almost like XP.)
On the flight back to Boston from Santa Fe, the pressure drop during the descent, combined with my bronchitis, sent my ears into pain for days.
The shitty economy is no longer just an abstraction, as friends and close family members have lost their jobs. I, the starving quantum complexity theorist, now feel like one of the last people I know with an income. (Though MIT, like other universities, has lost much of its endowment and now faces serious hardships as well.)
But its all OK, because the competent guy is president noweven if he flubbed his Oath of Office (update: it seems most of the fault lies with Roberts (another update: Steven Pinker theorizes that the problem was Robertss reluctance to split an infinitive)). Hes gonna fix everything. Just give him a day or two.
Happy Barackday, everyone!Thats not a proof, mate  thats a proof

I arrived Friday morning in an exotic, faraway Backwards-Land, where mammals have pouches, vegemite is considered edible, toilets should in principle flush the wrong way, and Christmas trees adorn a tropical summer landscape.
Im here to visit the University of Queensland physics department, which is probably best known as the home of the worlds longest-running experiment: a glob of congealed black tar thats been dripping through a funnel since 1927, at the rate of about one drop per decade. This important experiment recently won an Ig Nobel Prize in Physics, causing my colleague the Quantum Pontiff to regret not taking a photo of it while he had the chance. In perhaps the greatest advance in Catholic-Jewish relations since John Paul II prayed at the Western Wall, today Shtetl-Optimized proudly presents His Quantum Holiness with the following token of goodwill.
 

But theres more to Australia than funnels of congealed black tar. There are also strange and wonderful birds with that wander around the campus eating peoples garbage. Birdwatching is not a pastime Ive ever wished on anyone, but I think this one is an Australian White Ibis:

Finally, Australia is also home to terrible race riots, which erupted yesterday after a Lebanese gang apparently attacked two white lifeguards. I dont have anything amusing to say about that.At least theres fresh running water and a Start button

In response to my (justified) kvetching about Vista in my last post, a commenter named Matt wrote in:
I hear theres some free operating system written by a guy from Finland. Sounds pretty crazy to me, but I hear you can just download it for free. Maybe you could have used that if you didnt like Vista?
Yes, Ive heard of the OS by the guy from Finland, and even tried it. On introspection, though, my feelings about Windows are pretty much identical to my feelings about America: sure, its big and bloated and crass and flawed and overcommercialized and buggy and insecure, and at least 95% of the insults that the sophisticates hurl at it are true. And other countries and OSes have a great deal to be said for them, and indeed I do spend much of my time visiting them.  But this is home, dammit, its where I was brought up, and things would have to get a lot worse before Id consider moving away for good.
All I need, then, is the Windows analogue of Obama. Would that be the Windows 7 beta? (Vista, of course, being the Windows analogue of Bush?)The arc of complexity is long, but it bends toward lower bounds

As MIT grad student Jelani Nelson rightly pointed out to me, an historic world event took place on Tuesday, January 20an event that many of us have awaited for decades, one that we thought wed never live to seeand I inexcusably failed my readers by neglecting to blog about it. The event in question, as everyone knows, was Mark Braverman posting to his web page what looks to be a proof of the Linial-Nisan Conjecture. The LN conjecture, posed in 1990, held that
Polylog-wise independence fools AC0.
Alright, let me try again in English. The conjecture says that no logic circuit, composed of a polynomial number of AND, OR, and NOT gates (of unbounded fan-in) arranged in a constant number of layers, can distinguish n input bits x1,,xn that are truly random, from n input bits that look random on every subset of (say) n0.001 bits, but that could be correlated in arbitrary ways across larger scales. In other words, if such a circuit accepts truly random bits with probability close to 1, then it also accepts the pseudorandom bits with probability close to 1, and vice versa. If you want to distinguish the random bits from the pseudorandom bits with noticeable bias, then you need a more powerful kind of circuit: either greater depth (say, log(n) layers instead of O(1)), or more gates (say, exponentially many), or more powerful gates (say, XOR or MAJORITY gates instead of just AND, OR, and NOT). To a constant-depth, polynomial-size, AND/OR/NOT circuit (which we call an AC0 circuit for shortdont ask why), local randomness looks just the same as global randomness. Or so says the Linial-Nisan Conjecture.
Now, weve known since the eighties that AC0 circuits have serious limitations. In particular, weve known lots of specific pseudorandom distributions that fool them. What Linial and Nisan conjectured, and Braverman appears to have proved, is that any distribution will do the job, just so long as it looks random locally.
A year and a half ago, Bazzi proved the Linial-Nisan conjecture in the special case of depth-two circuits, in a 64-page tour de force. Then Razborov gave an essentially 2-page proof of the same result. (Need I explain how awesome that is?) Braverman extends Bazzis result to circuits of any constant depth; his proof is almost as short as Razborovs.
In proving these lower bounds, the name of the game is the polynomial method (the subject of my FOCS tutorial). Given an AC0 circuit C, you first construct a low-degree real polynomial that approximates C pretty well on most inputs. (How do you construct such a thing? And what does pretty well mean? Save it for the comments section.) Then you observe that no low-degree polynomial could possibly distinguish a random string from a string that only looks random locally. Why? Because a low-degree polynomial, by definition, is a sum of local terms, and if none of those individual terms can distinguish truly random bits from pseudorandom ones (as was assumed), then their sum cant distinguish them either, by the deep principle of the universe we call linearity of expectation. (By contrast, an AND or OR of terms could in principle detect global properties of the input that none of the individual terms detectedwhich is why we couldnt just apply such an argument to the AC0 circuit directly.) It follows, then, that the original circuit couldnt have distinguished local randomness from global randomness very well either, which is what we wanted to show.
So everything boils down to constructing these low-degree approximating polynomials and proving they have the right properties. And in that context, what Braverman does is almost hilariously simple. Given an AC0 circuit C, he first constructs a low-degree polynomial p that agrees with C on most inputs (from whatever fixed probability distribution you want), using the celebrated method of Valiant-Vazirani and Razborov-Smolensky. He then observes that, when p fails to agree with C, theres another AC0 circuit E, of depth slightly greater than C, that detects the failure. Next he finds a low-degree polynomial q that approximates E in L2-norm, using the also-celebrated 1993 theorem of Linial-Mansour-Nisan. Then he looks at p(1-q), and shows that its a polynomial that usually agrees with C, but when it does disagree, usually isnt too far off. And then  well, at that point hes really almost done.
While I had no involvement whatsoever with this beautiful result, Im pleased to have unwittingly set in motion a chain of events that led to it. Since the summer, Ive been trying to get as many lowerbounderati as possible interested in BQP versus PH, a central open problem of quantum complexity theory thats resisted progress since the prehistoric days of 1993. (There are certain problems that I mentally classify as rabbits, after the Killer Rabbit of Caerbannog from Monty Python and the Holy Grail. BQP vs. PH is one of the fluffiest, most adorable rabbits ever to leap for my throat.)
Concretely, the goal has been to construct an oracle relative to which BQP (Bounded-Error Quantum Polynomial-time, the class of problems that are feasible for a quantum computer) is not contained in PH (the Polynomial-time Hierarchy, a generalization of NP). Such a separation would give us probably our best evidence to date that BQP is not contained in NPor loosely speaking, that not only can quantum computers solve certain problems exponentially faster than classical ones, they can solve certain problems exponentially faster than classical computers can even verify the answers.
(NerdNote: We do have oracles relative to which BQPNP, and indeed BQPMA. But we still dont have an oracle relative to which BQPAM. And that sticks in the craw, since we know that AM=NP under a derandomization hypothesis.)
Now, it occurred to me that BQP versus PH is closely related to the Linial-Nisan Conjecture. Thats not quite as surprising as it sounds, since you can think of PH as the exponentially scaled-up version of AC0  so that fighting PH ultimately boils down to fighting AC0.
Alright, so consider the following problem, which well call Fourier Checking. Youre given black-box access to two Boolean functions f,g:{-1,1}n{-1,1}, and are promised that either

f and g were both generated uniformly at random (independently of each other), or
f and g were generated by first choosing a random 2n-dimensional unit vector v, then setting f(x)=sgn(vx) and g(x)=sgn((Hv)x), where H represents the Fourier transform over Z2n.

The problem is to decide which, with small probability of error.
Its not hard to see that Fourier Checking is in BQP (i.e., is efficiently solvable by a quantum computer). For to solve it, you just go into a uniform superposition over all x{-1,1}n, then query f, apply a Quantum Fourier Transform, query g, and see if youre left with (1) random garbage or (2) something close to the uniform superposition that you started with.
On the other hand, one can show that:

A certain generalization of Bazzis Theorem (from local randomness to local almost-randomnessas usual, ask in the comments section) would imply that Fourier Checking is not in an important subclass of PH called AM (for Arthur-Merlin). And thus, wed get an oracle relative to which BQPAM.
The analogous generalization of the full Linial-Nisan Conjecture would imply that Fourier Checking is not in PH. And thus, wed get our long-sought oracle relative to which BQPPH.

After realizing the above, I tried for months to prove the requisite generalization of Bazzis Theoremor better yet, get someone else to prove it for me. But I failed. All I managed to do was to goad Razborov into proving his amazing 2-page version of Bazzis original theorem, which in turn inspired Braverman to shoot for the full Linial-Nisan Conjecture.
In what appears to be a cosmic prank, about the only conjectures in this area that still havent been proved are the ones I needed for the quantum computing problem. And thus, I will offer $100 for a proof that Fourier Checking is not in AM, $200 for a proof that its not in PH. In so doing, my hope is to make Tuesday, January 20, 2009 remembered by all as the day our economy finally got back on track.Stayin alive

Within the last week and a half, I saw two movies that rank among the best Ive ever seen: Slumdog Millionaire and Defiance. Slumdog, as you probably know by now, is about an orphan from Mumbai who, in the process of fleeing starvation, murder, and the gouging out of his eyes, picks up enough trivia to go on the Indian version of Who Wants To Be A Millionaire and answer almost every question correctly. (Its about 100 times better than the premise makes it sound.) Defiance tells the true story of the Bielski brothers in Belorussia (where most of my family is from), who fled to the forest when the Jews were rounded up in December 1941, and eventually organized the largest Jewish resistance operation of the war.
On thinking it over, I was surprised to realize I liked these two seemingly-unrelated movies for the same reasons. Let me try to break down what made them good:

Both draw their emotional punch from reality. Almost everything in Defiance happened. Slumdog, while fictional, is (amazingly) the first Western blockbuster I can think of about modern Indiaa place where 21st-century communication, entertainment, and industry coexist with 16th-century squalor, and everyone acts as if thats normal. (If you havent been there, the anarchic street scenes might strike you as obviously exaggerated for effect. They arent.)


Both tell wildly-improbable tales of bare physical survival. Survival stories arent just the best for keeping you in your seat: they also provide a useful reminder that your beliefs about politics and human nature might be badly distorted by the contingent facts that you have enough to eat and that armed thugs arent trying to kill you. (I tried to think of a phrase to summarize my political philosophy, and came up with liberal pessimist pragmatist rationalist of an unsentimental kind. Slumdog and Defiance both explain this concept better than I could.)


Even as they starve, sleep in the rain, and flee their would-be killers, the protagonists in both movies pursue goals beyond just staying alivewhich is what lets us identify with them so strongly. Jamal Malik appears on a game show to win the beautiful Latika. Tuvia Bielski risks his life to exact revenge on the police officer who killed his parents. Days after losing their families to the Nazis, the young women who arrive at the Bielski settlement are weighing which of the men to offer themselves to as forest wives.


Both movies use visuals in the service of a story rather than vice versa. When Spielberg filmed Schindlers List in black and white (save for the famous girl in red), reviewers were full of praise: what a profound artistic statement he mustve been making! The result, though, was that people saw the Holocaust the same way theyd seen it everywhere else: as something from some remote, incomprehensible black-and-white past. But Defiance, like The Pianist, denies you the luxury of a visual removeas if to say, this is how it was. Its part of the same universe you live in right now. Its not even particularly incomprehensible, if you choose to comprehend it.


Both movies indulge the audience in what it already knows about the respective cultures. Slumdog features hilarious scenes at the Taj Mahal and a call center, and ends with a tongue-in-cheek Bollywood dance number. Defiance portrays the malbushim (the Bielskis derisive term for intellectuals) arguing and quoting Talmud as they starve in the woods. Its as if, instead of telling you that the stereotypes you came in with are false, these movies say and so what if theyre true?


Both movies have been criticized as simplistica word that seems to mean too clear or comprehensible for polite company, and that Ive found to be an almost-perfect marker for things that Im going to like or agree with. Even as the plots add on layers of complexitysibling rivalries, uneasy alliances, unconsummated lovethe dialogue is always straightforward enough that even a borderline Aspbergers case like myself could follow what was going on without difficulty.


Despite a backdrop of blood and tears on a continent-wide scalewhich the audience knows full well is real, not fictionalboth movies end up joyous and uplifting. Lots of bad guys get blown to pieces, while the good guys you most care about live. Is such uplift glib, problematic, or even simplistic? Well, whats the point of going to a movie in the first place? I want to walk away feeling that the inherent injustice of the universe can be successfully defied, that I need not apologize for taking comparatively benign steps to solve the comparatively trivial problems in my own life. I want my $10s worth.Math: the book

Today I continue a three-entry streak of praising things that are good. While visiting IAS to give a talk, I noticed on several of my friends desks heavily-bookmarked copies of the Princeton Companion to Mathematics: a 1000-page volume thats sort of an encyclopedia of math, history of math, biographical dictionary of math, beginners guide to math, experts desk reference of math, philosophical treatise on math, cultural account of math, and defense of math rolled into one, written by about 130 topic specialists and edited by the Fields medalist, blogger, and master expositor Timothy Gowers.
The best way I can explain what the PCM is trying to do is this. Suppose thatlike in the Hitchhikers Guide to the Galaxyaliens are threatening to obliterate the earth along with all its life to make room for an interstellar highway. But while the aliens are unresponsive to pleas for mercy, an exemption might be granted if the humans can show that, over the last four millennia, such mathematical insights as theyve managed to attain are a credit rather than an embarrassment to their species. To help decide the case, the aliens ask that humans send them an overview of all their most interesting mathematics, comprising no more than 1,000 of the humans pages. Crucially, this overview will not be read by the aliens great mathematicianswho have no time for such menial jobsbut by a regional highway administrator who did passably well in math class at Zorgamak Elementary School. So the more engaging and accessible the better.
I dont know what our chances would be in such a situation, but I know that the PCM (suitably translated into the aliens language) is the book Id want beamed into space to justify the continued existence of our species.
So what makes it good? Two things, mainly:

For some strange reason I still dont understand, its written as if you were supposed to read it. Picture a stack of yellow books (), and imagine cornering the authors one by one and demanding they tell you whats really going on, and the result might look something like this. Admittedly, there are plenty of topics I still didnt understand after reading about them hereCalabi-Yau manifolds, K-theory, modular formsbut even there, I gained the useful information that these things are apparently hard for me even when someones trying to make them easy.
The book is cheerfully unapologetic about throwing in wavelets, error-correcting codes, the simplex algorithm, and the Ising model alongside the greatest hits of algebra, geometry, analysis, and topologyas if no one would think to do otherwise, as if the former were part of the mathematical canon all along (as indeed they couldve been, but for historical accident). Nor does it dismay me that the book gives such a large role to theoretical computer sciencewith a 30-page chapter on complexity by Avi Wigderson and Oded Goldreich, as well as chapters on cryptography, numerical analysis, computability, and quantum computing (my tiny role was to help with the last). There are also essays on computer-assisted proofs, experimental mathematics, innumeracy, math and art, and the goals of mathematical research; a guide to mathematical software packages; advice to a young mathematician; and a timeline of mathematical events, from the first known use of a bone for counting through Shors factoring algorithm and the proofs of Wiles and Perelman.

But enough! I must now descend from Platonic heaven, reenter the illusory world of shadows, and finish my grant proposal  alright, maybe one more puff Popular complexity

A little-known discipline of science called computational intractability studies the boundaries of our understanding  not questions of the philosophical realm (Is there a god? An afterlife?) but of the everyday computational realm.
So says the Boston Globe, in an article thats finally appeared, after it apparently kept getting bumped for personal health stories (I guess NP-completeness still doesnt move papers like cancer). Im gratified: in this time of economic crisis, the world urgently needs more articles about what humans still wont be able to do in a billion years. (A colleague complained to me that computational intractability is not little-known; in fact, almost all computer scientists know what it is. Im not sure if he was joking.)
Speaking of Public Understanding of Science: as you may have heard, much of the future of American science now hinges on whether the Senate, as it haggles over the $800B stimulus, decides to sprinkle a breadcrumb or two off the table for us. If there was ever a time to email your Senators office, and have a staff person check a box marked constituent complaining about science funding in your name, its probably this week. The APS has drafted a letter for you.The complement of Atlas Shrugged

A few months ago I read Atlas Shrugged, the 1,069-page Ayn Rand opus that was recently praised by Stephen Colbert (for its newfound popularity with beleaguered CEOs). As I mentioned in the comments of a previous post, like many other nerds I went through a brief Aynfatuation around the age of 14. Rands portrayal of an anti-mind, anti-reason cabal of collectivist rulers, who spout oleaginous platitudes about love and self-sacrifice even as they mercilessly repress any spark of individuality, happens to be extremely relevant to at least two cases Im aware of:

Soviet Russia.
The average American high school.

But it didnt last long. Even in the midst of it, I could see problems: I wrote a term paper analyzing the rape scene in The Fountainhead as immoral and irreconcilable with the rest of an otherwise supremely-rational novel. And ironically, once I went to college and started doing more-or-less what Rand extols as lifes highest purposespursuing my ambitions, tackling math and science problems, trying to create something originalher philosophy itself seemed more and more quaint and irrelevant. I snapped out of it before I reached Atlas. (Or did I subconsciously fear that, if I did read Atlas, Id be brainwashed forever? Or did I just figure that, having read the 752-page Fountainhead and dozens of essays, I already got the basic idea?)
So, having now returned to Atlas out of curiosity, what can I say? Numerous readers have already listed the reasons why, judged as a conventional novel, its pretty bad: wooden dialogue, over-the-top melodrama, characters barely recognizable as human. But of course, Atlas doesnt ask to be judged as a conventional novel. Rand and her followers clearly saw it as a secular Bible: a Book of Books that lays out for all eternity, through parables and explicit exhortation, what you should value and how you should live your life. This presents an obvious problem for me: how does one review a book that seeks, among other things, to define the standards by which all books should be reviewed?
Mulling over this question, I hit on an answer: I should look not at whats in the bookwhose every word is perfect by definition, to true believers who define perfect as that exemplified by Atlas Shruggedbut at whats not in it. In other words, I should review the complement of the book. By approaching the donut through the hole, I will try to explain how, even considering it on its own terms, Atlas Shrugged fails to provide an account of human life that I found comprehensive or satisfying.
(Though on the positive side, it still makes much more sense than my 11th-grade English teacher.)
Without further ado, here are the ten most striking things I noticed in the complement of Atlas Shrugged.

Recent technologies. For a novel set in the future, whose whole point is to defend capitalism, technology, innovation, and industry, Atlas is startlingly uninterested in any technologies being developed at the time it was written (the fifties). For Rand, the ultimate symbol of technological progress is the railroadthough shes also impressed by steel mills, copper mines, skyscrapers, factories, and bridges. Transistors, computers, space travel, and even plastic and interstate highways seem entirely absent from her universe, while nuclear energy (which no one could ignore at the time) enters only metaphorically, through the sinister Project X. Airplanes, which were starting to overtake trains as a form of passenger travel even as Atlas was written, do play a tiny role, though its never explained where the busy protagonists learned to pilot. Overall, I got the impression that Rand didnt really care for technology as suchonly for what certain specific, 19th-century technologies symbolized to her about Mans dominance over Nature.
Curiosity about the physical universe. This, of course, is related to point 1. For Rand, the physical world seems to be of interest only as a medium to be bent to human will. When I read The Fountainhead as a teenager, I found myself wondering what Rand wouldve made of academic scientists: people who generally share her respect for reason, reality, and creative achievement, but not her metaphysical certainty or her hatred of all government planning. (Also, while most male scientists resemble a cross between Howard Roark and John Galt, it must be admitted that a tiny minority of them are awkward nerds.)
In Atlas, Rand finally supplies an answer to this question, in the form of Dr. Robert Stadler. It turns out that in Rands eschatology, academic scientists are the worst evil imaginable: people smart enough to see the truth of her philosophy, but who nevertheless choose to reject it. Science, as a whole, does not come off well in Atlas: the country starves while Stadlers State Science Institute builds a new cyclotron; and Dr. Floyd Ferris, the author of obscurantist popular physics books, later turns into a cold-blooded torturer. (That last bit, actually, has a ring of truth to it.)
More important, in a book with hundreds of pages of philosophizing about human nature, theres no mention of evolution; in a book obsessed with physics, theres no evidence of any acquaintance with relativity, quantum mechanics, or pretty much anything else about physics. (When Stadler starts talking about particles approaching the speed of light, Dagny impatiently changes the subject.) Its an interesting question whether Rand outright rejected the content of modern science; maybe well pick up that debate in the comments section. But another possibilitythat Rand was simply indifferent to the sorts of things an Einstein, Darwin, or Robert Stadler might discover, that she didnt care whether they were true or notis, to my mind, hardly more defensible for a philosopher of reason.
Family. Whittaker Chambers (of pumpkin patch fame) pointed out this startling omission in his review of 1957. The characters in Atlas mate often enough, but they never reproduce, or even discuss the possibility of reproduction (if only to take precautions against it). Also, the only family relationships portrayed at length are entirely negative in character: Reardens mother, brother, and wife are all contemptible collectivists who mooch off the great man even as they despise him, while Dagnys brother Jim is the wretched prince of looters. Any Republicans seeking solace in Atlas should be warned: Ayn Rand is not your go-to philosopher for family values (much less Judeo-Christian ones).
Angular, attractive people who also happen to be collectivists, or shapeless people who happen to be rational individualists. In the universe of Atlas, physical appearance is destinyalways, without exception, from John Galt down to the last minor villain. Whenever Rand introduces a new character, you learn immediately, after a one-paragraph physical description, everything she wants you to know about that characters moral essence: angular equals good, limp, petulant, and so on equal bad. Admittedly, most movies also save the audience from unwanted thought by making similar identifications. But Rands harping on this theme isso insistent, so vitriolic, that it leaves little doubt she really did accept the eugenic notion that a persons character is visible on his or her face.
Personalities. In Atlas, as in The Fountainhead, each character has (to put it mildly) a philosophy, but no personality independent of that philosophy, no Objectively-neutral character traits. What, for example, do we know about Howard Roark? Well, he has orange hair, likes to smoke cigarettes, and is a brilliant architect and defender of individualism. What do we know about John Galt? He has gold hair, likes to smoke cigarettes, and is a brilliant inventor and defender of individualism. Besides occupation and hair color, theyre pretty much identical. Neither is suffered to have any family, culture, backstory, weaknesses, quirks, or even hobbies or favorite foods (not counting cigarettes, of course). Yes, I know this is by explicit authorial design. But it also seems to undermine Rands basic thesis: that Galt and Roark are not gods or robots, but ordinary mortals.
Positive portrayal of uncertainty. In Atlas, rationality is equated over and over with being certain one is right. The only topic the good guys, like Hank and Dagny, ever change their minds about is whether the collectivists are (a) evil or (b) really, really evil. (Spoiler alert: after 800 pages, they opt for (b).) The idea that rationality might have anything to do with being uncertainwith admitting youre wrong, changing your mind, withholding judgmentsimply does not exist in Rands universe. For me, this is the single most troubling aspect of her thought.
Honest disagreements. Atlas might be the closest thing ever written to a novelization of Aumanns Agreement Theorem. In RandLand, whenever two rational people meet, they discover to their delight that they agree about everythingnot merely the basics like capitalism and individualism, but also the usefulness of Rearden Metal, the beauty of Halleys Fifth Concerto, and so on. (Again, the one exception is the disagreement between those whove already accepted the full evil of the collectivists, and those still willing to give them a chance.) In Galts Gulch (the books utopia), theres one judge to resolve disputes, but hes never had to do anything since no disputes have ever arisen.
History. When I read The Fountainhead as a teenager, there was one detail that kept bothering me: the fact that it was published in 1943. At such a time, how could Rand possibly imagine the ultimate human evil to be a left-wing newspaper critic? Atlas continues the willful obliviousness to real events, like (say) World War II or the Cold War. And yetjust like when she removes family, personality, culture, evolution, and so on from the pictureRand clearly wants us to apply the lessons from her pared-down, stylized world to this world. Which raises an obvious question: if her philosophy is rich enough to deal with all these elephants in the room, then why does she have to avoid mentioning the elephants while writing thousands of pages about the rooms contents?
Efficient evil people. In Atlas, theres not a single competent industrialist who isnt also an exemplar of virtue. The heroine, Dagny, is a railroad executive who makes trains run on timewho knows in her heart that reliable train service is its own justification, and that what the trains are transporting and why is morally irrelevant. Granted, after 900 pages, Dagny finally admits to herself that shes been serving an evil cause, and should probably stop. But even then, her earlier dont ask why policy is understood to have been entirely forgivable: a consequence of too much virtue rather than too little. I found it odd that Rand, who (for all her faults) was normally a razor-sharp debater, could write this way so soon after the Holocaust without thinking through the obvious implications.
Ethnicity. Seriously: to write two sprawling novels set in the US, with hundreds of characters between them, and not a single non-Aryan? Even in the 40s and 50s? For me, the issue here is not political correctness, but something much more basic: for all Rands praise of reality, how much interest did she have in its contents? On a related note, somehow Rand seems to have gotten the idea that the East, and India in particular, were entirely populated by mystical savages sitting cross-legged on mats, eating soybeans as they condemned reason and reality. To which I can only reply: what did she have against soybeans? Edamame is pretty tasty.

Murray Rothbard and Eliezer Yudkowsky take different routes to some of the same conclusions.The LEGO Turing machine

Just to get back into blogging mode, here it is. They do a good job of hamming it up, too. Courtesy of Mikkel Vester, Anders Nissen, Martin Have, and Sean Geggie at the University of Aarhus (which is hereby forgiven for coming before me alphabetically).The Email Event Horizon

I know Ive been gone from the shtetl too longI even stood by as a P=NP goon performed a drive-by shooting through my comments section. Part of the explanation, Im ashamed to admit, is that Ive been procrastinating by proving theorems and writing papers, rather than building up the massive corpus of blog entries on which my tenure case will undoubtedly rest.
But most of my absence has an unhappier source. At an unknown time about three weeks ago, I crossed the Email Event Horizondefined in General Unproductivity as the point beyond which you could literally spend your entire day answering emails, yet still have more emails at the end of the day demanding immediate attention than you had at the beginning. Not spam or crank mail, but worthy missives from students, prospective students, high-school students, secretaries, TAs, fellow committee members, conference organizers, visit hosts, speakers, editors, co-editors, grant officers, referees, colleagues  everything, always, requiring you to do something, commit to some decision, send a title and abstract, pick dates for the trip, exercise Genuine Conscious Thought. No one ever writes:
Please respond to the situation described above by cracking a joke, the less tasteful the better. You will never need to deal with this matter again.
I dont know the precise moment when I crossed the EEHthere was nothing to herald it, it felt like any other momentbut its obvious now that Im in a new, unfamiliar causal region (and that, while I might have thought Id crossed years ago, I hadnt). Communication from inside the EEH to the external universe is theoretically possible, but like Hawking radiation, it tends to be excruciatingly slowand when it finally arrives, might simply regurgitate the incoming information in garbled form.
When I was a student, I used to wonder constantly about the professors whod ignore my long, meticulously-crafted emails or fire off one-word replies, yet who might suddenly have an hour for me if I walked into their offices. Were they senile? Rude? Did they secretly despise me? Now I get it, now I understandyet I doubt I could explain the warped spacetime Gmailometry I now inhabit to my own past self. On the other hand, the recognition of whats happened is itself a sort of liberation. Im starting to grasp whats long been obvious to many of you, those who crossed the EEH before I got my first AOL account in seventh grade: that its useless to struggle. By definition, the speed required to escape the EEH exceeds that of typing, while the mental energy required to accelerate a massive, resting theorist to such a speed is infinite. So theres nothing to do but blog, goof off, prove theorems, let the starred-but-unanswered inquiries pile higher and higher, and await the Email Singularity in my causal future.Discuss: Should children have the right to vote?

The above is a question thats interested me for as long as I can remember, though I avoided blogging about it until now. See, unlike many libertarian economist Ayn-Rand types, I dont actually like asking social or political questions the very asking of which marks you as eccentric and Aspergerish. Id rather apply myself to proving lower bounds, popularizing quantum mechanics, or other tasks that are (somewhat) more respected by the society I depend on for my dinner. And Id rather pick battles, like evolution or climate change, where truth and justice have well-connected allies on their side and a non-negligible chance of winning. For years, Ive been studying the delicate art of keeping my mouth shut when what I have to say will be deeply unpopularand despite lapses, Ive actually made a great deal of progress since (lets say) the age of 14.
There are times, though, when a question strikes such an emotional chord with me that I break down and ask it in spite of everything. Such a case was provoked by this story in the New York Times a few weeks ago (registration required), about a 17-year-old girl who was jailed for creating a MySpace page.
At worst, Hillary Transue thought she might get a stern lecture when she appeared before a judge for building a spoof MySpace page mocking the assistant principal at her high school in Wilkes-Barre, Pa. She was a stellar student who had never been in trouble, and the page stated clearly at the bottom that it was just a joke.
Instead, the judge sentenced her to three months at a juvenile detention center on a charge of harassment.
She was handcuffed and taken away as her stunned parents stood by.
I felt like I had been thrown into some surreal sort of nightmare, said Hillary, 17, who was sentenced in 2007. All I wanted to know was how this could be fair and why the judge would do such a thing.
The answers became a bit clearer on Thursday as the judge, Mark A. Ciavarella Jr., and a colleague, Michael T. Conahan, appeared in federal court in Scranton, Pa., to plead guilty to wire fraud and income tax fraud for taking more than $2.6 million in kickbacks to send teenagers to two privately run youth detention centers run by PA Child Care and a sister company, Western PA Child Care.
The article expresses disapproval about the corruption of the judge and the severity of the sentence, but seems completely unfazed by the idea of an American citizen standing before a judge to answer for a satirical website. And this is actually understandable given the context. While childrens rights law is a notoriously murky area, it seems fair to say that childrens individual rights (free speech, due process, etc.) are generally thin to nonexistent, certainly in the US and probably elsewhere too. So for example, if Ms. Transue had been punished by her school rather than a court for setting up her website, it probably wouldnt even have been news.
The law strikes me as inconsistent in its attitude toward minors: first it denies them individual rights, on the ground that theyre not yet capable of exercising moral judgment. But then it punishes them harshly for all sorts of offenses (in many cases more harshly than adults), thereby presupposing the moral responsibility theyre not yet supposed to have.
Now, if I had political capital to spend, I would not want to spend it on childrens rights, just as I wouldnt want to spend it on legalizing marijuana. In both cases, Im guessing that lions will embrace vegetarianism and the polynomial hierarchy will collapse to the 23rd level before American law changes significantly. But Ive also noticed an interesting difference between the two issues. In the case of marijuana, almost every brainful person Ive met (whether liberal or conservative) has agreed that the current American laws are an absurdity; that all the power is on one side of the issue while all the evidence and arguments are on the other side; and that eventually, one imagines this will all be as obvious to everyone as its obvious today (say) that contraceptives should be legal. Its just a question of time, of the regrettable generations-long delay between the inarguable and the acted-upon.
By contrast, when it comes to granting legal rights to children, people whose intelligence I respect seem compelled to give really bad arguments for the status quoarguments that (so to speak) a 12-year-old could demolish. (I know of only two famous intellectuals whove publicly advocated changing things: the educator John Holt and the quantum computing pioneer David Deutsch. Anyone know of others?)
For simplicity, lets restrict attention to the question of whether suffrage should be extended to a large class of people under 18: either by lowering the voting age (say, to 12 or 14), or better yet (in my view), by giving any citizen the vote once he or she reaches a certain age or passes a test of basic civics knowledge analogous to a drivers-ed or citizenship test. (Just like with the plurality voting system, showing that the current rule is terrible is the easy part; figuring out the best among many possible better rules to replace it is the harder and more interesting problem.)
Ill also restrict attention to the US, even though most of the discussion applies more broadly. Finally, Ill use the word children to mean children and teenagers; I like it more than legal terms like minors or people under 18.
As John Stuart Mill pointed out in The Subjection of Women, its not clear how you make an affirmative case against a form of discrimination: pretty much all you can do is stand around, wait for people to suggest pro-discrimination arguments, and then answer them.
People say: should toddlers have the vote? Should embryos? You have to draw a line somewhere! But the real question is: granting that one has to draw a line, granting that any line will be arbitrary and unfair, cant one at least make it vastly, manifestly less unfair than the current line? To give two examples: if you can be imprisoned for a crime, shouldnt you be able to vote? If you can demonstrate knowledge of American politics and history well beyond that of the average voter, shouldnt you be able to vote? (In 1971, the 26th Amendment lowered the voting age from 21 to 18, on the ground that anyone who can be drafted into the military should be able to vote. It seems to me that one can take that same logic much further.)
People say: if you want to grant the vote to sufficiently knowledgeable children, then shouldnt you also take it away from sufficiently ignorant adults? Well, its going to be quite a while before the glorious age of the intellectual meritocracy, when all shall submit willingly to Platos philosopher-kings. And before that happens, well have probably all upgraded ourselves to post-Einsteinian superintelligences anyway, by downloading the requisite applet from the iBrain storeso the question of what to do with the ignoramuses will be moot. Until that day, Im content to imagine something thats merely politically impossible (like giving the vote to anyone over 18 and to all knowledgeable minors), rather than 2 to the politically impossible power.
(Notice also that slippery-slope arguments get invoked every time any new step away from medieval morality is on the table: if we legalize gay marriage, then dont we also need to legalize polygamy, etc. etc. Again, the fact that any rule we can think of is imperfect, doesnt imply that some rules we can think of wouldnt be much better than the current ones.)
People say: if youre going to grant votes to some children and not others on the basis of a test, isnt that elitist? But why isnt the drivers-ed test or the citizenship test given to immigrants similarly elitist?
People say: even supposing they can pass some test, doesnt everyone know that children are too immature and unwise to be entrusted with awesome burden of democracy? Ah, and who are the mature, wise elders, those paragons of Enlightenment rationality, who twice elected George W. Bush? If minors could vote, wouldnt Bush have almost certainly lost both timesthereby averting (or at least mitigating) the global disaster from which were now struggling to recover? Or was that a fluke: a case of the young disproportionately getting the right answer by accident, while the older and wiser made one of their rare mistakes? Or am I being reductive and simplistic? Does our belief in the political immaturity of the young belong to that special category of truths, the ones too profound to be confronted by data or experience?
People say: but children only care about the present; they lack foresight. But isnt it children pressuring their parents to worry about climate change and the Amazon rainforest, more often than the other way around? And isnt that just what youd expect, if children formed a self-interested bloc much like any other; if they grasped (some clearly, others less so) that theyd eventually run the planet, and if they consequently cared more rather than less about the distant future? So iflike me and many othersyou see excessive short-term focus as the central tragedy of politics, then shouldnt you be chomping at the bit to let more young people vote?
People say: but children will just vote however their parents tell them to. But to whatever extent this is true, doesnt it undercut the previous fears, of immature brats voting in Mickey Mouse for president? And if millions of wives in conservative parts of the country still vote however their husbands tell them to, is that an argument for denying those wives the vote? And dont most people of every age simply vote their demographics?
People say: but only a tiny minority of precocious, high-IQ children could possibly care about votingand while you might have a point in their case, you ignore the 99% of children who only care about the latest Hannah Montana accessory. But if less than 1% of Americans want to run for Congress, or file a Freedom of Information Act request, or do computer security research thats outlawed by the DMCA, does that make those rights unimportant? At the risk of the usual chargeelitismdoesnt the tiny minority that cares about such things tend to have a disproportionate impact on everyone else?
Also, suppose that in Victorian England, only a tiny percentage of women cared about politics rather than the latest in corsets and garden mazes: should that have carried much weight as an argument against womens suffrage? What if the denial of rights to a whole class of people is a reason why many in that class focus on trivialities, rather than the other way around?
People say: but its obvious that children shouldnt vote, because theyre not economically self-sufficient. Again, wouldnt it save time to pass these arguments through the Victorian England / womens suffrage filter before making them, rather than after?
People say: ah, but theres no comparison between the two cases, since unlike Victorian women, children will be able to vote once theyre old enough. Right, and what about the children who die before theyre 18? Even ignoring those cases, is it obvious that its okay to deny people their fundamental rights, provided that those people, in turn, will someday get to deny fundamental rights to others?
People say: at any rate, denying the vote to children doesnt seem to have any particularly bad consequences. I wish I agreed; the reasons why I dont are really a topic for another post. Briefly, though, I think our cultures insistence on treating children as children even after those children are ready to be treated as adults is

weird from the standpoint of anthropology and evolutionary psychology,
an excellent prescription for turning out adults who still think the way children are supposed to,
a useful tool for cracking down on unwanted precocity of all kinds, and
a terrific way to make up for the unfortunate encroachments these past few centuries of justice, civilized behavior, and protections for the nerdy and weak, by keeping human beings in such a savage environment for the first years of their lives that by the time theyre let out, the new Enlightenment nonsense has difficulty gaining a foothold.

(For more on similar themes, see Paul Grahams justly-celebrated essay Why Nerds Are Unpopular, or my Return to the Beehive.) The denial of suffrage is just a small part of the storynowhere near the most important partbut it works as an example.
Finally people say: thats just the way things are. This argumentalso useful for justifying chattel slavery if you happen to live in 1845is, at last, a sound one. I agree with it and accept it. Because of this argument, Ill now admit that this entire post has been nothing more than an intellectual exercise, a way for me to procrastinate from answering email. I dont actually believe any of what I wrotenor, for that matter, do I believe anything. Still, purely out of academic curiosity, Id be interested to know: are there any other arguments for the legal status of Hillary Transue, besides its being the way things are?My interview with Lance

Listen to the latest edition of Lance Fortnows ComplexityCast (Complexity on Your iPod) on Podcast or MP3.
The topic: What Physicists Should Know About Computational Complexity
Length: 22 minutes
Geekiness: High
Im, uh, sorry about all the, you know, mumbling.  Clearly I havent yet been media-trained.Time for another contest

Come up with the best mnemonic device for remembering which is injective and which is surjective.Sidesplitting proofs

One thing Ive always liked about theoretical computer science is the number of proofs that are patently ridiculouswhose concluding steps seem to call more for a gong or cymbal than a QED box. This is a property that CS theory inherited from logic, and that it shares with several other mathematical fields (though by no means all of them). The titans of the comedy-proof genre are of course Gdel and Turings undecidability results, the latter of which arguably found its best expression as a poem. But there are other examples all over the place, and many arent as well known as they should be.
I was reminded of this side of theory when my student Andy Drucker and I came up with yet another absurd proof: basically, a theorem thats true for one reason if a certain algebraic problem is hard, and true for a completely different reason if the problem is easy. Were still writing it up, so at Andys request I wont spill the joke yet. For now, please content yourself with the following tried-and-true komedy klassics.
Theorem 1 (folklore): E (that is, the class of problems solvable in 2O(n) time) does not equal PSPACE, the class of problems solvable in polynomial space. (Though we have no idea how to prove which one is bigger than the other oneor that theyre incomparable, as seems most likely.)
Proof: Suppose E=PSPACE. Then E=EXP by padding, where EXP is the class of problems solvable in 2poly(n) time. But that would contradict the Time Hierarchy Theorem.
Theorem 2 (classic, attributed to Levin): One can give a fixed, explicit algorithm, which finds satisfying assignments to Boolean formulas in polynomial time whenever they exist, assuming P=NP.
Proof: let M1, M2,  be a list of Turing machines that take a SAT instance  as input. The algorithm is as follows: dovetail (that is, run a step of M1, then another step of M1 and a step of M2, then another step of M1 and M2 and a step of M3, etc.), halting when one of the machines has output a valid satisfying assignment for . If P=NP, then theres some Turing machine Mi in the list that solves SAT, and that causes the whole algorithm to work in polynomial time assuming  was satisfiable. (The fact that youre also simulating quadrillions of other machines merely slows things down by a polynomial factor, independent of the input size n.)
Theorem 3 (Gutfreund, Shaltiel, Ta-Shma): Let A be an algorithm thats supposed to solve SAT in polynomial time (that is, find a satisfying assignment whenever one exists), but that actually fails on some SAT instance of size n. Then if someone gives you the source code of A, you can, in time polynomial in n, find a specific SAT instance that actually witnesses As failure.
Proof: By the Cook-Levin Theorem, you can create a SAT instance(x) which encodes the statement, x is a SAT instance of size n on which A fails (that is, either theres a satisfying assignment A fails to find, or A outputs an assignment for x that isnt satisfying). Then feed  as input to A. There are two cases: on the one hand, if A succeeds, then its helpfully provided you with a SAT instance on which it itself fails. On the other hand, if A fails on , then  itself is the SAT instance you were looking for.
Theorem 4 (Barak et al.): There exist programs that cant be obfuscatedthat is, for which having the actual code of the program lets you do something that you couldnt do if you could only run the program as a subroutine.
Proof: Let P be a program that takes a string x as input, and does the following. First, if x=a, where a is some n-bit secret string hardwired into Ps source code, then P(a) outputs another n-bit secret string b. Second, if x is the source code of a program Q such that Q(a) outputs b (after some fixed number of steps, say t=O(n)), then P outputs a third secret string c. Third, if x satisfies neither constraint, then P(x) outputs FAIL. Now, given the source code of P, its easy to find c: just run P with its own code as input. On the other hand, if you can only run P as a subroutine, then (unless you get extremely lucky) it will take exponential time to find any x for which P(x) outputs anything besides FAIL. Hence its infeasible to find c by running P, and yet theres no way to obfuscate Ps source code so as to hide c.
Theorem 5 (attributed by Razborov and Rudich to Wigderson): No natural proof can prove better than a half-exponential lower bound on the circuit complexity of the discrete logarithm problem. (Here half-exponential refers to a function fwhich exists, but cant be described analyticallysuch that f(f(n)) grows exponentially with n.)
Proof Sketch: Suppose we can prove an f(n) lower bound on the circuit complexity of discrete log, using a natural proof. Then by the definition of natural proof, there exists a 2O(n)-time algorithm to distinguish a truly random function g:{0,1}n{0,1} from a function with circuit size f(n). This means that any efficiently-computable pseudorandom function family (PRFF), with seed length m=f(n), can be distinguished from a random function in exp(f-1(m)) time. By standard equivalence theorems in cryptography, this means that any purported one-way functionso for example, the modular exponentiation functioncan be inverted in exp(f-1(n)) time. In other words, to prove a natural f(n) lower bound for the discrete logarithm problem, you must also discover an exp(f-1(n))-time algorithm for the discrete logarithm problem. As you show the discrete log problem to be harder, you simultaneously show it to be easier! And when f is greater than half-exponential, the lower bound becomes greater than the upper bound.
What is it that makes these theorems funny? (Alright, maybe not ha-ha funny, but at least snort-snort funny?) This is one case where a few readers might want me to break the rule about never explaining a joke. Theorems 1 and 2 are sort of like youre lost, as an answer to the balloonists plea of where am I?: theyre logically impeccable yet tell you nothing whatsoever about what you wanted to know. Theorems 3 and 4 are like someone whos so hungry he devours the menu at a restaurant, not even realizing that the menu itself was listed on the menu. They seem to involve a category mistake: a reference gluttonously repurposed as a referent only to become a reference again. (This, of course, is the joke behind Gdels theorem as well.) Theorem 5 is like a literary critic proving theres no reality separate from race, class, and gender biases, using arguments that are so well-grounded, even a white male plutocrat would have to concede their truth. The case is a self-immolating one: every argument that makes it stronger necessarily makes it weaker as well.
So whats your favorite sidesplitting proof?Literature that skewers pompous fools

Update (April 4): I just finished reading Postmodern Pooh by Frederick Crewsa hilarious spoof of modern literary criticism, by someone who was the chair of Berkeleys English department and understands the theories hes ridiculing as well as anyone.I actually found Crews fake Marxist, feminist, and deconstructionist exegeses of  Winnie the Pooh far more persuasive than the serious scholarship he reverently quotes. Crews seems to be breathing life into straw opponents here: making the obscurantist literary theories much more sensible and interesting than they really are, in order to give himself some challenge knocking them down.(The real fun comes when his intentionally goofy arguments start  working on youwhen you yourself can no longer read innocent passages about Eeyore, Piglet, and Tigger without seeing the simmering sexual innuendo and class struggle.) For anyone who likes the sort of books I discuss in this post, I recommend Postmodern Pooh in the strongest terms.
Several commenters on my last post asked why Id waste time with Atlas Shrugged, given its evident flaws. The reason is simple: because when theres so little literature that gets emotional about rationality, youre tempted to take what you can. Throughout history, the weapons of artpoetry, literature, movieshave been deployed mercilessly against scientists, engineers, and anyone else so nave or simplistic as to think there are right and wrong answers. Other times, a work of literature will praise scientists, but the science itself will be cringeworthyand worse yet, the juvenile humor at the core of how science works will be absent, replaced by a wooden earnestness more in line with the writers preconceptions. Occasionally, though, what you might call the satiric rationalist impulse (if you were writing a PhD thesis about it) has found superb expression in literature. So in this post, Id like to celebrate a few literary works that exemplify what appealed to me about Ayn Rand as a teenagerbut do so without Rands shrill libertarianism, suspicion of modern science, or deification of Nietszchean quasi-rapist supermen.At the head of the list is the Dialogue Concerning the Two Chief World Systems by Galileo Galilei. I submit that Galileos greatest contribution here was not his account of how it could be possible for the Earth to go around the Sun even though we dont feel the Earths motion. For that achievement was far surpassed by his creation of Simplicio: the amiable doofus (standing in for scholastic astronomers) who answers Salviatis patient explanations with pompous Latin phrases and quotations from Aristotle. Apparently the main reason Galileo was hauled before the Inquisition was not his scientific arguments, which the Church assumed most people wouldnt understand or care about anyway. Rather, Pope Urban VIII was outraged that Galileo put his (the Popes) own arguments about the limits of empirical thinking into the mouth of Simplicio.I find it interesting that Galileos dialogues are almost never assigned in high schools, despite being not merely among the most influential works of all time, but also uproariously funny. Why is that? After 400 years, is the parody still too barbed for some peoples tasteA not-quite-exponential dilemma

A commenter on my last post writes:
Scott, its your blog  but cant we switch back to some QC or TCS topics?
I confess: after three years of staid, dignified posts about quantum computing and theoretical computer science, I somehow did the unthinkable, and let this once-respected blog become less about elucidating research than procrastinating from it. Many readers, or so they tell me, rely on Shtetl-Optimized to keep abreast of the latest theoretical insights. And rather than ask those readers whether they also rely on deep-fried Snickers bars for the Vitamin E in the peanuts, I have a moral obligation to serve them.
Fortunately for the theory-starved among you, a certain je ne sais quoi in the air last week has caused me to refocus my attention on research. The mysterious force affected not only me, but seemingly my entire floor of the Stata Centergiving rise to a carnival-like crescendo of increasingly-frantic theorizing that ended just as inexplicably as it began, around 6:59PM Thursday night.
So today, Im proud to post something vaguely related to science once again. On the suggestion of Wim van Dam, I hereby announce another contest, with no prize or even possibly winner. Your task is simple:
Come up with a catchy name for growth rates of the form 2n^, 0<<1.
(For example, the running time of the fastest known classical factoring algorithm has this form, as does that of the fastest known algorithm for graph isomorphism.)
The word subexponential is often used, but should not be, since we already use it for growth rates smaller than 2n^ for all >0.
This just in: Friend-of-the-blog Greg Kuperberg, whos always more fun than a cinder block combined with a reprimand, informs me that 2n^ growth rates already have a name: stretched exponentials. But

Ive never heard that term in my life,
I dont like it: it sounds like something bigger than exponential, not smaller, and
Having called 2n subexponential in his otherwise-great paper on a quantum algorithm for the Dihedral Hidden Subgroup Problem, for Greg to now lecture others on this issue seems like  stretching it.

So my and Wims challenge to the readerariat stands.Corn, rice, and wheat

Now, Im not much of a farming type. But for some reason, about a year ago I became intensely curious about three cereal grainscorn, rice, and wheatand the central role they played in getting civilization off the ground. And so, on this Passover holiday, when Ashkenazi Jews are supposed to avoid not only leavened bread, but corn and rice as well (the reason? apparently some 13th-century rabbi feared that a grain of wheat might fall in undetected), I thought Id go against the grain, and ask Four Questions about all three of these strange plants.
Question I. How did hunter-gatherers ever get the idea to breed these grains? Of course, we know today that whether or not theyre labeled organic at Whole Foods, cereal grains arent much like anything found in nature, but are the result of thousands of years of selective breeding: massive genetic-engineering projects of the ancient world. The trouble is that, if you ran into one their wild ancestors, there probably wouldnt be anything appetizing about it. Corns ancestor, for example, seems to have been a barely-edible grass called teosinte. Does the only explanation we can ever hope for rely on anthropic postselection: eventually some cave-dwellers stumbled on the idea of breeding grain, and were all living in the aftermath of the resulting population explosion? But the fact that it happened not once, not twice, but three times independentlywith wheat in the Middle East, rice in Asia, and corn in the Americassuggests that it couldnt have been all that unlikely. Which brings us to
Question II. What other plants could similarly be used as the basis for a large civilization? The one other plant I can think of thats played a similar role is the yam, in parts of Africa. Has there ever been a culture that used the potato as its main food sourcemaybe in Russia or Eastern Europe? (Update, 4/12: Duhhhhhhh, the Irish, of course, hence the Irish Potato Famine. Thanks to several commenters for pointing this out.) OK, what about oats, barley, rye, or sorghum?
Question III. Corn, rice, wheat: which one is best? Is there one such that, if we all switched to it, wed be ten times healthier and also save the planet? Or, on the tiny chance that we cant settle that question via blog comments, can we at least elucidate the salient differences? (Corn does seem like the outlier among the three, much as I enjoy grilled rice and wheat on the cob)
Question IV. Should we still be eating these grains today? It seems clear that corn, rice, and wheat were directly responsible for a human population explosion, and that even today, the planet couldnt support most of its inhabitants without them. But for those who can afford to, the promoters of hunter-gatherer diets advocate returning to foods that were available in the ancestral environment, such as nuts, berries, and roasted mammoth leg. The underlying question here is actually an interesting one: did the switch to agriculture cause some sort of massive change in human health? The most surprising answer would seem to be that it didnt.
Despite the staggering amount of research I did for this post, it remains conceivable that there are readers who know more about these topics than I do. And so, having thrown out a few seeds, I look forward to reaping a bounteous harvest of grain-related comments.Teleport, tunnel, adiabatbut one way or another, get there

As a general rule, I dont post workshop announcements on this blog: if I did it for one, Id have to do it for all, etc. etc. But Ive decided that an exception can be made, if the requesting party has won a bet against Stephen Hawking. And so it is that I, on behalf of John Preskill, hereby encourage you to attend the Quantum Information Science Workshop in Vienna, VA, from April 23-25, which has been hastily called in response to the report A Federal Vision for Quantum Information Science. The whole quantum information community is invited, but the deadline for the workshop hotel rate is today! The future of our entire field will be decided at this workshop:

Should more quantum algorithms be discovered, or not?
Is battling decoherence important, or unimportant?
Are interdisciplinary insights needed from CS, physics, and other fields, or will a single discipline suffice?

If youre as hungry for the answers as I am, you wont want to miss this.Let no one call me an enemy of the arts

From San Francisco, CA, en route to UC Berkeley, Shtetl-Optimized is proud to bring you
I JUST DO THEORY

Winner of the 2007 Aaronson/Gasarch Complexity Theme Song Contest (beating out You Down with SPP and other audience favorites)
Da MP3, as recently recorded by Homage the Halfrican Cracker.
(Stage name of Dustin Lee, a singer and dance instructor based in Calgary, Canada. Homage is currently a finalist for Best Song at the Calgary Folk Festival. Here is his YouTube channel, and here are previews of his music. Hey, you sing the greatest CS theory rap of all time, you get a free plug on Shtetl-Optimized.)
Lyrics by Aaron Sterling, 23 June 2007.
Inspired by Weird Al Yankovics White & Nerdy.
Original music and words by Chamillionaire, Riding.
They see me proving my theorem.
I know theyre all thinking I just do theory.
Think I just do theory.
Think I just do theory.
Cant you see I just do theory?
Look at me, I just do theory!
I wanna code with the hackers
But so far they all think I just do theory.
Think I just do theory.
I just do theory.
I just do theory.
Really, truly, just do theory.
I wrote a program that solved TSP
Superquasipolynomially.
Aint no such thing as lunch for free
When youre digesting P-NP.
Unnatural proofs are my favorite vice
When I dream of solvers paradise.
But my poor construction wont suffice,
Even when I add Karp-Lipton advice.
Yo! Theres more to life than just systems!
Just too mathy? Quit your grumping.
I may not get the joint jumping
But my lemmas can do some pumping.
I declare to all my detractors
To exchange keys you need extractors.
You cant improve with blind refactors.
You need me, not ten contractors.
Dont know how to start an IDE
But I always win at compIP.
Im a wizard bounding MA-E,
Playing games in PPAD.
My languages are always acceptable.
My LaTeX skills? They are impeccable.
My proofs are probabilistically checkable.
But what I compile just isnt respectable.
You see, I just do theory.
Theyre on RA, while Im teaching.
Thats how they know that I just do theory.
Know I just do theory
Know I just do theory
I admit it, I just do theory.
Look at me, I just do theory.
Id like to code with the hackers
Although its apparent I just do theory
Yes, I just do theory
Right, I just do theory
I just do theory.
Why is it I can just do theory?
I aced math classes in school.
One-Ten is my favorite rule.
Intractabilitys really cool.
Ive been unplugging while you were debugging.
Your Windows crashed, your hard disks whirring,
But my platforms all are Turing.
Not a lot of exceptions get thrown
Approximating Diophantines with twelve unknowns.
Im the departments main instructor.
When they need a course taught, who do they ask?
Im always up to the task.
It beats sitting on my ass.
Im trying to cold-start my social network
Saying Busy Beaver with a smirk.
In galleries I troll, in weblogs I lurk.
But its hard to reach Big O if you wont tell the world hello.
My grandest conceit is that my brain is PSPACE-complete.
My calculus is lambda and my math is discrete.
The only problem that ever made me halt
Was whether Samson or Delilah won by default.
My theorem statements are ungrounded.
All my measures are resource-bounded.
They see me struggling at runtime.
They feel sorry because I just do theory.
Yes, its true, I just do theory.
Yes, its true, I just do theory.
All because I just do theory.
BQP, I just do theory.
I wanna code with the hackers
But oh well, they can tell I just do theory.
I just do theory.
I just do theory.
Yes, I just do theory.
QED, I just do theory.
(everybody shout) Box!
[Heres the PDF. Thanks so much to Aaron and Homage for the permission. After this song goes viral, and gets ten times more hits than Susan Boyle, just remember: you heard it here first. Peace out, BQP-dawg]One way Obama has supported scientists

By giving me a free blog post. From his address to the National Academy of Science (full text here):
A few months after a devastating defeat at Fredericksburg, before Gettysburg would be won and Richmond would fall, before the fate of the Union would be at all certain, President Lincoln signed into law an act creating the National Academy of Sciences. Lincoln refused to accept that our nations sole purpose was merely to survive. He created this academy, founded the land grant colleges, and began the work of the transcontinental railroad, believing that we must add the fuel of interest to the fire of genius in the discovery  of new and useful things 
At such a difficult moment, there are those who say we cannot afford to invest in science. That support for research is somehow a luxury at a moment defined by necessities. I fundamentally disagree
I am here today to set this goal: we will devote more than three percent of our GDP to research and development  This represents the largest commitment to scientific research and innovation in American history
The fact is, an investigation into a particular physical, chemical, or biological process might not pay off for a year, or a decade, or at all. And when it does, the rewards are often broadly shared, enjoyed by those who bore its costs but also by those who did not. Thats why the private sector under-invests in basic science  and why the public sector must invest in this kind of research. Because while the risks may be large, so are the rewards for our economy and our society
We double the budget of key agencies, including the National Science Foundation, a primary source of funding for academic research, and the National Institute of Standards and Technology, which supports a wide range of pursuits  from improving health information technology to measuring carbon pollution, from testing smart grid designs to developing advanced manufacturing processes. And my budget doubles funding for the Department of Energys Office of Science which builds and operates accelerators, colliders, supercomputers, high-energy light sources, and facilities for making nano-materials
Our future on this planet depends upon our willingness to address the challenge posed by carbon pollution. And our future as a nation depends upon our willingness to embrace this challenge as an opportunity to lead the world in pursuit of new discovery
On March 9th, I signed an executive memorandum with a clear message: Under my administration, the days of science taking a back seat to ideology are over. Our progress as a nation  and our values as a nation  are rooted in free and open inquiry. To undermine scientific integrity is to undermine our democracy
We know that the quality of math and science teachers is the most influential single factor in determining whether or a student will succeed or fail in these subjects. Yet, in high school, more than twenty percent of students in math and more than sixty percent of students in chemistry and physics are taught by teachers without expertise in these fields
My budget also triples the number of National Science Foundation graduate research fellowships. This program was created as part of the Space Race five decades ago. In the decades since, its remained largely the same size  even as the numbers of students who seek these fellowships has skyrocketed. We ought to be supporting these young people who are pursuing scientific careers, not putting obstacles in their path
I had only one quibble with the speech. The President says: The calculations of todays GPS satellites are based on the equations that Einstein put to paper more than a century ago. True enoughbut they depend not only on SR but even on GR, which was put to paper around 1916.
Predictably, coverage of this speech has concentrated on (1) some remarks about swine flu, and (2) a trivial incident where Obama got ahead of his TelePrompter. Clearly, he has a ways to go before matching the flawless delivery of our previous leader.
Im back in Boston, having returned from my trip to Berkeley and to the Quantum Information Science Workshop in Virginia. I understand that the slides from the QIS workshop will be available any day now, and Ill blog about the workshop once they are. (Sneak preview: it turns out that more quantum algorithms should be discovered, battling decoherence is important, and interdisciplinary insights are neededbut there were actually some pretty spectacular results and open problems that I hadnt heard before.)
Id also like to blog about two books Im reading: Outliers by Malcolm Gladwell, and First Principles by Howard Burton (about the founding of the Perimeter Institute, and the first scientific history Ive ever read for which I was there when a lot of it happened). Then again, if enough people discuss these books in the comments section, I wont have to.The QIS workshop

As promised, heres my report on the Quantum Information Science Workshop in Virginia, only a week or so behind schedule.
I tried to be cynicalreally I did. But despite my best efforts, somehow I went home more excited about quantum than Ive been in a long time.
The highlight of the workshop was of course the closed, invitation-only, late-night meeting in the basement of NSF headquarters, at which a group of us hidebound quantum computing reactionaries plotted to keep the field focused on irrelevant mathematical abstractions, and to ostracize the paradigm-smashing entrepreneurial innovators who threaten our status. I dont think Ive ever heard so much cackling in the space of a single evening, or so much clinking of bone goblets. Stuff like that is why I entered the field in the first place.
But there were some other highlights as well:
[Full list of talks iz heer]
1. In his talk on quantum algorithms with polynomial speedups, Andris Ambainis called attention to a spectacular recent paper by Ben Reichardt, which characterizes the quantum query complexity of any partial or total Boolean function f (up to a logarithmic factor) as the optimal witness size of a span program for f, and also as the negative-weight quantum adversary lower bound for f. Assuming this result is correct, it seems possible that the remaining open problems in quantum query complexity will be pulverized, one after another, by solving the associated SDPs for the optimal span programs. (Incidentally, using Reichardts result, it must be possible to prove, e.g., a (n1/3/log(n)) lower bound for the quantum query complexity of the collision problem using the adversary method. This was a longstanding open problem. Can one say, explicitly, what the adversary matrices are in this case?) Alas, it also seems possible that span programs will turn out to be almost as hard to analyze as quantum algorithms were
(1+5)/2. Despite the obvious danger to the future funding of the entire field, by some clerical error I was released from my padded cell to speak about Quantum Complexity and Fundamental Physics. My talk, if it can be called that, was in my opinion neither rational nor integral to the workshop.
2. In her talk on blind quantum computation, Anne Broadbent (whos also visiting MIT this week) described some beautiful new results that partly answer my Aaronson $25.00 Challenge from a year and a half ago. The Challenge, if you recall, was whether a quantum computer can always prove its work to a classical skeptic who doesnt believe quantum mechanicsor more formally, whether every problem in BQP admits an interactive protocol where the prover in BQP and the verifier is in BPP. Anne, Joe Fitzsimons, and Elham Kashefi havent quite answered this question, but in a recent paper theyve come close: theyve shown that a quantum computer can prove its work to someone whos almost completely classical, her only quantum power being to prepare individual polarized photons and send them over to the quantum computer. Furthermore, their protocol has the amazing property that the quantum computer learns nothing whatsoever about which particular quantum computation its performing! (Aharonov, Ben-Or, and Eban independently gave a protocol with the same amazing properties, except theirs requires the classical verifier to have a constant-sized quantum computer.) Anne et al. also show that two quantum computers, who share entanglement but cant communicate with each other, can prove their work to a completely classical verifier (while, again, remaining completely oblivious to what they computed).
On top of everything else, these results appear to be the first complexity-theoretic application of the measurement-based quantum computing paradigm, as well as the first inherently quantum non-relativizing results. (Admittedly, we dont yet have an oracle relative to which the blind quantum computing protocols dont workbut the protocols rely essentially on the gate structure of the quantum circuits, and I conjecture that such an oracle exists.)
Rereading my Challenge, I noticed that the [one-member] Committee may also choose to award smaller prizes for partial results. And thus, yesterday I had the pleasure of awarding Anne a crumpled $10 bill, with an additional $5 contributed by Seth Lloyd, for a grand total of $15.00 to be shared equally among Anne, Joe, and Elham. (Update: Since I wrote that, Anne has elected to trade in for three signed and doodled-upon $5 bills.) (Another Update: A $12, or $15-$O(1), prize shall be awarded to Dorit Aharonov, Michael Ben-Or, and Elad Eban the next time I see them.) This is, I believe, the first time a monetary reward offered on Shtetl-Optimized has actually been paid out.
3. In a talk that was so good, you almost forgot it involved chemistry, Aln Aspuru-Guzik discussed applications of quantum complexity theory to understanding photosynthesis and the design of efficient solar cells (!). To give you a sense of how mindblowing that is, it briefly made me wonder whether I should reread some of John Sidles cheerful ramblings about the coming merger of quantum systems engineering with biology in the 21st  century (of which, I predict, this very sentence will inspire dozens more).
So what then is the connection between quantum complexity theory and photosynthesis? Well, a few of you might remember my post Low-Hanging Fruit from Two Conjoined Trees from years ago, which discussed the lovely result of Childs et al. that a quantum walk on two conjoined binary trees can reach a designated end vertex exponentially faster than a classical walk on the same graph. That result interested me, among other things, because it can be shown to lead to an oracle relative to which BQP  SZK, which at the time I didnt know how to find otherwise. But especially given the bizarre nature of the graph needed to produce the oracle separation, I thought of this result as pretty much the prototype of an irrelevant complexity-theoretic curiosity (which, naturally, made me like it all the more).
You can probably guess where this is going.

Shown above is a light-harvesting molecule (image snagged from Alns slides), which apparently is efficient at concentrating light at its center for essentially the same reason the Childs et al. quantum walk reaches the target vertex exponentially faster than a classical walk: namely, because of destructive interference between the paths that point backward, toward the leaves. According to Aln, what plants do to harvest sunlight is not entirely unrelated either (it also involves quantum coherence), and fully understanding these mechanisms in quantum information terms might conceivably be useful in designing better solar cells. To be fair, a part of me always did suspect that quantum oracle separations would turn out to be the key to solving the world energy crisis. Ill point you here or here if you want to know more.
Incidentally, Alns talk had another, also extremely interesting part, which was about coming up with precise numerical estimates of the number of qubits youd need to simulate the wavefunctions of (say) benzene, caffeine, and cholesterol. (Many of us have long thought that simulating physics and chemistry will be the real application for scalable quantum computers if we ever build them, practical long before breaking RSA and ultimately more useful too. But its not something we often talk aboutostensibly for lack of meaty things to say, really because we dont know chemistry.)
4. In her talk, Dorit Aharonov posed an open problem that I now have no choice but to inflict on others, if I dont want to feel forced to think about it myself. So heres her problem: how hard is it to find the ground state of a local Hamiltonian H=H1++Hm (that is, a sum of k-qubit interactions, for some constant k), if we impose the constraint that the His all commute with each other? Clearly its somewhere between NP and QMA. It might seem obvious that this problem should be in NPto which I can only respond, prove it!
There were also lots of great talks by the experimentalists. Having attended them, I can report with confidence that (1) theyre still trying to build a quantum computer but (2) decoherence is still a big problem. If you want to know even more detail than Ive just providedor you want to know about the theory talks I didnt mention, or more about the ones I did mentionask away in the comments. I cant promise that no one will know the answer.Wanted: Quantum GGM theorem

A commenter on my last post writes:
Dear Scott, Please keep the focus of your blog. You have lately been losing science to your blog and started blogging about various loosely related things. One of the ways I subscribed to your blog was because your articles were very computation-oriented. Now you no longer keep the theme. And as you might have heard, shifting topics in your blog will lose your readers.
So today I noticed something bizarre. A celebrated result in cryptography, due to Goldreich, Goldwasser, and Micali, states that any pseudorandom generator gives rise to a pseudorandom function family. See Lucas notes or the original GGM paper for more.
Now Id always assumed, without thinking about it, that the GGM result obviously carries over to the quantum caseso that any pseudorandom generator secure against quantum attack would give rise to a pseudorandom function family secure against quantum attack. But now that Im writing a paper that actually relies on this fact, I realized I have no idea why its true.
Look: in the GGM argument, you start with a pseudorandom generator G:{0,1}n{0,1}2n, and you apply it recursively to produce a family of functions fs:{0,1}n{0,1}n, where s is the seed. You then consider a hypothetical polynomial-time algorithm A that distinguished fs from a truly random function. You show how you could use A to create a polynomial-time algorithm that distinguished the output of G from a truly random 2n-bit stringthereby contradicting the starting assumption that G was pseudorandom.
The trouble is, the argument relies crucially on the fact that A examines only a polynomial number of outputs of fsintuitively so that you can run a hybrid argument, changing the outputs that A actually examines one by one into truly random strings. But if A is a quantum algorithm, then (duh) it can examine all 2n outputs of fs in superposition! So any argument that depends on watching A to see which inputs it queries is toast.
But maybe we can recover the same conclusion in a fancier way? For at least seven years, Ive been going around conjecturing the following:
Conjecture (): Let Q be a quantum algorithm that makes T queries to a Boolean input X{0,1}N. Then for all ,>0, there exists a deterministic classical algorithm that makes poly(T,1/,log(1/)) queries to X, and that approximates Qs acceptance probability to within  on a 1- fraction of inputs.
My motivation for Conjecture () had nothing to do with cryptography. I was interested in whether we could rule out the possibility that P=BQP relative to a random oracle with probability 1. If Conjecture () holdsand if the classical algorithm is anything like I think it isthen we cant rule it out, at least not without proving PPSPACE or an even stronger separation in the unrelativized world.
It now occurs to me that, if we knew how to prove Conjecture (), then maybe we could push through a quantum GGM argument using similar ideasthat is, by identifying a tiny subset of inputs to fs that the quantum algorithms acceptance probability really depends on. Alas, I have good reason to believe that Conjecture () is hard.
So the task remains: prove a quantum GGM theorem. Or maybe Im missing something completely obvious?
PS. The promised report on the QIS conference in Virginia is coming tomorrow. Take that, future self!
Update (5/3): An anonymous commenter points out that we can use a simpler hybrid argument of Razborov and Rudichwhich doesnt break down in the quantum caseto show that if there exists a PRG thats secure against 2n^(1)-time quantum adversaries, then there also exists a PRF with polynomial seed length thats secure against exponential-time quantum adversaries. That somehow hadnt occurred to me, and its good enough for my purposes. (Masked cryptographer: emerge ye from the shadows, and claim thy rightful honour in my Acknowledgments!) On the other hand, the extremely interesting question still stands of whether one can prove a strong, GGM-style reduction: from PRGs secure against f(n)-time quantum adversaries to PRFs with linear seed length secure against f(n)(1)-time quantum adversaries, for any superpolynomial f.An unexpected application of the P vs. NP problem

Read to the end  hat tip to Michael Nielsen. And this post is just to get into blogging stride again. More coming soon.My long, complexity-theoretic journey

So, what was I doing these past few weeks that could possibly take precedence over writing ill-considered blog entries that Id probably regret for the rest of my life?
1. On the gracious invitation of Renato Renner, I visited one of Al Einsteins old stomping-grounds: ETH Zrich. There I gave a physics colloquium called How Much Information Is In A Quantum State?, as well as a talk on my paper Quantum Copy-Protection and Quantum Money, which has been more than three years in the procrastinating. Though I was only in Switzerland for three days, I found enough time to go hiking in the Swiss Alps, if by Swiss Alps you mean a 200-foot hill outside the theoretical physics building. Im quite proud of having made it through this entire tripmy first to Switzerlandwithout once yodeling or erupting into cries of Riiiiiiicola! On the other hand, what with the beautiful architecture, excellent public transportation, and wonderful hosts, it was a struggle to maintain my neutrality.
2. On the plane to and from Switzerland, I had the pleasure of perusing Computational Complexity: A Modern Approach, by Sanjeev Arora and Boaz Barak, which has just been published after floating around the interweb for many years. If youre a hardcore complexity lover, I can recommend buying a copy in the strongest terms. The book lives up to its subtitle, concentrating almost entirely on developments within the last twenty years. Classical complexity theorists should pay particular attention to the excellent quantum computing chapter, neither of whose authors has the slightest background in the subject. You see, people, getting quantum right isnt that hard, is it? The books only flaw, an abundance of typos, is one that can and should be easily fixed in the next edition.
3. I then visited the National Institute of Standards and Technologyproud keepers of the meter and the kilogramat their headquarters in Gaithersburg, MD. There I gave my talk on Quantum Complexity and Fundamental Physics, a version of the shtick I did at the QIS workshop in Virginia. Afterwards, I got to tour some of the most badass experimental facilities Ive seen in a while. (Setting standards and making precision measurements: is there anything else that sounds so boring but turns out to so not be?) A highlight was the Center for Neutron Research, which houses whats apparently the largest research reactor still operating in the US. This thing has been operating since 1967, and it shoots large numbers of slow-moving neutrons in all directions so that archaeologists, chemists, physicists, etc. can feed off the trough and do their experiments. The basic physics thats been done there recently has included setting bounds on possible nonlinearities in the Schrdinger equation (even though any nonlinearity, no matter how small, could be used to send superluminal signals and solve NP-complete problems in polynomial time), as well as observing the photons that the Standard Model apparently predicts are emitted 2% of the time when a neutron decays. I also got to see one of the worlds least jittery floors: using dynamical feedback, they apparently managed to make this floor ~107 times less jittery than a normal floor, good enough that they can run a double-slit experiment with slow neutrons on top of it and see the interference pattern. (Before you ask: yes, I wanted to jump on the floor, but I didnt. Apparently I wouldve messed it up for a day.)
I have to add: the few times Ive toured a nuclear facility, I felt profoundly depressed by the retro feel of everything around me: analog dials, safety signs from the 60s Why are no new reactors being built in the US, even while their value as stabilization wedges becomes increasingly hard to ignore? Why are we unwilling to reprocess spent fuel rods like France does? Why do people pin their hopes on the remote prospect of controlled fusion, ignoring the controlled fission weve had for half a century? Why, like some horror-movie character unwilling to confront an evil from the past, have we decided that a major technology possibly crucial to the planets survival must remain a museum piece, part of civilizations past and not its future? Of course, these are rhetorical questions. While you can be exposed to more radiation flying cross-country than working at a nuclear reactor for months, while preventing a Chernobyl is as easy as using shielding and leaving on the emergency cooling system, human nature is often a more powerful force than physics.
4. Next I went to STOC2009 in Bethesda, MD. Let me say something about a few talks that are impossible not to say something about. First, in what might or might not turn out to be the biggest cryptographic breakthrough in decades, Craig Gentry has proposed a fully homomorphic encryption scheme based on ideal lattices: that is, a scheme that lets you perform arbitrary computations on encrypted data without decrypting it. Currently, Gentrys scheme is not known to be breakable even by quantum computersdespite a 2002 result of van Dam, Hallgren, and Ip, which said that if a fully homomorphic encryption scheme existed, then it could be broken by a quantum computer. (The catch? Van Dam et al.s result applied to deterministic encryption schemes; Gentrys is probabilistic.)
Second, Chris Peikert (co-winner of the Best Paper Award) announced a public-key cryptosystem based on the classical worst-case hardness of the Shortest Vector Problem. Previously, Regev had given such a cryptosystem based on the assumption that theres no efficient quantum algorithm for SVP (see also here for a survey). The latter was a striking result: even though Regevs cryptosystem is purely classical, his reduction from SVP to breaking the cryptosystem was a quantum reduction. What Peikert has now done is to dequantize Regevs security argument by thinking very hard about it. Of course, one interpretation of Peikerts result is that classical crypto people no longer have to learn quantum mechanicsbut a better interpretation is that they do have to learn QM, if only to get rid of it! I eagerly await Oded Goldreichs first paper on quantum computing (using it purely as an intellectual tool, of course).
Third, Robin Moser (co-winner of the Best Paper Award and winner of the Best Student Paper Award) gave a mindblowing algorithmic version of the Lovsz Local Lemma. Or to put it differently, Moser gave a polynomial-time algorithm that finds a satisfying assignment for a k-SAT formula, assuming that each clause intersects at most 2k-2 other clauses. (It follows from the Local Lemma that such an assignment exists.) Mosers algorithm is absurdly simple: basically, you repeatedly pick an unsatisfied clause, and randomly set its variables so that its satisfied. Then, if doing that has made any of the neighboring clauses unsatisfied, you randomly set their variables so that theyre satisfied, and so on, recursing until all the damage youve caused has also been fixed. The proof that this algorithm actually halts in polynomial time uses a communication argument that, while simple, seemed so completely out of left field that when it was finished, the audience of theorists sort of let out a collective gasp, as if a giant black QED box were hovering in the air.
Fourth, Babai, Beals, and Seress showed that if G is a matrix group over a finite field of odd order, then the membership problem for G can be solved in polynomial time, assuming an oracle for the discrete logarithm problem. This represents the culmination of about 25 years of work in computational group theory. I was all pumped to announce an important consequence of this result not noted in the abstractthat the problem is therefore solvable in quantum polynomial time, because of Shors discrete log algorithmbut Laci, alas, scooped me on this highly nontrivial corollary in his talk.
5. Finally, I took the train up to Princeton, for a workshop on Cryptography and Complexity: Status of Impagliazzos Worlds. (For the insufficiently nerdy: the worlds are Algorithmica, where P=NP; Heuristica, where PNP but the hard instances of NP-complete problems are hard to find; Pessiland, where the hard instances are easy to find but none of them can be used for cryptographic one-way functions; Minicrypt, where one-way functions do exist, enabling private-key cryptography, but not the trapdoor one-way functions needed for public-key cryptography; and Cryptomania, where trapdoor one-way functions exist, and cryptography can do pretty anything you could ask.) I gave a talk on Impagliazzos worlds in arithmetic complexity, based on ongoing join work with Andy Drucker (where ongoing means were pretty sure more of our results are correct than would be expected by random guessing).
Tell you what: since its been a long time, feel free to ask whatever you feel like in the comments section, whether related to my journeys or not. Ill try to answer at least a constant fraction of questions.The Limits of Irany

Update (6/20/2009): If you agree about Mahmoud deserving his vacation, please read and sign this petition (courtesy of Elham Kashefi).  I have no doubt that if enough Shtetl-Optimized readers sign, it will force the ayatollahs to reconsider.
I havent heard frommy pal Mahmoudin years, but some mutual friends told me that hes been pretty stressed about his job lately. They said youre supposed to turn yourblogsbackgroundgreenif you agree with some concerned folks whove been marching around Tehran encouraging him to take a much-needed breatherUmeshisms

If youve never missed a flight, youre spending too much time in airports.
When I was a grad student at Berkeley, my advisor, Umesh Vazirani, liked to repeat this nugget of wisdom to students, friends, and colleagues. In a single sentence, Umesh was communicating an entire philosophy of life: concentrate on the high-order bits. The squash player who runs back and forth to attempt every shot, the student whos never late with an assignment, the researcher who stalks an unimportant problem like Captain Ahab: all have succumbed to the tyranny of the low-order bit. They need to realize that, as in a randomized algorithm, occasional failures are the inevitable byproduct of a successful strategy. If you always win, then youre probably doing something wrong.
On the other hand, having dropped Umesh off at 8PM for an 8:30 international flight, I can attest from personal experience that he was talking about actual air travel as well.
I thought about Umeshs Airport Law on my way to Australia, after I nearly missed my flight out of Heathrow, and then did miss the connection from Sydney to Brisbane, after waiting for an hour in customs so that my luggage could be searched for any contraband fruit or vegetables. I wondered: what other Umeshisms are waiting to be discovered? Here are the first four I came up with:
If you never cut yourself while shaving, youre not shaving close enough.
If youve never been robbed, youre spending too much time locking doors.
If youve never been rejected, youre not asking enough. (The easiest to state, the hardest to practice.)
If youve never regretted a blog entry, your blog is boring.
As a tribute to Umesh, I hereby open the comments section to a Best Umeshism Contest. The winner (as chosen by me) earns the right to ask any question, and then have me answer it on this blog, possibly after consulting with Umesh about the high-order bits. The deadline is December 28, 2005, 11:59PM EST. Limit three entries per person. Include your name and/or email.The secant had it coming

Yesterday DJ Strouse, a student in MITs quantum computing summer school, pointed me toA Mathematicians Lamentby Paul Lockhart, the most blistering indictment of K-12 math education Ive ever encountered.
Lockhart says pretty much everything Ive wanted to say about this subject since the age of twelve, and does so with the thunderous rage of an Old Testament prophet. If you like math, and more so if you think you dont like math, I implore you to read his essay with every atom of my being.
Which is not to say I dont have a few quibbles:
1. I think Lockhart gives too much credit to the school system when he portrays the bureaucratization, hollowing-out, and general doofusication of knowledge as unique to math. In my experience, science, literature, and other fields are often butchered with quite as much gusto. Not until grad school, for example, had I sufficiently recovered from eleventh-grade English to give Shakespeare another try (or from Phys Ed do push-ups).
2. Lockhart doesnt discuss the many ways motivated students can and do end up learning what math is, despite the best efforts of the school system to prevent it. These side-channels include the web, the books of Martin Gardner, recreational programming, and math competitions and camps. Obviously its no defense of an execrable system to point out how some people learn in spite of itbut these omissions make the overall picture too depressing even for me (which is really saying something).
3. In describing math purely as a soul-uplifting pursuit of beautiful patterns, Lockhart leaves open the question of why, in that case, its been in bed with science and technology throughout its historynot merely for the education bureaucrats but for Archimedes, Newton, and Gauss. (Of course, like most relationships, this one is not without its sniping feuds.) Personally I have no problem with teachers who want to recognize and celebrate that aspect of math, provided the students respond to it. So you say you want theorems that are not only beautiful, but also inspired by physics or economics or cryptography? Line up then, because here comes a heaping helping of them
4. Lockhart doesnt address an interesting problem thats arisen in my own teaching over the last few years. Namely, what happens when you try to teach as he advocateswith history and philosophy and challenging puzzles and arguments about the definitions and improvisation and digressionsbut the students want more structure and drill and routine? Should you deny it to them? (For myself, I concluded that brains come in different types, and that it would be presumptuous to assume a teaching style that wouldnt work for me cant possibly work for anyone else. Still, before beginning a traditional rote drill session, its probably a good idea for all parties involved to agree on a safe-word.)
In the end, Lockharts lament is subversive, angry, and radical  but if you know anything about math and anything about K-12 education (at least in the United States), I defy you to read it and find a single sentence that isnt permeated, suffused, soaked, and encrusted with truth.The Two-Conference Solution

Anyone who follows the theoretical computer science blogs knows that two peoplesthe Technicians and the Conceptualistshave been warring over the same tiny piece of land (the STOC/FOCS accepted papers list) for well over a generation. The most fundamentalist of the Conceptualists believe that STOC and FOCS were promised to them in a divine covenant with Merlin, while moderates simply point out that the Conceptualists have maintained a continuous presence in these conferences since the time of Cook and Karp, always turning STOCward in prayer on the day of the submission deadline; and that, if not for STOC and FOCS, conceptual papers might get wiped entirely off the face of the earth (or worse, shunted to CCC). For their part, the Technicians see the Conceptualists as unwelcome usurpers, infiltrating an ancient land of log factors with bizarre new models and definitions; and suggest that, if the Conceptualists feel so wronged by physicists, biologists, and economists who refuse to see the natural and social worlds in computational terms, then let the physicists, biologists, and economists give the Conceptualists sessions in their conferences.
To many of us, its become increasingly clear that the only long-term solution to this bitter conflict is partition: two sets of conferences for two peoples with irreconcilable intellectual aspirations. (A few old-timers, such as Noam Chomsky, still advocate technical and conceptual papers side-by-side in the same conference, but others consider Chomskys proposal as quaint and outdated as his hierarchy.)
And thus Im pleased to point my readers to two new conferences, one for each people, the first of which has the further merit of actually existing:

Innovations in Computer Science (ICS) (encouraging new ideas, approaches, perspectives, conceptual  frameworks and techniques), to be held for the first time January 4-7, 2010 in Beijing.


SLOGN (a new conference in theoretical computer science, narrowly construed, encouraging difficult arguments, analyses, and algorithms), to be held April 1, 2010 atop Mount Everest.

Mihai Ptracuarguably the most ircible of the Technicianshas announced his support for the new ICS conference, stating that ICS seems like one of the best ideas in decades for improving the quality of STOC/FOCS. As one of the handwaviest of the Conceptualists, I wish to announce my wholehearted support of SLOGN, for precisely the same reason.
And if Mihai and I are in complete agreement about how the field should evolve, what could there possibly be to argue about? Shalom, Salaam, and QED.What is it like to be a nerd?

No doubt many of you already know  but for the rest, todays xkcd comes impressively close (at least, I think it does) to solving the ancient philosophical riddle of how to convey what being a nerd feels like to someone cool since birth.You cant prove you wont want to be there

Avi Wigderson has asked me to announce that Princetons recently-founded and delightfully-named Center for Computational Intractability will be holding a week-long workshop on Barriers in Computational Complexity, this August 25th to 29th. Apparently Im even co-organizing one of the sessions. So register now! Lowerbounderati, provers of meta-impossibility theorems, and other congenital pessimists are particularly discouraged from not attending.Essentials of complexity-theoretic stand-up comedy

Recently someone asked me how to give funnier talks. My first response was to recoil at such an insolent question: doesnt everyone know that at the core of my shtick lies a unique and ineffable je ne sais quoi that cant be packaged, bottled, or resold? But the truth was not that I couldnt give advice; its that I didnt want to. For if everyone knew how easy it was to keep an audience at least half-awake, how would people like me maintain their edge? By proving better theorems? Having something new and relevant and say? These questions answer themselves.
But because I love you, my readers, so deeply, and because I feel guilty about abandoning you for so long, I shall now publicly deconstruct the main ingredients of seminar humor, insofar as Ive been able to find them. (A few ingredients are specific to theoretical computer science, but most are more general.)

Make fun of people in the audience. (Of course, you have to do it in such a way that theyre flattered youre ripping them and not someone else.)
Ridicule bogus claims related to your topic, particularly claims that received wide currency in the popular press. (To be honest, I do this not so much because it gets laughsthough it doesbut as a small service to humanity. If I can make one budding crackpot think twice before hitting Submit on a disproof of Bells Theorem, I will not have lived in vain. Of course, the ridicule should always focus more on ideas than people; and even then, a few in the audience will frown on it, considering it unscientific or unprofessional. Forty or fifty crackpots ago, I agreed with them. Its only experience that hardened me into a vigilante.)
Incorporate the audiences shared experiences into your talk (without making a big deal of it, as if its the most natural thing in the world). For example, when it comes time to trot out an Alice/Bob scenario, have yours wryly comment on a previous talk, an excursion everyone went on, a current event (like an election) that everyone actually cares about more than the talk
Self-deprecate. (My first conjecture was falsified. The following conjecture hasnt yet been falsified, and is obviously true)
Say things that recognize and comment on how neurotic the thought-process of theoretical computer scientists really is, by taking that thought-process to extremes. (Thats off by a factor of 1010^120, which is only O(1) and is therefore irrelevant. For years, people tried unsuccessfully to prove this sort of impossibility result was impossible. Our result shows the impossibility of their goal.)
If your field is interdisciplinary, the humor potential is almost limitless. Are you a physicist? Ridicule the computer scientists. A computer scientist? Ridicule the mathematicians. A mathematician? Ridicule the economists. Chances are, enough differences in notation, terminology, assumptions, and underlying goals will arise in the talk to give you a never-ending supply of material. Disciplinary humor is a more refined, intellectual variant of ethnic humor, and is effective for the same reasons.
Explain your results in an unusually vivid or graphic way. (If, at the moment of your death, your whole life flashed before you in an instant, and if while you were alive youd performed suitable quantum computations on your own brain, then you could solve Graph Isomorphism in polynomial time.) This type of humor is my absolute favorite: on a plot with laughter volume on one axis and scientific content on the other, its way out on the upper-right-hand corner.
If youre using PowerPoint, take full advantage of its comic potential: wild animations, text that pops up on the screen to question or even flat-out contradict what youre saying, a punchline at the bottom of the slide that only gets revealed when you press a key, etc. I love doing this because I have as much time as I need to precompute jokes (though Ill then often elaborate on them extemporaneously).
Banter with the crowd: if someone makes a crack at your expense, always respond, and even escalate the interaction into a staged fight (the rest of the audience will love it). If someone catches you in a mistake, or you dont know the answer to a question, make a self-deprecating joke that acknowledges the situation even as it wins you sympathy points.
Have high energy! Loud, lots of moving around, emotion in your voice  like you cant wait to invite everyone along to the most exciting journey in the history of the universe. Not only is that good practice in general (at the least, it keeps the audience from falling asleep), it also creates a general atmosphere in which its okay to laugh at jokes.
Pause a few beats before the punchline. (You can get better at this by watching professional comics.)
Experiment! If a particular joke bombs, drop it from your rotation; if it brings the house down, recycle it in future talks. Of course, you should drop a joke once it reaches its saturation point, where much of the audience has already heard it in previous talks. On the other hand, if this particular audience hasnt yet heard the joke, disregard your own internal sense of its being tired: it could go over just as well as the first time, or better.
Steal ideas shamelessly from other speakers. (I mean their humor techniques, not their results.) Just as importantly, study the lame jokes other speakers use, so as to avoid them. (For example, I estimate that 94% of quantum computing talks include a heavy-handed comment about someone or something being in superposition; this has not yet gotten a laugh. Or the talks repeat stories about Feynman, Bohr, etc. that everyone in the audience has already heard a thousand times.)
Tailor your jokes to the audiences background. For instance, I have some jokes that work great in the US, but sink in other countries. Or work on physicists but not computer scientists, or vice versa.
Make jokes about the country youre visiting. Of course, this is subject to common sense: Ive been known to resort to zed / aboot jokes in Canada, scone / royalty / powdered wig jokes in England, and neutrality / yodeling jokes in Switzerland, but I usually dont make the first joke that pops into my head when visiting Germany or Austria.
Take risks! Heres an Umeshism: if some of your jokes dont flop, then youre not being bold enough. Do things that people cant believe anyone would actually do in a talk. Most people seem to operate under the assumption that when theyre giving a talk, they have to be less funny than in regular conversation, when the truth is the opposite. If something comes into your head thats funny to you, and it passes the most flimsy and cursory of offensiveness checks  out with it, and worry later about the consequences!

Three final remarks.
First, reading over the list, I cant help but feel sheepish about how much one can do with such a crude and obvious bag of tricks.
Second, I only wish I applied this crude bag more consistently! Particularly when I have a new result and Im excited about the proof, I all too often ignore my own advice and lapse into boringness. But at least I notice Im doing it, get annoyed at myself, and resolve to be crasser, less mature, and less professional the next time around.
Third, you might feel that adding shtick to your talks makes you shallow, that all that should matter is the content of your results. In the relatively rare case where youre addressing experts in your own sub-sub-subfield, thats probably true: you can drop the funny business and get straight to the point. In all other cases, Im almost certain the audience will understand your results better if you incorporate some shtick than if you dont. But heyits up to you whether you want to address an ideal Platonic audience (more lemmas! no irrelevant distractions! yes! harder! faster!) or the actual flesh-and-blood hairless apes who are dozing off in the seminar room while you speak.Ask me (almost) anything

Update (8/19): Ive answered most of the remaining questions and closed this thread. If your question wasnt answered earlier, please check nowsorry for the delay! And thanks to everyone who asked.
This blog was born, in part, out of existential anguish. My starting axioms, reflected in the blogs title, were that

nerds like me are hothouse plants, requiring a bizarre, historically-improbable social environment to thrive in life;
if such an environment ever existed, then it didnt survive one or more major upheavals of the twentieth century, such as the sexual revolution, the Holocaust, or the end of the Cold War;
I and other nerds were therefore essentially walking fossils, absurdly maladapted for the civilization in which we found ourselves (even, ironically, as that civilization relied more than ever on nerdly skills); and
all that being the case, I might as well kill some time by proving quantum complexity theorems and writing a blog full of crass jokes.

And therein lies the problem: this summer, Ive simply been enjoying life too much to want to take time out to blog about it. Happiness, it seems, is terrible for my literary productivity.
Still, enough people now rely on this blog for their procrastination needs that I feel a moral obligation to continue serving them. So to overcome my own procrastination barrier, from now on Im going to try writing entries that are basically just requests for comment: stones in a stone soup, with the intellectual barley, discursive salt, argumentative carrots, and dialectical beef chunks to be supplied by you, my readers.
(To a few commenters: thanks so much for the plywood, rotting raccoon carcasses, and used syringes, but the soup should be fine without them)
To start things off, today were going to have another open thread. You can ask pretty much anything; my one request is that you dont ask for grad school or job application advice, since we already covered those things ad nauseum in two previous open threads.
Here are a few examples of things to ask me about:
1. My recent trip to the Azores for the FQXi Conference on Foundational Questions in Physics and Cosmology
2. My recent trip to Paris for the Complexity2009 conference
3. My recent trip to Lexington, Kentucky for the Quantum Theory and Symmetries conference
4. The recent breakthrough paper by Jain, Ji, Upadhyay, and Watrous, finally proving what many in the quantum complexity world long suspected: that QIP=IP=PSPACE. That is, quantum interactive proof systems provide no more computational power than classical ones. (For more see this post from Lance and Steve Fenner, or this one from the Pontiff.)
5. The exciting new Polymath Project, to find (under some number-theoretic assumption) a deterministic polynomial-time algorithm for generating n-bit primes. (Hat tip to Ryan ODonnell.)
Oh, one other thing: while youre welcome to ask personal questions, theyll most likely be answered not by me but by Pablo the PSPACE Pirate.
Update (7/31): One question per person, please!Malthusianisms

(See also: Umeshisms, Anthropicisms)
Why, in real life, do we ever encounter hard instances of NP-complete problems? Because if its too easy to find a 10,000-mile TSP tour, we ask for a 9,000-mile one.
Why are even some affluent parts of the world running out of fresh water? Because if they werent, theyd keep watering their lawns until they were.
Why dont we live in the utopia dreamed of by sixties pacifists and their many predecessors? Because if we did, the first renegade to pick up a rock would become a Genghis Khan.
Why cant everyone just agree to a family-friendly, 40-hour workweek? Because then anyone who chose to work a 90-hour week would clean our clocks.
Why do native speakers of the language youre studying talk too fast for you to understand them? Because otherwise, they could talk faster and still understand each other.
Why is science hard?  Because so many of the easy problems have been solved already.
Why do the people you want to date seem so cruel, or aloof, or insensitive? Maybe because, when they arent, you conclude you must be out of their league and lose your attraction for them.
Why does it cost so much to buy something to wear to a wedding? Because if it didnt, the fashion industry would invent more extravagant requirements until it reached the limit of what people could afford.
Why do you cut yourself while shaving? Because when you dont, you conclude that youre not shaving close enough.
These Malthusianisms share the properties that (1) they seem so obvious, once stated, as not to be worth stating, yet (2) whole ideologies, personal philosophies, and lifelong habits have been founded on the refusal to understand themMy diavlog with Eliezer Yudkowsky

Here it is. Its mostly about the Singularity and the Many-Worlds Interpretation.
(I apologize if Eliezer and I agreed too much, and also apologize for not quite realizing that the sun was going to set while I was speaking.)
And heres the discussion that already took place over at Eliezers blogging-grounds, Less Wrong.A setback for science

On Tuesday Judge John Jones III released a landmark 139-page decision, which finds that the Dover school board violated the Establishment Clause by endorsing intelligent design. Why is that a setback for science? Because I spent hours reading the decision instead of doing actual work, and so should everyone else.
In a case like this, of course, its not science thats on trial but the legal system itself. Can it distinguish a real idea from a sham, in the same way that a FOCS program committee would reject a paper claiming Grover search in O(log N) queries, no matter how well-written it was? This time, the system came through. Judge Jones  despite being a Republican appointed by Bush  proved himself capable of the following insight:
Because we are able to recognize design of artifacts and objects, according to Professor Behe, that same reasoning can be employed to determine biological design. Professor Behe testified that the strength of the analogy depends upon the degree of similarity entailed in the two propositions; however, if this is the test, ID completely fails.
Unlike biological systems, human artifacts do not live and reproduce over time. They are non-replicable, they do not undergo genetic recombination, and they are not driven by natural selection. For human artifacts, we know the designers identity, human, and the mechanism of design, as we have experience based upon empirical evidence that humans can make such things, as well as many other attributes including the designers abilities, needs, and desires (p. 80-81)
(Is one allowed to make that sort of argument in an official capacity? Strange thing, the Establishment Clause.)
But the section where Judge Jones rises from cogency to furious eloquence is the Purpose Inquiry (p. 90-132), where he shows that the Dover school board members were even bigger jokers than is directly inferrable from their decision. Heres William Buckingham, Chair of the Curriculum Committee, at a June 14, 2004 school board meeting:
Nowhere in the Constitution does it call for a separation of church and state  I challenge you [the audience] to trace your roots to the monkey you came from  2,000 years ago someone died on a cross. Cant someone take a stand for him? (p. 105)
(For readers who dont grok this allusion: while many people were crucified by the Romans around that time, Buckingham is most likely referring to Jesus of Nazareth, a Galilean Jewish preacher postulated by many ID proponents to be related to, or even identical with, the intelligent designer of their theory.)
Heres another gem:
At the June 2004 meeting, Spahr asked Buckingham where he had received a picture of the evolution mural that had been torn down and incinerated. Jen Miller testified that Buckingham responded: I gleefully watched it burn.  Burning the evolutionary mural was apparently insufficient for Buckingham, however. Instead, he demanded that the teachers agree that there would never again be a mural depicting evolution in any of the classrooms and in exchange, Buckingham would agree to support the purchase of the biology textbook in need by the students. (Judge Joness emphasis; p. 108)
The school board members took up a collection at a church to pay for the creationist book Of Pandas and People, then lied about it under oath (p. 114-115). They also testified at the trial that they didnt understand the substance of the curriculum change that, over the science teachers objections, they voted for (p. 121). In short, the plaintiffs couldnt have asked for better allies.
Admittedly, to anyone whos ever attended an American school board meeting, the Dover shenanigans wont come as much surprise. Mark Twain, as often, said it best:
First God created idiots, this was for practice. Then He made School Boards.
Part II of this post will appear after Ive returned to Pennsylvania (The Genius School Board State) later today, having completed my trip around the globe and gained a 2i phase in the process. Hey  judging from the number of comments on my previous evolution post, you people seem to like this issue. In a blogosphere with finitely many readers, only the fittest topics will survive.Barriers to snarky blogging

Im writing from the Barriers in Computational Complexity workshop in Princeton, where too many real things are happening for me to blog about nothing. I understand that streaming video of all the talks will be up eventually; for now, a few highlights:

On Tuesday I hosted a panel discussion on Barrier Problems in Boolean Complexity. The panelists were Steve Cook, Avi Wigderson, Russell Impagliazzo, and Sasha Razborov. We got lots of questions from the floor, about everything from whether PNP, to whether P vs. NP is independent of set theory, to whether the laws of physics can be understood as computer programs. Alas, there were few to no serious disagreements among the panelists (indeed, you can probably guess their answers to the last three questions).


I gave a talk entitled Has There Been Progress on the P vs. NP Question? (The link goes to the PowerPoint slides.)


Ketan Mulmuley spoke about Geometric Complexity Theory (GCT), his approach to P vs. NP and related problems based on algebraic geometry and group representation theory. For months Ive been planning a blog post about GCT. Spurred on by people at the workshop, I might actually finish it soon. In the meantime, those of you who cant wait for your daily helping of plethysms, Weyl modules, G-varieties might want to check out Mulmuleys new complexity-theoretic overview and complementary mathematical overview of GCT.


Ben Rossman spoke about recent lower bounds in circuit complexity: an ~nk/4 lower bound on the size of AC0 circuits computing the k-clique function, and (a brand-new result) an ~nk/4 lower bound on the size of monotone circuits computing the k-clique function, even on average.


Ran Raz gave an awesome talk on How to Fool People to Work on Circuit Lower Bounds. (Answer: by giving them completely innocuous-looking mathematical problems, without telling them that the answers would imply breakthroughs in complexity theory. Alas, presumably no one who attended Rans talkor for that matter whos reading this entrycan be fooled, since were in on the secret.) In particular, Ran spoke about his STOC08 paper on elusive functions, as well as some brand-new work on how lower-bounding the rank of explicit tensors would lead to circuit and formula size lower bounds.

Meanwhile, Lance has a superb survey article in Communications of the ACM about the status of the P vs. NP problem.
(An earlier version of this post discussed a preprint by Gus Gutoski on quantum multi-prover interactive proof systems. That preprint has since been retracted.)
And now I bid adieu, as the next talk is starting and my laptop is running out of batteries.Worldview Manager is live

A year ago, I wrote a blog entry seeking summer students to create a Worldview Manager: a web application that would prompt users to state their beliefs about various statements, and then notify them if two or more answers were in tension with one another, giving them the chance to modify their beliefs and thereby resolve the tension. The idea was then covered in a short piece by Lee Gomes at Forbes.com.
I ended up selecting two students: Louis Wasserman of the University of Chicago, and Leonid Grinberg of Belmont High School. They excelled at all aspects of this project, from low-level hacking to high-level design decisions. If there are enough young uns like them, I feel better about the future of the United States.
As a result of their work, Im pleased to announce that you can now try Worldview Manager here.
Currently, we have only a limited selection of topic files, all of them rather nerdy: Complexity Theory, Strong AI, the Axiom of Choice, Quantum Computing, Libertarianism, and Quantum Mechanics. However, if theres enough interest, well probably add more topic files soon. In the meantime, if you have any interest in contributing topic files yourself, please let me know! Its actually not hard.
And if you have praise, gripes, constructive feedback, nonconstructive feedback  hey, the comments section is right underneath this sentence.The Singularity: Now 50% Off!

Im normally loath to announce conferences on this blog, but my friend Michael Vassar has made an offer that appeals to my vanity, desire to please, and most of all legendary business sense. Here it is: anyone who registers for the upcoming Singularity Summit, October 3-4 in New York, can get 50% off the registration fee by mentioning this blog.
Topics on the agenda will include (I assume) the technical prospects for immortality, brain-uploading, superintelligent AIs, and the transformation of all matter in the universe into sentient computronium. (In other words, none of that loony stuff we discuss at CS conferences, Merlin-Arthur and whatnot.)
Speakers will include Ray Kurzweil, Michael Nielsen, Robin Hanson, Eliezer Yudkowsky, David Chalmers, and several others familiar in these parts of the nerdosphere.
Ive never been to one of these Singular shindigs before, and unfortunately cant make this one (Ill be visiting UC Santa Barbara and the University of Washington). But regular readers will know that I enjoy talking with Transhumanists and Singulatarianseven if I dont exactly share their urgency about the coming robot revolution, and worry more about the superdoofosities of today than the superintelligences of tomorrow. Im sure that, for some readers, the very fact that Im willing to debate people who consider me crazy for not arranging to have my brain frozen in liquid nitrogen when I dieor that Id advertise a conference for such peoplemakes me almost as far gone as the future meat-sicles themselves. So what can I say? Look, when I meet people who really care about the remote future, who talk about ending all the suffering in the universe like others talk about finishing an NSF proposal, who follow their chains of logic straight past the acceptably-quirky into the childish, weird, and nave without even noticing the WHAT WILL PEOPLE THINK? danger-signs  a little twelve-year-old nerd buried deep in my psyche cant help but rock approvingly in his chair.
The 2009 Singularity Summit: Advancing the messianic dream of Jeremiah, Isaiah, and the other ancient Israelite prophets  this time with more overclocked RAM and less overgrilled ram.A little experiment

In a New York Times column that exemplifies the highest instincts of science journalism, Dennis Overbye writes about two physicists idea that creating a Higgs boson is so abhorrent to the universe that backwards-in-time causal influences have conspired to prevent humans from seeing onefirst by causing Congress to cancel the Superconducting Supercollider in 1993, and more recently by causing the faulty electrical connections that have delayed the startup of the LHC. (For reactions, see pretty much any science blog. Peter Woit writes that, with the exception of a defense by Sean Carroll, pretty much all of [the blog chatter] has been unremittingly hostile, when not convinced that these papers must be some sort of joke.)
One of the originators of the theory, Holger Bech Nielsen, sounded familiar, so I looked him up. It turns out I once heard him lecture about a plan to predict the specific masses and coupling constants of the Standard Model, by starting from the assumption that the laws of physics were chosen randomly (from which distribution was never exactly clear). It struck me at the time that we had a shnood among shnoods here, a leader in the field of aggressively-wrong physics.
However, I didnt know at the time about Nielsen and his collaborator Masao Ninomiyas universe-conspiring-to-stop-the-LHC proposal. Mulling over the new theory, I realized that it has the ring of truth about it. Specifically, assuming (as I do) that Nielsen and Nanomiya are correct, their theory can explain an bigger deeper mystery than why we havent yet seen a Higgs boson: namely, why havent I blogged for a month? Why, when theres plenty to blog about  when I just spent two weeks at the Kavli Institute in Santa Barbara for their special semester on quantum computing, when Im now at Schloss Dagstuhl, Germany, for an exciting, lower-bound-packed workshop on algebraic methods in computational complexity?
Clearly, the universe itself must have decided last month that this blog was so abhorrent to it, it would employ quantum postselection effects to force me to procrastinate whenever I would otherwise have posted something. An obvious corollary is that, if I do manage to post something nevertheless, it will bring about the immediate end of the universe.
The beautiful thing about science is that theories of this kind can be tested by observation. So:
3 
2 
1 Off the grid

My primary link to the rest of the cosmosmy Gmail account, bqpqpoly at gmail.comhas been down for more than 36 hours. I get a 502 Server Error every time I try to log in, from any computer and any browser.
Any Shtetl-Optimized readers at Google: care to fix this for me?  (Or is this some sort of Halloween prank,or a paternalistic attempt to force me to stop answering emails and finish my STOC submissions?)
If you need to reach me in the meantime, please write to ghh1729 at gmail.com. (If you understand both bqpqpoly and ghh1729, Ill even guarantee you a response.)
Update (9PM Saturday): To be clear, the issue for me is not so much the outage itself, as the lack of any acknowledgment or response from Google.  (According to the Register article, even those who are paying $50 for Premier service cant get through to Googles support line, which is advertised as being 24-hour.)  I would like not merely a fix, but a personal apology from Larry and Sergey, and an explanation of what steps theyre taking to uphold the dont be evil creed in the future.And to the many CS majors who read this blog: is this the sort of unresponsive corporate behemoth you want to work forBQP Aarlines

The Onion has a new pieceUnited Airlines Exploring Viability of Stacking Them Like Cordwoodthat, as usual, is grossly unrealistic. If my own experience is any guide, the real United would never waste money on a grated floor for waste disposal, or people to shovel peanuts into a trough.
But The Onions exploration of the geometry of passenger-packing does raise some genuinely interesting questions. For years, Ive had this idea to start an airline where, instead of seats, passengers would get personal cubbyholes that were stacked on top of each other like bunk beds. (Id make sure the marketing materials didnt describe them as coffin-shaped, though thats what they would be.)
You could sleep in your cubbyholemuch more easily than in a seat, of coursebut you could also read, watch a movie, work on your laptop, or eat (all activities that I dont mind doing while lying down, and the first two of which I prefer to do lying down).
Besides passenger comfort, my arrangement would have at least two advantages over the standard one:
First, depending on the exact size of the cubbyholes, you could very likely fit more passengers this way, thereby lowering ticket costs.
Second, assuming the cubbyholes were ventilated, you could put little doors on them, thereby giving passengers far more privacy than in a conventional airline. No more being immiserated by screaming babies or inane conversations, or the B.O. of the person next to you, or reading lights while youre trying to sleep. And, as many of you will have noticed, BQP Aarlines could provide amorous couples with a far more comfortable alternative than the bathroom.
So, readers: do you know if any airline has tried something like this? If not, why not? Are there strong arguments against it that I havent thought of, besides the obvious cultural/psychological ones? Should I keep my day job?The winner

Alright, we had 35 submissions for the Best Umeshism Contest, of which 23 were eligible (i.e., had a name and were posted by the deadline).  After lengthy deliberation, the Shtetl-Optimized Executive Committee is pleased to announce a winner.  But first, the runners-up:
If youve never broken the bed, youre not experimenting enough. Miss HT Psych
If youve never hit the ground while skydiving, youre opening your parachute too early. Ari
If youve never written a sentence fragment. Andrew L.
If you win Scotts contest, then youve probably spent too much time thinking of a good Umeshism. Mohammad Mahdian
The following three anonymous entries also merited honorable mentions:
If youve never been fined $250,000, youre paying too much for your DVDs.
If all your students graduate, then youre spending too much time in your office.
If youve never missed a flight, then you dont know what its like to show up at the airport, stand in the wrong line for 20 minutes, be denied a checkin, and then be told that there is nothing available for the next 5 days (through Christmannukah), and then only with a 7-hour layover. So how about this one: If youve ever missed a flight, youre spending too much time in airports.  Thank you for the advice, Umesh Vazirani.
As you may have noticed, a large proportion of entries are actually ironic commentaries on the Umeshism concept.  But in the end, a simple focus on the high-order bits took the cake:
If youve never had children, then youre spending too much time using protection. Peter Brooke
Thanks to everyone who entered, and Happy New Year from your procrastinating, narcissistic friends here at Shtetl-Optimized!Simons postdoc: call for applications

Anyone who feared that my taking a real job would lead to the slow demise of this blog: your fears were entirely justified. I barely even read blogs anymoreor Twitters, or whatever the young people use nowadays. Though come to think of it, maybe I should switch to a Twitter feed, since blogging has become too weighty and substantive for me?
In the meantime, Ive been asked to post the following.
Simons Postdoctoral Fellowship at the Massachusetts Institute of Technology in Theoretical Computer Science
The Theory of Computation (TOC) group at the Computer Science and Artificial Intelligence Laboratory (CSAIL) at MIT is seeking candidates for a post-doctoral position in the general area of the theory of computation. Applicants in all areas of theory are encouraged to apply, including (but not exclusive to) algorithms, complexity theory, combinatorial optimization, cryptography, distributed computing, game theory and computation, geometry, parallel computing, and quantum computing. This fellowship is made possible by a generous gift from the Simons Foundation.
The fellowship is a two year position, starting the summer or fall of 2010. The fellowship stipend is gauged to attract the highest caliber of applicants. Generous funds for scientific travel will be available for use at the fellows discretion. Fellows will be assigned a faculty member close to their research interests from the TOC group. Fellows will be encouraged (although not required) to teach a graduate seminar in their area of research.

Eligibility: Candidates must receive their PhD during the academic year immediately preceding that in which the fellowship would begin. There are no other restrictions based on nationality or any other basis.


Application Process: Candidate applications should include a description of professional interests and goals in research. Each application should include a curriculum vitae and the names and addresses of three or more individuals who will provide letters of recommendation. Letter writers should submit their letters directly to MIT to the address below. Please submit complete applications by January 31st, 2010.


Address to submit application: All application materials and recommendation letters should be sent electronically to theory-postdoc@csail.mit.edu. The candidates name should be included in the subject line of the email. Alternatively, the materials can be also sent to the following address:Simons Postdoctoral Fellowship, c/o Joanne Hanley
MIT Computer Science and Artificial Intelligence Laboratory
The Stata Center, Building 32 G682
32 Vassar Street
Cambridge, MA 02139, USA.Hopefully my last D-Wave post ever

Several people asked me to comment on an entry by Hartmut Neven in the Google Research Blog, about using D-Waves quantum computers for image recognition.
I said nothing: what is there to say? Didnt I already spend enough time on this subject for 10400 lifetimes? I want to create, explore, discover things that no one expectednot be some talking-head playing his assigned role in a script, a blogger-pundit who journalists know they can rely on to say f(X) whenever X happens. Even if f(X) is true. Why cant I just tell the world what f is and be done with it?
Then more people asked me to comment.
I set the matter aside. I worked on the complexity problem thats currently obsessing me. I met with students, sent recommendation letters, answered emails, went ice-skating with my girlfriend.
Then more people asked me to comment.
And I thought: yes, I believe its vital for scientists to communicate with the broader public, not just a few colleagues. And yes, its important for scientists to offer a skeptical perspective on the newssince otherwise, they implicitly cede the field to those making dubious and unsubstantiated claims. And yes, blogging is a wonderful tool for scientists to connect directly with anyone in the world whos curious about their work. But isnt there some statute of limitations on a given story? When does it end? And why me?
Then more people asked me to commentso I wrote the following only-slightly-fictionalized exchange.
Skeptic: Let me see if I understand correctly. After three years, you still havent demonstrated two-qubit entanglement in a superconducting device (as the group at Yale appears to have done recently)? You still havent explained how your quantum computer demos actually exploit any quantum effects? While some of your employees are authoring or coauthoring perfectly-reasonable papers on various QC topics, those papers still bear essentially zero relation to your marketing hype? The academic physicists working on superconducting QCwho have no interest in being scoopedstill pay almost no attention to you? So, what exactly has changed since the last ten iterations? Why are we still talking?
D-Wave: Then you must not have read our latest press release! Your questions are all obsolete, because now were recruiting thousands of volunteers over the Internet to study the power of adiabatic quantum computing!
Onlooker: Hmm, an interesting counterargument! D-Wave might not be using quantum mechanics, but they are using the Internet! And their new project even has a cool code-name: AQUA@home! So, skeptic, how do you respond to that?
Skeptic (distractedly): You know, when I was eight years old, and dreamed of building starships and artificial intelligences in my basement, my first order of business was always to invent code-namesnot just for the projects themselves, but for every little subcomponent of them. The second order of business was to think through the marketing aspects. What should the robot look like? What recreational facilities should be available on the starship, and what color should it be painted? It really, genuinely felt like I was making concrete progress toward realizing my plans. Sure, the engine and control system still needed to be built, but at least I had code-names and design specs! How many others had even gotten that far?
D-Wave: Who cares? This isnt some childrens game. Keep in mind that were delivering a productserving our customers, by solving the 4-by-4 Sudoku puzzles they rely on to keep their businesses running.
Skeptic: Weve been through this how many times? A pigeon can probably be trained to solve 4-by-4 Sudokus. So the only relevant questions concern the details of how you solve them. For example, how do you encode a problem instance? How much of the work is done in the encoding procedure itself? What evidence do you have for quantum coherence at intermediate points of the computation? Can you measure an entanglement witness, to give people confidence that youre doing something other than classical simulated annealing?
Onlooker: Hmm, those do seem like important questions
D-Wave: But theyre based on outdated premises! Today, were pleased to announce that, using what might be a quantum computer, and might also be a noisy, probabilistic classical computer, we can solve 5-by-5 Sudoku puzzles!
Onlooker: Whoa, awesome! So were back to square one then. As long as D-Waves demos only involved 4-by-4 Sudokus, the skeptics arguments almost had me persuaded. But 5-by-5? I dont know what to think anymore. Skeptic, where are you? Whats your reaction to this latest development?
Skeptic: 
D-Wave: That silence you hear is the sound of the skeptics worldview crashing all around him! But we havent even played our top card yet. Today, were positively ecstatic to announce that weve entered into an official-sounding partnership with GOOGLE, Inc. (or anyway, with someone who works at Google Research). Together, were harnessing the power of quantum adiabatic optimization to create the next generation of car-recognition systems!
Onlooker: WOW! This debate is over, then. I confess: D-Wave on its own did seem a bit flaky to me. But Google is the company born without sin. Everything they do, have done, and will ever do is perfect by definitionfrom building the search engine that changed the world, to running mail servers that only fail for an insignificant 0.001% of users, to keeping the Chinese people safe from lies. And, as Google is infallible, so too its 20,000 diverse employeeswho are encouraged to spend 20% of their time on high-risk, exploratory projectshave nevertheless failed to come up with a single idea that didnt pan out. Skeptic, show your face! Will you admit that, through grit, moxie, old-fashioned Canadian inventiveness, and the transformative power of the Internet, D-Wave has finally achieved what the naysayers said was impossiblenamely, getting someone from Google Research to coauthor a paper with them?
Skeptic: Yes. I concede! D-Wave wins, and I hereby retire as skeptic. In particular, the next time D-Wave announces something, theres no need to ask me for my reaction. Ill be busy tending to my own project, codenamed ARGHH@home, which consists of banging my head against a brick wall.Prove my lemma, get acknowledged in a paper!

This will be a little experiment, in which the collaborative mathematics advocated by Timothy Gowers and others combines with my own frustration and laziness. If it goes well, I might try it more in the future.
Let p be a complex polynomial of degree d. Suppose that |p(z)|1 for all z such that |z|=1 and |z-1| (for some small >0). Then whats the best upper bound you can prove on |p(1)|?
Note: I can prove an upper bound of the form |p(1)|exp(d)indeed, that holds even if p can be a polynomial in both z and its complex conjugate (and is tight in that case). What really interests me is whether a bound of the form |p(1)|exp(2d) is true.
Update: After I accepted Scott Morrisons suggestion to post my problem at mathoverflow.net, the problem was solved 11 minutes later by David Speyer, using a very nice reduction to the case Id already solved. Maybe I should feel sheepish, but I dontI feel grateful. I am now officially a fan of mathoverflow. Go there and participate!Second Women in Theory Workshop

For the female readers of this blog: I thought all eight of you might be interested in the following announcement, which was sent to me by Tal Rabin.
We will be holding the Second Women in Theory Workshop at Princeton on June 19-23, 2010.
To apply please go to: http://intractability.princeton.edu/blog/2009/11/women-in-theory-2010-workshop/
The format will be similar to the WIT 2008 workshop.  You can view information on that workshop at:
http://www.cs.princeton.edu/theory/index.php/Main/WIT08
and view a video of WIT08 at: http://www.youtube.com/watch?v=uUBzBF2awZUAcknowledging the awesome

This holiday season, you should see Avatar and read Logicomix (if you havent already). I entered both expecting to wince over scientific inaccuracies and bad dialogue, and left both in a state of catharsis that few books or movies have ever brought me to. Both break new ground, deal with big issues in a visually stunning way, have been predictably criticized as simplistic, and need a sequel.Changing fields

Im at CWI in Amsterdam, after spending two weeks in Israel. Next week I head to QIP2010 in Zurich, and the week after that, to the Perimeter Institute in Waterloo.
The following meta-question emerged from a conversation with Dorit Aharonov two weeks ago:
Whats your favorite example of a result in theoretical computer science that works over finite fields, but doesnt work (or isnt known to work) over the reals or complex numbers?
Conversely, whats your favorite example of a result in TCS that works over the reals or complex numbers, but doesnt work (or isnt known to work) over finite fields?
In either case, whats the crucial property of the underlying field, that causes the result to work in one case but not the other?
By crucial property, I mean something like this:

Theres a natural metric (i.e., a distance measure) on the reals or complex numbers, but not on a finite field.
Theres a uniform distribution over a finite field, but not over the reals or complex numbers.

Id especially be interested in properties that dont reduce to one of the two above.QIP2010: The Power and the Glory of Quantum Complexity Theory

Firstly, if you havent contributed to relief efforts in Haiti, you can do so (the charity linked to was recommended by a Haitian-American working at MIT CSAIL). I wish I had something more useful to say about this tragedy, but I dont.
For the past couple days, Ive been at QIP2010 in Zurich, Switzerland. Id had premonitions, even before arriving, that this was going to be an unusually awesome QIP. Having been on the PC, I knew the strength of the technical program, and Id learned that the turnout320 participantswould be a record high. My positive feelings only intensified when I saw the following in the hallway of my hotel:

My buzz reached a fever pitch when I entered the lecture hall and found giant, gourmet Swiss chocolate bars on every seat.
But I only knew for sure that this QIP would rock when my erstwhile adviser, Umesh Vazirani, gave his opening plenary talk on New bridges between computer science and quantum computation. Umesh highlighted several developments, including:

the relationship I noticed last year between the BQP versus the polynomial hierarchy problem and the Generalized Linial-Nisan Conjecture.
the QIP=PSPACE breakthrough of Jain et al. (based on the recent multiplicative-weights update method from classical computer science).
recent breakthroughs in lattice-based cryptography (most famously, Gentrys fully homomorphic encryption system), which took inspiration from the quantum computing work of Oded Regev five years ago.
the work of Broadbent, Fitzsimons, and Kashefi and independently Aharonov, Ben-Or, and Eban (for which I paid out pieces of the Aaronson $25.00 Prize), which lets a classical verifier (equipped with the ability to send single, unentangled qubits through a channel) verify an arbitrary quantum computation; and which Umesh illustrated by a story about a verifier investigating the claims of a shady, fly-by-night company called Q-Wave.

Umesh argued that the deepening connections between quantum computing and classical complexity theoryopen problems in classical complexity being solved using quantum-inspired techniques, tools that werent available in the classical world until a year or two ago already being used for quantum purposes, etc.represent one of the most exciting new developments in the field.
The combination of the chocolate bar (which I was already eating), and Umesh preaching so much truth from the pulpit, was heavenly.
Amazingly, subsequent talks managed to keep up the momentum. Daniel Gottesman spoke about his work with Sandy Irani on the quantum complexity of translationally-invariant tiling and Hamiltonian problems. By giving tools to say something useful about computational complexity even in cases where the only free parameter is the system size, Gottesman and Irani open up some exciting avenues for further work. Jordan Kerenidis spoke about the effort to prove an analogue of the Valiant-Vazirani witness isolation theorem for QMA (Quantum Merlin-Arthur). Stefano Pironio talked about how you can exploit the Bell inequality violations to generate a long random string starting from a short random seed, assuming only the locality of the laws of physics, and not assuming anything about the reliability of your randomness-generating devices. This observation, which I find to be of great conceptual (and conceivably even practical) interest, is related to the so-called Free Will Theorem of Conway and Kochen, as well as to a result I proved eight years ago in my review of Stephen Wolframs book. For Conway and Kochen, though, the motivation was to prove that subatomic particles have free will (a strange interpretation that I dont by any means endorse!), while for me, the motivation was to prove that Wolfram was wrong. Neither I nor (as far as I know) Conway and Kochen thought about the obvious-in-retrospect application to generating random numbers. (Incidentally, if anyones interested, my talk slides from yesterday morning are here.)
Theres also been a great deal of excitement at this years QIP about the efficient simulation of quantum systems occurring in nature, using recent techniques for model-order reduction (including MERA, matrix product states, quantum metropolis sampling, area laws). I hope I havent just made John Sidles faint from excitement.
The full schedule is here; feel free to ask in the comments about any talks I didnt mention. If theres enough interest, I might also write a followup post about the rest of the conference.Announcement

I thought the eight people who still read this blog might be interested to know that the FOCS2010 Call for Papers is now out.We the nerds

are you referring to yourself in the plural now?  Its getting a little spooky
(from a comment on a previous post)
Mark Twain wrote that only presidents, editors and people with tapeworms have the right to use the editorial we.  Here at Shtetl-Optimized, we couldnt agree more.  The trouble is that we  sorry, I  have spent too much time in the grammatical dungeon of academic science, where the first-person singular is vaguely taboo.
But why is it taboo? you ask.  Simple: because if people referred to themselves as I in single-author scientific papers, then theyd deprive readers of the fun of reading a sentence like
Hence we see that H is Hermitian
and wondering exactly how to parse it.  Personally, I can think of at least seven possibilities:

Hence I see that H is Hermitian, and so do you, dear reader, unless you have the IQ of a trout.


Hence Reason, Truth, and Reality themselves, with me as humble scribe, have all testified to the Hermitianness of H since the beginning of time, and will continue to do so after all is naught.


Hence, though modesty forbids me from saying so, I have shown that H is Hermitian.  But one shouldnt forget all the little people who helped make it possible.


Hence, after meeting over wine and cheese in our ivory tower, we, the High Priests of the Scientific Orthodoxy, have arrogantly decided that H shall henceforth be Hermitian.


Hence I  a sniveling wuss who cant even directly acknowledge his own existence, and probably got beat up a lot in junior high school  have shown that H is Hermitian.


Hence I  a resident of the collectivist dystopia of Ayn Rands novel Anthem, in which the word I has been abolished  have shown that H is Hermitian.

And finally:

Hence H is Hermitian.Schrdingers cash

Theres an article in this weeks New Scientist by Justin Mullins about unforgeable quantum money. By the standards of quantum mechanics journalism, the article is actually really good; Id encourage you to read it if you want to know whats going on in this area. In particular, Mullins correctly emphasizes that the point of studying quantum money is to understand quantum mechanics better, not to mint practical QCash anytime soon (to do the latter, youd first have to solve the minor problem of the money decohering within microseconds).
My main quibble is just that I think the article overstates my own role! In my Complexity09 paper, the main thing I showed is that secure quantum money that anyone can verify is possible, assuming the counterfeiters only have black-box access to the device for verifying the money. I also showed that, to get quantum money that anyone can verify, you have to make computational assumptions. (By contrast, Stephen Wiesners scheme from the 1960s, in which only the bank could verify the money, was information-theoretically secure.) But in terms of coming up with actual candidate quantum money schemes (as well as breaking those schemes!), the other members of the quantum money clubAndy Lutomirski, Avinatan Hassidim, David Gosset, Ed Farhi, Peter Shorhave been more active than me.
Two other quibbles:
(1) Mullins writes: Then last year, Aaronson proposed a new approach that does away with the banknote and  concentrates instead on the stream of information that represents  quantum cash. In Wiesners scheme, too, I think it was pretty clear that the banknote with qubits stuck to it was just a fun way to tell the story
(2) The article does a good job of explaining the distinction between information-theoretic and computational security. But it doesnt stress that, with the latter, we cant actually prove that any of the hard problems are hard, without also proving PNP! (Ill admit that the importance of this point is slightly hard to convey in a popular article, possibly because many people, or so Im told, go about their lives without proving anything.) The best we can do is show that, if you could solve this problem, then you could also solve this other problem that people have studied for a long time. But in the case of quantum money, we dont even know how to do thatwhich is what we meant when we wrote in our ICS paper that it seems possible that public key quantum money intrinsically requires a  new mathematical leap of faith.
Considered as research topics in complexity theory, uncloneable quantum money, copy-protected quantum software, and so on are almost as wide-open today as public-key encryption was in the 1970s. That is, we dont have a compelling intuition as to whether these tasks are possible at all: all quantum mechanics does is open up the possibility of them, which wasnt there in the classical world. Unfortunately, in the case of quantum money, most of the ideas weve had for realizing the possibility have turned out to be insecureoften for non-obvious reasons. Assuming quantum money is possible, we dont know what the right protocols are, what types of math to base them on, or how to argue for their security. So if youre not impressed by the results we have, why dont you try your hand at this quantum money business? Maybe youll have better luck than we did.
(Addendum: I also have a PowerPoint presentation on quantum money, which ironically goes into more detail than my Complexity paper.)Whats taking so long, Mr. Babbage?

Recently a journalist asked me why we dont yet have quantum computers. Since I get that question, in some form, at least 300 times per day, I thought it might be worthwhile to collect my thoughts about it in one place. The essay below doesnt say anything that I and others in the field havent said many times before, so hardcore Shtetl-Optimized fans should probably skip it. (Dont worry, Ill let yall know when I have something new to say and am reckless enough to say it.)
When people ask me why we dont yet have quantum computers, my first response is to imagine someone asking Charles Babbage in the 1820s: so, when are we going to get these scalable classical computers? by 1830? or maybe 1840? In that case, we know that it took more than a century for the technology to catch up with the theory (and in particular, for the transistor to be invented). More generally, we have lots of precedents for a technology being imaginable decades or even centuries before it became technologically feasibleheavier-than-air flight is another example. So theres nothing weird or anomalous about our current situation.The central technological obstacle to building a scalable quantum computer is well-known, and is decoherence, or unwanted interaction between the computer and its external environment. When information about a quantum state leaks into the outside worldby any means whatsoever, intended or notthe state loses its quantumness and reverts to being classical. So to do a quantum computation, its necessary to keep the qubits (atomic nuclei, photons, or whatever else they are) almost fanatically isolated from their environment. But at the same time, you also need to manipulate the qubits, move them around, etc., in such a way as to carry out the computation. Those twin requirements are the reasons why the most famous success of practical quantum computing to date was factoring 15 into 35The Prince of Nerds has left us

Fighting Hype with Hype

Ive been depressed all month about the oil spill. So what better to cheer me up than a flurry of comments and emails asking me to comment on an Ars Technica story by Chris Lee, reporting that its now been proven once and for all that quantum computers dont help with NP-complete problems?
Now, just to really put the screws on any optimists out there, a new paper has shown  that adiabatic computers are actually quite bad at hard math problems 
What [the researchers] have shown is that, whenadiabatic quantum computers are used  to solve NP-complete problems,the energy gap between the lowest energy  state and the next state up is not well behaved. Instead, it narrows  faster than exponentially, meaning the adiabatic quantum computing  cannot, even in principle, solve NP-complete problems faster than a  classical computer 
In the end, they conclude that NP-complete problems are just as hard on  an adiabatic quantum computer as on a classical computer. And, since  earlier work showed the equivalence between different variants of  quantum computers, that pretty much shuts down the possibility of any  quantum computer helping with NP-complete problems.
I dont think anyone in the field will be particularly surprised by  this. The failure of earlier work to show that quantum computers offered  a speed-up on any NP-complete problem indicated that it was likely that  it simply was not possible.
Im heartened by the progress weve made these last ten years: from overhyped and misleading claims that quantum computers can solve NP-complete problems in polynomial time, to overhyped and misleading claims that they cant.
The link to the paper from the article is broken, and the article doesnt give the names of the researchers involved, but from the context, Im pretty sure the articles attempting to talk about this paper by Boris Altshuler, Hari Krovi, and Jeremie Roland, amusingly entitled Anderson localization casts clouds over adiabatic quantum optimization. This paper really is an interesting and important onebut alas, the Ars Technica story grossly misstates and exaggerates what it does.
For what I hope will be the last time, but Im sure wont: yes, almost everyone in the field believes its true that quantum computers cant solve NP-complete problems in polynomial time. But we have no idea at present how to prove anything of the kind. In fact, we dont even know how to prove classical computers cant solve NP-complete problems in polynomial time (thats called the P vs. NP question; maybe youve heard of it!). Nor do we even know how to prove a conditional statement, like quantum computers cant solve NP-complete problems in polynomial time unless classical computers can also. Any such result would be the biggest advance in theoretical computer science at least since I was born.
So then what do Altshuler, Krovi, and Roland do? They consider a specific quantum algorithmnamely, the quantum adiabatic algorithm with linear interpolationapplied to random instances of an NP-complete problem, namely Exact Cover. They then argue, based on a combination of numerical simulations and perturbation theory approximation, that the spectral gap decreases exponentially (actually, like 1/n!), which would imply that the adiabatic algorithm generally requires exponential time to reach the ground state.
If that sounds pretty interesting, youre right! But whats the fine print? Well, lets accept, for the sake of argument, Altshuler et al.s claim that their conclusions about Exact Cover would likely generalize to 3SAT and other standard NP-complete problems. Even then, there are three crucial caveats, all of which the Ars Technica story ignores:

Most importantly, the limitation (if it is one) applies only to one specific algorithm: namely the adiabatic optimization algorithm (with a specific interpolation schedule, but lets ignore that for now). Now, some people seem to think a limitation on the adiabatic algorithm implies a limitation of quantum computers in general, since adiabatic is universala buzzphrase thats caused a lot of confusion. In reality, what Aharonov et al. proved, in a beautiful paper six years ago, is that the adiabatic model of computation is universal. But they were talking about something much more general than the adiabatic optimization algorithm. For example, the ground state of Aharonov et al.s adiabatic process is not the solution to a combinatorial optimization problem, but rather a history state that encodes an entire computation itself.
The Altshuler et al. paper talks about random instances of the Exact Cover problembut the uniform distribution over instances is just one particular distribution. Even if the adiabatic algorithm doesnt help there, its possible that there are other natural distributions over instances for which it exponentially outperforms (say) classical simulated annealing.
Finally, even given the above two caveats, Altshuler et al. only show that the adiabatic algorithm fails on random Exact Cover instances at a physics level of rigor. In other words, their argument relies on a perturbative approximation that seems plausible but isnt proved. A cynic might retort that, at a physics level of rigor, we also know that PNP! But such a cynic would be unfair. I dont want to knock Altshuler et al.s contribution. For almost two decades, theres been a spectacularly fruitful interaction between the physicists and the math/CS folks in the study of random constraint satisfaction problems. Indeed, many of the conjectures (or, in physics lingo, results) in this area that the physicists derived using their hocus-pocus methods, were later rigorously confirmed by the mathematicians, and I dont know of any that were disconfirmed. Even so, the distinction between a proof and a physics proof is one that seems worth insisting onespecially in theoretical computer science, an area thats often far removed from conventional physical intuition.

In summary, while it feels like swimming through a burning oil slick to say so, I have to side with D-Wave about the Ars Technica piece (though my reasons are mostly different).
So congratulations, Ars Technica! Like The Economist before you, youve successfully cast clouds over yourself when reporting about stuff I dont understand.
PS. Im at STOC2010 right now, in exotic Cambridge, MA. If youre interested, heres the talk I gave this morning, on BQP and the Polynomial Hierarchy, and heres the talk my PhD student Andy Drucker gave, on A Full Characterization of Quantum Advice. And Lance, please stop looking over my shoulder!But what if?

I still owe you Part II of my Darwinism post.  But in the meantime, Id like to pontificate about a fallacy that Ive seen so often it deserves a name.  Ill call it the But-What-If? Fallacy, after the following joke:
Let n be an integer
But what if n isnt an integer?
The fallacy consists of bringing something up that was specifically defined to be irrelevant.   Of course, no one would be silly enough to do that in real life!  Except

I would never want to live in a society where people were always happy.  Such a society would be a stifling, conformist dystopia, like in Gattaca or Brave New World.

Well then, people wouldnt always be happy, would they?

If quantum mechanics is nonlinear, then P=NP in the physical world.

This one makes steam emanate from my ears.  Lets repeat three times: P and NP are purely mathematical concepts.    As such, the laws of physics can have no bearing on whether or not they are equal.
(Of course, it could be that PA=NPA where A is a real world oracle.  But if you understood that point, then youre already way beyond the P=NP in the physical world crowd.)
Continuing:

I could never marry a guy I didnt love, even if he was unfailingly kind, generous, and loyal.  Id never know when he might abandon me.


You shouldnt take this drug, even if it will help reduce your anxiety.  You can reduce your anxiety just as well without it.


Sure, a perfect computer simulation of a human being might hold an intelligent conversation.  But could it ever write a poem, or laugh at a joke, or fall in love, or

GODDAMMIT!  WHAT PART OF BY ASSUMPTION DONT YOU UNDERSTAND?
Sorry, I sometimes get carried away.  In the past, my favored solution to the BWI? Fallacy was forcible re-education camps for everyone who commits it.  But lately, Ive come to think that a softer approach might work.
See, the problem is that most people (even theoretical physicists) have very little experience thinking like mathematicians.  By nature, people want to keep coming back to the issues they care about, even when you ask them a hypothetical question that defines those issues away.  The key is, first, to identify the real question on the other persons mind:
Are NP-complete problems hard in the physical world?
Is this guy as kind and generous as he seems?
Will this drug really help reduce my anxiety?
Could a computer that writes decent poetry, laughs at jokes, etc. be built?
You can then point out the difference between this question and the one that was asked.  Often, the more abstract question wont even have occurred to the other person.  But once the person understands the abstract question  and why it remains, even after the concrete one has been answered  its time to extend your hand.  Welcome to the business.Doing my oracle duty

I promised myself Id stop blogging about controversial issues whose mere mention could instigate a flamewar and permanently get me in trouble. Well, today Im going to violate that rule, by blogging about the difference relativized and unrelativized complexity classes.
Recently a colleague of mine, who works in the foundations of quantum mechanics, sent me a long list of questions about the seminal 1993 paper of Bernstein and Vazirani that introduced the complexity class BQP (Bounded-Error Quantum Polynomial-Time). It was clear to me that all of his questions boiled down to a single point: the distinction between the relativized and unrelativized worlds. This is an absolutely crucial distinction that trips up just about everyone when theyre first learning quantum computing.
So I fired off a response, which my colleague said he found extremely helpful. It then occurred to me that what one person found helpful, another might as welland that which makes 30% of my readers eyes glaze over with its thoroughgoing duh-obviousness, might be very thing that another 30% of my readers most want to see. So without further ado, the two worlds of quantum complexity theory
In the relativized world, we let our algorithms access potentially-powerful oracles, whose internal structure we dont examine (think of Simons algorithm for concreteness). In that world, we can indeed prove unconditionally that BPPBQPthat is, quantum computers can solve certain problems exponentially faster than classical computers, when both computers are given access to the same oracle.
In general, almost every natural complexity class has a relativized version associated with it, and the relativized versions tend to be much easier to separate than the unrelativized versions (its basically the difference between a masters or PhD thesis and a Fields Medal!) So for example, within the relativized world, we can separate not only BPP from BQP, but also P from NP, NP from PSPACE, NP from BQP, etc.
By contrast, in the unrelativized world (where there are no oracles), we cant separate any complexity classes between P and PSPACE. Doing so is universally recognized as one of the biggest open problems in mathematics (in my opinion, its far-and-away the biggest problem).
Now, Bernstein and Vazirani proved that BQP is sandwiched between P and PSPACE. For that reason, as they write in their paper, one cant hope to prove PBQP in the unrelativized world without also proving PPSPACE.
Lets move on to another major result from Bernstein and Vaziranis paper, namely their oracle separation between BPP and BQP. You might wonder: whats the point of proving such a thing? Well, the Bernstein-Vazirani oracle separation gave the first formal evidence that BQP might be larger than BPP. For if BPP equaled BQP relative to every oracle, then in particular, theyd have to be equal relative to the empty oraclethat is, in the unrelativized world!
(The converse need not hold: it could be the case that BPP=BQP, despite the existence of an oracle that separates them. So, again, separating complexity classes relative to an oracle can be thought of as a baby step toward separating them in the real world.)
But an even more important motivation for Bernstein and Vaziranis oracle separation is that it led shortly afterward to a better oracle separation by Simon, and that, in turn, led to Shors factoring algorithm.
In a sense, what Shor did was to remove the oracle from Simons problem. In other words, Shor found a concrete problem in the unrelativized world (namely factoring integers), which has a natural function associated with it (namely the modular exponentiation function, f(r) = xr mod N) that one can usefully treat as an oracle. Treating f as an oracle, one can then use a quantum algorithm related to Simons algorithm to find the period of f, and that in turn lets you factor integers in polynomial time.
Of course, Shors algorithm became much more famous than Simons algorithm, since the implications for computer science, cryptography, etc. were so much more concrete and dramatic than with an abstract oracle separation. However, the downside is that the speedup of Shors algorithm is no longer unconditional: for all anyone knows today, there might also a fast classical algorithm to factor integers. By contrast, the speedup of Simons algorithm (and of Bernstein-Vazirani before it) is an unconditional one.The Generalized Linial-Nisan Conjecture is false

In a post a year and a half ago, I offered a prize of $200 for proving something called the Generalized Linial-Nisan Conjecture, which basically said that almost k-wise independent distributions fool AC0 circuits. (Go over to that post if you want to know what that means and why I cared about it.)
Well, Im pleased to report that thats a particular $200 Ill never have to pay. I just uploaded a new preprint to ECCC, entitled A Counterexample to the Generalized Linial-Nisan Conjecture. (Thats the great thing about research: no matter what happens, you get a paper out of it.)
A couple friends commented that it was wise to name the ill-fated conjecture after other people rather than myself.  (Then again, who the hell names a conjecture after themselves?)
If you dont feel like downloading the ECCC preprint, but do feel like scrolling down, heres the abstract (with a few links inserted):
In earlier work, we gave an oracle separating the  relational versions of BQP and the polynomial hierarchy, and showed that  an oracle separating the decision versions would follow from what we  called the Generalized Linial-Nisan (GLN) Conjecture: that  almost k-wise independent distributions are indistinguishable from the  uniform distribution by constant-depth circuits.  The original  Linial-Nisan Conjecture was recently proved by Braverman; we offered a  $200 prize for the generalized version.  In this paper, we save  ourselves $200 by showing that the GLN Conjecture is false, at least for  circuits of depth 3 and higher.
As a byproduct, our counterexample also implies that 2pPNP  relative to a random oracle with probability 1.  It has been  conjectured since the 1980s that PH is infinite relative to a random  oracle, but the best previous result was NPcoNP relative to a random  oracle.
Finally, our counterexample implies that the famous results of  Linial, Mansour, and Nisan, on the structure of AC0  functions, cannot be improved in several interesting respects.
To dispel any confusion, the $200 prize still stands for the original problem that the GLN Conjecture was meant to solve: namely, giving an oracle relative to which BQP is not in PH.  As I say in the paper, I remain optimistic about the prospects for solving that problem by a different approach, such as an elegant one recently proposed by Bill Fefferman and Chris Umans.  Also, its still possible that the GLN Conjecture is true for depth-two AC0 circuits (i.e., DNF formulas). If so, that would imply the existence of an oracle relative to which BQP is not in AMalready a 17-year-old open problemand net a respectable $100.My philomath project: Sensitivity versus block-sensitivity

If you like math, and you dont yet have a Math Overflow account, stop reading this post now (not right now, but by the end of the sentence) and set one up, before returning here to finish reading the post. Math Overflow is the real deal: something that Ive missed, dreamed about, and told my friends someone ought to set up for the last fifteen years, and that now finally actually exists. (It was founded by Berkeley grad students and postdocs Anton Geraschenko, David Brown, and Scott Morrison.) If you have a research-related math problem you cant solve, you can post it there and theres a nontrivial chance someone will solve it (or at least tell you something new), possibly within eleven minutes. If youre an ambitious student looking for a problem to solve, you can go there and find one (or a hundred).
To take one example, heres a terrific complexity question asked by Timothy Gowers, about a notion of average-case NP-completeness different from the usual notions (if you think hes asking about a well-studied topic, read the question more carefully). I didnt have a good answer, so I wrote a long, irrelevant non-answer summarizing whats known about whether there are average-case NP-complete problems in the conventional sense.
But my real topic today is the sensitivity versus block-sensitivity problem, which I recently posted to MO in a disguised (and, dare I say, improved) form.
For non-Boolean-function-nerds, sensitivity vs. block-sensitivity is a frustrating and elusive combinatorial problem, first asked (as far as I know) by Noam Nisan and by Nisan-Szegedy around 1991. Heres a lovely paper by Claire Kenyon and Samuel Kutin that gives background and motivation as well as partial results.
Briefly, let f:{0,1}n{0,1} be a Boolean function, with n input bits and 1 output bit.  Then given an input x=x1xn to f, the sensitivity of x, or sx(f), is the number of bits of x that you can flip to change the value of f. The sensitivity of f is s(f) = maxx sx(f). Also, the block-sensitivity of an input x, or bsx(f), is the maximum number of disjoint sets of bits of x (called blocks) that you can flip to change the value of f, and the block sensitivity of f is bs(f) = maxx bsx(f). Clearly 1  s(f)  bs(f)  n for every non-constant Boolean function f. (bs(f) is at least s(f) since you could always just take each block to have size 1.)
To give some examples, the n-bit OR function satisfies s(OR)=bs(OR)=n, since the all-zeroes input is sensitive to flipping any of the n input bits. Likewise s(AND)=bs(AND)=n, since the all-ones input is sensitive to flipping any of the bits. Indeed, its not hard to see that s(f)=bs(f) for every monotone Boolean function f. For non-monotone Boolean functions, on the other hand, the block-sensitivity can be bigger. For example, consider the sortedness function, a 4-input Boolean function f that outputs 1 if the input is 0000, 0001, 0011, 0111, 1111, 1110, 1100, or 1000, and 0 otherwise. Then you can check that bs(f) is 3, whereas s(f) is only 2.
Heres the question: Whats the largest possible gap between s(f) and bs(f)? Are they always polynomially related?
What makes this interesting is that block-sensitivity is known to be polynomially related to a huge number of other interesting complexity measures: the decision-tree complexity of f, the certificate complexity of f, the randomized query complexity of f, the quantum query complexity of f, the degree of f as a real polynomial, you name it. So if, as is conjectured, sensitivity and block-sensitivity are polynomially related, then sensitivityarguably the most basic of all Boolean function complexity measuresceases to be an outlier and joins a large and happy flock.
The largest known gap between sensitivity and block-sensitivity is quadratic, and is achieved by Rubinsteins function. To define this function, assume for simplicity that n is an even perfect square, and arrange the input bits into a n-by-n square grid. Then well set f(x)=1, if and only if there exists a row that has two consecutive 1s and all other entries equal to 0. You can check that bs(f)=n/2 (for consider the all-zeroes input), whereas s(f)=2n (the worst case is when every row contains exactly one 1).
Its a reasonable guess that Rubinsteins function gives pretty much the largest gap possible, and how hard could that possibly be to prove? Well, how hard could a white rabbit in front of a cave possibly be to kill?
Ill confess to going on sensitivity versus block-sensitivity binges every couple of years since I first learned about this problem as an undergraduate at Cornell. The last binge occurred this weekend, triggered by the strange block-sensitivity properties of my counterexample to the GLN Conjecture. And thats when it occurred to me to use the hyper-inter-network tools of Web 2.0, together with my power and influence here at Shtetl-Optimized, to unleash a new flood of activity on the problem. There are at least four factors that make this problem well-suited to a collaborative math project:

The statement can be understood by almost anyone. I could explain it to my parents.
It seems unlikely (though not impossible) that the solution will require any heavy-duty math. What seems needed, rather, is lots of creativity to come up with new ideas specific to the problem at hand, as well as diabolical examples of Boolean functions that refute those ideas.
Even though the problem has been around for 20 years, the relevant literature is very small (maybe half a dozen papers); it would take at most a day to learn everything known about the problem.
Despite 1-3, this is a real problem that a significant number of people would care about the answer to.

If you feel like you want a new angle on the problemsomething that hasnt already been explored to death, or even to serious injuryyou can try my geometric variant of sensitivity vs. block sensitivity described on Math Overflow.
Im calling this a philomath project, a term that pays tribute to the successful polymath projects popularized by (and carried out on) Timothy Gowers wonderful blog, but that avoids infringing on a registered trademark of GowersCorp.
So, here are the philomath project rules: do you have an idea about sensitivity vs. block sensitivity? Or a vague pseudo-idea? Or a proposal for an easier variant?  Then post it here! Or go over to Math Overflow and post it there. Lets see if a block of us acting in unison can flip this problem.My diavlog with Anthony Aguirre

Bloggingheads hasjust posted an hour-long diavlogbetween the cosmologist Anthony Aguirre and your humble blogger. Topics discussed include: the anthropic principle; how to do quantum mechanics if the universe is so large that there could be multiple copies of you; Nick Bostroms Gods Coin Toss thought experiment; the cosmological constant; the total amount of computation in the observable universe; whether its reasonable to restrict cosmology to our observable region and ignore everything beyond that; whether the universe is a computer; whether, when we ask the preceding question, were no better than those Renaissance folks who asked whether the universe is a clockwork mechanism; and other questions that neither Anthony, myself, nor anyone else is really qualified to address.
There was one point that sort of implicit in the discussion, but I noticed afterward that I never said explicitly, so let me do it now. The question of whether the universe is a computer, I see as almost too meaningless to deserve discussion. The reason is that the notion of computation is so broad that pretty muchany system, following any sort of rules whatsoever (yes, even non-Turing-computable rules) could be regarded as some sort of computation. So the right question to ask is not whether the universe is a computer, but rather what kind of computer it is. How many bits can it store? How many operations can it perform? Whats the class of problems that it can solve in polynomial time?Going into deep freeze

Im leaving tomorrow for a grand tour of Banff, then Israel, then Greece, then Princeton. Blogging may be even lighter than usual.
In the meantime, my friend Michael Vassar has asked me to advertise the 2010 Singularity Summit, to be held August 14-15 in San Francisco. Register now, because the summit is approaching so rapidly that meaningful extrapolation is all but impossible.
While Im traveling, heres a fun Singularity-related topic to discuss in the comments section: have you signed up to have your head (and possibly body) frozen in liquid nitrogen after you die, for possible Futurama-style resuscitation in the not-a-priori-impossible event that technology advances to the point where such things become possible? Whatever your answer, how do you defend yourself against the charge of irrationality?Putting my money where my mouth isnt

A few days ago, Vinay Deolalikar of HP Labs started circulating a claimed proof of PNP. As anyone could predict, the alleged proof has already been Slashdotted (see also Liptons blog and Bacons blog), and my own inbox has been filling up faster than the Gulf of Mexico.
Alas, a simple top kill seems unlikely to work here. Whats obvious from even a superficial reading is that Deolalikars manuscript is well-written, and that it discusses the history, background, and difficulties of the P vs. NP question in a competent way. More importantly (and in contrast to 98% of claimed PNP proofs), even if this attempt fails, it seems to introduce some thought-provoking new ideas, particularly a connection between statistical physics and the first-order logic characterization of NP. Ill leave it to the commenters to debate whether Deolalikars paper exhibits one or more of the Ten Signs A Claimed Mathematical Breakthrough Is Wrong.
But enough question-dodging! you exclaim. Is the proof right or isnt it? Cmon, its been like three hours since you first saw itwhats taking you so long? Well, somehow, I havent yet found the opportunity to study this 103-page manuscript in detail. Furthermore, I dont plan to interrupt my vacation time in Israel and Greece to do so, unless experts who have studied the paper in detail start telling me that I should.
Unfortunately, I can already foresee that the above response will fail to staunch the flow of emails. As a blogger, Im apparently expected to
(1) render an instantaneous opinion on any claimed mathematical breakthrough,
(2) be consistently right, and
(3) do the above without looking like Im being unfair or rushing to judgment.
While requirements (1) and (2) are not so hard to satisfy simultaneously, (3) makes my job an extremely difficult one. In fact, I could think of only one mechanism to communicate my hunch about Deolalikars paper in a way that everyone would agree is (more than) fair to him, without having to invest the hard work to back my hunch up. And thus I hereby announce the following offer:
If Vinay Deolalikar is awarded the $1,000,000 Clay Millennium Prize for his proof of PNP, then I, Scott Aaronson, will personally supplement his prize by the amount of $200,000.
Im dead seriousand I can afford it about as well as youd think I can.
Update (August 10): One whole day into this saga, Dick Lipton and Ken Regan have written a detailed post setting out four possible problems that have already been identified in the proof, and which the ball is now in Deolalikars court to address. Kudos to Dick, Ken, and numerous commenters for actually digging into the paper (unlike some lazier folks I could name  ).
Another Update: Since some journalists seem (unbelievably) to have missed the point of this post, let me now state the point as clearly as I can. The point is this: I really, really doubt that Deolalikars proof will stand. And while I havent studied his long, interesting paper in detail and pinpointed the irreparable flaw, something deep inside me rebels against the charade of keeping an open mind, when long experience with competent but ultimately unsuccessful proof attempts allows me to foresee perfectly well how things are going to play out here. I would make a terrible trial court judge: ten minutes into the proceedings, Id be screaming, The defendant obviously did it! I sentence him to death! Fortunately Im not a judge, and I have a way of stating my prediction that no reasonable person could hold against me: Ive literally bet my house on it.
Yet Another Update: Whats emerged as the perhaps central issue is the bane of so many attempted PNP proofs in the past: namely, why does the proof not work for 2SAT, XOR-SAT, and other problems that are very similar to 3SAT in their statistical properties, yet for which polynomial-time algorithms are known?  If Deolalikar cant provide a clear and convincing answer to that question, the proof is toast.The ethics of scientific betting

Throughout the day, Dick Liptons blog has hosted a phenomenal discussion of Vinay Deolalikars attempted proof of PNP (of which a new draft appeared as this blog entry was going to press). As of this writing, the discussion seems to have led to the following two conclusions:

Deolalikar deserves our gratitude; he did a wonderful thing by bringing the TCS community together, in Stone Soup fashion, to talk about the P vs. NP problem, and also to stimulate public interest in this fascinating problem.
My $200,000 is safe.

See in particular this magisterial summary by Terry Tao.
For those of you who just arrived from Mars, Id recommend starting with a BBC News piece by Victoria Gill, which by the standards of articles about P vs. NP in major news outlets, bears an amazingly close relation to reality. Indeed, the only thing about the article that I disagreed with was the headline: Million dollar maths puzzle sparks row. Its not a row, a spat, or even a squabble: at most its a friendly scientific disagreement among friends.
As many others have already said, and as the BBC News piece hints at, the clearest reason for skepticism is (basically) that Deolalikar hasnt convincingly explained why his approach doesnt also prove problems are hard that are already known to be easy. This is the simplest sanity check for any attempted proof of PNP: if youre showing that an NP-complete problem like 3SAT is not in P, then your proof had better fail for related problems like 2SAT and XOR-SAT, which are known to be in P. Everyone agrees that, if Deolalikar cant answer this objection, the proof is toast.Unfortunately, Deolalikar has responded to pointed questions about this issue with vague promises to address it in a later draft (together with worries that the manuscript is already too long!). This doesnt inspire confidence: if one had really proved PNP, one should be able to explain immediately why the proof fails for XOR-SAT.This is far from the only problem with the writeup, but its a good example of the sort of basic question that Deolalikar needs to answer and hasntEight Signs A Claimed PNP Proof Is Wrong

As of this writing, Vinay Deolalikar still hasnt retracted his PNP claim, but a clear consensus has emerged that the proof, as it stands, is fatally flawed. The first reason is that were not going to separate k-SAT from much easier problems purely by looking at the structure of the solution space: see for example this comment by Ryan Williams. The second reason is that, independently of the solution-space issue, Neil Immerman has identified critical flaws in the finite model theory part of the paper.
The researchers who actually studied Deolalikars paper, thought hard about it, and figured out in a matter of days why it doesnt work deserve our undying gratitude (they certainly have mine!). At the same time, if someday we have a PNP claim at this level several times per yearwhich I see as entirely possiblethen its clear that the sort of heroic effort we saw over the last week isnt going to scale. And thus, several commenters wanted to know how someone as lazy as I am could nevertheless be so confident in predicting what would happen:
Would you enlighten us as to what was the PROCESS behind your quick  and correct judgment?  Your quick nondeterministic hunch  about the wrongness of all the 100 pages was quickly verified as  correct. But how did you do it, confidently risking your reputation like  a smooth poker player?
Scott Aaronsohn [sic], like Nassim Nicholas Taleb, you predicted the  crash before it happened! You knew some fundamental weaknesses  intuitively that the other Myron-Scholes Nobel prize winning economists  (computer scientists) fell for!
While it pains me to say so, these commenters give me way too much credit. The truth, as far as I can tell, is that many (most?) complexity theorists reached exactly the same conclusion as I did and just as quickly; its just that most (with some notable exceptions) were too cautious to say so in public. Among those who did comment publicly, the tendency was to bend over backwards to give Deolalikar the benefit of the doubtan approach that I considered taking as well, until I imagined some well-meaning economist or physicist reading my generous words and coming away with the impression that PNP must be either licked or else hanging by a thread, and at any rate couldnt have been nearly as hard as all those computer scientists made it out to be.
So, in the future, how can you decide whether a claimed PNP proof is worth reading? Ill now let you in on my magic secrets (which turn out not to be magic or secret at all).
The thing not to do is to worry about the authors credentials or background. I say that not only for ethical reasons, but also because there are too many cases in the history of mathematics where doing so led to catastrophic mistakes. Fortunately, theres something else you can do thats almost as lazy: scan the manuscript, keeping a mental checklist for the eight warning signs below.

The author cant immediately explain why the proof fails for 2SAT, XOR-SAT, or other slight variants of NP-complete problems that are known to be in P. Historically, this has probably been the single most important sanity check for claimed proofs of PNP: in fact, Im pretty sure that every attempt Ive ever seen has been refuted by it.
The proof doesnt know about all known techniques for polynomial-time algorithms, including dynamic programming, linear and semidefinite programming, and holographic algorithms. This is related to sign 1, but is much more stringent. Mulmuleys GCT program is the only approach to P vs. NP Ive seen that even has serious aspirations to know about lots of nontrivial techniques for solving problems in P (at the least, matching and linear programming). For me, thats probably the single strongest argument in GCTs favor.
The paper doesnt prove any weaker results along the way: for example, PPSPACE, NEXPP/poly, NPTC0, permanent not equivalent to determinant by linear projections, SAT requires superlinear time  P vs. NP is a staggeringly hard problem, which one should think of as being dozens of steps beyond anything that we know how to prove today. So then the question arises: forget steps 30 and 40, what about steps 1, 2, and 3?
Related to the previous sign, the proof doesnt encompass the known lower bound results as special cases. For example: where, inside this proof, are the known lower bounds against constant-depth circuits? Wheres Razborovs lower bound against monotone circuits? Wheres Razs lower bound against multilinear formulas? All these things (at least the uniform versions of them) are implied by PNP, so any proof of PNP should imply them as well. Can we see more-or-less explicitly why it does so?
The paper lacks the traditional lemma-theorem-proof structure. This sign was pointed out (in the context of Deolalikars paper) by Impagliazzo. Say what you like about the lemma-theorem-proof structure, there are excellent reasons why its usedamong them that, exactly like modular programming, it enormously speeds up the process of finding bugs.
The paper lacks a coherent overview, clearly explaining how and why it overcomes the barriers that foiled previous attempts. Unlike most PNP papers, Deolalikars does have an informal overview (and he recently released a separate synopsis). But reading the overview felt like reading Joseph Conrads Heart of Darkness: Id reread the same paragraph over and over, because the words would evaporate before they could stick to my brain. Of course, maybe that just means I was too dense to understand the argument, but the fact that I couldnt form a mental image of how the proof was supposed to work wasnt a promising sign.
The proof hinges on subtle issues in descriptive complexity. Before you reach for your axes: descriptive complexity is a beautiful part of TCS, full of juicy results and open problems, and I hope that someday it might even prove useful for attacking the great separation questions. Experience has shown, however, that descriptive complexity also a powerful tool for fooling yourself into thinking youve proven things that you havent. The reason for this seems to be that subtle differences in encoding schemesfor example, whether you do or dont have an order relationcan correspond to huge differences in computational complexity. As soon as I saw how heavily Deolalikars proof relied on descriptive complexity, I guessed that he probably made a mistake in applying the results from that field that characterize complexity classes like P in terms of first-order logic. Im almost embarrassed to relate this guess, given how little actual understanding went to it. Intellectual honesty does, however, compel me to point out that it was correct.
Already in the first draft, the author waxes philosophical about the meaning of his accomplishment, profusely thanks those who made it possible, etc. He says things like, confirmations have already started arriving. To me, this sort of overconfidence suggests a would-be PNP prover who hasnt yet grasped the sheer number of mangled skeletons and severed heads that line his path.

You might wonder: if I had all these more-or-less articulable reasons for doubting Deolalikars proof, then why didnt I just state my reasons in the first place, instead of placing a $200,000 wager?
Well, I probably should have stated the reasons. I apologize for that.
The best one can say about the lazy alternative I chose is that it led to a somewhat-interesting socio-mathematical experiment. By putting my life savings on the line, could I give the world a dramatic demonstration of just how high the stakes are with P vs. NPthat when computer scientists say this problem wont be solved without a titanic advance in human knowledge, without overcoming obstacles like the ones mentioned in points 1-4 above, theyre not kidding? After such a demonstration, would more people get it? Would they refrain from leaping out of their chairs at the next P vs. NP announcement? Like Richard Dawkins staring unflinchingly at a steel pendulum swinging toward his face (which he knows has enough potential energy to almost hit him but not quite), would they remember that the only miracle in life is that there are no miracles, neither in mathematics nor in anything else?
I dont know how well the experiment succeeded.
Update (8/14): Somehow I completely forgot, over the course of the last three posts, to link to the PowerPoint talk Has There Been Progress on the P vs. NP Question?, which has lots of relevant material about why its so hard to prove PNP and how to evaluate proposed attempts.  Thanks to several commenters for correcting my oversightIll try to give the author of those slides proper credit in the futureP vs. NP for Dummies

A reader named Darren commented on my last post:
I have this feeling that this whole P and NP thing is not only a  profound problem that needs solving, but something that can be  infinitely curious to try and wrap your mind around
Thing is- theres a whole world of great minded, genius hackers out  here that cant understand one iota of what anyone is talking about.  Were not your traditional code-savvy hackers; were your inventors,  life hackers, researchers, scientists and I think I can speak for most  of us when I say: We would love to take the time to really dive into  this thread, but we ask that someone (you) write a blog that breaks this  whole thing down into a rest-of-the-world-friendly P/NP for dummies or  at least explain it to us like were stupid as hell at this point Im  really okay with even that.
Im of course the stupid one here, for forgetting the folks like Darren who were enticed by LAffaire Deolalikar into entering our little P/NP tent, and who now want to know what it is were hawking.
The short answer is: the biggest unsolved problem of theoretical computer science, and one of the deepest questions ever asked by human beings! Here are four informal interpretations of the P vs. NP problem that people give, and which I can endorse as capturing the spirit of whats being asked:

Are there situations where brute-force searchthat is, trying an exponential number of possibilities one-by-one, until we find a solution that satisfies all the stated constraintsis essentially the best algorithm possible?
Is there a fast algorithm to solve the NP-complete problemsa huge class of combinatorial problems that includes scheduling airline flights, laying out microchips, optimally folding proteins, coloring maps, packing boxes as densely as possible, finding short proofs of theorems, and thousands of other things that people in fields ranging from AI to chemistry to economics to manufacturing would like to solve? (While its not obvious a priori, its known that these problems are all re-encodings of each other. So in particular, a fast algorithm for any one of the problems would imply fast algorithms for the rest; conversely, if any one of them is hard then then they all are.)
Is it harder to solve a math problem yourself than to check a solution by someone else?  [[This is where you insert a comment about the delicious irony, that P vs. NP itself is a perfect example of a monstrously-hard problem for which we could nevertheless recognize a solution if we saw oneand hence, part of the explanation for why its so hard to prove PNP is that PNP]]
In the 1930s, Gdel and Turing taught us that not only are certain mathematical statements undecidable (within the standard axiom systems for set theory and even arithmetic), but theres not even an algorithm to tell which statements have a proof or disproof and which dont. Sure, you can try checking every possible proof, one by onebut if you havent yet found a proof, then theres no general way to tell whether thats because there is no proof, or whether you simply havent searched far enough. On the other hand, if you restrict your attention to, say, proofs consisting of 1,000,000 symbols or less, then enumerating every proof does become possible. However, it only becomes possible in an extremely Platonic sense: if there are 21,000,000 proofs to check, then the sun will have gone cold and the universe degenerated into black holes and radiation long before your computers made a dent. So, the question arises of whether Gdel and Turings discoveries have a finitary analogue: are there classes of mathematical statements that have short proofs, but for which the proofs cant be found in any reasonable amount of time?

Basically, P vs. NP is the mathematical problem that youre inevitably led to if you try to formalize any of the four questions above.
Admittedly, in order to state the problem formally, we need to make a choice: we interpret the phrase fast algorithm to mean deterministic Turing machine that uses a number of steps bounded by a polynomial in the size of the input, and which always outputs the correct answer (yes, there is a solution satisfying the stated constraints, or no, there isnt one). There are other natural ways to interpret fast algorithm (probabilistic algorithms? quantum algorithms? linear time? linear time with a small constant? subexponential time? algorithms that only work on most inputs?), and many are better depending on the application. A key point, however, is that whichever choices we made, wed get a problem thats staggeringly hard, and for essentially the same reasons as P vs. NP is hard! And therefore, out of a combination of mathematical convenience and tradition, computer scientists like to take P vs. NP as our flagship example of a huge class of questions about what is and isnt feasible for computers, none of which we know how to answer.
So, those of you who just wandered into the tent: care to know more? The good news is that lots of excellent resources already exist.  I suggest starting with the Wikipedia article on P vs. NP, which is quite good. From there, you can move on to Avi Wigdersons 2006 survey P, NP and mathematics  a computational complexity perspective, or Mike Sipsers The History and Status of the P vs. NP Question (1992) for a more historical perspective (and a translation of a now-famous 1956 letter from Gdel to von Neumann, which first asked what wed recognize today as the P vs. NP question).
After youve finished the above  well, the number of P vs. NP resources available to you increases exponentially with the length of the URL. For example, without even leaving the scottaaronson.com domain, you can find the following:

Ten Reasons to Believe PNP
Great Ideas in Theoretical Computer Science Lecture 9 (P and NP)
Quantum Computing Since Democritus Lecture 6 (P, NP, and Friends)
Has There Been Progress on the P vs. NP Question? (PowerPoint talk, from the Barriers workshop last year in Princeton)
Is P vs. NP Formally Independent? (2003 survey article)
Algebrization: A New Barrier in Complexity Theory (2009 paper by Avi Wigderson and myself)

Feel free to use the comments section to suggest other resources, or to ask and answer basic questions about the P vs. NP problem, why its hard, why its important, how it relates to other problems, why Deolalikars attempt apparently failed, etc. Me, I think Ill be taking a break from this stuff.Stroke of God

From CNN:
Television evangelist Pat Robertson suggested Thursday that Israeli Prime Minister Ariel Sharons stroke was divine retribution for the Israeli withdrawal from Gaza, which Robertson opposed.
Though many have condemned Robertsons latest insight, I myself feel only admiration and gratitude.  Admiration for one of the creative giants of American comedy, and gratitude to be alive in the 21st century, when the God of Christianity smites the Jews for not being greedy enough.And now a word from our sponsors

Today I interrupt your regularly-scheduled P vs. NP programming to bring you a special message from Dmitry Maslov, the program director at NSF Computing and Communication Foundations (CCF) who handles quantum information science. Besides paying for my CAREER grant (and thus, arguably, in an indirect sense, for this blog), Dmitry also happens to be one of my favoritest people anywhere: a stand-up guy whos doing an incredible amount to help quantum computing research in the United States. So, given that what he wants is for us to send in more proposals, so that he can help us even more, I found it impossible to say no to his request for some advertising space on Shtetl-Optimized. Announcement follows.
The Division of Computing and Communication Foundations at the National  Science Foundation invites proposal submissions in the area of Quantum  Information Science (QIS). NSFs interest in Science and Engineering  Beyond Moores Law emphasizes all areas of QIS. The range of topics of  interest is broad and includes, but is not limited to, all topics  relevant to Computer Science in the areas of quantum computing, quantum  information, quantum communication, and quantum information processing.  Please note the deadlines:MEDIUM Projects
Full Proposal Submission Window: September 1, 2010  September 15, 201Bringing a sacrificial goat and n-bit string to the oracle

Ive been enjoying Athens and the coast of Greece for the past four days. I was going to take a day trip to Delphi, for the sole purpose of blogging about having queried the Oracle there, but I ultimately decided to confine this trip to the unrelativized regions of Greece.
However, I do have something else related to oracles that Id like to blog about today. Last week I put out a preprint on the ECCC (thats the Electronic Colloquium on Computational Complexity for newbs), entitled The Equivalence of Sampling and Searching. There, I use Kolmogorov complexity to prove the surprising (to me) fact that

FBPP=FBQP if and only if SampP=SampBQP.

In other words: classical computers can efficiently solve every search (i.e., functional or relational) problem that quantum computers can solve, if and only if they can efficiently approximately sample the output distribution of every quantum circuit. (Note that, although this result involves the names of quantum complexity classes, it has almost nothing to do with quantum computing.) Anyway, when I gave a talk about this result at Hebrew University, Noam Nisan raised two excellent questions, neither of which Id thought to ask and neither of which I knew the answers to:

Is there an oracle relative to which BPP=BQP but PromiseBPPPromiseBQP? (In other words: an oracle that makes classical and quantum computers equivalent for language decision problems, but different for promise problems?)
Is there an oracle relative to which PromiseBPP=PromiseBQP but FBPPFBQP? (In other words: an oracle that makes classical and quantum  computers equivalent for promise problems, but different for search problems? Here FBPP and FBQP are the classes of search problems solvable in polynomial time by classical and quantum computers respectivelysee my preprint for formal definitions of them.)

Affirmative answers to these questions would imply that any extension of my equivalence theorem to decision and promise problems would have to be non-relativizing. Id be incredibly grateful for any thoughts about these questions, and will even offer a $5 reward for each one.
However, since I have a feeling that these oracle challenges wont generate quite enough comments, let me now pour some gasoline on the fire. You may have noticed that what I did above, among other things, was to call attention to my own ECCC preprint. Up till today, Ive had an informal policy of almost never using Shtetl-Optimized to blog about my own research, except indirectly (e.g., when I talk about open problems that arose out of my papers). I had three reasons for this policy: first, blogging about ones own research always runs the severe risk of boring everyone. Second, after Ive finished a paper, Im usually bored with it; writing a blog entry that rehashes whats already in the paper is usually the last thing I want to do. Third, and most importantly, I didnt want to create the impression that I was using this blog to give my papers an unfair advantage over everyone elses.
However, recently a consensus seems to have formed, among the community of disgruntled anonymous commenters on computational complexity blogs, that Im some sort of clown who bets $200,000 against alleged PNP proofs for the sole reason that hes unable to do any actual research of his own. While I ought to have the Obamalike composure to remain unaffected by such gutter-sniping, I have to admit that it pissed me off. To be sure, I am a clown who bets $200,000 against alleged PNP proofs instead of doing actual research. However, this is not because I cant do actual research; rather, its because I dont feel like it. To help prove this, Ive decided to abandon my previous no-tooting-my-own-research-horn policy. So, anonymous commenters: you wanna know about my actual research? Well then, blog entries about actual research are what youre gonna getso much that youll wish you never brought it up.Teaching your students not to need a teacher

Yesterday, after coming across my teaching statement, a reader named Arber Borici sent me the following questions:
In your opinion and based on your experience at various institutions, what would you recommend to me (a young, inexperienced scholar) regarding on how to best remove students attention from the mediocrity of grading to the eagerness for knowledge or, at least, high culture?  I would also appreciate it if you could provide me with one or two guidelines in approaching students to appreciate what they are being taught and to teach them on how to seek knowledge for themselves.
It seemed like good fodder for a blog entry, so with Arbers kind permission, Ive decided to post my response to him here (with only light editing).
Dear Arber,Thanks for your thoughtful email! Im always delighted to hear from people who share my views about the inherent problems in combining teaching with evaluationPhysics for Doofuses: Why Beds Exist

I promised to blog more about research, and I will. Unfortunately, in the one week between my world tour and the start of the fall semester, Ive been spending less time on quantum complexity research than on sleeping on a new mattress that I bought. This has provided ample time to ponder the following question, which Ive decided to add to the Shtetl-Optimized Physics for Doofuses series:
Why is a soft bed more comfortable than a hard one?
At first glance, this question seems too doofusy even for a series such as this, which makes its target audience clear. The trouble is that, while perfectly reasonable-sounding answers immediately suggest themselves, several of those answers can be shown to be wrong.
Lets start with the most common answer: a soft bed is more comfortable than a hard bed because it molds to your shape.  The inadequacy of this answer can be seen by the following thought experiment: lie on a soft bed, and let it mold to your body. Then imagine that the bed retains exactly the same molded shape, but is replaced by ceramic. No longer so comfortable!
Ah, you reply, but thats because a ceramic bed doesnt change its shape as you shift positions throughout the night. But this reply is still inadequatesince even if youre lying as still as possible, it still seems clear that a soft bed is more comfortable than a hard one.
So it seems any answer needs to start from the observation that, even when youre lying still, youre not really lying still: youre breathing in and out, there are tiny vibrations, etc. The real point of a soft bed is to create a gentler potential well, which absorbs the shocks that would otherwise be caused by those sorts of small movements.
(I was tempted to say the point is to damp the movements, but that cant be right: trampolines are designed for minimal damping, yet sleeping on a trampoline could actually be pretty comfortable. So the essential thing a bed needs to do is simply to make way in response to small movements and vibrations. How hard the bed tries to spring back to its original shape is a secondary questionthe answer to which presumably influences, for example, whether you prefer an innerspring or a memory-foam mattress.)
So then why arent beds even softer than they are? Well, the limit of infinite softness would be a bed that immediately collapsed to nothing when you lay on it, dropping you to the floor. But even before that limit, a bed that was too soft would give you too much freedom to shift into awkward positions and thereby cause yourself back problems. This suggests an answer to a question raised by a colleague: is the purpose of a bed to approximate, as well as possible on the earths surface, the experience of sleeping in zero gravity? Unless Im mistaken, the answer is no. Sleeping in space would be like sleeping on a bed that was too soft, with the same potential for back problems and so forth.
Given that lying in bed is normally the least active thing we do, I find it ironic that the only reasons we lie in bed in the first place (as opposed to, say, on steel beams) are dynamical: they involve the way the bed responds to continual vibrations and movements.
Ill be grateful if knowledgeable physicists, physiologists, or sleepers can correct any errors in the above account. Meantime, the next time your spouse, partner, roommate, parent, etc. accuses you of lounging in bed all afternoon like a comatose dog, you can reply that nothing could be further from the truth: rather, inspired by a post on Shtetl-Optimized, youre struggling to reconcile your modern understanding of the physics and biology of lying in bed with the prescientific, phenomenal experience of lying in bed, and thereby make yourself into a more enlightened human being.Possibly the best thing ever to happen to my inbox

Just a quick (but important) announcement: theorist-extraordinaire and friend-since-back-in-undergrad Ryan Williams reports that the Theoretical Computer Science Stack Exchange website is now up in beta! What is this TCS Stack Exchange? Its a place where you can post your questions about theoretical computer science and get informed answers to themintended as the homegrown CS theory analogue of the wildly-successful Math Overflow site. From an initial perusal, the TCSSE looks awesome. Indeed, the only small suggestion I can make is to propose a motto:
The TCS Stack Exchange. Exponentially better than emailing Scott Aaronson.
Update (Sep. 10): While Im on the topic of announcements, the early registration deadline for FOCS2010 in Las Vegas is September 30. Hope to see many of you there!
Another Update (Sep. 14): Theres now a beautiful talk by Ken Clarkson, Ron Fagin, and Ryan Williams looking back on the Deolalikar affair and explaining the problems with the proof, which I recommend in the strongest terms to anyone who followed this story. (And yes, I think looking back is the right term here.)NRC: Nonsensical Ranking Clowns

As those of you in American academia have probably heard by now, this week the National Research Council finally released its 2005 rankings of American PhD programs, only five years behind schedule. This time, the rankings have been made 80% more scientific by the addition of error bars. Among the startling findings:

In electrical and computer engineering, UCLA and Purdue are ahead of Carnegie Mellon.
In computer science, UNC Chapel Hill is ahead of the University of Washington.
In statistics, Iowa State is ahead of Berkeley.

However, before you base any major decisions on these findings, you should know that a few  irregularities have emerged in the data used to generate them.

According to the NRC data set, 0% of graduates of the University  of Washingtons Computer Science and Engineering Department had academic plans for 2001-2005. (In  reality, 40% of their graduates took faculty positions during that  period.) NRC also reports that UW CSE has 91 faculty  (the real number is about 40). Most of the illusory faculty, it turned out, were industrial colleagues who dont supervise students, and who thereby  drastically and artificially brought down the average number of  students supervised. See here and here for more from UW itself.


According to the NRC, 0% of MIT electrical engineering faculty  engage in interdisciplinary work. NRC also reports that 24.62% of MIT  computer science PhDs found academic employment; the actual number is  twice that (49%).
The more foreign PhD students a department had, the higher it  scored. This had the strange effect that the top departments were punished for managing to recruit more domestic students, who are the ones in much shorter supply these days.
The complicated regression analysis used to generate the scoring formula led to the percentage of female faculty in a given department actually counting against that departments reputation score (!).


Ever since the NRC data were released from the parallel universe in which they were gathered, bloggers have been having a field day with themsee for example Dave Bacon and Peter Woit, and especially Sariel Har-Peleds Computer Science Deranker (which ranks CS departments by a combined formula, consisting of 0% the NRC scores and 100% a random permutation of departments).
Yet despite the fact that many MIT departments (for some reason not CS) took a drubbing, I actually heard some of my colleagues defend the rankings, on the following grounds:

A committee of good people put a lot of hard work into generating them.
The NRC is a prestigious body that cant be dismissed out of hand.
Now that the rankings are out, everyone should just be quiet and deal with them.

But while the Forces of Doofosity usually win, my guess is that theyre going to lose this round. Deans and department headsand even the Computing Research Associationhave been livid enough about the NRC rankings that theyve denounced them with unusual candor, and the rankings have already been thoroughly eviscerated elsewhere on the web.
Look: if I really needed to know what (say) the best-regarded PhD programs in computer science were, I could post my question to a site like MathOverflowand in the half hour before the question was closed for being off-topic, Id get vastly more reliable answers than the ones the NRC took fifteen years and more than four million dollars to generate.
So the interesting questions here have nothing to do with the rankings themselves, and everything to do with the process and organization that produced them. How does Charlotte Kuh, study director of the NRCs Assessment of Research Doctorate Programs, defend the study against what now looks like overwhelming evidence of Three-Stooges-level incompetence? How will the NRC recover from this massive embarrassment, and in what form should it continue to exist?
The NRC, as I had to look up, is an outfit jointly overseen by the National Academy of Sciences (NAS), the National Academy of Engineering (NAE), and the Institute of Medicine (IOM). Which reminded me of the celebrated story about Richard Feynman resigning his membership in the NAS. When asked why, Feynman explained that, when he was in high school, there was an honor club whose only significant activity was debating who was worthy of joining the honor club. After years in the NAS, he decided it was no different.
Now that I write that, though, an alternative explanation for the hilarious problems with the NRC study occurs to me. The alternative theory was inspired by this striking sentence from an Inside Higher Ed article:
When one of the reporters on a telephone briefing about the rankings  asked Ostriker [the chairman of the NRC project committee] and his fellow panelists if any of them would defend the  rankings, none did so.
So, were these joke rankings an elaborate ruse by the NRC, meant to discredit the whole idea of a strict linear order on departments and universities? If so, then I applaud the NRC for its deviousness and ingenuity in performing a much-needed public service.The converse of smoothed analysis

A year ago, Timothy Gowers posted the following beautiful question to MathOverflow:
Are there any interesting examples of random NP-complete problems?
Heres an example of the kind of thing I mean. Lets  consider a random instance of 3-SAT, where you choose enough clauses for  the formula to be almost certainly unsatisfiable, but not too many more  than that. So now you have a smallish random formula that is  unsatisfiable.
Given that formula, you can then ask, for any subset of its clauses,  whether that subset gives you a satisfiable formula. That is a random  (because it depends on the original random collection of clauses)  problem in NP. It also looks as though it ought to be pretty hard. But  proving that it is usually NP-complete also seems to be hard, because  you dont have the usual freedom to simulate.
So my question is whether there are any results known that say that  some randomized problem is NP-complete. (One can invent silly artificial  examples like having a randomized part that has no effect on the  problem  hence the word interesting in the question.)
On skimming this question, my first thought was: aha, hes obviously groping toward the well-studied notion of average-case complexity! Let me generously enlighten him. But no, it turns out he wasnt asking about average-case complexity, but about something different and novel. Namely, the random generation of computational problems consisting of exponentially many instances, for which were then interested in the worst-case instance. When I explained to Gil Kalai what Gowers wanted, Gil amusingly described it as the converse of smoothed analysis. In smoothed analysisone of many contributions for which Dan Spielman recently won the Nevanlinna Prizewe start with a worst-case instance of a problem (such as linear programming), then perturb the instance by adding some random noise. Gowers wants to do the opposite: start from a random instance and then perform a worst-case perturbation of it. (The closest existing notions I could think of were trapdoor one-way functions and other primitives in cryptography, which involve the random generation of a computational problem thats then supposed to be hard on average.)
Anyway, I tossed the question onto my stack of questions that could develop into whole new branches of theoretical computer science, if someone felt like developing them, and pretty much forgot about it. Then, at dinner last night, I posed the question to Allan Sly, whos visiting MIT to talk about his exciting new FOCS paper Computational transition at the uniqueness threshold. Within an hour, Allan had emailed me a sketch of an NP-hardness proof for the random 3SAT problem that Gowers asked about. I repost Allans solution here with his kind permission.
Group the n variables into N=n groups of size n1-,  M1,MN arbitrarily. For each group Mi take all the clauses with  all 3 variables in Mi such that it satisfies both the all 1 and the all  0 assignments i.e. clauses that have either 1 or 2 variables negated.  I think that just a first moment estimate should show that with high  probability the only assignments on Mi that satisfies all of these clauses should be the all 1 assignment or the all 0 assignment  other assignments are just too unlikely. So in taking these clauses we reduce to the case where we have constant values on each of the groups.
Once you have these clauses you can then treat each group as a new variable and can construct any SAT assignment on these new variables.  Because now you only need to find a clause with 1 variable in each Mi,  Mj, Mk for each (i,j,k)  [N]3 that has the right negations.  With high probability all of them should exist so you should be able to make  whatever SAT assignment on the N variables you want.
My back of the envelope calculation then suggests that as long as you have n1+ random clauses to  begin with then this should be enough.
Its not hard to see that Allans solution generalizes to 3-COLORING and other constraint satisfaction problems (maybe even all NP-complete CSPs?). In retrospect, of course, the solution is embarrassingly simple, but one could easily generate other problems in the same vein for which proving NP-hardness was as nontrivial as you wanted it to be. Further development of this new branch of theoretical computer science, as well as coming up with a catchy name for it, are left as exercises for the reader.Im asking cause I want to know

Is there an algorithm to decide whether the nth Busy Beaver number is even or odd?  Or is this problem r.e.-complete?  Or might it have intermediate Turing degree?
(For readers with social lives: Busy Beaver is not what you think.  As discussed in this Wikipedia article and this old essay of mine, its the maximum number of 1s that an n-state, 2-symbol Turing machine could write on an initially blank tape before halting.)The Aaronson Postdoctoral Fellowship

So, Ive decided to simultaneously do something positive for theoretical computer science, stimulate BQPology research at MIT, and solve the problem of having too much grant money by hiring a postdoc. The main area of interest for this postdoc is quantum complexity theory, but Ill also consider outstanding applicants of a more classical bentin fact, the ideal applicant is someone equally excited to tackle meaty open problems in quantum complexity, classical complexity, or any combination of the two. As a postdoc here, youll collaborate (I hope) with me and my PhD students, but youll also have plenty of opportunities for interaction with the other quantum computing theory folks at MIT (Peter Shor, Ed Farhi, Seth Lloyd), as well as the other computational complexity folks (too many to list). This postdoc is for one year, with the expectation of a renewal for a second year.
If youre interested, email your CV, a link to your homepage, and what you consider your top 3 or 4 publications to aaronson@csail.mit.edu, and also arrange to have 3 rec letters emailed to me. Feel free to apply even if you previously applied for other postdocs at MIT: this is a new opportunity thats somewhat different from previous ones. The application deadline is, shall we say, December 1st? Let me know if you have any questions.
Finally, while I was tempted to make reading Shtetl-Optimized an effective prerequisite for the postdoc, feel free to distribute this call for applications more widely.Research projects in quantum complexity theory

Today Im in College Park, Maryland, for a fun quantum information workshop. I just came from Las Vegas, where I was at FOCS 2010, appropriately held at the Monte Carlo. (Dont tell anyone, but I also skipped out on part of the conference for a helicopter tour of the Grand Canyon.)
However, while Ill be happy to answer questions about either of those conferences (or about the Grand Canyon, I guess), the rest of this post wont be about them. Instead, it will be about some relatively approachable-looking open problems in quantum complexity theory: basically, the problems that Id be tackling today if I were a bright-eyed grad student instead of a senile, over-the-hill 29-year-old.
The inspiration for this open problems list came from the graduate course Im currently teaching on Quantum Complexity Theory. Just like when I taught this class two years ago, Im asking every student to complete a term project, either individually or in groups of two. Heres the thing: assigning student projects in theoretical computer science turns out to be damn hard. Even if you make it clear that a literature survey is fine, many of the students admirably want to do something original. But how do you come up with a theory problem that
(a) hasnt been solved, and
(b) can be solved by someone whos just learning the material, with a high probability of success, in 1-2 months?
And thus it is that I present my sort-of updated version of my Ten Semi-Grand Challenges for Quantum Computing Theory. Despite the original motivation, most of these problems are probably too  hard for a student term projectbut all of them, I think, have  term-project-sized chunks that could be ripped off. The new challenges list makes no claim whatsoever of comprehensiveness, and is heavily skewed toward problems that I, personally, have worked on.
Without further ado, and organized into seven topics, starting with the one closest to my heart:
Quantum Query Complexity
Can we use Reichardts breakthrough characterization of quantum query complexity by span programs and the negative-weight adversary method to obtain new results on quantum query complexity for concrete problems?
In the quantum black-box model, if we relax the assumption that the  linear transformations are unitary, and merely require that, for every  Boolean input x, the sum of the squares of the amplitudes of the  accept states is a probability (i.e., belongs to [0,1]), do we ever get  an asymptotically smaller query complexity? What about an exponentially smaller query complexity?
Given a quantum algorithm that makes T queries, can we approximate its acceptance probability on most Boolean inputs using a classical algorithm that makes poly(T) queries? (See here for more.)
Are randomized and quantum query complexities polynomially related for all functions f(x1,,xn) that are invariant under permuting the indices 1,,n (for example, the Collision and Element Distinctness functions)? (In previous work with Ambainis, we showed randomized and quantum query complexities are polynomially related for all functions that are invariant under permuting both the indices and the values of x1,,xn.)
Can every quantum algorithm that makes k queries to an n-bit string, be simulated by a randomized algorithm that makes n1-1/2k queries? Does the k-fold generalization of the Fourier Checking problem provide an example for which this conjectured bound is tight?
Let f be a black-box function, which is promised to be either 1-to-1 or 2-to-1. Is there a polylog(n)-qubit quantum proof that f is 1-to-1, which can be verified using polylog(n) quantum queries to f? (If not, then we get an oracle relative to which SZK is not in QMA.)
Let f be a black-box function, which is promised either to satisfy the  Simon promise or to be one-to-one. Can a prover with the power of BQP convince a BPP verifier that f is one-to-one?
Cryptography
Are there interesting functionalities, besides point functions, that can be quantumly copy-protected?
Can we give classical oracles relative to which publicly-verifiable quantum money and copy-protected quantum software are possible?
Is the GGM construction of pseudorandom functions from pseudorandom generators secure even against quantum adversaries? If not, can we give an analogous construction thats secure?
Intermediate Possibilities Between BPP And BQP
Is it true that every set of unitary quantum gates (acting on qubits) is either universal for quantum computation, or else simulable in classical polynomial time?
If a quantum computer is in a tree state at every time step, does it follow that the computer can be simulated in classical polynomial time (i.e., in BPP)?
If a quantum computer is in a separable mixed state at every time step, does it follow that the computer can be simulated in classical polynomial time?
Postselection
Can we take any quantum computational model that allows adaptive measurements, and simulate it by a model that allows postselected measurements instead?
What are the weakest models of quantum computation that yield all of PostBQP when combined with postselection on measurement outcomes?
Communication Complexity
In the Group Membership Problem, there is a finite group G known to both Alice and Bob. Alice is given a subgroup H of G, Bob is given an element x of G, and the problem is for Bob to decide whether x is in H. What is the randomized one-way communication complexity of GM? Can we prove a lower-bound better than the trivial log|G|, thereby separating randomized and quantum one-way communication complexities for a total Boolean function?
Are the randomized and quantum one-way communication complexities polynomially related for every total Boolean function f? What about the randomized and quantum two-way communication complexities?
QMA(2)
Is QMA(2) contained in EXP? To put it differently: let V be a two-outcome measurement, which acts on the tensor product of two n-dimensional Hilbert spaces.  Is there a quasipolynomial-time classical algorithm that approximates max|>[V accepts |>2] to constant additive error?
Is QMA(2) with real amplitudes the same thing as QMA(2) with complex amplitudes?
Quantum Computing With Locality Constraints
Let G be a graph with n vertices, and let U be an nxn unitary matrix with the property that uij0 only if (i,j) is an edge of G. Then how efficiently can we represent (or approximate) U as a product of unitaries that are local with respect to G? This is a vague question, but see my paper with Ambainis for ways of making it precise.
Given n bits arranged in a nxn square grid, suppose we want to know whether every row contains at least one 1 bit. Can we do this using an ~O(n) quantum algorithm that is local in the sense defined by myself and Ambainis? Can we beat the trivial upper bound of n3/4?State of circuit lower bounds now slightly less humiliating

When people want to emphasize how pathetically far we are from proving PNP, they often use the following argument: for godsakes, we cant even prove that NEXP-complete problems arent solvable by depth-3, polynomial-size circuits consisting entirely of mod 6 gates!
But no more.
As some of you may have heard, recently Ryan Williams achieved a breakthrough in circuit lower bounds. And as a result, now we can prove that NEXP-complete problems arent solvable by depth-3, polynomial-size circuits consisting entirely of mod 6 gates.
More generally, Williams proves that NEXP does not have ACC circuits of third-exponential size: that is, size f(n) where f(f(f(n))) is exponential. Here NEXP means nondeterministic exponential time (the exponential-time analogue of NP), and was long a barrier class for circuit lower bounds. (Note that, if we go even slightly above NEXP, to MAEXP, then Buhrman, Fortnow, and Thierauf proved in 1998 that MAEXP doesnt have polynomial-size circuits of any depth, and here the polynomial can be improved to half-exponential.) Meanwhile, by ACC circuits we mean a nonuniform family of constant-depth circuits consisting of AND, OR, NOT, and MOD m gates for arbitrary positive integers m. ACC is another barrier class for circuit lower bounds: if we go even slightly below it, to AC0[p] (the same as ACC, except that now we only allow MOD p gates for some fixed prime p), then weve known how to prove exponential circuit-size lower bounds since the work of Razborov and Smolensky in the 1980s.
To achieve the combination of NEXP and ACC, Williams implements a program proposed in his previous STOC2010 paper, for the specific case of ACC. At the core of his lower bound is an algorithm for deciding satisfiability of ACC circuits, which does slightly (not much) better than brute-force search. (The algorithm relies on, of all things, fast multiplication of rectangular matrices.) While Williamss techniques have nothing to do with Mulmuleys GCT program, they do fit in well with the Mulmuleyist flip philosophy of proving lower bounds by proving upper bounds.
I havent verified Williamss proof, but the high-level ideas are compellingand while the result is one of the most spectacular of the decade, its not so far beyond the current frontier as to strain credulity. Suffice it to say that I wont be betting $200,000 against this one.
Congratulations, Ryan!
Update: Amusingly, if you google Ryan Williams ACC, you get a football player of the same name who was apparently Rookie of the Year in the Atlantic Coast Conference. Lets all link to Ryans paper from our homepages, and see if we can make our ACC Rookie of the Year win out!The Computational Complexity of Linear Optics

I usually avoid blogging about my own paperssince, as a tenure-track faculty member, I prefer to be known as a media-whoring clown who trashes D-Wave Sudoku claims, bets $200,000 against alleged PNP proofs, and complains about his lecture notes being appropriated by Australian actresses to sell printers. Any research that I happen to do is best kept secret, lest it interfere with that carefully-constructed persona.
Today, though, Im making an exception. On Thursday, my PhD student Alex Arkhipov and I finally finished our mammoth 94 95-page preprint on The Computational Complexity of Linear Optics, which we were writing for the past year. (Remarkably, this is Alexs first paper. Congratulations, Alex!) Never before was I involved in a project that forced me to learn so many unfamiliar things, from experimental quantum optics to random matrix theory to exotic complexity classes like BPPNP and PostBQP. (Alright, that last one wasnt particularly unfamiliar, but the others were.)
In one sentence, the goal of our paper is to help bridge the yawning gap between what complexity theorists believe is true about quantum mechanicsnamely, that its exponentially-hard to simulate on a classical computerand what experimentalists can currently demonstrate. To do so, we try to meet the experimentalists halfway, by proposing a linear-optical setup that seems significantly closer to practicality than (say) a universal quantum computer, but still solves a computational problem that we can show is intractable for classical computers, under plausible and clearly-stated hardness assumptions (which dont just amount to our system is hard to simulate!).
Without further ado, heres the abstract:
We give new evidence that quantum computers  moreover, rudimentary quantum computers built entirely out of linear-optical elements  cannot be efficiently simulated by classical computers.  In particular, we define a model of computation in which identical photons are generated, sent through a linear-optical network, then nonadaptively measured to count the number of photons in each mode.  This model is not known or believed to be universal for quantum computation, and indeed, we discuss the prospects for realizing the model using current technology.  On the other hand, we prove that the model is able to solve sampling problems and search problems that are classically intractable under plausible assumptions.
Our first result says that, if there exists a polynomial-time classical algorithm that samples from the same probability distribution as a linear-optical network, then P#P=BPPNP, and hence the polynomial hierarchy collapses to the third level.  Unfortunately, this result assumes an extremely accurate simulation.
Our main result suggests that even an approximate or noisy classical simulation would already imply a collapse of the polynomial hierarchy.  For this, we need two unproven conjectures: the Permanent-of-Gaussians Conjecture, which says that it is #P-hard to approximate the permanent of a matrix A of independent N(0,1) Gaussian entries, with high probability over A; and the Permanent Anti-Concentration Conjecture, which says that |Per(A)|(n!)/poly(n) with high probability over A.  We present evidence for these conjectures, both of which seem interesting even apart from our application.
This paper does not assume knowledge of quantum optics. Indeed, part of its goal is to develop the beautiful theory of noninteracting bosons underlying our model, and its connection to the permanent function, in a self-contained way accessible to theoretical computer scientists.
As you can see from the abstract, theres a huge amount still to be doneof which the most obvious is (1) proving our #P-hardness conjecture and (2) doing our experiment! Im also hopeful that people will take up the challenge of proving similar hardness results for other rudimentary quantum systems, besides linear optics. In that vein, one immediate question is whether we can give evidence that the beautiful commuting quantum computations model of Bremner, Jozsa, and Shepherd is hard to simulate even approximately by a classical computer.
Here are a few options for anyone whos slightly curious about our work, but not curious enough to, yknow, download the paper:

My PowerPoint slides.
Alexs PowerPoint slides, which I like better than mine.
A MathOverflow question that I posted yesterday about the Permanent Anti-Concentration Conjecture, and which was quickly answered by Terry Tao.
A CS Theory StackExchange question about our paper posted by Andrs Salamon, which I answered this morning.
New: An interesting blog post about our work by Gil Kalai.

Anyway, the main purpose of this post was simply to provide a place for people with questions about our paper to ask them. So, shoot!Anti-Complexitism

Its time someone said it. There exists, among a small but vocal subset of the nerd community, a strange animus against computational complexity theory, which is often rooted in factual misunderstandings, and seems wholly out of proportion to any real shortcomings that complexity theory has. Granted, every field of science has its backseat-drivers, those extralusionary intellects who feel sure they could best the experts, but havent expended any actual effort in solving the problems on which the experts are stuck. But, perhaps because of the unusual accessibility of its open problems, complexity theory seems (I might be wrong) to attract more such naysayers than other mathematical fields.
It goes without saying that no intellectual pursuit is automatically entitled to respect: it has to earn it by actual accomplishments. But even after complexity theory delivers spectacular accomplishmentsfrom NP-completeness to PCPs to public-key cryptography to zero-knowledge proofs to quantum computingthe carping continues unabated. Its this phenomenon that Id like to understand better.
Here are the main manifestations of anti-complexitism that Ive witnessed:
Monday-morning quarterbacking of complexity breakthroughs. For an example, see this thread on Lance and Bills blog, which is full of knowing comments seeking to minimize Ryan Williamss recent NEXP vs. ACC breakthrough. Some of these comments are strangely off the mark: for example, the new result is taken to task for being nonconstructive, relying on the ability to perform diagonalization within the huge set NEXP. But weve known since Natural Proofs that, if you want to make progress on the P vs. NP question, then youll need nonconstructive techniques that seize on a special property of the function f being lower-boundedand diagonalization remains one of the few examples of such a technique that we have. On the other hand, weve also known that, if you do use diagonalization, then youll need to combine it with some new ingredient to get around both the relativization and algebrization barriers. Ryans proof actually does all of that, which is why many of us are so excited about it.
Refusal to accept the incremental nature of complexity theory (which is shared by every other scientific field known to humankind). To me, one of the more humorous criticisms of Ryans breakthrough is that it merely shows NEXP is not in ACC, and not (for example) that the MAJORITY function is not in ACC. Granted, the statement NEXPACC is pathetically weak compared to what we believe is true. But then again, what have you done thats advanced circuit complexity by 1% as much as this pathetic lower bound?
Fervent desire to see complexity theorists get their comeuppance from an outsider. The anonymous blog-commentariats pooh-poohing of the ACC breakthrough stands in contrast to the praise that same commentariat heaped on Vinay Deolalikars unsuccessful attempt at proving PNP a few months ago. Even though Vinay and Ryan are both academic researchers working at industry labs (HP and IBM respectively), from reading the comments, it appears part of the reason for the differing reactions is that Deolalikar was seen as more of an outsider. Now, I like to root for the underdog as much as the next American, but its worth remembering that every scientist starts as an outsider. It was only a decade ago that Ryan and I were both nerdy kids at Cornell, trying to get our respective crazy ideas taken seriously by professors. To paraphrase Niels Bohr, is a scientific insider anything more than an outsider whos already made most of the egregious mistakes in some subfield?
Presenting obvious, universally-known limitations of asymptotic analysis as if they were new insights. Yes, Im aware that a polynomial-time algorithm can be impractical because of huge constant factors or a whopping exponent. Im aware that an NP-complete problem can be easy on those instances that arise in practice. Even if I have a debilitating brain injury, so that I no longer remember my own name or how to count to 10, I like to think that Ill still be aware of these facts. To me, dismissing complexity theory because of its love affair with worst-case, asymptotic analysis is like dismissing physics because of its love affair with frictionless surfaces, point particles, elastic collisions, and ideal springs and resistors. In both cases, people make the simplifying assumptions not because theyre under any illusions that the world really is that way, but rather because their goal is understanding. And in both cases, the theory itself gives you the tools to complicate your modelto put legs and hooves on your spherical cowuntil you get reasonably-accurate predictions for the practical problems that interest you. (See: D. E. Knuth, The Art of Computer Programming.)
Dismissal of complexity theory as not real mathematics. Theres no denying that complexity theory is young compared to (say) complex analysis, differential equations, or Lie groups. But if you were choosing an area to work on, why would that be a point against complexity? It means all the more to do and discover: instead of having the elegant, unifying theory presented to you in yellow books, you get to create it! Furthermore, weve seen that the connections between complexity theory and traditional areas of mathematics are as deep as people want to make them (and often deeper): in recent years, metric embeddings, elliptic curves, algebraic geometry, and arithmetic combinatorics have all played starring roles in complexity results. On the other hand, yes, sometimes you can achieve a complexity breakthrough the way Ryan did, not by using deep mathematics, but just by thinking incredibly hard about simple facts like fast matrix multiplication and the Time Hierarchy Theorem. Again, thats a negative?
Attacks on complexity theory for over-reliance on conjectures, even though almost every field outside mathematics (and quite a few within mathematics) rely on conjectures as well. This one really gets meand is the reason why I often point out that, if we complexity theorists were physicists, we would have declared PNP a law of nature decades ago, then looked back with pride on our far-reaching discovery about the workings of the universe. The problem of rigorously proving the No-SuperSearch Law would have been relegated to the mathematical physicists, much like the problem of proving the consistency of (3+1)-dimensional quantum field theory. Instead, because we complexity theorists have the custom of trumpeting what we cant prove from the rooftops, we give our extralusionary friends the ammunition they need to regard us as dismal failures, should they so choose. So you landed on the moon? How adorable. But tell me, why does that represent even the slightest progress toward the real goal of visiting other galaxies? The response, which should be obvious, is that taunting mountain-climbers for being out-of-shape laggards works best when youre at the peak of the mountain looking down at them, not at the base looking up. But then again, if you were climbing the mountain too, youd be less likely to want to taunt other climbers, even those behind you: for then the competitive instincts common to all humans would have to contend with the feeling of being part of a great and difficult shared enterprise.Welcome to my weblog!

Youre probably wondering about the title. I chose it because (1) I was pretty sure it wouldnt be taken already, and (2) it evokes what Ive come to see as the defining problem of my life.
A couple years ago, when I was still at Berkeley, some fellow grad students and I were discussing who we would have been had we lived 700 years ago. Would we have been farmers and bricklayers, like pretty much everyone else? Or kings and duchesses, as the people who go to Renaissance Fairs all apparently were? More interestingly, would we have found some way to capitalize on our bizarre gifts  say, by developing a new field-ploughing algorithm that was provably within a 1+ factor of optimal? (That we would still have our nerdy gifts wasnt open to question  for if we didnt, then we would no longer be ourselves.)
I wouldve been the chief rabbi of my shtetl, I said. All day long, Id debate questions like how much restitution youd have to pay if your ox gored your neighbors sheep. And for this, Id get an arranged marriage with the most beautiful girl in town.
Someone interjected that I shouldnt sentimentalize too much: After all, Scott, you wouldnt have had any complexity theory! Or quantum computing!
Thats true, I confessed.  So, you know  you win some, you lose some.
Complexity and quantum computing will indeed play a role on Shtetl-Optimized, as will politics, economics, history, free will, global warming, The Simpsons  the whole megillah, or at least the sections Ive skimmed.  But the overarching theme will be how to survive as a penguin in the desert, or a camel in Antarctica, or a caveman in  well, anyway, as someone who feels himself exquisitely adapted to an environment utterly unlike the one into which he was born. If youve ever felt that way or even if youd just enjoy the spectacle of someone groping his way out of the nebbish-bin of history  I hope you find it enlightening.Waste papers

To get this blog rolling, Id like to put forward a modest idea that Ive been chewing on for a while.  Ready?  Here it is:
Scientific papers are a waste of time. Therefore, we should stop writing them, and find a better way to communicate our research.
Among the likely readers of Shtetl-Optimized, I cant imagine that this idea would cause the slightest controversy. But just in case Im mistaken, let me stress that the idea would have seemed crackbrained to me, too, back when I was young and green.
Are you kidding? I would have screamed at my decrepit 24-year-old future self. Research papers have been humankinds great instrument of progress for 300 years! Theyre the bulwark that separates Crick from creationists, Chandrasekhar from Chopra, and Wigderson from wackballs like this! Without peer-reviewed papers, how would we verify each others claims? How would we establish priority? What would we fill our c.v.s with?
So I came to my current view slowly and reluctantly, as a result of spending the past five years struggling (often unsuccessfully) to write up results that Id proven long before, and that I could easily explain in half an hour to anyone who asked me, and that only a tiny group of experts would ever need to see the details of, and that
God, those years. They went by so quickly. They shouldve been the best years of my life. I shouldve been saving all of my scarce brain cycles for solving big, meaty problems. And in the meantime, I shouldve been learning how to salsa dance, and exploring San Francisco, and giving talks for elementary school kids, and having dumb affairs that Id later regret. Instead, what was I doing? Responding to referee reports for this and this and this and this and this.
In an infamous guest post on Lance Fortnows blog, I advocated a rather different philosophy. I realize now that I was wrong, and I apologize to any colleagues who were hurt by what I said there. For I now understand that the true time-sucker is neither sailing nor surfing nor clubbing. These things take up only a finite number of hours in any case; once theyre done, theyre done. No, the true enemy of scientific productivity is having to write everything up in such a goddamned painstaking way.
Ill estimate that I spend at least two months on writing for every week on research. I write, and rewrite, and rewrite. Then I compress to 10 pages for the STOC/FOCS/CCC abstract. Then I revise again for the camera-ready version. Then I decompress the paper for the journal version. Then I improve the results, and end up rewriting the entire paper to incorporate the improvements (which takes much more time than it would to just write up the improved results from scratch). Then, after several years, I get back the referee reports, which (for sound and justifiable reasons, of course) tell me to change all my notation, and redo the proofs of Theorems 6 through 12, and identify exactly which result Im invoking from [GGLZ94], and make everything more detailed and rigorous. But by this point Ive forgotten the results and have to re-learn them. And all this for a paper that maybe five people will ever read.
Lets try some thought experiments.  Steve Cook never bothered to write up a journal version of this STOC abstract.  Suppose he did; what of it?  After he wrote On Computable Numbers in 1936, Turing wrote an erratum in 1937, correcting a few bugs. Did you even know that? Do you care? Would Turings place in history be any different had he left the bugs unfixed?
So whats the solution? Personally, my hope is that the Internet will eventually make not only traditional print journals obsolete (as it already has in some fields), but traditional papers as well. Instead well have permanently-archived interactive proofs: discussions that look, more than anything else, like the emails exchanged between coauthors before they start writing up the paper.
I think I can prove X like so.
But how do you handle Y and Z?
Well, what about W?
Assuming the participants are serious researchers, I believe that the limit of such a discussion is every bit as reliable as the paper itself. After all, if absolute rigor is the goal, then you shouldnt believe the paper either. You should insist that everything be formalized in ZF set theory  and even then, how would you know that what was proved corresponded to the informal statement?
(To be clear, Im not advocating some sort of woo-woo philosophy of mathematics.  I dont have a philosophy of mathematics  or if I do, then its nave Platonism. All Im advocating is that we consistently adopt the same standards of convincingness that we already adopt when arguing in front of a blackboard. I leave as an open problem how all of this applies to the softer sciences, like biology or string theory.)
But until the post-paper world Im championing becomes a reality, what should you do?  Heres my advice: write the most informal, sloppy, essayistic, stream-of-consciousness, conversational papers you can possibly get away with. Write as if you were firing off an email to a skeptical but impatient friend. I promise to do my part by reviewing such papers leniently (at least in terms of the presentation), and no longer demanding pointless revisions.BQPOTUS (or, the Big-O)

Disclaimer: The White House Office of Science and Technology Policy has asked me to clarify that, although this post will contain a photograph of me standing near the President of the United States, nothing in the post, or in Shtetl-Optimized more generally, is endorsed in any way by the White House or the President. You know, just in case you were wondering.
Its a good thing that I chose a career in science rather than in public relations.
Within one century, government-sponsored scientific research radically changed the ways that human beings exist on this planet. Electronics are possible because of the quantum revolution of the 1920s, a revolution that many of us are still trying to understand the full implications of. While it benefited from a government monopoly, Bell Labs was able to invent and/or commercialize the transistor, the laser, the fiber-optic cable, and the communications satellite. (As soon as Congress opened the telecom market to competitors, Bell Labs capacity to innovate was permanently crippled.) Computers, the Internet, cell phones, nuclear energy, DNA testing, and widespread vaccination are a reality today largely because of a partnership between academic scientists and their governments, in the US and elsewhere, that started in earnest during World War II and has continued to the present.
I sort of imagined that, if you were reading this blog, then you knew all of that, and also knew that I knew it. But I was mistaken. In writing about what seemed to me like a slam-dunk issue for any thinking personnamely, protecting the0.18% of the United States federal budgetthat goes to the National Science FoundationI somehow managed to make enemies not only of the NSFs opponents, who skewered me asan ivory-tower elitist, but also of many of itssupporters,who either didnt understand or didnt appreciate my attempts at gallows humor.
Fortunately, today I have a happy story involving the NSF. As Lance Fortnowkindly mentioneda month ago, I had the honor of being included in this yearsPECASE(Presidential Early Career Award for Scientists and Engineers) class. Here I followed in the footsteps ofAdam SmithandSean Hallgren, two theoretical computer scientists from Penn State (and very nice people) who won last year. The PECASE is given for a combination of research and outreach, so theres little doubt this blog played a role, in addition (I hope!) to the research and teaching that I sometimes do in my spare time. Theres no money in the PECASE, just a fun trip to DC for ceremonies and a photo-op with the President.
The day (last Monday) started with a ceremony in the Department of Agriculture building.  There was a Color Guard, then a beautiful live performance of the national anthem, then short speeches, then a presentation ofawards that resembled a high-school graduation, then a reception where they served these really nice smoked-salmon wraps, as well as chocolate truffles that were on sticks like lollipops. The awardees families were all there with us, but unfortunately, only the awardees themselves were cleared to enter the White House complex for the presidential photo-op. There was no Air Force One pickup to get to the White House: we took the Metro. We arrived at the Eisenhower Executive Office Building, which is to the left of the White House, adjacent to the West Wing. There were Christmas decorations all around.
After going through a security check, wewere ushered into a room that seemed specially designed for presidential photo-ops. It had staggered platforms for standing on, with curtains in the background.
I was allowed to bring my cellphone, but it didnt work inside the White House. There was a strict no-photography rule.
We were called to pose for the photo in order of height: people over 6ft in the back row, then people over 5ft 10in in the next two rows, etc. I was lucky to be short enough to land a spot in the second-to-front row. We stood there for about fifteen minutes while waiting for the President to arrive.
The organizer from the Office of Science and Technology Policy warned the women in the front row that last year, the President put his arm around them for the photoso they should be prepared!
At 1:55pm, we received word that the President would arrive at 2:05pm, and at 2pm, we received word that he was on his way over. Finally, at 2:05 on the dot, he bounded into the room and the PECASE awardees erupted into applause. My MIT colleague Manolis Kellis bellowed Mr. President!, which made the President laugh.
The President looked and sounded pretty much the same as on TV. I was happy to see that his lip looked fine. He shook hands with everyone in the front row, assuring everyone else that theyd get a chance to shake his hand later as well.

(Im the one wearing a tie with a little drawing of the MIT Stata Center on the bottom.)
The President spoke for about five minutes, while Secret Service agents stood unobtrusively in the corners of the room. Here were his main points, as I remember them:

He couldnt be more proud of us.
Science and technology are extremely important for the nations future.
Hes been fighting for more science funding. (At this, the PECASE awardees burst into applause again.)
Science will be a highlight of his next State of the Union address. (Hey, you read it here first.)
He understands that the PECASE award is not just for research but also for outreach and education, which is great.
As someone with two daughters, hes especially happy to see so many female PECASE winners.
He feels so honored to be able to pose for a photo with us. (At this, everyone laughed.)
He made a reference to young people, which most of you still qualify as (causing more laughter), and said hes expecting us to produce and win some Nobel prizes.

As the rows cleared out, the President shook hands with everyone in turn. A few people said Merry Christmas. I just said thank you, and he said thank you back. Then I quickly moved away, since I had a cold and was worried about giving it to him. (Also, my hand was sweating for some reasonmaybe because I was wearing a suit, which was definitely one of the more unusual aspects of the day for me!)
Immediately after the photo, we were escorted out of the Eisenhower Building. (Apparently the PECASE awardees in some previous years got a tour of the White House, but we didnt.)
Later in the afternoon, there was a reception at NSF headquarters for the 19 PECASE winners whose research was sponsored by NSF (the remaining 66 were sponsored by the National Institutes of Health, the Department of Energy, the Defense Department, NASA, or other agencies).  After opening remarks by Subra Suresh, the new NSF director and previously Dean of Engineering at MIT, each of the awardees gave a 3-minute speech about his or her work.  I really enjoyed listening to the other 18 talks (as for my own, I spoke too fast and probably lost people).
At the risk of annoying earnestness, Id like to thank:

My NSF program officer (and all-around favorite government official),Dmitri Maslov.
Every reader of this blog who ever said anything positive (or at least non-negative) about it.
The Office of Science and Technology Policy, for putting together an awesome day (and inducing me to wear a tie even though no one was being married, buried, or bar-mitzvahed).
President Obama, for supporting science and education even in the face of determined opposition.
My fellow American taxpayers, for bankrolling the NSF.  May all who receive grants strive to be worthy of them.
My family.Portugal: Non-Catholics Once Again Welcome

I arrived yesterday morning in Lisbon.  Im here to give a talk at the Instituto Superior Tcnico, which is working to build up a quantum information group.  On Saturday I leave for QIP2006 in Paris, then for New York City, before returning to Waterloo.  Academia is not an easy life, but I try to bear it like a soldier.
Lisbon is beautiful: sort of like San Francisco, except more so.  Yesterday I hiked up to the Castelo de So Jorge, a 100% genuine castle (with turrets, a moat, etc.) that overlooks the city from a hilltop.  I took lots of photos, but then lost the cable with which to upload them to my computer.  Sorry!
As my host, Yasser Omar, explained to me, Portugal missed half of the 20th century: specifically the years 1932-1974, when it was run by a backwards dictatorship.  Even today, a tradition of bureaucratic incompetence lingers on.  Yasser said that when he was looking for a tenure-track physics job, he could find only one opening in the whole country  and that one was only for geophysics or the history of physics!   (He now works in a math department.)  He and like-minded academics are now doing their best to help Portugal make up for the lost time.
PS. For those Shtetl-Optimized readers who dont know a shtetl from schmaltz (and its come to my attention that such exist): King Manuel I of Portugal expelled the Jews in 1497, five years after Ferdinand and Isabella expelled them from Spain.  Apparently, King Manuel realized that this would devastate Portugals economy, so he only signed the order reluctantly, after Princess Isabel of Spain demanded he do it as a precondition of marriage (!).  Portugal started readmitting Jews in the 1800s, and eventually became a transit point for over 100,000 refugees from the Nazis.  You can read more here.The quantum jester

Ive been told that the world is awaiting my report about the QIP2006 conference.  So here it is.  Im in Paris, near the Pantheon.  The buildings are beautiful, but the weather is crummy.  The food is tasty, expensive, and fattening.  Everyone here has been friendly,  which is surprising  considering that Im conspicuously American, and that my French consists almost entirely of the following phrases:
Bonjour!
Merci!
Oui!
Je ne comprends pas!
Monsieur
Madame
cole Polytechnique
Croissant
Baguette
Ravioli (no, wait  thats Italian)
(Im in a talk right now, using the wireless Internet, and Harry Buhrman is reading this over my shoulder and laughing.  Stop that, Harry!)
Oh, right: there have also been talks here.  Maybe Ill blog about them in a later post, but then again, maybe not.  Im not giving a talk, but I am giving the after-dinner speech on Thursday, the quantum computing community having relegated me to the role of jester.  Which reminds me that I should write the speech.
I should also apply for jobs for next year.  Actually, would anyone like to offer me a tenure-track faculty position right now?  Most of the deadlines have passed, and I havent even written my research statement  so if that sort of thing doesnt bother you, your chances of getting me are excellent.By popular demand

How To Be A Serious Researcher, my infamous after-dinner speech at QIP2006, is now available as an mp3 (5MB, 21 minutes). If you want to tar-and-feather me for this, dont forget Ben Toner (who made the recording) or Julia Kempe (who sent the photo).The Future of Computer Science, and Why Every Other Major Sucks By Comparison

Does this post finally herald my return to regular blogging after a months-long absence?
I dont know. For me, writing a Shtetl-Optimized entry always followed the same process: Id get an idea and start typing, furiously rocking back and forth in my chair. Then the voices in my head would pipe up: no, I cant say thatwhat will everyone think?judging from past experience, theyll probably take offenseI can already see the commenters boiling me alivemaybe if I rephrased it, or, yknow, provided some contextbut to explain the real context, Id need a whole bookand who has the time for that?better wait till after tenuremeantime, maybe I could blog about something light and uncontroversial insteadbut then whats the point?we already have one GASARCHwell, I could always put off a decision till later
Back in the blogs heyday, Id win these fights about 40% the time and the voices would win about 60%. (In other words: if youve ever taken offense at an entry of mine, rest assured that you havent even seen the half of my drafts folder.) But now that I have an actual stake in this shabby worldstudents to advise and look after, a tenure case to build, conceivably even a family to startthe voices win more like 98% of the time. And thats why my blogging fell off.
Occasionally, though, something comes along so uncomplicatedly joyous that I feel no reservations about sharing it with the world. Such was the case this weekend, when I was somehow called upon to represent MITs EECS Department in the annual Professor Talent Show at Campus Preview Weekend. This is an event where six faculty members square off, taking eight minutes each to
(1) explain why their department is the coolest,
(2) crack jokes, and
(3) possibly demonstrate a musical or athletic talent.
Then, using electronic clickers, the several hundred prefrosh in attendence vote for which major carried the day. Though I had no absolutely no talent of any kind to demonstrate, and was up against a banjo-player, violinist, and basketball-spinner among other tough competitors, for some reason EECS won! You can see my PowerPoint slides here:
The Future of Computer Science, and Why Every Other Major Sucks By  Comparison
http://www.scottaaronson.com/talks/futurecs.ppt
(You can read the jokes that go along with each slide in the slide notes at the bottom.)
Update (4/15): I hadnt realized at all that theres actually a video of me giving the talk! (Click on Part 2.)QCut

WARNING:This post makes (what turned out in retrospect to be) advanced use of sarcasm, irony, and absurdism. Indeed, even after I added a disclaimer explaining the sarcasm, many commenters still responded as if I actually favored gutting the National Science Foundation.(Unless, of course, those commenters were also being sarcasticin which case, touche!)
The confusion is completely my fault. When I write a post, I have in my mind a reader whos read this blog for a while, and knows that obviously I dont favor gutting the fraction of a percentage of the Federal budget devoted to the progress of human understanding and American leadership thereof; obviously the NSF wastes plenty of money, but if it didnt, then it would be doing a terrible job, because research is all about trying stuff that has a good chance of failure; obviouslyif you were seriously looking for waste, you could find orders of magnitude more of it in the military and elsewhere. So then the only remaining question is: how can we best have fun with a disgusting and contemptible situation? I forgot how many people come to this blog not having any idea who I am or why Im writingand for that, I sincerely apologize.
Now, if youd like a sarcasm-detection challenge, I did leave lots of hints in the following post that I didnt actually agree with Congressman Smith. See how many of them you can find!

As some of you may have heard, the incoming Republican majority in Congress has a new initiative calledYouCut, which lets ordinary Americans like me propose government programs for termination. So imagine how excited I was to learn that YouCuts first targetyes, itsfirst targetwas that notoriously bloated white elephant, the National Science Foundation. Admittedly, Ive already tried to save NSF from some wasteful expenditures, in my occasional role as an NSF panel member. But this is my first chance to join in as a plain US citizen.
In a video explaining the new initiative, Congressman Adrian Smith concedes that the NSF supports worthy research in the hard sciences, but then gives two examples of NSF grants that strike him as wasteful: one involving collaboration among soccer players, the other involving modeling the sound of breaking objects. This articlegives some more detail about the projects in question.
While I cant wait to participate, I have a few questions before I start:

Exactly which sciences count as hard? Once the pitchforks are raised, how far do we go? Is math fair game? What about economics, cosmology, evolutionary biology?
Has there ever been a research project that couldnt be described in such a way as to sound absurd? (Even in the middle of a war, university academics in Chicago are spending taxpayer dollars in a quixotic attempt to smash teeny-tiny uranium atoms underneath a football field)
Years ago, several commenters on my and Lances blogs eloquently argued that science funding isnt a traditional left vs. right issue, that Republicans are at least as friendly to science as Democrats, and that viewing the modern GOP as the party of ignorance is inaccurate, simplistic, and offensive. Would any of those commenters kindly help us understand whats going on?

Let me end this post with a request: I want all of my readers tovisit the YouCut page, and propose that quantum computing and theoretical computer science research be completely eliminated. Heresmy own CAREER Award; go ahead and cite it by number as a particularly egregious example of government waste.
See, Im hungry for the honor (not to mention the free publicity) of seeing my own favorite research topics attacked on the floor of the House. As we all know, itschilds playto make fun of theoretical computer science: its abstruseness, its obvious irrelevance to national goalshowever infinitesimal the cost is compared to (say) corn subsidies or defense contracts for stuff the military doesnt want, however gargantuan the payoffs of such research have been in the past. So what are Reps. Eric Cantor and Adrian Smith waiting for? I dare them to do it!
Obviously, though, before the House Republicans end American participation in theoretical computer science, theyll want to familiarize themselves with what our tiny little field actually is. To that end, let me humbly offer the links on the sidebar to the right as one place to get started.
Update (12/18):When a friend read this post, his first reaction was that the sarcasm would be lost on most readers. I didnt believe him. See, I exist in a frame of reference wherein, when the mob shows up at your house with torches, you dont argue with them. Instead you say: Oh, so youre the ones here to burn me? Then please, lets get started! Theres plenty of flammable fat around my torso area. Do you prefer rare, medium, or well done? That way, at least history will record you as having gone down with your middle finger proudly aloft, rather than cowering in a corner. However, its now obvious that my friend was right. So, for the literal-minded: I think reacting to our countrys debt crisis by looking for NSF grants to ridicule is a really terrible idea, for reasons that are so self-evident Ill simply provide some blank space for you to fill them in yourself: _______________________________.  And, having devoted my whole career to quantum computing and theoretical computer science research, I dont wish to see them eliminated. On the other hand, if science in United States were going to be dismantled (which, despite the efforts of some politicians, I dont think it will be), then Id consider it an honor for theoretical computer science to be the first in the crosshairs.Alex Halderman, and Indias assault on academic freedom

Five years ago, not long after the founding of Shtetl-Optimized, Iblogged about Alex Halderman: my best friend since seventh grade at Newtown Junior High School, now a famous security researcher and a computer science professor at the University of Michigan, and someone whose exploits seem to be worrying at least one government as much as Julian Assanges.
In the past, Alex has demonstrated thefutility of copy-protection schemesfor music CDs, helped force the state of California to change its standards for electronic voting machines, andled a spectacular attackagainst an Internet voting pilot in Washington DC. But Alexs latest project is probably his most important and politically-riskiest yet. Alex, Hari Prasad of India, and Rop Gonggrijp of the Netherlands demonstratedmassive security problemswith electronic voting machines in India (which are used by about 400 million people in each election, making them the most widely-used voting system on earth). As a result of this work, Hari wasarrested in his homeand jailed by the Indian authorities, who threatened not to release him until he revealed the source of the voting machine that he, Alex, and Rop had analyzed. After finally being released by a sympathetic judge, Hari flew to the United States, where he received theElectronic Frontier Foundations 2010 Pioneer Award. I had the honor of meeting Hari at MIT during his and Alexs subsequent US lecture tour.
But the story continues. Earlier this week, after flying into India to give a talk at the International Conference on Information Systems Security (ICISS2010) in Gandhinagar, Alex and Rop weredetained at the New Delhi airportand threatened with deportation from India. No explanation was given, even though the storybecame front-page news in India. Finally, after refusing to board planes out of New Delhi without being given a reason in writing for their deportation, Alex and Rop were allowed to enter India, butonly on the condition that they did so as tourists.In particular, they were banned from presenting their research on electronic voting machines, and the relevant conference session was cancelled.
To those in the Indian government responsible for the harassment of Alex Halderman andRop Gonggrijp and (more seriously) theimprisonment of Hari Prasad: shame on you! And to Alex, Hari, and Rop: let the well-wishes of this blog be like a small, nerdy wind beneath your wings.My painful lesson for the week

Years ago, Sasha Razborov taught me one of my all-time favorite jokes.
In the 1960s, a man starts handing out leaflets in Moscows Red Square.  Needless to say, hes immediately apprehended by the KGB.  On examining the leaflets, however, the KGB agents discover that theyre just blank pieces of paper.  What is the meaning of this? the agents demand.
What could I write? exclaims the man.  Its so obvious!
The lesson Ive learned this week is that the man was wrong.  In politics, nothing is ever too obvious.Oops, we did it again

Genocide.  Global warming.  Nuclear proliferation.  Sex trafficking in Cambodia.  Famine in sub-Saharan Africa.
If history has taught us anything, its that problems like these tend to sort themselves out if we just ignore them for long enough.  So I get annoyed when guys like Nicholas Kristof keep reminding people about them, thereby diverting attention from real issues like steroid abuse in the NFL.
In his latest piece of offbeat journalism, Kristof pulls out the stops, explicitly comparing humankinds current failure to prevent the Darfur genocide with its failure to prevent earlier genocides:
During the Holocaust, the world looked the other way. Allied leaders turned down repeated pleas to bomb the Nazi extermination camps or the rail lines leading to them, and the slaughter attracted little attention. My newspaper, The New York Times, provided meticulous coverage of World War II, but of 24,000 front-page stories published in that period only six referred on page one directly to the Nazi assault on the Jewish population of Europe. Only afterward did many people mourn the death of Anne Frank, construct Holocaust museums, and vow: Never Again.
The same paralysis occurred as Rwandans were being slaughtered in 1994. Officials from Europe to the US to the UN headquarters all responded by temporizing and then, at most, by holding meetings. The only thing President Clinton did for Rwandan genocide victims was issue a magnificent apology after they were dead.
Much the same has been true of the Western response to the Armenian genocide of 1915, the Cambodian genocide of the 1970s, and the Bosnian massacres of the 1990s. In each case, we have wrung our hands afterward and offered the lame excuse that it all happened too fast, or that we didnt fully comprehend the carnage when it was still under way.
And now  let me guess  the same is happening in Darfur.  Arab Janjaweed militias, supported by the Sudanese government, are systemically massacring, raping, and mutilating non-Arab civilians, while the world watches on in horror but does nothing.  Dude, what a shocker.  I never could have predicted that one.
Think about it.  Sixty years after Auschwitz, obviously the world must have solved this genocide thing.  The US, or EU, or UN, or someone must have set up some sort of special army that, you know, goes in and stops it before it happens.  I mean, anything else would be criminally insane!  It would be like 911 putting people on hold for an hour, or a hospital telling a guy spewing arterial blood to sit in the waiting room and read a magazine.  Right?
Even if not, Ive just spent over 20 minutes of valuable procrastination time writing this post and sending some money.  So regardless of what happens in Darfur, you cant accuse me of having sat in my chair and done nothing.  No, I sat in my chair and did something.Burnt Carmel

Three (pseudo-)random updates:
First, sadly, Ill be going to neither ICS2011 in Beijing nor QIP2011 in Singapore this coming weektoo much travel!  If youre going to either conference and would like to contribute a guest post, please let me know.
Second, I posted a note to the arXiv this week called Impossibility of Succinct Quantum Proofs for Collision-Freeness. Heres the abstract:
We show that any quantum algorithm to decide whether a function  f:[n][n] is a permutation or far from a permutation must make (n1/3/w)  queries to f, even if the algorithm is given a w-qubit quantum witness  in support of f being a permutation.  This implies that there exists an  oracle A such that SZKAQMAA, answering an  eight-year-old open question of the author.  Indeed, we show that  relative to some oracle, SZK is not in the counting class A0PP defined by Vyalyi.  The proof is a fairly simple extension of the quantum lower bound for the collision problem.
This result is neither hard nor surprising, but it does more-or-less solve a problem thats bothered me since grad school (and which I mentioned a couple months ago on this blog) in a ridiculously simple-in-retrospect way, which is either nice or disappointing depending on how you look at it.
Third, some of you might have heard that the Carmel region in Israel recently suffered a terrible forest fire, which destroyed about 30 million trees and killed 44 people, and which required the assistance of many countries to put out. Yesterday, after giving a talk at the Technion in Haifa, I had a chance to tour some of the fire damage. While we were on the hike, a torrential downpour started (which caught me without coat or umbrella)if only the rain had come a few weeks earlier! Anyway, here are some photos:Quantum Complexity Theory student project showcase!

This fall, for the second time, I taught my 6.845 Quantum Complexity Theory graduate course (see here for the lecture notes from the first iteration). Thanks so much to the students for making the course a successI hope they enjoyed it at least half as much as I did!
A central part of 6.845 is the course project, which can be either a literature survey or original research in quantum complexity, and which can be done either individually or in pairs. The majority of the students chose to do original researchwhich surprised me, given how little time was available and how inherently unpredictable theorizing is. Yet all the projects ended up being good, and some ended up being spectacularinitiating new topics, making progress on open problems that Id worked on without success, etc. So with the students kind permission, I decided to pick six outstanding projects for a blog showcase. (Obviously, inclusion in this showcase doesnt preclude the projects being published for real, as I hope and expect they will be!)
Without further ado:
Alessandro Chiesa and Michael Forbes, A Note on QMA With Multiple Provers. Here Ale and Michael improve previous QMA(k) protocols for NP-complete problems due to Aaronson-Beigi-Drucker-Fefferman-Shor and Beigiboosting the success probability by polynomial factors and showing how to verify a much wider range of problems than just 3SAT and 3-Coloring.
Paul Christiano, Toward Quantum Money Relative to a Classical Oracle. In a Complexity09 paper (whose full version, alas, isnt yet finished), I showed that there exists a quantum oracle relative to which quantum money, which anyone can verify but no one can efficiently counterfeit, is possible. Here Paul takes the next step, giving a candidate quantum money scheme that only requires a classical oracle. Unfortunately, theres still a gap in the security proof for this scheme, but Im optimistic that with new ideas the gap can be filled.
Alan Deckelbaum, Quantum Correlated Equilibria in Classical Complete Information Games. In this innovative paper, Alan defines a new concept of quantum correlated equilibria in quantum game theory (see here for the definition of classical correlated equilibria, due to Aumann), and studies its basic properties. In particular, he proves the nontrivial result that there exist equilibria that can be realized using classical correlation, but that cant be realized using pure-state entanglement without one or more players having incentive to deviate. See here for some independent related work by Shengyu Zhang.
Shelby Kimmel, Quantum Adversary (Upper) Bound. (Also on the arXiv; two closely-related arXiv preprints are Speed from Repetition by Shelby, and Super-Polynomial Quantum Speed-ups for Boolean Evaluation Trees with  Hidden Structure by Shelby along with Bohua Zhan and Avinatan Hassidim.) This work has to be read and understood to be believedI too was skeptical at first! Basically, Shelby gives an example of a promise problem with a constant-query quantum algorithmexcept she has no idea what the algorithm is! She can only prove its existence nonconstructively, by first giving a quantum algorithm for a composed version of the problem, and then appealing to Ben Reichardts breakthrough characterization of quantum query complexity in terms of span programs. For a special case of the problem, shes able to give an explicit O(1)-query quantum algorithm by using the Haar wavelet transform.
Andy Lutomirski, On the Query Complexity of Counterfeiting Quantum Money. Independently of Paul Christiano, here Andy proposes a different quantum money scheme using a classical oracle, which again ought to work but is missing only a security proof. Along the way, Andy also proposes a beautiful new query complexity problemthe Separate Components Problemwhich cries out for a quantum lower bound, and might also lead to a classical oracle separation between QMA and QCMA.
Raluca Ada Popa, Witness-Indistinguishability Against Quantum Adversaries. Building on John Watrouss work on quantum zero-knowledge, here Raluca defines the new notion of quantum witness-indistinguishability, and proves many of its basic properties. For example, she shows that if quantum computationally-concealing commitment schemes exist, then all of NP has witness-indistinguishable proofs that are computationally secure against quantum adversaries. As with so much else in cryptography, even just getting the definitions right is a nontrivial affair!Hooray for democracy!

Timeline of computer science

Update (Feb. 14): Thanks so much to the many commenters who offered suggestionsIve implemented a large fraction of them! In addition to many clarifications and corrections of existing entries, Ive added entries for:
Al-Khwarizmi
The slide rule
William Stanley Jevonss logic piano
The Atanasoff-Berry computer
Claude Shannons cryptographic work
Reed-Solomon codes (replacing the Hamming code)
Solomonoff-Kolmogorov-Chaitin complexity
The 1ESS switching system
Semaphores
Viterbis algorithm
Simula 67
Back-propagation (now sharing an entry with the book Perceptrons)
The Solovay-Strassen primality test
Lempel-Ziv compression
PAC-learning
Microsoft Office
Global Positioning System
Slashdot (replacing the entry for the word blog)
CAPTCHAs
BitTorrent
Egypts Twitter revolution
The trouble is that I now have 165 entries, whereas I was told to deliver 150. So, after realizing the infeasibility of simply choosing items for deletion, the MIT150 folks and I reached a decision to set up a voting site for the top 150 entries, which should be available within a couple weeks. In the meantime, if you want to suggest even more entries, you can go ahead and do so  thanks!
This year, MIT is celebrating its 150th anniversaryand as part of the birthday festivities, I somehow got roped into creating a timeline of 150 major events in computer science history (i.e., in the world, not MIT).  I understand that the timeline will go up on a wall somewhereHark!  From the Fortress of STOC

The list of accepted papers for STOC06 is now available. The process of forming this list confirmed my fundamental respect for the scientific peer review process  a process that, in its speed, objectivity, and reliance on reasoned argument, might someday rival such renowned deliberative bodies as the US House of Representatives.
For this experience Im deeply grateful to my 19 fellow program committee members, except of course when they mistakenly disagreed with me. Im especially grateful to Jon Kleinberg, the PC chair, for inviting me to join the committee, even though he only gave me an A- in his COMS681 Analysis of Algorithms class my freshman year at Cornell. Finally I feel like Ive made it.
Id love to tell you all about the heated debates, shifting alliances, and last-minute turnarounds that characterized our committee meeting in the moonlit Fortress of STOC  until we, clad in hooded robes, brandishing our laptops as torches, and calling on NEXP and PSPACE for benediction, sealed the minutes of our deliberations in the sacred Vault of Turing, which no one without a PhD in a technical subject can gaze upon and live, and which can only be opened if all twenty of us come together with twenty golden keys. (We thought of using encryption, but it seemed too complicated and theoretical.)
Yes, Id love to tell you about it, but Id have to kill you afterwards, and then who would be left to read my blog?The students and the TAs are one hand

Last night, the MIT Egyptian Club hosted a Whats Going On In Egypt? event, which included a lecture, a Q&A session with Egyptian students, Egyptian music, and free falafel and baklava. I went, not least because of the falafel.
The announcement that Mubarak was leaving came just a few hours before the event, which was planned as a somber discussion but hastily reconfigured as a celebration. As youd imagine, the mood was ecstatic: some people came draped in Egyptian flags, and there was shouting, embracing, and even blowing of vuvuzelas. Building E51 wasnt quite Tahrir Square, but it was as close as I was going to get.
About 300 people showed up. Id expected an even bigger turnoutbut then again, this was MIT, where the democratic awakening of the Arab world might have to wait if theres a pset due next week. Many of the people who came were speaking Arabic, greeting each other with salaam aleykum. But only a minority were Egyptians: I met jubilant Syrians and Saudi Arabians, and pan-Arab pride was a major theme of the evening.
At one point, I overheard two guys speaking something that sounded like Arabic but wasnt: yesh khasa? eyn? It was Hebrew, which Im proud to say I now speak at almost the level of a 3-year-old. The Israelis were debating whether there was lettuce in the falafel (there wasnt). Joining their conversation, I confirmed that we had come for basically the same reasons: first, to witness (insofar as one could without leaving campus) one of the great revolutions of our time; secondly, the falafel.
Two socialist organizations were selling newspapers, with headlines trumpeting the events in Egypt as the dawn of a long-awaited global workers revolt against capitalism. Buying a $1 newspaper (and politely turning down a subscription), I thought to myself that one has to admire these folks persistence, if not their powers of analysis.
Finally the main event started. An Egyptian student from Harvard presented a slideshow, which summarized both the events of the last three weeks and the outrages of the last 30 years that led to them (poverty, torture, suppression of opposition parties, indefinite detention without charges, arrests for things like having long hair). He said that this uprising wasnt anything like Irans 30 years ago, that it was non-Islamic and led by the pro-democracy Facebook generation. Then there was half an hour for Q&A.
Someone asked about the protesters economic goals. One student panelist started to answer, but then another interjected: Look, the people in Tahrir Square just overthrew the government. I dont think theyve had much time yet to think through their economic plan.
Someone else asked about the role of the US. A student answered that it was complicated, to say the least, and that the Obama administration seemed internally divided.
Perhaps the most interesting question was whether the students themselves planned to return to Egypt, to help build the new democratic society. After a long silence, two students said yes.
No one asked about the future of Egypt/Israel relations, and the subject never came up. But it seemed obvious that, if the students I saw were running Egypt, theyd be too busy modernizing their countrys economy to spend much time denouncing Zionist iniquities.
In general, I agree with Natan Sharansky that, for the US and Israel, it would be incredibly shortsighted to see only danger and instability in the Great Egyptian Twitter Revolt of 2011. The variance is enormous, which makes it almost impossible to estimate the expectation, but theres certainly large support on the positive half of the spectrum.
So, to my Egyptian readers: congratulations, best wishes, mazel tov, and mabrouk from the entire executive staff of Shtetl-Optimized. May your revolution be remembered with those of 1776 and 1989 and not with those of 1917 and 1979.Compressed squeals

My car battery died. My latest research languishes half-written on my hard drive. My receipts for travel reimbursement lie unsubmitted on my floor. My academic future is yet to be decided. So what better way to spend an afternoon than by browsing the SPAM Haiku Archive, and compiling the 62 finest exemplars of the genre into this file?
If youre sitting in a shared office, or are drinking a beverage such as milk, please click at your own risk. The yuks-to-syllable ratio is one of the highest Ive seen in months, and Ive never even tasted the stuff.My TEDxCaltech talk

A month ago, Caltech hosted a daylong event called TEDxCaltech / Feynmans Vision: the Next 50 Years, which was attended by about a thousand people.  Celebrity participants included Stephen Hawking, Carl and Michelle Feynman (Carl told me hes a fan of the bloghi Carl!), and Ondar, a Tuvan throat-singer who pretty much stole the show.
Videos are finally being posted on YouTube; my talk is here.  My goal was to cover the P versus NP question, quantum computing, conceptual issues in quantum mechanics, and Feynmans relation to all three, while also cracking crude masturbation jokes (in a talk like this, one has to bring out the heavy humor cannons), and to finish in 15 minutes.  I dont know how well I succeededbut if I die tomorrow, then at least Stephen Hawking was in the audience when I made my case for P and NP being as big a deal as anything in physics.
Two explanatory comments:

By far my most successful joke was a reference to prime numbers, such as 3, 5, 1  Before the lunch break, the emcee had told everyone to be back by 1:35, which Im sure you nerds will remember since its the first three prime numbers.
Yeah, I know the current upper bound on the matrix multiplication exponent is 2.376, not 2.736!  It was correct on the slides I submitted, but got transposed when the slides were converted into TED format.

If you think my talk stinks, my only defense is that showing up to give it was already an accomplishment: my flight (from Tel Aviv to LA through Newark) was canceled because of a snowstorm, so I arrived at Caltech exhausted and barely conscious, via a 36-hour alternate route through Frankfurt and London.
I have to confess that I was skeptical of this events entire premise.  Richard Feynman was famous for his contempt of pomp and authority; would he really have enjoyed a heavily-scripted day extolling him as a secular saint?  In the end, though, the quality of many of the talks made the event more than worthwhile for me, even without counting Ondars throat-singing as a talk.  I particularly enjoyed the cosmology talk of fellow-blogger Sean Carroll (yo, Sean), the Feynman stories of Lenny Susskind, a demonstration of the mind-blowing WorldWide Telescope by Curtis Wong of Microsoft, and a Who Wants to be a Millionaire? parody skit put on by the three black hole bettors (John Preskill, Kip Thorne, and Hawking, the last of whom wheeled into the auditorium to thunderous applause and the opening fanfare of Thus Spake Zarathustra).  I understand that all the talks will eventually be on YouTube here.
Thanks to Michael Roukes, Mary Sikora, John Preskill, Ann Harvey, and the other organizers for putting this thing together and for inviting me.The Cringeometer

Over at Not Even Wrong, Peter Woit pans Down the Rabbit Hole, a movie about quantum mechanics, paranormal phenomena, and the deep imaginary connection between the two thats setting the pseudoscience world on fire.  (Dont worry  the fire is harmless to those who have balanced their chakras.)
Rabbit Hole is a rehash of the 2004 film What the Bleep Do We Know!?; apparently the new version is longer and includes more crackpots, but the basic howlers are the same.  (Woits summary: entanglement=we are all connected, superposition=anything you  want to be true is true.)
I suppose Ill eventually have to don a fake mustache, clothespin my nose, and go endure this movie, since people often bring it up when I tell them what I do for a living:
ME: so, at least in the black-box model that we can analyze, my result implies that the quantum speedup for breaking cryptographic hash functions is only a polynomial one, as opposed to the exponential speedup of Shors factoring algorithm.
PERSON AT COCKTAIL PARTY: How interesting!  Its just like they were saying in the movie: reality is merely a construct of our minds.
But if I do jump down the Rabbit Hole, my worry is that I wont make it through:
Sir, if you dont stop causing a disturbance, well have to escort you out of the movie theater
BUT YOU CANT USE QUANTUM MECHANICS TO CHANNEL DEAD PEOPLE! ITS A LINEAR THEORY!    POSTSELECTIONS NOT ALLOWED!
Alright, come with us, sir.
LINEAR, I TELL YOU!   AND THE MEASUREMENTS OBEY THE ||2 RULE!   WHAT THE %*#()$*$ DO THESE IDIOTS KNOW!?  IM BEGGING YOU, STOP THE PROJECTOR!
Since this hasnt yet happened, what inspired the present post was not the movie itself, but its title graphic:

Staring at this image, I came up with something that I call the Cringeometer: a quick way for anyone, scientist or not, to predict whether a given popular depiction of science will cause scientists to cringe.  To use the Cringeometer, you dont have to make any decisions about technical accuracy.  All you have to do is look for mathematical symbols such as , , and , and then ask yourself two questions:

Are the symbols used to create an aura of profundity and unintelligibility, without regard for their meaning  more or less like Christmas tree ornaments?
If so, is the effect humorous?

The results should be self-explanatory  but just in case they arent, Ill end with three sample applications of the Cringeometer.

What the Bleep? explodes the Cringeometer even before the movie has started.


NUMB3RS also sets the Cringeometer off, even though it probably does more good than harm for public math appreciation.  This illustrates that the Cringeometer cant predict scientists detailed opinions  only the involuntary, physical reaction of cringing.


The Far Side cartoons never set the Cringeometer off.Discussion questions about Watson

Wouldnt Jeopardy! be better without those stupid buzzers? Even if the contestants just, yknow, took turns? In a game focused solely on question-answering (OK, OK, answer-questioning) rather than buzzing, Watson would still have done amazingly well and reflected credit on its developers, but the man/machine competition would have been much closer and much more interesting to watch. No one needs a repeated demonstration that computers have faster reaction times than humans.
Inspired by the timeline discussion: could something like Watson have been built in, say, 2000? If not, then which developments of the past decade played important roles?
Back when Deep Blue beat Kasparov, IBM made a big to-do about the central role played by its large, specially-designed mainframe with custom chess chipsbut then it wasnt long before programs like Deep Fritz running on desktop PCs produced similar (and today, probably superior) performance. How long before we can expect a computer Jeopardy! champion that fits behind the podium?A Euclidean theater of misery

As winner of the Best Umeshism Contest (remember that?), Peter Brooke earned the right to ask me any question and have me answer it on this blog. Without further ado, here is Peters question:
If it is assumed that God exists, what further, reasonable, conclusions can be made, or is that where logical inquiry must end? Reasonable means in the light and inclusive of present scientific understanding. Defend any assumptions and conclusions you make.
At least Peter was kind enough not to spring Is there a God? on me.  Instead, like a true complexity theorist, he asks what consequences follow if Gods existence is assumed.
Alas, Peter didnt say which God he has in mind.  If it were Allah, or Adonai, or Zeus, or the Flying Spaghetti Monster, then Id simply refer Peter to the requisite book (or in the case of the Spaghetti Monster, website) and be done. As it is, though, I cant assume anything about God, except that

He exists,
He created the universe (if He didnt, then its not He were talking about), and
Hes a He.

(Note for Miss HT Psych: the third assumption is a joke.)
So the only way I see to proceed is to start from known facts, and then ask what sort of God would be compatible with those facts. Though others might make different choices, the following facts seem particularly relevant to me.

About 700,000 children each year die of malaria, which can easily be prevented by such means as mosquito nets and the spraying of DDT. That number will almost certainly grow as global warming increases the mosquitoes range. As with most diseases, praying to God doesnt seem to lower ones susceptibility or improve ones prognosis.


According to our best theories of the physical world, its not enough to talk about the probability of some future event happening. Instead you have to talk about the amplitude, which could be positive, negative, or even complex. To find the probability of a system ending up in some state, first you add the amplitudes for all the ways the system could reach that state. Then you take the absolute value of the sum, and lastly you take the square of the absolute value. For example, if a photon could reach a detector one way with amplitude i/2, and another way with amplitude -i/2, then the probability of it reaching the detector is |i/2 + (-i/2)|2 = 0. In other words, it never reaches the detector, since the two ways it could have reached it interfere destructively and cancel each other out. If we required the amplitudes to be positive or negative reals rather than complex numbers, there would be some subtle differences  for example, we could just square to get probabilities, instead of taking the absolute value first. But in most respects the story would be the same.


From 1942 to 1945, over a million men, women, and children died in one of four extermination complexes at Birkenau, or Auschwitz II (Auschwitz I was the smaller labor camp). Each complex could process about 2,500 prisoners at a time. The prisoners were ordered to strip and leave their belongings in a place where they could find them later. They were then led to an adjacent shower room, containing shower heads that were never connected to any water supply. Once they were locked inside, guards dropped pellets from small openings in the ceiling or walls. The pellets contained Zyklon B, a cyanide-based nerve agent invented in the 1920s by the German Jewish chemist Fritz Haber. The guards then waited for the screams to stop, which took 3-15 minutes, depending on humidity and other factors. Finally, Sonderkommandos (prisoners who were sent to the gas chambers themselves at regular intervals) disposed of the bodies in the adjacent crematoria. With the arrival of 438,000 Hungarian Jews in 1944, the crematoria could no longer keep up, so the bodies were burned in open pits instead. Besides those killed at Auschwitz, another 1.6 million were killed at the four other death camps (Sobibor, Belzec, Treblinka, and Chelmno). In the USSR and Poland, another 1.4 million were shot in front of outdoor pits by the Einsatzgruppen; still others died through forced starvation and other means. Judged on its own terms, the extermination program was a spectacular success: it wiped out at least 2/3 of Russian and European Jewry and changed the demography of Europe. The Americans and British declined numerous opportunities to take in refugees, or to bomb the camps or the train tracks leading to them. Most of the perpetrators, except for a few top ones, returned to civilian life afterward and never faced trial. Millions of people today remain committed to the goal of a Judenrein planet; some, like my friend Mahmoud, are working to acquire nuclear weapons.


According to our best description of space and time, the faster an object is moving relative to you, the shorter that object will look in its direction of motion, and the slower time will pass for it as observed by you. In particular, if the object is moving at a fraction f of the speed of light, then it will contract, and time will slow down for it, by a factor of 1/(1-f2)1/2.  This does not mean, as some people think, that concepts like distance have no observer-independent meaning  only that we were using the wrong definition of distance. In particular, suppose an observer judges two events to happen r light-years apart in space and t years apart in time. Then the interval between the events, defined as r2-t2, is something that all other observers will agree on, even they disagree about r and t themselves. The interval can also be defined as r2+(it)2: in other words, as the squared Euclidean distance in spacetime between the events, provided we reinterpret time as an imaginary coordinate. (This is known as Wick rotation.)


When I was younger, my brother and I went to an orthodontist named Jon Kraut. Dr. Kraut was a jovial guy, who often saw me on weekends when I was home from college even though his office was officially closed. He was also an aviation enthusiast and licensed pilot. About a week ago, Kraut was flying a twin-engine plane to South Carolina with his wife, Robin, their three kids (ages 2, 6, and 8), and the kids babysitter. Kraut reported to the control tower that he was having problems with his left engine. The plane made one approach to the airport and was coming back to try to land again when it crashed short of the runway, killing the whole family along with the babysitter. On the scale of history, this wasnt a remarkable event; I only mention it because I knew and liked some of the victims.

Now, based on the facts above, plus many others I didnt mention, and in the light  of present scientific understanding, what can we say about God, assuming He exists? I think we can say the following.
First, that Hes created Himself a vale of tears, a theater of misery beyond the imagination of any horror writer. That Hes either unaware of all the undeserved suffering Hes wrought, or else unable or unwilling to prevent it. That in times of greatest need, Hes nowhere to be found. That He doesnt answer the prayers of the afflicted, or punish evildoers in any discernible way. That He most likely doesnt intervene in human affairs at all  though I wouldnt want to argue with those who say He does intervene, but only for the worse.
Second, that He apparently prefers complex numbers to real numbers, and the L2 norm to the L1 norm.Science journalism: good and hilarious

On Wednesday, Larry Hardesty of the MIT News Office published a nice article about my work with Alex Arkhipov on the computational complexity of linear optics. Although the titleThe quantum singularitymade me wince a little, I was impressed by the effort Larry put into getting the facts right, and especially laying out the problems that still need to be solved.
Less successful was a story in PC Magazine based on MITs press release, which contained the following sentence (let me know if you can decipher what the author meantI couldnt):
Aaronson says that he and Arkhipov have not successfully proven that  designing a device capable of testing the theory is impossiblewhich is  an important first step, whether to eventually building a quantum  computer, or even just laying the initial framework for using the  microscopic secrets of the universe to let humans better understand the  world that surrounds them.
However, in the competition for Popular Science Article Sentence of the Year, the sentence above will have to contend with a now-classic sentence from the New York Times article about Watson:
More than anything, the contest was a vindication for the academic field  of computer science, which began with great promise in the 1960s  with the vision of creating a thinking machine and which became the  laughingstock of Silicon Valley in the 1980s, when a series of heavily  financed start-up companies went bankrupt.
 
To the NYTs credit, they quickly posted a correction:
An article last  Thursday about the I.B.M. computer Watson  misidentified the academic  field vindicated by Watsons besting of two  human opponents on  Jeopardy! It is artificial intelligence  not  computer science, a  broader field that includes artificial intelligence.The Fable of the Chessmaster

If a layperson asks you what computational complexity is, you could do worse than to tell the following story, which I learned from Steven Rudich.
A man with a flowing gray beard is standing on a street corner, claiming to be God. A bemused crowd gathers around him. Prove it! they taunt.
Well, says the man,I can beat anyone at chess.
A game is duly arranged against Kasparov, who happens to be in town. The man with the gray beard wins.
OK, so youre pretty good at chess, the onlookers concede.  But that still doesnt mean youre God.
O ye of little faith!  As long as I play White, its not just hard to beat me  its mathematically impossible! Play Black over and over, try every possible sequence of moves, and youll see: I always win.
A nerd pipes up. But there are more sequences of moves than there are atoms in the universe! Even supposing you beat us every day for a century, wed still have no idea whether some sequence of moves we hadnt tried yet would lead to your defeat. Well be long dead before every possibility is examined. So unless youre prepared to grant us immortality, theres no way you can possibly convince us!
Most of you know the punchline to this story, but for those who dont: the nerd is wrong. By asking a short sequence of randomly-chosen questions, each a followup to the last, the crowd can quickly convince itself, to as high a confidence as it likes, that the man theyre interrogating knows a winning strategy for White  or else expose his lie if he doesnt. The reason was discovered in 1990 by Lund, Fortnow, Karloff, Nisan, and Shamir, and has less to do with chess than with the zeroes of polynomials over finite fields.
There are two lessons Id like to draw from Rudichs Fable of the Chessmaster.
The first lesson is that computational complexity theory is really, really, really not about computers. Computers play the same role in complexity that clocks, trains, and elevators play in relativity. Theyre a great way to illustrate the point, they were probably essential for discovering the point, but theyre not the point.
The best definition of complexity theory I can think of is that its quantitative theology: the mathematical study of hypothetical superintelligent beings such as gods.  Its concerns include:

If a God or gods existed, how could they reveal themselves to mortals? (IP=PSPACE, or MIP=NEXP in the polytheistic case.)


Which gods are mightier than which other gods? (PNP vs. PP, SZK vs. QMA, BQPNP vs. NPBQP, etc. etc.)


Could a munificent God choose to bestow His omniscience on a mortal?  (EXP vs. P/poly.)


Can oracles be trusted?  (Can oracles be trusted?)

And of course:

Could mortals ever become godlike themselves? (P vs. NP, BQP vs. NP.)

Incidentally, its ironic that some people derisively refer to string theory as recreational mathematical theology. String theory has to earn the status of mathematical theology  right now its merely physics! A good place for string theorists to start their theological training is this recent paper by Denef and Douglas.
So that was my first lesson. The second lesson is that interaction helps: you can get your message across a lot faster if people are continually challenging you. If the gray-bearded man were just lecturing to a passive audience, rather than being grilled by doubters trying to trap him in a contradiction, then it would take longer than the age of the universe for him to prove his unbeatability at chess. Or rather, we theologians conjecture that it would.
Im reminded of the power of interaction every time I give a talk. Despite a certain reputation for cheap yuks, Ive never been a good speaker. Im terrible at explaining anything coherently  that is, in a way that anticipates peoples objections. Fortunately, as long as people interrupt me, it doesnt matter much, since I can easily answer the objections once I know what they are. Indeed, not only do interruptions clue me in on whats bugging people  as in the Fable of the Chessmaster, they also let me prove that I basically know what Im talking about, even if I cant articulate it in the allotted time!
(In my ideal talk, I would begin by saying Thank you. Are there any questions?)
For another example, take the sex columnist Dan Savage. Savage has a philosophy, which consists partly of a refusal to condemn sex acts if they dont harm anyone, and a willingness to condemn them if they do. But if he tried to state his philosophy explicitly, he wouldnt do it justice any more than I just did. So instead he answers questions about used underwear fetishes and masturbating parakeets.
The same goes for comedians, at least the good ones like Jon Stewart. Stewart has an enviably easy job: news happens, he reacts to it. Its like my ideal talk that consists entirely of questions  except that instead of questions, theres Bush warning about human-animal hybrids in his State of the Union address, or Cheney shooting his hunting buddy in the face.
Inspired by such examples, and by my recent positive experience answering Peter Brookes question, Ive decided to open this blog to questions on a regular basis. Email them, post them in the comments section, whatever. I cant promise to take up everything. Try to guess which of the following would have a better chance:
Please discuss the relative merits of conference and journal publication in theoretical computer science.
How could schools be redesigned to improve the sex lives of nerds?Valiants valiance recognized

Update (March 25): I have a new paper called A Linear-Optical Proof that the Permanent is #P-Hard, which is dedicated to Les Valiant on the occasion of his Turing Award. Heres the abstract:
One of the crown jewels of complexity theory is Valiants 1979 theorem  that computing the permanent of an n*n matrix is #P-hard.  Here we show  that, by using the model of linear-optical quantum computingand in  particular, a universality theorem due to Knill, Laflamme, and  Milburnone can give a different and arguably more intuitive proof of  this theorem.

For decades, HarvardsLeslie Valiant has obviously deserved a Turing Awardand today, the ACMmost excellently announced its agreement with the obvious. I have little to add to the prize citation (see also Lances post): from launching new fields whose reach extends beyond theory (PAC-learning),to proving epochal results (#P-completeness of the permanent), to asking hugely influential questions (permanent vs. determinant), Valiant has been a creative powerhouse of theoretical computer science for longer than Ive been alive.
One thing the prize citation doesnt mention is that Valiant is now the third Turing Award winner (after Andy Yao and Len Adleman) to have made a major contribution to quantum computing theory. Valiants 2001 paper Quantum Computers that can be Simulated Classically in Polynomial Time introduced the beautiful computational model that computer scientists now know as matchgates, and that physicists know as noninteracting fermions. It still amazes that Valiant proposed this model for purely mathematical reasonshitting physical relevance straight between the eyes despite (as far as I can tell) not having that target anywhere in his sights.
To put the point in terms that my physicist friends will understand, that Valiant himself would probably dispute, but that I would defend:
Valiants work has shown that, even if our universe hadnt been made of bosons and fermions, theoretical computer scientists would have had compelling reasons of their own to invent those particles or something equivalent to themand furthermore, that at least one theoretical computer scientist would have had the imagination to do so.
Certainly Valiant has had a huge influence on me, both through his work and as someone who made time to talk to me as an obscure grad student a decade ago.  Three of my papersThe Learnability of Quantum States, A Full Characterization of Quantum Advice, and The Computational Complexity of Linear Opticswould collapse entirely without Valiant-laid foundations.
Congratulations, Les!Eigenvalues up the wazoo

An anonymous commenter on my last post asks:
isnt the real problem with complexity theory that the resulting mathematics is usually superficial and shallow?
does this make it less fun to do complexity theory?
are complexity theorists ever saying something deep?
Later, the same commenter writes:
im just curious because I dont really understand how I feel about the issue myself.
maybe we should start with something more basic. can we all agree that logic (i.e. foundations of math) is pretty boring and flavorless?
sure, we all got that little rush when we heard the story of the fall of mathematics in the early 20th century  and then maybe again with the axiom of choice, continuum hypothesis, independence, forcing, and various incompleteness theorems.
but is logic actually fun to do?  on an emotional level, do you achieve understanding, intuition?
Alright, look, anonymous. Youve nailed why I dont work on logic myself  besides not understanding what the big, meaty open problems are. For me, frankly, reading about logic (or recursion theory, or programming language semantics, or distributed computing) has always felt like sipping broth. Sure, it might be delicious broth. In the case of (say) Gdel and Cohens independence results, it might even be the best broth Ive ever tasted. But eventually I hanker for some noodles, some carrots, maybe some complex numbers or a Cauchy-Schwarz inequality. I mean, how long can a person go without bounding anything?
But you see, anonymous, thats what I like about complexity. It packs the same theological punch as logic does, but its got math in it too. And Im not just talking combinatorics and graph theory. Let me put it to you this way:
You like groups?  We got groups.
You like vector spaces?  We got them too.
But what about number theory?  Finite fields?  Fourier transforms?  Continued fractions?  Shor.
Eigenvalues? Chebyshev polynomials? Gaussians? Random walks? Lattices? Convex polytopes? Banach spaces? Metric embeddings? You better believe it.
Or how about this, anonymous: whats your favorite constant? ? e? The golden mean? Maybe 0.288=(1/2)(3/4)(7/8)(15/16)? Becoming a complexity theorist doesnt mean bidding any of them goodbye.
Look, we even got knots, braids, manifolds, unitary representations, varieties, cohomologies, plethysms  alright, maybe not so much of the last few. But if your favorite mathematical object isnt in stock, bring it yourself! Thats the thing about complexity: anything is fair game if it yields a new upper or lower bound. The reason its so hard to prove P!=NP is precisely that a fast SAT algorithm could be hiding anywhere in the math library.
Now let me turn the tables, anonymous.  Can you name a subfield of math that involves so many different kinds of math?Top 150 computer science events to be decided once and for all

Today I break Shtetl-Optimizeds long radio silence with a relatively-exciting announcement: you remember my timeline of computer science history? Well, MIT students Jason Zhu and Ammar Ammar have now kindly created a website where you can vote on each of the entries, as well as new entries suggested by commenters. Its pretty simple: you just register (by entering an email address, username, and password), then upvote each entry you like and downvote each entry you dislike (you can also abstain on any entry).
The voting site arrives just in time for the MIT symposium Computation and the Transformation of Practically Everything, which is happening today and tomorrow.
For reference, here are the 17 new contenders added by popular demand:
150BC Chinese text describes Gaussian elimination
499 Indian mathematicianAryabhata describes the kuttaka algorithm for solving Diophantine equations
1206 al-Jazari builds elaborate water clocks and musical automata
1801 The Jacquard loom uses punched cards to control textile manufacturing
1951 Wilkes, Wheeler, and Gill describe the concept of closed subroutines
1956 Stephen Kleene invents regular expressions
1962 The Atlas computer begins operation in Manchester
1962 Robert Gallager introduces low-density parity check codes
1968 First deployed packet-switching network
1969 Strassens algorithm for fast matrix multiplication
1969 Stephen Wiesner conceives of quantum money and multiplexing
1971 Vapnik and Chervonenkis introduce VC dimension
1982 PostScript
1992 The PCP Theorem
1999 SETI@home
2006 DaVinci surgical robot performs the first unaided operation
2007 Checkers solved
Update: A new feature has been added that lets you rank four randomly-selected entriesclick Done on the bottom of the page to access it.
Update: You can now undo a vote by clicking twice on the same arrow.Jewish inferiority complex in brief, unfamiliar remission

Five days after the Washington Posts Richard Cohen shared his doofus insights about algebra, experts debate whether the Cohen balance of the universe has been restoredThree museum reviews

The American Museum of Natural History has two temporary exhibits that are drawing large crowds. One, Brain: The Inside Story, I can attest is worth a visit the next time youre in NYC. From the New York Times review, Id been worried that the exhibit would be full of la-de-da generalities: how marvelously complicated is the brain! how little we understand about it! But it turned out that was just the review. The exhibit itself does a pretty good job of summarizing whats known about how the brain is organized, how it develops, how various drugs affect it, and more. One highlight for me was a model brain that you can take apart to see how the brain stem, limbic system, and cerebral cortex fit togethersomething that 2D images had never successfully conveyed to me. The other exhibit, The Worlds Largest Dinosaurs, was sold out for the entire day when we tried to go there, so we had to content ourselves with the smaller dinosaurs in the rest of the museum.
The Mark Twain House and Museum in Hartford, Connecticut, should be avoided at all costs. On a recent visit, I and my family of Twain fans were snidely turned away since we hadnt booked a toura requirement buried in the website, which someone googling for the opening hours would almost certainly miss. (This despite the fact that the museum wasnt crowded, and we could have easily joined a tour that was starting as we arrived.) So dont suffer the petty bureaucrats who curate Twains legacy, and treat the town of Hartford the way theyd apparently like you to: as a bathroom stop along the highway from New York to Boston. Twain wouldve been amused. Jeffrey Nichols, Executive Director of the Mark Twain House, left me a personal apology in comments section. I thank him warmly for that, and maybe I will visit again sometimethough it will help if I have some way of knowing I wont just be turned away again! 
The Yad Vashem Holocaust History Museum in Jerusalem has been redesigned since the last time I was there, in 2002. In the old Yad Vashem, you walked around more-or-less randomly looking at the exhibits; in the new one, you proceed in a more linear order (similar to the US Holocaust Memorial Museum in Washington DC): from the rise of Nazism to the first anti-Jewish laws to the ghettoes to the gas chambers and crematoria. The tour ends powerfully, with the Hall of Names (a large circular room with photos of victims and bookshelves of data about 3.8 million of them), followed by a balcony with a spectacular view of West Jerusalemas if the building itself is trying to explain why the country its in exists. I recommend a visit, even if youve been to Yad Vashem before its redesign in 2005. But be careful to check the opening hours: the first time my family and guests tried to visit, the museum was closing, we were turned away, and we ended up going instead to a rest stop full of Elvis statues, where people lined up to use the bathroom and bought Elvis t-shirts. (I thought that belonged in some anthology of Jewish humor.)
Summary: While the worlds museums have a great deal to teach us, they ought to devote more of their attention to the fundamental tasks of being open and letting people in. People turned away from a museum are not just lost customers: theyve often spent hours getting to an unusual place, and may be so annoyed by the wasted trip that they wont want to return, even if they have the opportunity to do so. In two of the cases above, I checked the website beforehand and that didnt  suffice, since the key information I needed wasnt there or was buried. Yeah, I suppose I could call  ahead before every museum visit, but I hate doing that. If someone wants to start CanIActuallyGetInToTheMuseum.com, it could be a fantastic way to not make any money.Mistake of the Week: Empathy=Sympathy

With this post, I begin an occasional series called Mistake of the Week  in which Ill explore obvious howlers that nevertheless show up in many different contexts, are made by people who should know better, and do real damage in the world. If you like, you can retroactively consider my post But What If? to be part of this series.
(Note that, as in This Weeks Finds by John Baez, the word week means there will be at most one installment per week, not at least one.)
This weeks mistake is that empathy  the ability to imagine yourself into someone elses skin  is basically the same as sympathy.  In reality, these concepts are not just subtly different: theyre often directly opposed to each other!
Scam artists, stalkers, abusers, rapists, and serial killers often have tremendous empathy for their victims. If they didnt, they wouldnt know how to scope them out, isolate them, and prey on their vulnerabilities. In The Blank Slate, Steven Pinker discusses research showing that attempts to cure psychopaths by teaching them empathy can make them even more dangerous.
Of course, the world champions of empathy are the guys with dozens of nicks on their bedposts. Its precisely because they understand women that theyre able to exploit them for their own enjoyment.
So that was empathy without sympathy.  What about sympathy without empathy?
I was in Berkeley on 9/11, and many students I talked to in the weeks afterward thought that America basically deserved it. In their analysis, if the US had only ratified the Kyoto Protocol, increased its aid to the developing world, etc., it would have had nothing to fear from al Qaeda. It struck me that these students had considerable sympathy for the 9/11 hijackers, but no empathy for them. They couldnt understand Mohammed Atta on his own terms  only through the lens of their own values and beliefs. (Predictably, Americas homegrown fundamentalists showed much greater empathy. They understood immediately what their Islamic counterparts were up to.)
History is full of bad people who achieved their goals because good people failed to empathize with them. But surely this Mein Kampf must only be bluster, written for internal political purposes. Theres no way Hitler could actually believe what he wrote  hed have to be a lunatic!
Alright, its too easy to bring up examples that everyone already knows about. So heres a different one: have you ever heard of a feminist writer named Valerie Solanas? If you havent (say, because you were born after the 60s, like me), then I invite you to take the following empathy quiz.
In 1967, Solanas wrote a booklet called the S.C.U.M. Manifesto (S.C.U.M. stands for Society for Cutting Up Men). In it, she argues that the human male is a walking abortion and an emotional cripple, and calls for eradicating men and creating an all-female society. Any man who resists is to be killed. Once women rule the world, however, the few remaining men will kindly be permitted to exist out their puny days dropped out on drugs or strutting around in drag or passively watching the high-powered female in action, or else to go off to the nearest friendly suicide center where they will be quietly, quickly, and painlessly gassed to death.
Solanas is vague about what her female utopia will be like; however, it will definitely be groovy. In a female society, she writes, the only Art, the only Culture, will be conceited, kooky, funky females grooving on each other and on everything else in the universe. There will be no need for a government or even a money system. (Hence, no shoe shopping.) Solanas strikes todays reader as perhaps too sanguine about technology: after the male scientists have been murdered, she writes, women will be able to build a fully-automated society within weeks, and eliminate death and disease within years.
(Incidentally, curing death is only one way Solanass utopia could perpetuate itself after the sperm banks have run dry. Another way, which she doesnt discuss, is cloning from stem cells.)
In short, the whole thing reads like Rush Limbaughs fantasy of what feminists believe. Thats why I was surprised to learn that, far from being universally condemned, the S.C.U.M. Manifesto has been praised by feminist leaders such as Ti-Grace Atkinson, assigned in womens studies courses, and distributed by government-run womens shelters in Sweden. Whats going on here? The answer seems to be that, for many readers, Solanass final solution to the male problem is so outlandish that no one, including Solanas herself, could possibly intend it literally. Instead, her proposal must be interpreted as an ironic critique of patriarchal assumptions, or something like that.
Here, then, is my empathy quiz.  Read the S.C.U.M. Manifesto, trying as you do to imagine what it would be like to have written it. Then answer this question: does the author strike you as a clever ironist, or as a sincere psychopath who might actually try to kill someone? You can check your answer here.CS timeline voting: the results are in!

The top ten:
1. Euclids Elements: 116 votes
2. Turings On Computable Numbers: 110 votes
3. Gdels Incompleteness Theorem: 107 votes
4. Gdels P vs. NP Letter to von Neumann: 106 votes
5. George Booles Logic: 88 votes
6. Shors Algorithm: 88 votes
7. Wikipedia: 85 votes
8. Claude Shannons Digital Logic: 82 votes
9. PRIMES in P: 82 votes
10. Cook-Levin Theorem: 80 votes
The rest:
Al-Khwarizmis On the Calculation with Hindu Numerals: 79 votes
Bardeen, Brattain, and Shockley Invent Transistor: 79 votes
Babbages Analytical Engine: 77 votes
Tim Berners-Lee Invents WWW: 75 votes
Fast Fourier Transform: 73 votes
Brin and Page Create Google: 73 votes
von Neumann Architecture: 71 votes
RSA: 70 votes
Hilbert Calls for Mechanization of Mathematical Reasoning: 69 votes
Simplex Algorithm: 69 votes
Claude Shannon Formalizes Cryptography: 68 votes
Dijkstras Algorithm: 68 votes
Gaussian Elimination Described in Ancient China: 67 votes
Quicksort: 65 votes
UNIX and C: 65 votes
Newtons Method: 64 votes
Leibniz Describes Binary Notation, Calculus Ratiocinator: 64 votes
First Program written by Ada Lovelace: 64 votes
Gausss Disquisitiones Arithmeticae: 62 votes
Monte Carlo Method: 62 votes
Bit Coined: 62 votes
TeX Typesetting: 62 votes
Ginsparg Creates arXiv: 61 votes
Kleene Invents Regular Expressions: 61 votes
McCarthy Invents LISP: 59 votes
The Art of Computer Programming: 59 votes
TCP/IP Protocol: 58 votes
Strassens Algorithm: 58 votes
PCP Theorem: 56 votes
Turing Test: 55 votes
Randomized Primality Testing: 55 votes
IP=PSPACE: 55 votes
Scott and Rabins Paper on Nondeterminism: 54 votes
Jacquard Loom: 54 votes
Colossus Begins Operation at Bletchley Park: 53 votes
Integrated Circuit: 53 votes
Chomsky Hierarchy: 52 votes
Pascal Builds Arithmetic Machine: 51 votes
First Genome Sequenced: 51 votes
Reed-Solomon Codes: 50 votes
Time Hierarchy Theorem: 50 votes
ARPAnet: 49 votes
Four Color Map Theorem Proved: 49 votes
Linux: 49 votes
Diophantine Equations Proved Undecidable: 46 votes
Feynman Suggests Quantum Computing: 46 votes
Deep Blue Defeats Kasparov: 46 votes
Solomonoff-Kolmogorov-Chaitin Complexity: 44 votes
Lempel-Ziv Data Compression: 43 votes
GPS: 42 votes
Marian Rejewskis Bombe + Alan Turings Improvements: 41 votes
Diffie-Hellman Public Key Exchange Protocol: 41 votes
Zuses Z1: 40 votes
Viterbi Algorithm: 40 votes
First Email Message: 38 votes
Pseudorandom Generators: 37 votes
Oughtred Invents Slide Rule: 36 votes
FORTRAN: 36 votes
ENIAC: 35 votes
Semaphores: 35 votes
Gottlob Freges Begriffsschrift: 34 votes
Grace Murray Hopper Creates A-O Compiler: 34 votes
Conways Game of Life: 34 votes
Xerox Parcs Alto With First GUI: 33 votes
Kuttaka Algorithm from Ancient India: 32 votes
Scientific Computing During Manhattan Project: 30 votes
Wilkes, Wheeler, and Gill Define Closed Subroutines: 29 votes
Stroustrup creates C++: 28 votes
Zimmermann creates PGP: 28 votes
Dartmouth Conference Popularizes Term AI: 27 votes
Moores Law: 27 votes
Boosting in Machine Learning: 27 votes
Codd Proposes Relational Databases: 26 votes
Ethernet Invented: 26 votes
Valiant Proposes PAC-Learning: 26 votes
Stallman Writes GNU Manifesto: 25 votes
Wiesner Proposes Quantum Money and Multiplexing: 24 votes
Antikythera Mechanism: 23 votes
BitTorrent: 23 votes
Low-Density Parity Check Codes: 23 votes
McCulloch and Pitts A Logical Calculus Immanent in Nervous Activity: 22 votes
Engelbart and English Invent Mouse: 22 votes
Dijkstras Go To Statement Considered Harmful: 22 votes
Back-Propagation: 22 votes
MIT SAGE Creates First Large-Scale Computer Network: 21 votes
Vannevar Bush Creates First Large-Scale Analog Calculator: 20 votes
IBM Introduces Hard Drive: 20 votes
Checkers Solved: 20 votes
First Packet-Switching Network: 20 votes
Atanasoff and Berrys Vaccum-tube Computer: 19 votes
Vannevar Bushs As We May Think: 19 votes
Holleriths Electromechanical Counting Machine: 18 votes
MIT Builds First Time-Sharing System: 18 votes
First Computer Virus: 18 votes
IEEE Floating-Point Standard: 18 votes
IBM PC: 18 votes
Spacewar!, First Computer Game: 17 votes
RISC Architecture: 17 votes
Intels 8086: 17 votes
al-Jazaris Water Clocks and Musical Automata: 17 votes
Edward Lorenz (Re)discovers Chaos Theory: 16 votes
Apollo Guidance Computer: 16 votes
CAPTCHAs: 16 votes
VC Dimension: 16 votes
Macsyma Computer Algebra System: 15 votes
Amazon.com: 15 votes
UNIVAC I: 13 votes
DaVinci Surgical Robot: 13 votes
Mark II Incident Popularizes Word Bug: 12 votes
Weizenbaum Creates ELIZA: 12 votes
ASCII: 11 votes
TI Handheld Calculator: 11 votes
Simula 67: 11 votes
MIT Whirlwind I Displays Graphics: 10 votes
Sketchpad, First CAD Software: 10 votes
NCSA Mosaic: 10 votes
Robert Morris Computer Worm: 9 votes
Pixar Releases Toy Story: 9 votes
Stuxnet Worm: 9 votes
IBM System/360: 8 votes
Mac Hack Chess Program: 7 votes
Microsoft Windows: 7 votes
Sojourner on Mars: 7 votes
BASIC: 6 votes
Apple Macintosh: 6 votes
SETI@home: 6 votes
IBMs Watson Wins At Jeopardy!: 5 votes
Ataris Pong: 4 votes
Atlas Computer in Manchester: 4 votes
Norbert Wiener Founds Cybernetics: 3 votes
First ATM in Tokyo: 3 votes
Youtube Launched: 3 votes
VisiCalc: 2 votes
Jevons Logic Piano: 1 vote
Apple II: 1 vote
Adobe PostScript: 1 vote
SABRE Travel Reservation System: 0 votes
Fischer-Lynch-Paterson Theorem: 0 votes
Facebook, Twitter Use in Egypt Revolution: 0 votes
First Machine Translation Demonstration: -1 vote
Usenet: -1 vote
Akamai: -2 votes
TX-0: -3 votes
CDC 6600: -3 votes
Compact Disc Invented: -3 votes
Aikens Mark I: -4 votes
CM-1 Connection Machine: -4 votes
Whirlwind I Displays Graphics: -5 votes
Floppy Disk Invented: -6 votes
MITS Altair Microcomputer and Microsoft BASIC: -6 votes
Axelrods The Evolution of Cooperation: -7 votes
Microsoft Office: -7 votes
Pentium FDIV Bug: -7 votes
EDSAC: -8 votes
UNIMATE, First Industrial Robot: -9 votes
CLU Programming Language: -9 votes
1ESS Switching System: -11 votes
UNIVAC Predicts Presidential Election: -12 votes
Stanford Arm: -13 votes
2001 A Space Odyssey Introduces HAL: -15 votes
Spam Coined: -16 votes
First Denial-of-Service Attack: -17 votes
Y2K Bug: -18 votes
Facebook Launched: -18 votes
Nintendos Donkey Kong: -19 votes
Robot Coined: -21 votes
CSIRAC -21
Apples iPhone: -21 votes
Slashdot: -27 votes
Godwins Law: -29 votes
Asimovs Three Laws of Robotics: -32 votes
Match.com: -34 votes
de Vaucansons Mechanical Duck: -39 votes
von Kempelens Mechanical Turk: -52 votes
A few comments:

Its (just-barely) conceivable that the results could have been slightly skewed by the quantum- and complexity-loving readership of this blog.
Voters really didnt like fiction/pop-culture references, mechanical contrivances, or anything that sounded like a publicity stunt. They were much keener on conceptual advances (even to the extent of putting Gdel well ahead of the transistor).

I need to catch a plane to give the Buhl Lecture at Carnegie Mellon tomorrow, so Ill leave you to draw any further conclusions.Lord, send no sign

Lars Johansson asks me to comment on a press release entitled Quantum computer solves problem, without running.  Alright, what have we got this time?
CHAMPAIGN, Ill.  By combining quantum computation and quantum interrogation, scientists at the University of Illinois at Urbana-Champaign have found an exotic way of determining an answer to an algorithm  without ever running the algorithm.
Using an optical-based quantum computer, a research team led by physicist Paul Kwiat has presented the first demonstration of counterfactual computation, inferring information about an answer, even though the computer did not run.
Readers, my sole ambition in life, outside the purely personal, is to prevent stuff like this from being spouted.
Im serious. You see, I have no philosophy to offer the world, no unifying theory, no startling new idea. All I have is a long howl of rage, which admittedly tends to take the form of STOC/FOCS papers. But if you read those papers, youll see that almost every one of them was born when I came across some specific claim and said, No. Dammit. No. That cant possibly be right.
Look  if you tell a layperson that a computer has solved a problem without ever having been switched on, then not only have you not explained anything, you havent even asserted anything.  All youve done is pose a question: namely, whats the catch?
In this case, the catch is simple. Say youve got two programs, Dif and Doof, running in the Windows taskbar. Dif is performing some enormous calculation, while Doof (being a Doof) is doing nothing. If Difs calculation returns any answer other than 5, then Dif closes Doof. You come back to your computer and find that Doof is still running. Even though Doof didnt calculate anything, and even though Dif never did anything to Doof, you can immediately conclude  from Doof alone  that the answer you wanted was 5.  Mindblowing!  Unbelievable!
Now let Dif and Doof run, not in different windows, but in different branches of the wavefunction  that is, in quantum superposition. And instead of Dif using an operating system to close Doof, have Difs branch of the wavefunction interfere destructively with Doofs branch, thereby preventing Doofs branch from being observed. Thats the idea of counterfactual quantum computing.
I suppose this is mysterious, in the same way that a dog claiming to hate doggie-treats would be mysterious. In the former case, the mystery is quantum mechanics. In the latter case, the mystery is a talking dog.
Having said that, the original paper by Jozsa and Mitchison is actually lovely and well worth reading. It proves some nontrivial results about limits of counterfactual computing, and it also gives a good introduction to the Vaidman bomb (which I think of as a precursor to Grovers algorithm).
Ill end with the clearest account of counterfactual computing Ive seen, courtesy of one Homer J. Simpson.
Dear Lord, the gods have been good to me. As an offering, I present these milk and cookies. If you wish me to eat them instead, please give me no sign whatsoever.

Thy will be done (munch munch munch).
Update (3/1): Paul Kwiat has written in to the comments section with some helpful clarifications.Better late than never

No, Im not talking about Osama, but about my reactions below to a New Yorker article about quantum computingreactions whose writing was rudely interrupted by last nights news.   Of all the possible times in the past decade to get him, they had to pick one that would overshadow an important Shtetl-Optimized discussion about complexity theory, the Many-Worlds Interpretation, and the popularization of science?  Well, I guess Ill let it slide.

As already discussed on Peter Woits blog, this weeks New Yorker has a long piece about quantum computing by the novelist Rivka Galchen (unfortunately the article is behind a paywall). Most of the article is about the quantum computing pioneer David Deutsch: his genius, his eccentricity, his certainty that parallel universes exist, his insistence on rational explanations for everything, his disdain for intellectual obfuscators (of whom Niels Bohr is a favorite example), his indifference to most of the problems that occupy other quantum computing researchers, the messiness of his house, his reluctance to leave his house, and his love of the TV show House.
Having spent a wonderful, mind-expanding day with Deutsch in 2002at his house in Oxford, of courseI can personally vouch for all of the above (except the part about House, which hadnt yet debuted then). On the one hand, Deutsch is one of the most brilliant conversationalists Ive ever encountered; on the other hand, I was astonished to find myself, as a second-year graduate student, explaining to the father of quantum computing what BQP was. So basically, David Deutsch is someone who merits a New Yorker profile if anyone does. And I was pleased to see Galchen skillfully leveraging Deutschs highly-profilable personality to expose a lay audience (well, OK, a chardonnay-sipping Manhattan socialite audience) to some of the great questions of science and philosophy.
However, reading this article also depressed me, as it dawned on me that the entire thing could have  been written fifteen years ago, with only minor changes to the parts about experiment and zero change to the theoretical parts. I thought: has there really been that little progress in quantum computing theory the past decade and a halfat least progress that a New Yorker reader would care about? Even the sociological observations are dated: Galchen writes about interest in quantum computing as the Oxford flu, rather than the Waterloo flu or Caltech flu that its been since 2000 or so (the latter two capitals of the field arent even mentioned!). A good analogy would be an article about the Web, published today, that described the strange and exciting new world of Netscape, HotBot, and AltaVista.

A more serious issue is that the article falls victim to almost every misleading pop-science trope about quantum computing that some of us have trying to correct for the past decade. For example:
With one millionth of the hardware of an ordinary laptop, a quantum  computer could store as many bits of information as there are particles  in the universe.
Noooooo! Thats only for an extremely strange definition of store
Oxfords eight-qubit quantum computer  has significantly less  computational power than an abacus, but fifty  to a hundred qubits could  make something as powerful as any laptop.
Noooooo!  Fifty to a hundred qubits could maybe replace your laptop, if the only thing you wanted to use your laptop for was simulating a system of fifty to a hundred qubits
In a 1985 paper, Deutsch pointed out that, because Turing was working  with classical physics, his universal computer could imitate only a  subset of possible computers. Turings theory needed to account for  quantum mechanics if its logic was to hold. Deutsch proposed a  universal quantum computer based on quantum physics, which would have  calculating powers that Turings computer (even in theory) could not  simulate.
There are at least three problems here. The first is conflating simulation with efficient simulation. At the risk of going hoarse, a classical Turing machine can calculate absolutely everything that a quantum computer can calculate! It might merely need exponentially more time. Second, no one has proved that a classical Turing machine really does need exponentially more time, i.e., that it cant efficiently simulate a quantum computer. That remains a (deep, plausible, and widely-believed) conjecture, which will take enormous mathematical advances to resolve. And third, Deutschs landmark paper wasnt among the ones to give evidence for that conjecture. The first such evidence only came later, with the work of Bernstein-Vazirani, Simon, and Shor.
To be fair to Galchen, Deutsch himself has often been inaccurate on these points, even though he ought to (and does!) know better. Specifically, he conflates the original Church-Turing Thesis (which isnt challenged in the slightest by quantum computing) with its modern, polynomial-time version (which is), and he neglects to mention the conjectural status of quantum computers speedup. Here are two examples out of many, from The Fabric of Reality:
quantum computers can perform computations of which no (human) mathematician will ever, even in principle, be capable.
if the visible universe were the extent of physical reality, physical reality would not even remotely contain the resources required to factorize such a large number.
Am I just harping over technicalities here? In my view, the issue goes deeper. All of the above oversights can be understood as symptoms of complexophobia: the fear of acknowledging that one is actually making statements about computational complexity theory. Again and again, Ive seen science writers go through strange verbal contortions to avoid the question of how anyone could know that a computation inherently requires a huge amount of timeas if the reader must be prevented, at all costs, from seeing such a claim as anything other than obvious. It can be fascinating to watch, in the same way its fascinating to watch a politician discuss (say) Confederate History Month without mentioning slavery. How long can you poke and prod the P versus NP beast without rousting it?
On the other hand, complexity theory does show up in Galchens article, and in an extremely interesting context: that of explaining where Deutsch got the idea for quantum computing.
According to Deutsch, the insight for [his famous 1985 paper] came from a  conversation in the early eighties with the physicist Charles Bennett,  of I.B.M., about computational-complexity theory, at the time a sexy new  field that investigated the difficulty of a computational task.
Is at the time meant to imply complexity theory is no longer sexy, or merely that  its no longer new? Leaving that aside
Mass, for instance, is a fundamental property, because it remains  the same in any setting; weight is a relative property, because an  objects weight depends on the strength of gravity acting on it  If  computational complexity was like massif it was a relative  propertythen complexity was quite profound; if not, then not.
I was just sounding off, Deutsch said. I said they make too much  of thismeaning complexity theorybecause theres no standard  computer with respect to which you should be calculating the complexity  of the task. Just as an objects weight depends on the force of  gravity in which its measured, the degree of computational complexity  depended on the computer on which it was measured. One could find out  how complex a task was to perform on a particular computer, but that  didnt say how complex a task was fundamentally, in reference to the  universe  Complexity theorists, Deutsch reasoned, were wasting their  time.
The tale continues with Bennett pointing out that the universe itself could be taken to be the fundamental computer, which leads Deutsch to the shocking realization that the complexity theorists werent complete morons. Sure, they had a silly theory where all the answers depended on which computer you chose (which somehow none of them ever noticed), but luckily, it could be fixed by the simple addition of quantum mechanics!
Over the anguished howls of my classical complexity-theorist friends, I should point out that this story isnt completely false. Theres no denying that merging quantum mechanics with theoretical computer science was a major advance in human knowledge, and that the people who first had the idea to merge the two were not computer scientists, but physicists like Deutsch and Feynman (the latters role is completely left out of Galchens story).
But complexity theory wasnt so much a flawed early attempt at quantum computing as an essential prerequisite to it: the thing that made it possible to articulate how quantum computers might differ from classical computers in the first place. Indeed, it occurs to me that Deutsch and Bennetts conversation provides the key to resolving a puzzle discussed in the article:
Quantum computers should have been invented in the  nineteen-thirties, [Deutsch] observed near the end of our conversation. The  stuff that I did in the late nineteen-seventies and early  nineteen-eighties didnt use any innovation that hadnt been known in  the thirties. That is straightforwardly true. Deutsch went on, The  question is why.
I used to go around saying the same thing: someone like John von Neumann could have easily invented quantum computing in the 1930s, had he just put the pieces together! But I now suspect this view is a mistake, the result of projecting whats obvious today onto a much earlier era. For theres at least one essential ingredient for quantum computing that wouldnt enter scientific consciousness until the 1970s or so: complexity theory, and particularly the distinction between polynomial and exponential time.

Over the years, Ive developed what I call the Minus-Sign Test, a reliable way to rate popularizations of quantum mechanics. To pass the Minus-Sign Test, all a popularization needs to do is mention the minus signs: i.e., interference between positive and negative amplitudes, the defining feature of quantum mechanics, the thing that makes it different from classical probability theory, the reason why we cant say Schrdingers cat is really either dead or alive, and we simply dont know which one, the reason why the entangled particles cant have just agreed in advance that one would spin up and the other would spin down. Another name for the Minus-Sign Test is the High-School Student Test, since its the thing that determines whether a bright high-school student, meeting quantum mechanics for the first time through the popularization, would come away thinking of superposition as
(a) one of the coolest discoveries about Nature ever made, or
(b) a synonym used by some famous authority figures for ignorance.
Despite the low bar set by the Minus-Sign Test, Im afraid almost every popular article about quantum mechanics ever written has failed it, the present piece included.

Reading Not Even Wrong, I was surprised at first that the discussion centered around Deutschs argument that quantum computing proves the existence of Many Worlds. (More precisely, Deutschs position is that Many Worlds is an established fact with or without quantum computing, but that for those who are too dense or stubborn to see it, a working quantum computer will be useful for hitting them over the head.)
As others pointed out: yes, the state of the universe as described by quantum mechanics is a vastly, exponentially bigger thing than anything dreamt of in classical physics; and a scalable quantum computer would be dramatic evidence that this exponentiality is really out there, that its not just an artifact of our best current theory. These are not merely truths, but truths worth shouting from the rooftops.
However, theres then the further question of whether its useful to talk about one quantum-mechanical universe as an exponential number of parallel semi-classical universes. After all, to whatever extent the branches of a superposition successfully contribute to a quantum computation, to that extent theyre not so much parallel universes as one giant, fault-tolerantly-encoded, self-interfering blob; and to whatever extent those branches do look like parallel universes, to that extent theyre now forever out of causal contact with each otherthe branches other than our own figuring into our explanations for observable events only in the way that classical counterfactuals figure in.
Anyway, I thought: does anyone still care about these issues? Wasnt every possible argument and counterargument explored to death years ago?
But this reaction just reveals my personal bias. Sometime in graduate school, I realized that I was less interested in winning philosophical debates than in discovering new phenomena for philosophers to debate about. Why brood over the true meaning of (say) Gdels Theorem or the Bell Inequality, when there are probably other such worldview-changing results still to be found, and those results might render the brooding irrelevant anyway? Because of this attitude, I confess to being less interested in whether Many-Worlds is true than in whether its scientifically fruitful. As Peter Shor once memorably put it on this blog: why not be a Many-Worlder on Monday, a Bohmian on Tuesday, and a Copenhagenist on Wednesday, if thats what helps you prove new theorems?
Ironically, this attitude seems to me to mesh well with Deutschs own emphasis on explanation as the goal of science. Ask not whether the parallel universes are really there, or whether they should really be called parallel universesask what explanatory work they do for you! (That is, over and above the explanatory work that QM itself already does for you, assuming you accept it and know how to use it.)
So for me, the single strongest argument in favor of Many-Worlds is what I call the Deutsch argument:
Many-Worlds is scientifically fruitful, because it led David Deutsch to think of quantum computing.
This argument carries considerable force for me. On the other hand, if we accept it, then it seems we should also accept the following argument:
Bohmian mechanics is scientifically fruitful, because it led John Bell to think of the Bell inequality.
Furthermore, consider the following facts:
David Deutsch is a brilliant, iconoclastic theoretical physicist, who thought deeply about quantum foundations at a time when it was unfashionable to do so. His extraordinary (and not wholly-unjustified!) self-confidence in his own powers of reasoning has led to his defending not one but many heterodox ideas.
Is it possible that these facts provide a common explanation for Deutschs certainty about Many-Worlds and his pioneering role in quantum computing, without our needing to invoke the former to explain the latter?

Let me end with a few miscellaneous reactions to Galchens article.
Physics advances by accepting absurdities. Its history is one of unbelievable ideas proving to be true.
Id prefer to say the history of physics is one of a vast number of unbelievable ideas proving to be false, and a few specific unbelievable ideas proving to be trueespecially ideas having to do with the use of negative numbers where one might have thought only positive numbers made sense.
[Robert Schoelkopf and his group at Yale] have configured their computer to run what is known as a Grovers algorithm, one that deals with a four-card-monte type of question: Which hidden card is the queen? Its a sort of Shors algorithm for beginners, something that a small quantum computer can take on.
No, small quantum computers can and have taken on both Shors and  Grovers algorithms, solving tiny instances in each case. The real difference between Shors and Grovers algorithms is one that complexophobia might prevent Galchen from mentioning: Shor gives you a (conjectured) exponential speedup for some highly-specific problems (factoring and discrete log), while Grover gives you merely a quadratic speedup, but for a much wider class of problems.
Look, [Deutsch] went on, I cant stop you from writing an article about a weird English guy who thinks there are parallel universes. But I think that style of thinking is kind of a put-down to the reader. Its almost like saying, If youre not weird in these ways, youve got no hope as a creative thinker. Thats not true. The weirdness is only superficial.
This was my favorite passage in the article.Its all about the hyperfractals

Given my public role as zookeeper, blogger, and jester, you might expect that Id get a lot of strange email: from would-be Ramanujans whove proved or disproved P!=NP, stoners with bold new insights about string theory and consciousness, and complexity groupies who wanna collapse my hierarchy. And youd be right, at least about the first two. But once in a while Im graced with a missive so sublime  so perfect  that theres nothing to do but post it here in its entirety.
RE: HYPERFRACTALS  SHORTCUTS TO QUANTUM COMPUTING
Dont let scientists intimidate you  quantum mechanics is simple. If you can read a hyperfractal, then all you need is common sense and an inquiring mind.
You dont even need any math. Just follow the hyperfractal wiring diagram and figure it out for yourself. Real-life quantum applications are all around you waiting to be solved by you, your friends, relatives and co-workers. Together you can dig into all of the unknowables of academic science and discover that nature is logical and you own the keys to unlocking the future for your own benefit. There are faster, simpler, easier, stronger, cheaper ways to improve the world around you. The hyperfractal is your diagnostic tool for probing the quantum world and making it work  without scientific credentials.
For instance. On Sunday, February 26th the University of Illinois released a press statement concerning A Strange Computer is Both On an Off. Odd concept: The experiment could aid in understanding quantum computing. The bizarre realm of quantum mechanics  the physics theory that stumped even Albert Einstein  tiny things like electrons and packets of light often seen to be in two places at once in total violation of common sense. The newspaper article says that the tightest codes used in banking transactions that would take 100 million serial computers a thousand years to decipher can be solved by quantum computers in minutes. Scientists are hyperventilating and reeling in shock.
Actually, the hidebound computer research scientists are sixteen years overdue for recognizing quantum computing that operates on natures universal hyperfractal architecture. So far, its only encryption and decoding that has them terrified of the change from serial computers to serial/parallel quantum computing. However, to scientists, the scariest of all is the prospect of losing their authoritative power and prestige to the masses  the ordinary people who have common sense, a difficult problem to solve and the means to achieve their goals using their knowledge of nature as it really is  without academic indoctrination programs.
Cleaning up the environment by putting all the oil/coal/gas/nuclear power plants into functional obsolescence will take decades if the government, corporate or academic scientists try to use force to make nature obey orders  but only weeks or months to spread the word that natural energy is free energy and we can harness the unlimited spectrum of energy  its ours. Lets take advantage.
Take charge of your own future  trailblazers can popularize quantum mechanics for the end users  the public. Theres nothing to be afraid of. Nature is a friend  not an adversary. Quantum mechanics is simple. Peer-to-peer groups can debunk the Energy Shortage and demonstrate how ordinary people can overcome stale, restrictive, authoritarian thinking if we put our creative minds to it. Youll need a hyperfractal diagnostic tool  on request Ill send you a hyperfractal wiring diagram. Can we talk about it peer-to-peer?
Carla Hein
President/Coordinator
The DoubleParadox Network, P2P
Ms. Hein actually sent this gem to my colleague Alex Russell, but thoughtfully cced it to me. Of course I wrote back to request the hyperfractal wiring diagram (assuming Im included in her offer). Ill let you know if she sends it.Point/Counterpoint: speaking truth to power vs. speaking power to idiocy

Reflections on a Flamewar (May 14, 2011)
Spoiler: Actual change of opinion below! Youll need to read to the end, though.
Ive learned that the only way to find out who reads this blog is to criticize famous people. For example, when I criticized Ayn Rands Atlas Shrugged, legions of Objectivist readers appeared out of nowhere to hammer me in the comments section, while the left-wing readers were silent. Now that I criticize Chomsky (or originally, mainly just quoted him), Im getting firebombed in the comments section by Chomsky fans, with only a few brave souls showing up from the right flank to offer reinforcements. One would imagine that, on at least one of these topics, more readers must agree with me than are making themselves heard in the commentsbut maybe I just have the rare gift of writing in a way that enrages everyone!
Yesterday, I found myself trying to be extra-nice to people I met, as if to reassure myself that I wasnt the monster some of the Chomskyan commenters portrayed me as. I told myself that, if agreeing with President Obamas decision to target bin Laden made me a barbarian unworthy of civilization, then at least Id have the likes of Salman Rushdie, Christopher Hitchens, and Jon Stewart with me in hellbetter company than Sean Hannity and Rush Limbaugh.
In my view, one of the reasons the discussion was so heated is that two extremely different questions got conflated (leaving aside the third question of whether al Qaeda was really responsible for 9/11, which I find unworthy of discussion).
The first question is whether, as Chomsky suggests, the US government is uncontroversially a vastly worse terrorist organization than al Qaeda, since its caused many more civilian deaths. On this, my opinion is unchanged: the answer is a flat-out no. There is a fundamental reason, having nothing to do with nationalist prejudices, why Osama bin Laden was much more evil than Henry Kissinger, Donald Rumsfeld, Dick Cheney, and George W. Bush combined. The reason is one that Chomsky and his supporters find easy to elide, sincelike many other facts about the actual worldit requires considering hypothetical scenarios.
Give Kissinger, Rumsfeld, Cheney, and Bush magic dials that let them adjust the number of civilian casualties they inflict, consistent with achieving their (partly-justified and largely-foolish) military goals. As odious as those men are, who can deny that they turn the dial to zero? By contrast, give bin Laden a dial that lets him adjust the number of Jews, Americans, and apostates he kills, and what do you think the chances are that he turns it from 3000 up to 300 million, or infinity? But if, implausibly (in my view), one maintains that bin Laden would have preferred not to kill any civilians, provided that he could magically attain his goal of imposing Sharia law on the world, then the crux of the matter is simply that I dont want to live under Sharia law: I even prefer living in George W. Bushs America. (One obvious reason these hypotheticals matter is that, once the Jihadists get access to nuclear weapons, the dial is no longer particularly hypothetical at all.)
So much for the first question. The second, and to me much more worthwhile question, is whether the US should have made a more strenuous effort to capture bin Laden alive and try him, rather than executing him on the spot. (Of course, part of the problem is that we dont really understand how strenuous of an effort the SEAL team did make. However, lets suppose, for the sake of an interesting question, that it wasnt very strenuous.) Its on this second question that my views have changed.
My original reasoning was as follows: the purpose of a trial is to bring facts to light, but this is an unusual case in which the entire world has known the facts for a decade (and the defendant agrees to the facts, having openly declared war on the West). Its almost impossible to conceive of a person who would be convinced after a trial of bin Ladens guilt, who wasnt already convinced of it now. The people who need convincingsuch as Jihadists and 9/11 conspiracy theoristsare people who can never be convinced, for fundamental reasons. Therefore, while a trial would have been fineif bin Laden had come out with his hands up, or (lets suppose) turned himself in, at any point during the last decadea bullet to the head was fine as well.
To put it differently: trials struck me as merely a means to the end of justice, just as college courses are merely a means to the end of learnin. Now personally, I always favor letting a student skip a course if its obvious that the student already knows the materialeven if that means bending university rules. It stands to reason, then, that I should similarly favor letting a government skip a trial if the verdict is already obvious to the entire sane world.
Many commenters made arguments against this viewpointoften phrased in terms of bin Ladens rightsthat did nothing to persuade me. The one argument that did ultimately persuade me was that, at least for some people, trials are not just a means to an end: theyre an end in themselves, a moving demonstration of the superiority of our system to the Nazis and the Jihadists. Heres how a reader named Steve E put it, in a personal email that hes kindly allowed me to quote:
I wonder what you think of the proposition that the Jews of Norwich  [the victims of the first blood libel, in 1190] would have preferred a show trial to the mob justice they received. Im  not sure of this proposition, because I could also see a show trial  being somehow worse, but on the other hand wouldnt we all prefer a real  trial to a show trial and a show trial to no trial when our lives hang  in the balance? Trials perform a nontrivial service even if they  dont convince anyone who is not already convinced, just as human babies  perform a nontrivial service even if they have no use, and particle  colliders perform a nontrivial service even if they dont defend our  nation. Trials make our nation worth defending; they, like human babies,  have intrinsic value not just for their potential. In this case, it may  be true that giving bin Laden a trial would have been a bonus rather  than a requirement, but wouldnt you agree that itd have been a bonus?  Trying Osama bin Laden would have shown our moral high ground, maybe not  to some who cant be convinced of Americas goodness, but it would have  done so for me! (Im very proud that Israel tried Eichmann, not just  because it showed the world about the Holocaust, but also because it  showed me about Israels character. Let people react to the trial as  they may. That trial had meaning to me.)
And so Ive decided that, while assassinating bin Laden was vastly better than leaving him at large, and I applaud the success of the operation, it wouldve been even better if hed been captured alive and triedeven if thats not what bin Laden himself wanted. For the sake of people like Steve E.

Noam Chomsky:
Its increasingly clear that the operation was a planned assassination,  multiply violating elementary norms of international law. There appears  to have been no attempt to apprehend the unarmed victim, as presumably  could have been done by 80 commandos facing virtually no  oppositionexcept, they claim, from his wife, who lunged towards them.  In societies that profess some respect for law, suspects are apprehended  and brought to fair trial. I stress suspects. In April 2002, the head  of the FBI, Robert Mueller, informed the press that after the most intensive investigation in history, the FBI could say no more than that it believed that the plot was hatched in Afghanistan, though implemented in the UAE and  Germany. What they only believed in April 2002, they obviously didnt  know 8 months earlier, when Washington dismissed tentative offers by the  Taliban (how serious, we do not know, because they were instantly  dismissed) to extradite bin Laden if they were presented with  evidencewhich, as we soon learned, Washington didnt have. Thus Obama  was simply lying when he said, in his White House statement, that we  quickly learned that the 9/11 attacks were carried out by al Qaeda.
Nothing serious has been provided since. There is much talk of bin  Ladens confession, but that is rather like my confession that I won  the Boston Marathon. He boasted of what he regarded as a great  achievement.
There is also much media discussion of Washingtons anger that Pakistan  didnt turn over bin Laden, though surely elements of the military and  security forces were aware of his presence in Abbottabad. Less is said  about Pakistani anger that the U.S. invaded their territory to carry out a political assassination
We might ask ourselves how we would be reacting if Iraqi commandos  landed at George W. Bushs compound, assassinated him, and dumped his  body in the Atlantic. Uncontroversially, his crimes vastly exceed bin  Ladens, and he is not a suspect but uncontroversially the decider  who gave the orders to commit the supreme international crime differing  only from other war crimes in that it contains within itself the  accumulated evil of the whole (quoting the Nuremberg Tribunal) for  which Nazi criminals were hanged
There is much more to say, but even the most obvious and elementary facts should provide us with a good deal to think about.
President Obama:
Shortly after I got into office, I brought [CIA  director] Leon Panetta privately into the Oval Office and I said to him,  We need to redouble our efforts in hunting bin Laden down. And I want  us to start putting more resources, more focus, and more urgency into  that mission 

We had multiple meetings in the Situation Room in  which we would map out  and we would actually have a model of the  compound and discuss how this operation might proceed, and what various  options there were because there was more than one way in which we might  go about this.
And in some ways sending in choppers and  actually puttin our guys on the ground entailed some greater risks than  some other options. I thought it was important, though, for us to be  able to say that wed definitely got the guy. We thought that it was  important for us to be able to exploit potential information that was on  the ground in the compound if it did turn out to be him.
We  thought that it was important for us not only to protect the lives of  our guys, but also to try to minimize collateral damage in the region  because this was in a residential neighborhood 

You know one of the things that weve done here is to build a team  that is collegial and where everybody speaks their mind  And so the fact that there were some  who voiced doubts about this approach was invaluable, because it meant  the plan was sharper, it meant that we had thought through all of our  options, it meant that when I finally did make the decision, I was  making it based on the very best information 
As nervous as I was about this whole process, the one thing I didnt  lose sleep over was the possibility of taking bin Laden out. Justice was  done. And I think that anyone who would question that the perpetrator  of mass murder on American soil didnt deserve what he got needs to have  their head examined.

Update (May 11): Commenter B makes a wonderful point. If Osamas statements arent enough to convince Chomsky that al Qaeda was behind the 9/11 attacks, then why are Obamas statements enough to convince Chomsky that the US was behind the raid in Abbottabad?
Update (May 12): Many of you have asked me to get back to quantum complexity theory, or some other topic that we know more about (or rather: that other people know less about). Dont worry, BQPs a-comin! But in the meantime, I wanted to thank all of you (especially the ones who disagreed with me) for a genuinely interesting discussion. I havent been forced to think so much about the philosophical underpinnings of vigilante justice since watching the Batman and Spiderman moviesToday I am a mathematician

I have made my first (and, I expect, last) contribution to the Sarong Theorem Archive, the only public repository of images of people proving theorems  while  wearing sarongs.  I encourage all of you to contribute as well to this important archive.  Thanks to Daniel Gottesman for the photography (and the use of his office), Karp and Lipton for the theorem, and Kelly Itakura for the sarong.Quantum-Effect-Demonstrating Beef

Update (May 25): See my Q&A about D-Waves new announcement at Forbes.com.
Update (May 26): See also this very helpful Quora post by Dave Bacon, who says mostly the same things I did (though it always sounds better when he says it!)
Clearly, there hasnt been enough controversy on Shtetl-Optimized this past week. But I have just the thing to fix that: a new D-Wave post!
For three days, people have been sending me the news by land, sea, and air that D-Wave just published a paper in Nature, describing evidence for quantum annealing behavior in a system of eight superconducting flux qubits. The paper itself is behind a paywall, but the more detailed Electronic Supplementary Material is available for free (see also D-Waves blog post). As usual, my readers apparently expect me to render an instantaneous opinion.
But for the first time in the history of major D-Wave announcements, Im unable to do so. For D-Wave is finally doing the very thing that I and others have been begging them to do for years: that is, directly addressing the question of whether their systems actually exploit quantum effects, or just perform classical simulated annealing. In the new work, they apply an annealing operation to eight coupled qubits arranged in a 1D chain, then plot the probability of a particular basis state as a function of time, by running the experiment over and over and stopping it at various intermediate points. They then look at the dependence of the probability-versus-time curve on a third parameter, the temperature, and claim that they can explain the curves temperature dependence by a numerical simulation that assumes quantum mechanics, but not by one that assumes classical simulated annealing.
To be clear, an eight-qubit spin chain with a quantum-mechanical temperature dependence is still a very long way from anything commercially useful (and its notable that, now that D-Wave has happily joined the ruling-out-the-null-hypothesis club, were down from 128 qubits back to 8). This paper also makes no claims to demonstrate entanglement, which is almost certainly necessary for any interesting quantum speedup, and which has been verified in other superconducting qubit experiments (e.g., the Schoelkopf Labs at Yale), but as far as I know still not in D-Waves. Even so, after four years of the quantum computing community being told to review a restaurant based solely on its ice water and table settings, Im delighted that D-Wave has finally brought an appetizer. Expert readers whove actually tasted the appetizer are urged, in the strongest terms, to share their analysis in the comments section. Im looking forward to our least-uninteresting D-Wave discussion ever.
But first, let me anticipate the question that at least one commenter will ask (I mean you, rrtucci). No, I dont have any regrets about pouring cold water on D-Waves previous announcements, because as far as I can tell, I was right! For years, D-Wave trumpeted quantum computing demonstrations that didnt demonstrate anything of the kind; tried the research communitys patience with hype and irrelevant side claims; and persistently dodged the central question of how it knew it was doing quantum computing rather than classical simulated annealing. So when people asked me about it, thats exactly what I told them. Now, whether because it took the skeptics criticisms to heart, or for whatever other reasons, D-Wave has done a real experiment that deserves the careful scrutiny it will receive. I just call the shots as theyre fired.
As some of you might be aware, Im a theoretical computer scientist, not a physicist (much less an experimentalist). So in previous posts, the only  reason I even presumed to comment on experimental matters is that D-Wave made  it easy for me! My expert analysis mostly just consisted of  pointing out, over and over, that D-Wave hadnt yet brought the QEDB (Quantum-Effect-Demonstrating Beef)and that, until they did so, there seemed to be little reason even to discuss the other issues that D-Waves marketing materials and the press were both spending 95% of their time on. Now that a slice of QEDB (or something that looks like one, anyway) is on the table, I think theres at least as much need as ever for critical evaluation of D-Waves claims from the quantum computing research community, but I no longer see Shtetl-Optimized filling that need. So I hereby announce my retirement as Chief D-Wave Skeptic, a job that I never wanted in the first place. New applicants for this rewarding position are urged to apply in the comments section; background in experimental physics a must.Alan Turing, moralist

Strong AI. The Turing Test. The Chinese room. As Im sure youll agree, not nearly enough has been written about these topics. So when an anonymous commenter told me theres a new polemic arguing that computers will never think  and that this polemic, by one Mark Halpern, is being blogged about in a positive way (getting reviews like thoughtful and fascinating)  of course I had to read it immediately.
Halperns thesis, to oversimplify a bit, is that artificial intelligence research is a pile of shit. Like the fabled restaurant patron who complains that the food is terrible and the portions are too small, Halpern both denigrates a half-century of academic computer science for not producing a machine that can pass the Turing Test, and argues that, even if a machine did pass the Test, it wouldnt really be thinking.  After all, its just a machine!
(For readers with social lives: the Turing Test, introduced by Alan Turing in one of the most famous philosophy papers ever written, is a game where you type back and forth with an unknown entity in another room, and then have to decide whether youre talking to a human or a machine.  The details are less important than most people make them out to be.  Turing says that the question Can machines think? is too meaningless to deserve discussion, and proposes that we instead ask whether a machine can be built that cant be distinguished from human via a test such as his.)
If you havent read Halperns essay, the following excerpts should help you simulate a person who has.
Turing does not argue for the premise that the ability to convince an unspecified number of observers, of unspecified qualifications, for some unspecified length of time, and on an unspecified number of occasions, would justify the conclusion that the computer was thinking  he simply asserts it.
A conversation may allow us to judge the quality or depth of anothers thought, but not whether he is a thinking being at all; his membership in the species Homo sapiens settles that question  or rather, prevents it from even arising.
the relationship of the AI community to Turing is much like that of adolescents to their parents: abject dependence alternating with embarrassed repudiation. For AI workers, to be able to present themselves as Turings Men is invaluable; his status is that of a von Neumann, Fermi, or Gell-Mann, just one step below that of immortals like Newton and Einstein. He is the one undoubted genius whose name is associated with the AI project  When members of the AI community need some illustrious forebear to lend dignity to their position, Turings name is regularly invoked, and his paper referred to as if holy writ. But when the specifics of that paper are brought up, and when critics ask why the Test has not yet been successfully performed, he is brushed aside as an early and rather unsophisticated enthusiast.
Apart from [the Turing test], no one has proposed any compelling alternative for judging the success or failure of AI, leaving the field in a state of utter confusion.
[W]hen a machine does something intelligent, it is because some extraordinarily brilliant person or persons, sometime in the past, found a way to preserve some fragment of intelligent action in the form of an artifact. Computers are general-purpose algorithm executors, and their apparent intelligent activity is simply an illusion suffered by those who do not fully appreciate the way in which algorithms capture and preserve not intelligence itself but the fruits of intelligence.
Of course, Halpern never asks whether the brains apparent intelligence is merely a preserved fragment of its billion-year evolutionary past. That would be ridiculous!  Indeed, Halpern seems to think that if human intelligence is open to question, then the Turing Test is meaningless:
One AI champion, Yorick Wilks  has questioned how we can even be sure that other humans think, and suggests that something like the Test is what we actually, if unconsciously, employ to reassure ourselves that they do. Wilks  offers us here a reductio ad absurdum: the Turing Test asks us to evaluate an unknown entity by comparing its performance, at least implicitly, with that of a known quantity, a human being. But if Wilks is to be believed, we have unknowns on both sides of the comparison; with what do we compare a human being to learn if he thinks?
I think Halpern is simply mistaken here.  The correct analogy is not between computers and humans; its between computers and humans other than oneself.  For example, I have no direct evidence that the commenters on this blog think.  I assume they think, since theyre so darned witty and insightful, and my own experience leads me to believe that that requires thinking.  So why should this conclusion change if it turns out that, say, Greg Kuperberg is a robot (the KuperBlogPoster3000)?
Turing himself put the point as well as anyone:
According to the most extreme form of [the argument from consciousness] the only way by which one could be sure that a machine thinks is to be the machine and to feel oneself thinking. One could then describe these feelings to the world, but of course no one would be justified in taking any notice. Likewise according to this view the only way to know that a man thinks is to be that particular man. It is in fact the solipsist point of view. It may be the most logical view to hold but it makes communication of ideas difficult. A is liable to believe A thinks but B does not whilst B believes B thinks but A does not. Instead of arguing continually over this point it is usual to have the polite convention that everyone thinks.
Theres a story that A. Lawrence Lowell, the president of Harvard in the 1920s, wanted to impose a Jew quota because Jews cheat.  When someone pointed out that non-Jews also cheat, Lowell replied: Youre changing the subject.  Were talking about Jews.  Likewise, when one asks the strong-AI skeptic how a grayish-white clump of meat can think, the response often boils down to: Youre changing the subject.  Were talking about computers.
And this leads to my central thesis: that the Turing Test isnt really about computers or consciousness or AI.  Take away the futuristic trappings, and what youre left with is a moral exhortation  a plea to judge others, not by their inner essences (which we can never presume to know), but by their relevant observed behavior.
It doesnt take a hermeneutic acrobat to tease this out of Turings text.  Consider the following passages:
The inability to enjoy strawberries and cream         may have struck the reader as frivolous. Possibly a machine might be made         to enjoy this delicious dish, but any attempt to make one do so would         be idiotic. What is important about this disability is that it contributes         to some of the other disabilities, e.g. to the difficulty of         the same kind of friendliness occurring between         man and machine as between white man and white man, or between black man         and black man.
It will not be possible to apply exactly the same teaching process to         the machine as to a normal child. It will not, for instance, be provided         with legs, so that it could not be asked to go out and fill the coal scuttle.         Possibly it might not have eyes. But however well these deficiencies might         be overcome by clever engineering, one could not send the creature to         school with out the other children making excessive fun of it.
If you want to know why Turing is such a hero of mine (besides his invention of the Turing machine, his role in winning World War II, and so on), the second passage above contains the answer.  Let others debate whether a robotic child would have qualia or aboutness  Turing is worried that the other kids would make fun of it at school.
Look, once you adopt the moral stance, this whole could-a-computer-think business is really not complicated.  Let me lay it out for you, in convenient question-and-answer format.
Q. If a computer passed the Turing Test, would we be obligated to regard it as conscious?
A. Yes.
Q. But how would we know it was conscious?
A. How do I know youre conscious?
Q. But how could a bunch of transistors be conscious?
A. How could a bunch of neurons be conscious?
Q. Why do you always answer a question with a question?
A. Why shouldnt I?
Q. So youre saying theres no mystery about consciousness?
A. No, just that the mystery seems no different in the one case than the other.
Q. But you cant just evade a mystery by pointing to something else thats equally mysterious!
A. Clearly youre not a theoretical computer scientist.
As most of you know, in 1952  a decade after his contributions to breaking the U-boat Enigma saved the Battle of the Atlantic  Turing was convicted of gross homosexual indecency, stripped of his security clearance, and forced to take estrogen treatments that caused him to grow breasts (it was thought, paradoxically, that this would cure him of homosexuality).  Two years later, at age 41, the founder of computer science killed himself by biting the infamous cyanide-laced apple.
I agree with what I take to be Turings basic moral principle: that we should judge others by their relevant words and actions, not by what they really are (as if the latter were knowable to us).  But I fear that, like Turing, I dont have any argument for this principle that isnt ultimately circular.  All I can do is assert it, and assert it, and assert it.Quin puede nombrar el mayor nmero?

Jorge Alonso has kindly translated my essay Who Can Name The Bigger Number? into Spanish.  You can read his translation here, or my original English version here.
Even though I wrote this piece seven years ago, as an undergraduate at Cornell, I still get more mail about it than about anything else Ive written.  Which depresses me, because I know I couldnt write it today.  Id be too embarrassed to trot out the Ackermann and Busy Beaver numbers as if they were the awesomest things ever.  This is standard, decades-old material!  Doesnt everyone know it by now?
They dont, of course.  But the price I paid for learning enough to do science is that I can no longer work up childlike wonder over, say, humankinds inability to pin down BB(7).  The things that are new to me are too hard to explain to a popular audience, and the things that are easy to explain are no longer new to me.  How I long for the power to return, at will, to my intellectual adolescence.The Territory Around BQP

A commenter named Blake Stacey pointed me to a talk entitled The Territory Around BQP: Results and Open Problems, which was given at the Perimeter Institute this past Friday, and which Id had no idea was available on streaming video. This talk was part of a fantastic workshop called Conceptual Foundations and Foils for Quantum Information Processing, which was about ways of changing the laws of quantum mechanics to get alternative theories that still make some sort of sense, and that might shed new light on the tried-and-true original. In this particular talk, the speaker discusses a large number of ways to make the complexity class BQP (Bounded-Error Quantum Polynomial-Time) slightly bigger or smaller. Im embarrassed to admit that I watched this particular talk transfixed to the computer screen: I genuinely couldnt predict how BQP was going to get mutilated next, and I looked forward to finding out.Projects aplenty

When ambitious students ask me for projects to work on, I usually kick myself for not having a list of favorite open problems that I can simply point them to. Sure, half a year ago I listed some of my favorite open problems in quantum complexity theorybut what can I give the majority of students who are more classically-inclined? The following haphazard list is my attempt at an answer. Some of the problems are open-ended or ill-defined, some are actually implementation projects, some are no doubt trivial or solved, others are no doubt hopelessly difficult, and a couple are shamelessly filched from MathOverflow or CS Theory StackExchange. Almost all are missing motivation and context. Without further apologies
1. Create a zoo of cryptographic primitives (one-way functions, one-way permutations, pseudorandom generators, etc.) and the relationships between them, paralleling the Complexity Zoo.
2. Build a public library of 3SAT instances, with as few variables and clauses as possible, that would have noteworthy consequences if solved. (For example, instances encoding the RSA factoring challenges.) Investigate the performance of the best current SAT-solvers on this library.
3. Find an explicit n (the smaller the better) for which you can prove that the value of BB(n) (the nth Busy Beaver number) is independent of ZF set theory. More generally, find a way to enumerate the proofs of ZF set theory, which requires a shorter or simpler program than the obvious proof-enumerating program.
4. Call a cellular automaton physically universal if any polynomial-time transformation on any subset of n bits can be implemented by choosing a suitable initial configuration of the surrounding poly(n) bits. (Note that my definition is potentially more inclusive than Janzings.) Find interesting examples of cellular automata that you can prove are or are not physically universal.
5. Prove explicit lower bounds on the number of arithmetic operations needed to compute the permanents and determinants of 33 and 44 matrices. In the 44 case, can you obtain a separation between the permanent and the determinant?
6. Are there proofs with (say) n2 symbols, in a proof system of your choice, for which (a) there exist proofs of the same statements with n symbols, but (b) finding the shorter proofs is computationally intractable?
7. Call a set of k-by-k unitary matrices U1,,Uk linear-optics universal, if for any n, any n-by-n unitary matrix U, and any >0, its possible to approximate U to within error  by applying some finite set of Uis to various ordered lists of k of the n indices. Give necessary and sufficient conditions for a set of unitaries to be linear-optics universal.
8. How hard is it to sample a (nearly) uniformly-random n-by-n invertible matrix over GF(2)? Clearly it can be done in matrix multiplication time, but can we give evidence that it cant be done in less?
9. Is collinearity logic in NP? In other words: given a collection of n points in the Euclidean plane, together with a list of triples of points that should be collinear and a list of triples that should not be collinear, is the problem of deciding whether the requirements are consistent in NP? (It follows from known results about the existential theory of reals that this problem is in PSPACE; I thank Peter Shor for that observation.)
10. Given a weighted bipartite graph, is there a polynomial-time algorithm to decide whether or not there are two perfect matchings with the same weight?
11. Give nontrivial examples of problems that are complete for PromiseBPP. Could approximating the permanent of a nonnegative matrix be an example of such a problem? Alternatively, can that problem be solved in randomized NC?
12. Given an explicit description of a Boolean circuit C of size (say) n3, and promised there exists a circuit of size (say) n2 that computes almost the same function as C, how hard is it to find the smaller approximating circuit? Can we give cryptographic evidence that this problem is hard? What additional assumptions about C make the problem easy (ideally, easy for reasons that require looking at the structure of C, rather than just treating it as a black box)?
13. What is the randomized one-way communication complexity of the Group Membership Problem (in which, given a finite group G known to both players, Alice knows a subgroup HG, Bob knows an element x of G, and Alices goal is to send Bob a short message that enables him to decide whether x is in H)?
14. Study the lower bounds on Manifestly-Orthogonal Tree Size in my paper Multilinear Formulas and Skepticism of Quantum Computing. In particular, do these lower bounds evade the Razborov-Rudich natural proofs barrier?
15. Prove an oracle separation between BPP and PBPNC. (Likewise, prove an oracle separation between BQP and BPPBQNC.)
16. Are there plausible pseudorandom functions computable by ACC0 circuits?
17. Prove a strong anti-concentration theorem for the permanent of a matrix of iid Gaussian entries.
18. Given the truth table of a Boolean function f:{0,1}n*{0,1}m{0,1}, are there efficient algorithms to compute (or approximate) the randomized and quantum one-way communication complexities of f?
19. Classify the possible sets of classical reversible gates acting on bits, by the sets of transformations that they generate. (I.e., what is the analogue of Posts lattice in this setting?) As a warmup, classify the possible sets of classical reversible gates that act linearly over GF(2) (like the NOT and CNOT gates).
20. Do there exist probability distributions D1,D2 over n-bit strings such that (D12+D22)/2 (an equal mixture of two independent samples from D1 and two independent samples from D2) is efficiently samplable, even though D1 and D2 themselves are not efficiently samplable? (This is closely-related to a beautiful question posed by Daniel Roy, of whether the de Finetti Theorem has a polynomial-time analogue.)
21. Is BB(n) (the nth Busy Beaver number) odd infinitely often? Is it decidable whether BB(n) is odd?
22. Show there are tasks that Turing machines with (d+1)-dimensional tapes can solve polynomially faster than Turing machines with d-dimensional tapes.
23. Extend my results from A Counterexample to the Generalized Linial-Nisan Conjecture to show that 2PA  2PA with probability 1, relative to a random oracle A.
24. Given a function f:[N][N], which is promised to be either one-to-one or two-to-one, whats the optimal MA-protocol for proving f is one-to-one (i.e., whats the optimal tradeoff between the size of the witness and the number of queries needed to verify it)?A personal post

Heres an interview with me by math grad student Samuel Hansen, as part of a podcast he runs called Strongly Connected Components. (Also check out the interviews with Steven Rudich, Steven Rudich a second time, Lance Fortnow, Doron Zeilberger, and your other favorite stars of the nerdosphere!) In the interview, I talk about my passion for baseball stats, what you dont know about llama-breeding, the use of color in Matisses later works  oh all right, its mostly about quantum computing and P vs. NP.
Heres a story I told for an event called Story Collider, which was back-to-back with a superb production of Breaking the Code (Hugh Whitemores acclaimed play about the life of Alan Turing) in Cambridges Central Square Theater. I was honored to serve as a scientific consultant to the Breaking the Code production, and to do audience Q&A before and after a couple performances. In the Story Collider, I talk about the Turing phase I went through as a teenager and Alan T.s impact on my life.
(Note: For the past couple years, Ive avoided talking much about my personal   life on this blog, since I pride myself on being someone who learns from experience and  adjusts his behavior accordingly. But two months ago, something truly  happy occurred in my life, and if you listen to the end of the Story Collider, youll find out what it was)
One last personal note: Im at the Federated Computing Research Conference in San Jose all week. If you read Shtetl-Optimized, are here at FCRC, see me, and wouldnt do so otherwise, come and say hi!And the CMB spoke unto WMAP

On Thursday afternoon, the WMAP team released its latest data about the origin and fate of the universe.  For readers with social lives, WMAP is the Wilkinson Microwave Anisotropy Probe, which was launched in 2001 and cost $150 million.  While thats less than a third the cost of a single Space Shuttle launch, keep in mind that WMAP has taught us next to nothing about the effects of weightlessness on snails, toads, or even fish.  Its sole mission is to study nerdy, technical things like what the universe is made of and whether its finite or infinite.
I was at Perimeter Institute on Thurday morning, and people there were awaiting the data as if  (har, har) the fate of the universe depended on it.   I especially enjoyed chatting with Justin Khoury, a cosmologist who studies the ekpyrotic scenario.  What is the ekpyrotic scenario?  Well, three things I know about it are that

it posits that our universe is a 4-dimensional brane embedded in a 5-dimensional manifold, and that the Big Bang was caused by a different brane slamming into ours 13.6 billion years ago,
it doesnt say where the branes or the manifold came from originally, and
it was co-invented by the father of my former MathCamp roommate.

Like its chief rival  Alan Guths inflationary cosmology  the ekpyrotic scenario predicts the fluctuations in the cosmic microwave background that WMAP (as well as its predecessor COBE) observed.  But inflation also predicts long-wavelength gravity waves, while the ekpyrotic scenario doesnt.  There was a tiny chance that Thursdays WMAP release would show evidence of such waves  in which case the ekpyrotic scenario would be killed (or in technical terms, braned).
As it turns out, though, the latest results mostly confirm what we already thought, albeit with better precision.  The observable universe looks to be 4% normal stuff (mostly intergalactic baryons, but also free AOL trial CDs), 22% cold dark matter, and 74% dark energy.  Theres no doubt at all that the dark energy is there, and that it will continue pulling the universe apart (so if you want to visit a different galactic supercluster, leave now).  The scalar spectral index seems to be slightly less than 1, which is apparently is what youd expect if inflation were true.  Also, space continues to look pretty flat  but then again, the Earth also looks pretty flat, even from the window of a commercial airliner. At least we can say that, if space has a nontrivial curvature, then the radius is a lot bigger than the 14 billion light-years we can see.
(Note that its logically possible for space to be finite  that is, to loop back on itself  despite having zero curvature.  In that case, the universe would be like one of those arcade games where, when your spaceship goes off the edge of the screen, it reappears on the other edge.  The questions of the geometry and topology of space are related but different.)
What general conclusions can we draw from all this?
First, that we theoretical computer scientists really ought to get ourselves one of these space probes  one that can peer directly into the face of God and report back to us on whether P=BPP, whether BQP is in AM, and so on.  What the physicists do feels like cheating to me, like peeking at the answers in the back of the book.  (When I griped about this to Lee Smolin, he offered the following consolation: At least when you guys answer a question, it stays answered.)
Second, that space is where the excitement is in fundamental physics these days.  If you dont believe me, look at these awesome slides by John Baez (as well as this from Baez and this from Lee Smolin).  Baez points out that, of the three big discoveries of the past 25 years  dark matter, dark energy, and neutrino mass  all three came from astronomy (not from particle accelerators), and not one was predicted by theorists (whove been busily trying to explain them post hoc).  From my outsider perspective, it seems clear that the astrophysicists have some sort of unfair advantage here, and that the only way to rectify the situation is to cut NASAs space science budget.  Fortunately, thats exactly what W. has done.
The third conclusion is that its time for a new religion: one that would celebrate the release of new CMB data as an event roughly analogous to Moses descending from Sinai with new tablets in hand, and that would regard the Space Shuttle as a blasphemy, an orbiting golden calf.  Seriously  am I the only person who sees measuring the CMB fluctuations as a religious obligation?Tools for the modern complexity theorist

Youre deep in the Congo. Youve got an iPhone with some charge left, but theres no cell tower for hundreds of miles. With life-or-death urgency, you need to know the definition of the complexity class SBP and its relationship to BPPpath. What do you do?
Not to worry: Satoshi Hada has created a free Complexity Zoo app for the iPad and iPhone. I tried it out and it works great!

You get a cold call from yet another solitary genius whos discovered a simple linear-time 3SAT algorithm. You tell him to implement the algorithm and test it out, and then youll talk. Half an hour later, he tells you hes done so and it works perfectly. So you tell him to go factor the 617-digit RSA challenge number. But being an iconoclastic genius, he never learned how to reduce factoring to 3SAT. What do you do?
Relax: answering challenge #2 from this blog post even before the post went up, USC students Henry Yuen and Joe Bebel have created a great web application called ToughSAT, which generates hard SAT instances on demand, based on factoring, subset sum, or even a hard problem cocktail. As a commenter helpfully alerted us, a few years ago Paul Purdom and Amr Sabry of Indiana University already created a similar site that generates hard SAT instances based on factoring.Mmm, sacrilicious!

So it seems The Simpsons  the show that FOX executives will cite as they plead with Satan to be spared from hellfire  has been renewed for two more seasons.  One more renewal, and The Simpsons will become the longest-running primetime TV series in history.
The Simpsons is one of the few examples of something thats known to everyone, even though it profoundly deserves to be.  (The other examples that spring to mind are Shakespeare, Einstein, and the Internet.)  To call it the best TV show of all time is like calling Huck Finn the best adventure novel set on the Mississippi.  The Simpsons is what justifies the existence of television as a medium.
(I read a wonderful story about this in William Poundstones biography of Carl Sagan.  Apparently Sagan disapproved of his teenage daughter watching The Simpsons, seeing the show as a symptom of the educational decline that hed been fighting in his books and speeches.  His daughter challenged him: You say reason and empiricism are so important, so how can you condemn The Simpsons without ever having watched it?  Shamed, Sagan agreed to watch an episode.  He quickly became a fan, and watched it regularly in his last years of life.)
Of course, like Einstein in his Princeton period, The Simpsons has lost much of its power with age.  In my opinion, both South Park and the much-mourned Futurama surpassed The Simpsons years ago in terms of vrc/s (viewer ribcage convulsions per second).  But thats hardly a discredit to the mighty trunk of which South Park and Futurama are the branches.
Popular perception of The Simpsons underwent an interesting evolution.  For the first few seasons, everyone seemed to think the show was about Bart: the proud underachiever, scandalizing parents by telling them to eat his shorts.  (Man, I feel like a fogey.)  By the mid-90s that was already history, the focus having shifted to Homer: the fat, beer-swilling symbol of America itself.
But the longer I watched, the clearer it became to me that the central character is Lisa.  Dan Castallaneta, who does Homers voice, also does Grandpa, Groundskeeper Willy, Barney, Krusty, and several others.  Nancy Cartwright, who does Bart, also does Nelson, Ralph Wiggum, and Todd Flanders.  But Yeardley Smith, who does Lisa, only does Lisa.  Born into a world of cartoon yellow doofuses, Lisa is the solitary champion of reason and principle  even if she is tempted to abandon her principles for a pony.  In a cacophony of hundreds of voices, hers is the only soliloquy.
But the simplest proof of The Simpsons Shakesperian greatness is the number of secondary characters who are richer, more vivid, than the lead characters of all but the very best novels.  Mr. Burns.  Smithers.  Apu.  Skinner.  Mrs. Krabappel.  Flanders.  Uncle Herb.  Abe.  Patty and Selma.  Moe.  Barney.  Artie Ziff.  Nelson.  Krusty.  Sideshow Bob.  Every one of them has a story, what literary types might call interiority.  Every one, for better or worse, will be seared in my memory for as long as I live.
Come to think of it, thats probably even true of the ones who dont have much interiority: Comic Book Guy, Frink, Duff Man, the Sea Captain, Disco Stu, Cletus, Kang and Kodos
But enough of this.  Its time for the hard (but necessary) part of the post: my personal selection of Simpsons moments.  If you have work to do, I advise you to stop reading right now.
Still with me?  Yeah, I thought so.
Homer: The Internet?  Is that thing still around?
Lisa: What is the sound of one hand clapping?
Bart: Piece of cake.  [claps his fingers against his palm]

Lisa: If a tree falls in the woods and no ones around, does it make a sound?
Bart: Absolutely!  Eeeewww-PLUNK!
Selma: Oh, we promise we wont tell [that Marge is pregnant].
[Back at their apartment, Patty and Selma open the phone book to the first page.]
Patty: [dials] Hello, is this A. Aaronson? It might interest you to know that Marge Simpson is pregnant again.
[Flash forward]
Patty: Just thought youd like to know, Mr. Zykowski. [hangs up, sighs] There. Aaronson and Zykowski are the two biggest gossips in town. In an hour, everyone will know.
Can you name the truck with four wheel drive,
Smells like a steak, and seats thirty five?
Canyonero! Canyonero!
Well, it goes real slow with the hammer down
Its the country-fried truck endorsed by a clown
Canyonero! Canyonero!
Hey, hey!
Twelve yards long, two lanes wide,
Sixty five tons of American pride!
Canyonero! Canyonero!
Top of the line in utility sports,
Unexplained fires are a matter for the courts!
Canyonero! Canyonero!
She blinds everybody with her super high beams
Shes a squirrel-squashin, deer-smackin drivin machine
Canyonero! Canyonero! Canyonero!
Whoa, Canyonero! Whoa!
Talking toilet in Japan: Welcome! I am honored to accept your wastes.
Bart: And I think Ive finally found what I was put on this earth to do  knife goes in, guts come out, knife goes in, guts come out [pulls out a talking fish]
Fish: Spare my life and I will grant you three 
Bart: [guts the talking fish] Knife goes in, guts come out.
Chinese Dragons: [singing in falsetto voices] American jerks are going home Now we sleep for a thousand years When we wake the world will end
USA A-OK, the award-winning speech by Trong Van Din:
When my family arrived in this country four months ago, we spoke no English and had no money in our pockets.  Today, we own a nationwide chain of wheel-balancing centers.  Where else but in America, or possibly Canada, could our family find such opportunity?  Thats why, whenever I see the Stars and Stripes, I will always be reminded of that wonderful word: flag!
Bart and Greta watch Itchy & Scratchy on DVD.  They then go to the bonus features, and choose the running audio commentary.  Scratchy starts to discuss the filming of the episode, but then Itchy slices his head off within the commentary box
Homer: Marge, anyone could miss Canada, all tucked away down there.
Campaign commercial for Sideshow Bob:
[scene shows prisoners going in and out a revolving door]
Voice: Mayor Quimby supports revolving door prisons.  Mayor Quimby even released Sideshow Bob  a man twice convicted of attempted murder.  Can you trust a man like Mayor Quimby?  Vote Sideshow Bob for mayor.
Skinner: [on the phone] I know Weinsteins parents were upset, uh, superintendent, but, but  but I was sure it was a phony excuse.  I mean, it sounds so made up: Yahm Kip-Pur?
On a ship in international waters, a man wearing a tuxedo is shown marrying a cow.  The cow then smashes a glass with its hoof (in keeping with Jewish wedding tradition).
[Homer is being attacked by a mobster]
Mark Hamill (aka Luke Skywalker):   Homer!  Use the for
Homer: The Force?
Hamill: The forks!  Use the forks!
[Homer jabs his assailant with a fork]
[At Sideshow Bobs parole hearing]
Lawyer: But what about that tattoo on your chest?  Doesnt it say Die Bart, Die?
Bob: No, thats German for The Bart, The.
[The spectators laugh, understanding]
Mrs. Lovejoy: No one who speaks German could be an evil man!
Lisa: Dad, as intelligence goes up, happiness often goes down.  In fact, I made a graph.  [She holds up a concave decreasing graph on axes marked intelligence and happiness]
Lisa: [sadly] I make a lot of graphs.
Marge: Homer, thats not God.  Thats just a waffle that Bart tossed up there.
[Marge scrapes it off into Homers hands]
Homer: I know I shouldnt eat thee, but  [bites] Mmm, sacrilicious!
Lisa: Well, wheres my dad?
Frink: Well, it should be obvious to even the most dimwitted individual who holds an advanced degree in hyperbolic topology, ngee, that Homer Simpson has stumbled into[the lights go off] the third dimension.
Lisa: [flips the light switch back] Sorry.
Frink: [drawing on a blackboard] Here is an ordinary square.
Wiggum: Whoa, whoa  slow down, egghead!
Frink:  but suppose we extend the square beyond the two dimensions of our universe, along the hypothetical z-axis, there.
Everyone: [gasps]
Frink: This forms a three-dimensional object known as a cube, or a Frinkahedron in honor of its discoverer, nhey, nhey.
[Lisa wonders why a bully attacks only nerds]
Lisa:  Why does she only go after the smart ones?
Nelson:  Thats like asking the square root of a million!  No one will ever know.
Krusty: [asked to say grace at dinner] Baruch atah adonai, eloheinu melech haolam, hamotzi lechem min haaretz.
Homer: Hee hee hee hee hee! Hes talking funny-talk!
Lisa:   No Dad, thats Hebrew!  Krusty must be Jewish.
Homer:  A Jewish entertainer?  Get out of here!
Principal Skinner: Do you kids want to be like the real UN, or do you want to squabble and waste time?
Bruno the Australian: This is an outrage! Im going to take this all the way to the Prime Minister! [Yells out window] Hey Mr. Prime Minister! Andy!
Scientist: This cant be right.  This man has 104% body fat! [turns to Homer] Hey, no eating in the tank!
Homer: [eating a chicken drumstick] Go to hell.
Frink:  Youve got to listen to me.  Elementary chaos theory tells us that all robots will eventually turn against their masters and run amok in an orgy of blood and kicking and the biting with the metal teeth and the hurting and shoving.
Repairman: How much time do we have, professor?
Frink [checks clipboard]:  Well, according to my calculations, the robots wont go berserk for at least 24 hours.
[A robot grabs a man by the throat]
Oh, I forgot to, er, carry the one.
Homer [at Renaissance Fair]: Ive eaten eight different meats.  Im a true renaissance man!
Fortune Teller to Lisa: [concentrating] Its coming to meyes, I see an eastern university in the year 2010.  The world has become a very different place.
[in the future, a line of robots clatters past]
[they walk past a sign saying Wizard of Oz auditions today]
[these are followed by a scarecrow and a lion]
At the rigged spelling bee:
George: Okay, your word is whether.
Girl: Um, which one? Could you use it in a sentence?
George: Certainly. I dont know whether the weather will improve.
Homer: Your old meat made me sick!
Apu: Oh, Im so sorry.  [gets a pail of shrimp] Please accept five pounds of frozen shrimp.
Homer: [holds one up, sniffs it] This shrimp isnt frozen!  And it smells funny.
Apu: OK, ten pounds.
Homer: Woo hoo!
Bob: You wanted to be Krustys sidekick since you were five!  What about the buffoon lessons?  The four years at Clown College?
Cecil: Ill thank you not to refer to Princeton that way.
Burns: Well, did you meet Larry?
Man from Yale: Oh, yes.  He made light of my weight problem, then suggested my motto be semper fudge.  At that point, he told me to [making quotes with fingers] relax.
Burns: How were his test scores?
Woman from Yale: Lets just say this: he spelled Yale with a six.
Burns: I see.  Well, I  ooh, you know, I just remembered, its time for my annual donation.  [brings out checkbook and pen]  I wonder how much I should give.
Man: Well, frankly, test scores like Larrys would call for a very generous contribution. [opens book] For example, a score of 400 would require a donation of new football uniforms, 300, a new dormitory, and in Larrys case, we would need an international airport.
Woman: Yale could use an international airport, Mr. Burns.
Mrs. Krabappel:  Now whose calculator can tell me what 7 times 8 is?
Milhouse:  Oh! Oh! Oh!  Low battery?
Nelson:  Psst, Lisa!  Check it out.  [He shows her a piece of paper.]  Tomorrows fractions quiz:  Ill give you the numerators free, but the denominators are gonna cost you.
Lisa:  I dont want your dirty denominators!
Prof. Frink:  Scientists  Scientists, please!  Im looking for some order.  Some order, please, with the eyes forward and the hands neatly folded and the paying of attention.  Pi is exactly three!
[crowd gasps]
Frink:  Very sorry that it had to come to that, but now that I have your attention, we have some exciting new research from young Lisa Simpson.
Adil:  How can you defend a country where five percent of the people control ninety-five percent of the wealth?
Lisa:  Im defending a country where people can think and act and worship any way they want.
Adil:  Cannot!
Lisa:  Can too!
Adil:  Cannot!
Lisa:  Can too!
Homer: Please, please, kids, stop fighting.  Maybe Lisas right about America being the land of opportunity, and maybe Adils got a point about the machinery of capitalism being oiled with the blood of the workers.
Bart says Krusty couldnt have committed a robbery, since hes illiterate, but the videotape shows the culprit picking up the Springfield Review of Books.
Sideshow Bob: The fact is, you dont have to be able to read to enjoy the Springfield Review of Books.  Just look at these amusing caricatures of Gore Vidal and Susan Sontag!
Skinner: We can buy real periodic tables instead of these promotional ones from Oscar Meyer.
Krabappel: Who can tell me the atomic weight of bolognium?
Martin: Ooh  delicious?
Krabappel: Correct. I would also accept snacktacular.
Lisa: A rose by any other name smells as sweet.
Bart: Not if you call them stench blossoms.
Grandpa: My Homer is not a communist.  He may be a liar, a pig, an idiot, a communist, but he is not a porn star.
Scully: Homer, were going to ask you a few simple yes or no questions. Do you understand?
Homer: Yes. [lie dectector explodes]
Homer: Got any of that beer that has candy floating in it? You know, Skittlebrau?
Apu: Such a beer does not exist, sir. I think you must have dreamed it.
Homer: Oh. Well, then just give me a six-pack and a couple of bags of Skittles.
Homer: Oh, so they have the Internet on computers now?
Marge: I really think this is a bad idea.
Homer: Marge, I agree with you  in theory.  In theory, communism works.  In theory.
Mr. Burns: What good is money if it cant inspire terror in your fellow man?
Bart: Christmas is a time when people of all religions come together to worship Jesus Christ.
Homer: [stuffing his face] Stop being such babies.  You cant be afraid to try new things.  For instance, tonight Im using a  Apu, what do you call this thing again?
Apu: A napkin.
Homer: Ha ha ha ha!  Outrageous!
Skinner: Our next budget item: $12 for doorknob repair.
Parents: Nay!
[Groundskeeper Willy, who is on fire, tries to escape, but the doorknob falls off]
Skinner: Recharge fire extinguishers?  Now, this is a, uh, free service of the fire department 
Parents: Nay!
[Willy tries to use the fire extinguisher, but its empty]
[Still engulfed in flames, he breaks out and runs into the classroom]
Willy: Help!  Please help me!
Skinner: Willy, please!  Mr. Van Houten has the floor.
Lisa: I like you too, Milhouse, but not in that way.  Youre like a big sister.
Milhouse: No, Im not!  Why does everybody keep saying that?
Lisa: Would you do me a favor?  When you get back to class, just give him this note  please?
Milhouse: [thinking] When she sees youll do anything she says, shes bound to respect you!
Bart:  Can you give us the rabbis address?
Reverend Lovejoy: Oh, sure thing.  Let me just check my non-Christian rolodex
Dolph: Oh, man!  You kissed a girl!
Jimbo: That is so gay!
Jimbo: [sings] Gonna dig me a hole
Dolph & Kearney: Gonna dig me a hole
Jimbo: Gonna put a nerd in it
Dolph & Kearney: Gonna put a nerd in it
Lisa: Dad, its not fair to claim this things an angel.  Theres no proof of that.
Homer: No ones calling it an angel, Lisa.  If you look carefully I never once used the word angel.
Lisa: Whats that sign over there? [It says Angel in big letters.]
Homer: Thats a typo.ICS gets a new name and a new location

Shafi Goldwasser has asked me to announce that the next Innovations in Theoretical Computer Science (ITCS) conferencepreviously called Innovations in Computer Science (ICS)will be held January 8-10, 2012 in Cambridge, MA, the first I(T)CS to be held outside of China. The submission deadline is August 7. The call for papers is here, and the conference website is here.Spouting Buhl

For those who are interested, video of my Buhl Lecture in Physics at Carnegie Mellon is now available on YouTube. (The lecture was on April 29; the topic was Quantum Computing and the Limits of the Efficiently Computable.) Thanks to everyone at CMU for their amazing hospitality.The mouth that cannot bite

Warning: Todays post has not been approved by the Family Research Council.
Theres a puzzle about evolution thats been bothering me for years.  The most vivid way to state it is as follows: why dont vaginas have retractable teeth?
Think about it.  If vaginas had teeth, rape would be difficult if not impossible.  Females would have much greater control over which males could impregnate them.  Wouldnt a biting vagina be a useful Darwinian adaptation?
Of course, the question applies not only to humans, but to any species where the females can be impregnated against their will.  (I guess seahorses and black widow spiders dont count.)
I realize that feminists, psychoanalysts, and comedians could all have a field day with my puzzle, but lets set that aside and see if we can actually answer it.  I can think of five hypotheses, but none of them completely satisfy me.
The first is the boring spandrels hypothesis: that putting teeth in vaginas would be too difficult embryologically to be worth the Darwinian payoff.  This hypothesis would only convince me if accompanied by an explanation of why a biting vagina would be so much harder to build than a bee stinger, or an elephant tusk, or any of evolutions other strange inventions.
The second hypothesis is that, if vaginas had teeth, then rapists would just threaten their victims with injury or death if they resisted (as, alas, they often do anyway).  But this hypothesis can be made irrelevant by changing the thought experiment a little.  Instead of a biting vagina, imagine a flap between the vagina and uterus that could be open or closed at will.  If a woman had such a flap, then she could consciously decide whether to let a sex partner impregnate her, without the partner knowing her decision until possibly months later.  In other words, she would have built-in birth control.
The third hypothesis is that, even without the teeth or flap, women already have lots of control over which sex partners can impregnate them.  As we all know, women in developed countries gained such control in the 20th century  and despite the best efforts of the Republicans, theyve fortunately retained it, more or less, in every US state except South Dakota.  But Im asking whether women had such control for most of evolutionary history, and also whether females elsewhere in the animal kingdom have it.
In particular, you might have heard the controversial theory that a woman can choose to retain more of her partners sperm (thereby increasing the chance of conception) by having an orgasm  and indeed, that thats why the female orgasm evolved in the first place.  This theory, if true, would be one example of what Im talking about, but not the only possible example.  Do any of you know how far back in human history abortions were performed  and also, whether any non-human animals perform abortions?
The fourth hypothesis is what Ill call genetic paternalism.  This is the idea that, while giving birth to a rapists child is an unimaginable trauma from the womans perspective, her genes perspective might differ from hers.  From the genes standpoint, maybe the child will grow up to become a rapist himself, thereby spreading his mothers genes to yet more victims.
(Here I should state an obvious ground rule: when engaging in Darwinian speculation, you have to wear the distinction between is and ought like a radiation suit.  Theres no scientific discovery that could possibly justify violence against women, since the wrongness of such violence isnt based on science to begin with.)
Of course, the genetic paternalism hypothesis begs the question of why a womans genes would build a brain so opposed to the genes own interests.  But that question shows up all over the place in human evolution.
The fifth hypothesis is that vaginas lack teeth for the same reason many women wear high heels and the Chinese used to mutilate girls feet.  As Carl Sagan and Ann Druyan point out in their superb book Shadows of Forgotten Ancestors, men have always fetishized female helplessness.  For most of human history, marriage wasnt a union of soulmates; it was a deal between the groom and the brides parents.  If a man invested in a wife, hed want to be sure she would bear him children, just like if he invested in a cow, hed want to be sure it would give him milk.  (In Fiddler on the Roof, theres a hilarious exchange between Tevye the dairyman and Lazar Wolf the butcher playing on that similarity.)  So, if most women had teeth in their vaginas, then a woman who was known not to have such teeth might be a hot commodity on the marriage market.  Of course, that leaves open the question of how she would advertise her toothlessness to prospective suitors (Hi, Im Alice, and my vagina doesnt bite!).
Surprisingly, Ive never seen my biting vagina puzzle discussed in any book or article on evolutionary biology.  (Id be grateful for a reference.)  I have seen plenty of other sex-related puzzles.  For example, why are there homosexuals?  Why dont women just clone themselves, instead of diluting their genetic contribution by 50% by mixing their genes with a mans?  For that matter, why is there sex in the first place?  To me, all these questions are so perplexing that its a wonder the creationists never harp on them.  I guess that to harp on them, theyd first have to understand them.My responses to GASARCHs P vs. NP poll

The poll is here; my (slightly-edited) responses are below. It took heroic self-restraint, but I tried to answer with straightforward statements of what I actually think, rather than ironic humor.
1. Do you think P=NP or not? You may give other answers as well.
I think PNP (on more-or-less the same grounds that I think I wont be devoured tomorrow by a 500-foot-tall salsa-dancing marmoset from Venus, despite my lack of proof in both cases).
 2. When do you think it will be resolved?
In his recent book The Beginning of Infinity, David Deutsch argues that we cant even make decent probabilistic predictions about a future event, to whatever extent that event depends on new knowledge being created. I agree with him on this: a proof of PNP, like other major mathematical advances, would depend almost entirely on new knowledge, and because of that, my uncertainty applies not only to the approximate number of years but to the approximate log of that number: decades, centuries, millennia, who knows? Maybe the question should be rephrased: will humans manage to prove PNP before they either kill themselves out or are transcended by superintelligent cyborgs? And if the latter, will the cyborgs be able to prove PNP?
3. What kinds of techniques do you think will be used?
Obviously I dont knowbut if we look at the techniques used in (say) Ryan Williams recent result, and then remember that that proof only separates NEXP from ACC0, we can get a weak hint about the scale of the techniques that would be needed for problems like P vs. NP. Right now, Mulmuleys GCT is the only approach out there that even tries to grapple with the biggest barrier we know, beyond even relativization, natural proofs, and algebrization: the barrier that many nontrivial problems (including matching and linear programming) are in P! Thats not to say Mulmuleys specific program will succeed: indeed, I suspect that the right chain of reasoning might diverge from Mulmuleys at an earlier rather than later point. But even for the seemingly-easier permanent versus determinant problem, I fear Mulmuley is basically right that the key insights lie in yellow books yet to be written.
4. Will the problem still be relevant given advances in algorithms and in SAT Solvers?
Yes, in the same way the Second Law of Thermodynamics is still relevant given advances in hybrid cars.
5. Feel free to comment on anything else: Graph Isomorphism, Factoring, Derandomization, Quantum computers, and/or your own favorite problem.
Graph Isomorphism: Probably in P.
Factoring: Probably hard for classical computers, but unlike with NP-complete problems, if it isnt then were still living on Earth.
Derandomization: I think P=BPP (with essentially the same strength of conviction as PNP), and likewise L=RL, etc.
Quantum computing: I think BPPBQP (though not with the same strength of conviction as PNP), and also predict that no bizarre changes to quantum mechanics will be discovered of the sort needed to make scalable quantum computing impossible.

For those who are still reading, as a special bonus I present my answers to the large and interesting questions asked by a commenter on my last post named Mike S.
One thing Ive heard before about NP(-hard) problems is that often  certain instances are much harder than others.  What are your feelings  on the physical practicality of a computer that solves only most cases  of NP(-hard) problems quickly?  Also, is determining the difficulty of  particular instances of NP-complete problems NP(-hard)?
It depends what you mean by most!  I think its almost certainly  possible to generate a probability distribution over 3SAT instances  almost all of which are hard (indeed, that assumption is central to  modern cryptography).  As one example, the approximate shortest vector problem is known to be just as hard on average as it is in the worst case, and  it can easily be reduced to 3SAT.  Another candidate is random k-SAT  instances at the critical ratio of clauses to variables, for k4.
But maybe what you meant was those instances of NP-hard problems that  typically arise in real life.  Here all sorts of issues come into  play: for example, often the instances that arise in practice have  symmetries or other structure that makes them easy.  And often your goal  is not to find the best solution, but just a better solution  than your competitors.  And often we terminate trains of thought long  before they lead to hard instances of NP-complete problemswere usually  not even conscious that thats what were doing; we just have an  intuition that such-and-such would require a hopeless search.
But at the same time, when we do ask explicitly for optimal solutions, that request for optimality often has a way of finding the hard instances for us.
Less seriously, you said something along the lines of P!=NP keeps  mathematicians in business.  If math is so hard computationally, how do  WE do it?  Or on the other hand, if the computational complexity of  certain problems is a fundamental property of the universe, and we are  part of the universe, doesnt it follow that we could make computers  that are as good or better at doing math than we are?
The short answer is that math (as practiced by humans) is an  extremely hit-or-miss business!  A billion years of evolution have  equipped us with a lot of useful heuristics, as has the much faster  evolution of mathematical ideas over the last few thousand years.
Probably even more important, we normally dont care about arbitrary mathematical questions (does this random Turing machine halt?), but  only questions that arise in some explanatory framework.  And that  criterion tends to select extremely strongly for questions that we can  answer!  Why it does so is a profound question itself, but  whatever the answer, the history of math provides overwhelming evidence  that it does.  Goldbachs Conjecture and the Collatz 3x+1 Conjecture are  more-or-less arbitrary questions (at least in our present state of  knowledge), and indeed they havent been answered yet.  Fermats Last  Theorem might have seemed pretty arbitrary at first (Gauss regarded it as such), but  it wasnt. Indeed, in the 1980s it was embedded into the deep explanatory framework of elliptic curves and modularity, and a decade later it was solved.
Of course, despite these factors in mathematicians favor, theyre  very far from having a general-purpose method to solve all the problems  they want solved.
Incidentally, PNP means computers can never replace human  mathematicians is a forehead-bangingly common misunderstanding.   Personally, I see no reason why the brain couldnt be simulated  by computer (neuron-by-neuron if necessary), and PNP does nothing to  challenge that belief.  All PNP suggests is that, once the robots do overtake us, they wont have a general-purpose way to automate mathematical discovery any more than we do today.What Alan T. did for his PhD

Weve all been there before: by the time you start graduate school in Princeton, youve already invented the Turing machine, pioneered the concept of computational universality, and proved the unsolvability of Hilberts Entscheidungsproblem. A few years from now, youre going to return to England to make decisive contributions to the breaking of the Enigma and the winning of World War II. Your problem is, what do you do for the couple years in between? (Keep in mind that you have a PhD thesis to submit, and the Turing machine is already old hat by now!)
The answer, apparently, is to tackle a neat problem in logic, one version of which was asked three weeks ago by a Shtetl-Optimized commenter named Schulz. Not knowing the answer, I posted Schulzs problem to MathOverflow. There, Franois Dorais and Philip Welch quickly informed me that Turing had already studied the problem in 1939, and Timothy Chow pointed me to Torkel Franzens book Inexhaustability: A Non-Exhaustive Treatment, which explains Turings basic observation and the background leading up to it in a crystal-clear way.
The problem is this: given any formal system F that we might want to take as a foundation for mathematics (for example, Peano Arithmetic or Zermelo-Fraenkel set theory), Gdel tells us that there are Turing machines that run forever, but that cant be proved to run forever in F. An example is a Turing machine M that enumerates all the proofs in F one by one, and that halts if it ever encounters a proof of 0=1. The claim that M doesnt halt is equivalent to the claim that F is consistentbut if F is indeed consistent, then the Second Incompleteness Theorem says that it cant prove its own consistency.
On the other hand, if we just add the reasonable axiom Con(F) (which asserts that F is consistent), then our new theory, F+Con(F), can prove that M runs forever. Of course, we can then construct a new Turing machine M, which runs forever if and only if F+Con(F) is consistent. Then by the same argument, F+Con(F) wont be able to prove that M runs forever: to prove that, well need a yet stronger theory, F+Con(F)+Con(F+Con(F)). This leads inevitably to considering an infinite tower of theories F0, F1, F2, , where each theory asserts the consistency of the ones before it:
F0 = F
Fi = Fi-1 + Con(Fi-1) for all i1
But theres no reason not to go further, and define another theory that asserts the consistency of every theory in the above list, and then another theory that asserts the consistency of that theory, and so on. We can formalize this using ordinals:
F = F + Con(F0) + Con(F1) + Con(F2) + 
F+i = F+i-1 + Con(F+i-1) for all i1
F2 = F + Con(F) + Con(F+1) + Con(F+2) + 
and so on, for every ordinal  that we can define in the language of F. For every such ordinal , we can easily construct a Turing machine M that runs forever, but that cant be proved to run forever in F (only in the later theories). The interesting question is, what happens if we reverse the quantifiers? In other words:
Given a Turing machine M that runs forever, is there always an ordinal  such that F proves that M runs forever?
This is the question Turing studied, but I should warn you that his answer is disappointing. It turns out that the theories F are not as well-defined as they look. The trouble is that, even to define a theory with infinitely many axioms (like F or F2), you need to encode the axioms in some systematic way: for example, by giving a Turing machine that spits out the axioms one by one. But Turing observes that the power of F can depend strongly on which Turing machine you use to spit out its axioms! Indeed, he proves the following theorem:
Given any Turing machine M that runs forever, there is some version of F+1 (i.e., some way of encoding its axioms) such that F+1 proves that M runs forever.
The proof is simple. Assume for simplicity that F itself has only finitely many axioms (removing that assumption is straightforward). Then consider the following Turing machine P for outputting the axioms of F, which gives rise to a version of F that well call FP:
Output the axioms of F
For t=0,1,2,
If M halts in t steps or fewer, then output Con(FP); otherwise output Con(Ft)
Next t
You might notice that our description of P involves the very theory FP that were defining! What lets us get away with this circularity is the Recursion Theorem, which says (informally) that when writing a program, we can always assume that the program has access to its own code.
Notice that, if P ever output the axiom Con(FP), then FP would assert its own consistency, and would therefore be inconsistent, by the Second Incompleteness Theorem. But by construction, P outputs Con(FP) if and only if M halts. Therefore, if we assume FPs consistency as an axiom, then we can easily deduce that M doesnt halt. It follows that the theory F+1 := FP + Con(FP) proves that M runs forever.
One question that the above argument leaves open is whether theres a Turing machine M that runs forever, as well as a system S of ordinal notations extending as far as possible, such that if we use S to define the theories F, then none of the Fs prove that M runs forever. If so, then there would be a clear sense in which iterated consistency axioms, by themselves, do not suffice to solve the halting problem. Alas, I fear the answer might depend on exactly how we interpret the phrase extending as far as possible  elucidation welcome!
Update (June 29, 2011): In a comment, Franois Dorais comes to the rescue once again:
In connection with your last paragraph, Feferman has shown that there  are paths through O such that the resulting theory proves all true 01 statements. [JSL 27 (1962), 259-316] Immediately after Feferman and  Spector showed that not all paths through O do this. [JSL 27 (1962),  383-390] In particular, they show that any good path must be more  complicated than O itself: the path cannot be 11. In other words,  there is no simple way to form a wellordered iterated consistency extension that captures all true 01 statements.The Glorious Blog of the People

I have good news and bad news, though neither of them has much to do with biting vaginas.
The good news is that Luca Trevisan  complexity theorist extraordinaire, member of my thesis committee at Berkeley, occasional commenter on Shtetl-Optimized, world-renowned for his pronunciation of the word pseudorandom  has recently started a blog.  Right now Luca is filing travel reports from Beijing, where apparently the food is excellent.
The bad news is that, according to Luca, Shtetl-Optimized has been blocked by the Great Firewall of China! Even though Luca congratulates me on my accomplishment of being censored in China  an accomplishment not shared by a certain unnamed competitor  this is actually a serious blow to me. See, Ive long felt that the 1.3 billion citizens of the Middle Kingdom represent the single most promising growth market for the complexity/physics/Jewish-humor/biting-vagina weblog industry. (Oh, you think the Chinese can live without Jewish humor? You might as well say the Jews can live without mu shu and crunchy noodles!)
But what makes this ban by Beijing particularly unfortunate is that, just today, I was planning to blog about my contempt for the moronic pseudoscience of Falun Gong. But thats only a taste of what Ive been hoping to tackle in the weeks ahead  including the absurd pretensions of the Dalai Lama (whats with that robe, dude?), the benefits of collectivized agriculture, the impudence of the Tiananmen Square traitors, and of course, my profound respect for the awesomest person ever:

If you ask me, Marx, Lenin, and Stalin might have paved the way, but Mao surpasses them all as the true voice of the proletariat. Down with capitalist-bourgeois idealism! Reunite Zhnggu Tibi with the motherland!
And while Im at it, here another experiment, this one aimed at increasing the number of comments on this post: biting vaginas  biting vaginas  biting vaginas  biting vaginas  biting vaginasWeeding out the undesirables

This New Yorker piece by Malcolm Gladwell shows once again why, despite all the hype surrounding him, Gladwell really is one of the most perceptive social observers of our time. Gladwell is reviewing The Chosen by Jerome Karabel, which relates the history of the undergraduate admissions process at Harvard, Princeton, and Yale.
Have you ever wondered why that process places so much emphasis on sports, extracurriculars, personality, leadership, character, and suchlike, as opposed to the more obvious intellectual criteria? The answer, it turns out, is that in the early 1920s, Harvard and Co. had to find some way to limit the number of Jewish admits:
By 1922, [Jews] made up more than a fifth of Harvards freshman class. The administration and alumni were up in arms. Jews were thought to be sickly and grasping, grade-grubbing and insular. They displaced the sons of wealthy Wasp alumni, which did not bode well for fund-raising. A. Lawrence Lowell, Harvards president in the nineteen-twenties, stated flatly that too many Jews would destroy the school  Finally, Lowell  and his counterparts at Yale and Princeton  realized that if a definition of merit based on academic prowess was leading to the wrong kind of student, the solution was to change the definition of merit. Karabel argues that it was at this moment that the history and nature of the Ivy League took a significant turn.
Gladwell writes that from that point forward,
The admissions office at Harvard became much more interested in the details of an applicants personal life. Lowell told his admissions officers to elicit information about the character of candidates from persons who know the applicants well, and so the letter of reference became mandatory. Harvard started asking applicants to provide a photograph. Candidates had to write personal essays, demonstrating their aptitude for leadership, and list their extracurricular activities  The personal interview became a key component of admissions in order, Karabel writes, to ensure that undesirables were identified and to assess important but subtle indicators of background and breeding such as speech, dress, deportment and physical appearance.
The byzantine admissions process that Harvard and the other name-brand schools set up pretty much remains in place to this day. (I still remember the Potpourri section of the Princeton application, which asked applicants to list their favorite movies, music, etc. It reminded me of the bridgekeeper from Monty Python and the Holy Grail: What is your name?  What is your quest?  What is your favorite color?)
Granted, the Ivy League admissions process no longer serves its original purpose, possibly because most American Jews have become so assimilated themselves. But today, the enormous preferences given to legacies, athletes, and other students of character work very similarly to limit the number of Asians. To which I can only say: huzzah! For as Gladwell explains: If Harvard had too many Asians, it wouldnt be Harvard, just as Harvard wouldnt be Harvard with too many Jews or pansies or parlor pinks or shy types or short people with big ears.The dude invented nondeterminism

Michael Mitzenmacher asked me to post the following announcement:
On August 29-30, 2011, there will be a conference in celebration of Michael Rabins 80th birthday at the Harvard School of Engineering & Applied Sciences.  The speakers include Yonatan Aumann, Michael Ben-Or, Richard Karp, Dick Lipton, Silvio Micali, Michael Mitzenmacher, David Parkes, Tal Rabin, Ron Rivest, Dana Scott, Madhu Sudan, Salil Vadhan, Moshe Vardi, and Avi Wigderson. The conference is open to the public, but registration is required by August 25. For more information, see the conference website at https://www.events.harvard.edu/web/4352.The rumors are true

Yeah, alright.  I, Scott Aaronson, have been arrested and have spent eight hours in the custody of the Waterloo police.
Since a lot of bogus information has been circulating about how this happened, let me give you my side of the story.  Its easiest to start with Gaurav Mukherjee, whos currently an undergrad at IIT New Delhi.  I assume most of you have heard of him by now (hes been all over the blogosphere), but for those who havent: earlier this week Mukherjee announced a proof of the physical independence of P versus NP and related questions.  In a manuscript thats been circulating by email, he claims to exhibit laws of physics under which P equals NP (in the unrelativized setting), and different laws under which P doesnt equal NP.  Indeed, he even claims to give laws under which P=NP can exist in a quantum superposition of truth and falsehood.
When Gaurav sent me the manuscript on Wednesday, I immediately wrote it off as crackpot nonsense.  So when I visited Perimeter Institute yesterday afternoon, I was astonished to find it was all anyone was talking about!  I tried in vain to argue with the physicists: Look, you dont get it.  P versus NP is a mathematical question.  By definition, its truth or falsehood cant depend on any assumptions about physics.
Have you even read the paper? the physicists would shoot back.  That kind of statement only makes sense in a pre-Mukherjee ontology.  You might as well say after Einsteins paper that the rate of time cant possibly depend on how fast youre moving!
No, thats a shitty analogy! Id respond, getting more and more agitated as the afternoon wore on.
At 9PM or so, a bunch of us decided to hit Jane Bond, a popular bar in Waterloo, to argue about it some more.  Thats where things took a turn for the worse.  Ive never held my alcohol well, but the physicists were all ordering three or four beers apiece, so I did the same.  By midnight, Id gotten into an especially ugly argument with a certain postdoc who will remain anonymous.  You complexity theorists, youre all the same, he drawled.  Prove this, bound that, this makes no sense, this cant possibly influence that.  Buncha stuck-up pussies.
The physicists all laughed, and thats when I lost it.
You idiot! I screamed.  You doofus!  You ignorant farmer!
What did you call me? the postdoc said, pushing my shoulder so hard I almost fell off my chair.
An ignorant farmer, I said, socking him in the jaw as hard as I could.
We both got up.  I noticed that the postdocs jaw was bleeding.  The other Perimeter guys gathered around us  quantum information theorists on one side, cosmologists and quantum gravity theorists on the other.  The postdoc and I traded blows for a minute or two until the cops showed up.  When they asked who started it, everyone pointed to me, and as a result, I was the only one they arrested!  Fortunately, the cops said they wouldnt charge me with anything, but they did keep me at the station until I sobered up.
I had plenty of time there to think things over.  What if Mukherjee is right? I thought.  What if the very formulation of Turing machines, P versus NP, and so on depends on presuppositions that Ive never seriously thought through?  There was one particular point in Mukherjees paper  the construction of an ontology where polynomial time means the same as exponential time  that I hadnt understood till then, but that I finally got at 4AM or so.  Staring at the walls of the station, the lone officer pacing back and forth, my handcuffs, etc. I could feel my previous worldview crumbling all around me.
By now  Saturday morning  Mukherjees paper has changed how I think about almost everything.  This might seem like a stretch, but its even made me more sanguine about the George W. Bush presidency.  Look, if whether P=NP can depend so strongly on our beliefs and assumptions, then why not whether the universe is 6,000 or 14 billion years old, or whether a missile defense system will or wont work?  The bottom line is that facts, logic, and objective reality (whatever that means) arent nearly as important as I thought they were.  If enough people want something to be true, it becomes true.  I guess Ill keep writing this blog, but from now on its never going to be the same.Rossers Theorem via Turing machines

(Thanks to Amit Sahai for spurring me to write this post!)
The Background
We all remember Gdels First Incompleteness Theorem from kindergarten. This is the thing that, given a formal system F, constructs a sentence G(F) thats a mathematical encoding of
This sentence is not provable in F.
If F proves G(F), then F proves both that F proves G(F) and that F doesnt prove G(F), so F is inconsistent (and hence also unsound). Meanwhile, if F proves Not(G(F)), then it believes theres a proof of G(F). So either that proof exists (in which case it would render F inconsistent, by the previous argument), or else it doesnt exist (in which case F is unsound). The conclusion is that, assuming F is powerful enough to express sentences like G(F) in the first place, it cant be both sound and complete (that is, it cant prove all and only the true arithmetical statements).
OK, but the way most people like to state Gdels Theorem is stronger than that: no sufficiently-powerful formal system F can be both complete and consistent. Note that soundness implies consistency, but not vice versa. (If I believe that theres a giant purple boogeyman on the moon, then presumably my belief is unsound, but it might be perfectly consistent with my various other beliefs about boogeymen.)
Unfortunately, neither Gdels original proof, nor computer scientists favorite alternative proofs, actually give you the stronger statement about completeness and consistency. And this has been a persistent problem when I teachGdel in my undergraduate computability and complexity class.
Wheres the catch inGdels argument? Its in the case where F proves Not(G(F)) (i.e., that G(F) is provable), even though in reality G(F) is true (i.e., G(F) isnt provable). In that situation, F would clearly be unsound, but it might not contain any contradictionbasically because, no matter how long you looked, you could never rule out Fs (false) belief that G(F) is provable. Indeed, F would be what I like to call a self-hating theory: a theory, like F+Not(Con(F)), that pessimistically believes in its own inconsistency, even though in fact its perfectly consistent. (By contrast, if F arrogantly believes in its own consistency, then it cant be consistent by the Second Incompleteness Theorem! Theres a lesson there somewhere)
The way Gdel himself solved this problem was by introducing a new concept called -consistency, which is intermediate between consistency and soundness. He then showed that F cant be both complete and -consistent. (Why didnt Gdel simply talk about soundness? Because unlike consistency or -consistency, soundness is a metatheoretic concept thats impossible to formalize in F. So, if he used soundness, then the First Incompleteness Theorem couldnt even be stated, let alone proved, in F itself, and that in turn would create problems for the proof of his Second Incompleteness Theorem.)
Anyway, from the standpoint of an undergrad class, the fear is that, once you start talking about -consistency, all the romance and self-referential magic ofGdel will vanish in a morass of technicality.
So surely we can dot the is here (or rather, put the umlauts on the s), and prove the stronger, cleaner statement that F cant be both complete and consistent?
Yes we canbut to do so we need Rossers Theorem: a strengthening of Gdels Theorem from 1936 thats much less well-known among the nerd public than it ought to be. In Rossers proof, we replace G(F) by a new sentence R(F), which is a mathematical encoding of the following:
For every proof of this sentence in F, theres a shorter disproof.
If F proves R(F), then it also proves that theres a disproof of R(F) thats shorter than the proof of R(F) whose existence we just assumed. So we can look for that disproof (since there are only finitely many strings of symbols to check), and either well find it or we wontbut in either case, well have revealed F to be inconsistent. Meanwhile, if F proves Not(R(F)), then it proves that there is a proof of R(F) with no shorter disproof. So in particular, it proves that theres a proof of R(F) thats no longer than the proof of Not(R(F)) whose existence we just assumed. But once again, we can look for that proof (there are only finitely many strings to check), and either well find it or we wont, and in either case, F is revealed to be inconsistent.
Notice what the Rosser sentence accomplishes: it creates a symmetry between the cases that R(F) is provable and R(F) is disprovable, correcting the asymmetry between the two cases in Gdels original argument.
Alright, so then why dont I just teach Rossers Theorem in my undergrad class, instead of Gdels?
Ill tell you why: because, when I teach Gdel to computer scientists, I like to sidestep the nasty details of how you formalize the concept of provability in F. (From a modern computer-science perspective, Gdel numbering is a barf-inducingly ugly hack!)
Instead, I simply observe Gdels Theorem as a trivial corollary of what I see as its conceptually-prior (even though historically-later) cousin: Turings Theorem on the unsolvability of the halting problem.
For those of you whove never seen the connection between these two triumphs of human thought: suppose we had a sound and complete (and recursively-axiomatizable, yadda yadda yadda) formal system F, which was powerful enough to reason about Turing machines. Then I claim that, using such an F, we could easily solve the halting problem. For suppose were given a Turing machine M, and we want to know whether it halts on a blank tape. Then wed simply have to enumerate all possible proofs in F, until we found either a proof that M halts, or a proof that M runs forever. Because F is complete, wed eventually find one or the other, and because F is sound, the proofs conclusion would be true. So wed decide whether M halts. But since we already know (thanks to Mr. T) that the halting problem is undecidable, we conclude that F cant have existed.
Look ma, noGdel numbers!
The New Observation
The above discussion leads to an obvious question:
Is there also a proof of Rossers Theorem that uses only Turing machinesanalogous to the computer-scientist-friendly proof we just gave for the original Incompleteness Theorem?
My initial worry was that the answer would be no. For not only is Rossers sentence more complicated thanGdels, but it depends essentially on an ordering of proofsand its not clear what such an ordering would correspond to in the world of Turing machines.
Why did this worry me? Because it threatened my conviction that computer programs are really at the core of Gdels Theorem, whatever any tradition-minded philosopher or logician might claim to the contrary. If even the modest step from Gdel to Rosser required abandoning the computability perspective, then my faith in the Almighty Turing Machine would be shaken.
But never fear! A few months ago, I found a short, simple, Turing-machine-based proof of Rossers Theorem. While this seemed too small to write up as a paper, Id never seen it before (please let me know if you have!), so I thought Id share it here. (Update: Makoto Kanazawa points me to a basically-similar argument in Kleenes 1967 textbook. So, you can consider what follows to be a popularization of Kleene.)
The first step is to define the following variant of the halting problem:
The Consistent Guessing Problem
Given as input a description of a Turing machine M:

If M accepts on a blank tape, then accept.
If M rejects on a blank tape, then reject.
If M runs forever on a blank tape, then either accept or reject, but in any case, halt!

Its easy to show that theres no Turing machine to solve the Consistent Guessing Problem, by a modification (arguably, even a simplification) of Turings original argument for the halting problem. Indeed, I put the unsolvability of the Consistent Guessing Problem on last semesters midterm, and at least half the students got it. (Damn! I guess I cant use that one again.)
See it yet? No? Alright, so let P be a Turing machine that solves the Consistent Guessing Problem. Then we can easily modify P to produce an new Turing machine Q that, given as input a description M of another Turing machine M:

Rejects if M(M) accepts.
Accepts if M(M) rejects.
Halts (either accepting or rejecting) if M(M) runs forever.

Now run Q on its own description Q. If Q(Q) accepts, then it rejects; if Q(Q) rejects, then it accepts. So the only remaining option is that Q(Q) runs forever, violating the third condition.
From the unsolvability of the Consistent Guessing Problem, I claim that Rossers Theorem follows. For suppose we had a complete and consistent (but not necessarily sound!) formal system F, which was powerful enough to talk about Turing machines. Then using F, we could solve the Consistent Guessing Problem, as follows. Given as input a Turing machine description M, start enumerating all possible proofs and disproofs of the statement M accepts on a blank tape. Accept as soon as you find a proof, or reject as soon as you find a disproof.
Because F is complete, you must eventually find either a proof or a disproof (and therefore halt, either accepting or rejecting). Also, because F is consistent, if M really rejects then F cant prove that M accepts, while if M really accepts then F cant prove that M doesnt accept (since in either case, the contradiction could be discovered in finite time). So youll accept if M accepts and reject if M rejects. But this means that youre solving Consistent Guessing! Since we already showed theres no Turing machine to solve Consistent Guessing, we conclude that F cant have existed.
QED: the moral order of the universe is restored, and the Turing machines exalted position at the base of all human thought reaffirmed.
(Incidentally, you might wonder whetherGdels Second Incompleteness Theorem, on the impossibility of a consistent F proving its own consistency, can also be proved in a Turing-machine-centric way. To anticipate your question, the answer is yesand better yet, it even involves Kolmogorov complexity! See, for example, this beautiful recent paper by Shira Kritchman and Ran Raz.)
So, will Gdels Theorem always and forevermore be taught as a centerpiece of computability theory, and will theGdel numbers get their much-deserved retirement? I dont see a reason why that shouldnt happenbut alas, the consistency of my prediction isnt enough to imply its metatheoretic truth.Im mad as hell and Im not gonna take it anymore

What am I mad about?  Oh, God.
Im mad about Bush receiving Michael Crichton in the White House, to be reassured that climate change is a hoax even as the Northwest Passage opens up for the first time in a few million years.  Im mad about the Democrats failure to capitalize on the Enron scandal, and particularly the infamous Grandma Millie tapes (having just watched the film Enron: The Smartest Guys in the Room).  Im mad about Pius XII, the man who arm-twisted Germanys 23 million Catholics into cooperating with the Nazis despite their initial opposition, being considered for sainthood (Im in the middle of a book about it, Hitlers Pope by John Cornwell).  Im mad about my own procrastination in writing a popular article for Scientific American about the limits of quantum computing.  Im mad about a public school system that condemns any math or science tracking as elitist, while the football and basketball programs arent similarly condemned.  Im mad about people who declare that a proof of P!=NP would be worthless, since what if there were an algorithm for SAT that took 1.0000001n steps?, as if no one had ever had such a perceptive insight in the 50-year history of complexity theory.
But, as for the not gonna take it anymore part, one does have to restrict ones focus a bit.  So recently I decided to concentrate my anger on overpriced journal subscriptions  and in particular, on the gouging of university libraries by companies like Kluwer and Elsevier.  Ive  just written a three-page polemic about this issue (technically a book review), which is going to appear in SIGACT News, possibly with a rebuttal and counter-rebuttal.  Id be grateful for comments.  Note that what I write about scientists peculiar anger deficiency applies to many other issues, global warming being one obvious example.  There comes a time when its no longer enough to be correct: you also have to be angry!
Thanks to Bill Gasarch, both for commissioning the review and for suggesting the title of this post.
Note: My diatribe is also available in HTML and postscript.Force multiplier

We live in perilous times. Within a few days, the United States might default on its debt, plunging the country into an unprecedented catastrophe. Meanwhile, the tragedy in Norway (a country Ill visit for the first time next month) reminds us that the civilized world faces threats from extremists of every ideology. All this news, of course, occurs against the backdrop of record-breaking heatwaves, the decimation of worldwide fish stocks, the dwindling supply of accessible oil, and the failure of the Large Hadron Collider to find supersymmetry.
But although the future may have seldom seemed bleaker, I want people to know that we in MITs complexity theory group are doing everything we can to respond to the most pressing global challenges. And nothing illustrates that commitment better than a beautiful recent paper by my PhD student Andy Drucker (who many of you will recognize from his years of insightful contributions to Shtetl-Optimized: most recently, solving an open problem raised by my previous post).
Briefly, what Andy has done is to inventand demonstratea breakthrough method by which anyone, including you, can easily learn to multiply ten-digit numbers in your head, using only a collection of stock photos from Flickr to jog your memory.
Now, you might object: but isnt it cheating to use a collection of photos to help you do mental mathjust like it would be cheating to use pencil and paper? However, the crucial point is that youre not allowed to modify or rearrange the photos, or otherwise use them to record any information about the computation while youre performing it. You can only use the photos as aids to your own memory.
By using his method, Andywho has no special mental-math training or experience whatsoeverwas able to calculate 9883603368 x 4288997768 = 42390752785149282624 in his head in a mere seven hours. I havent tried the method myself yet, but hope to do so on my next long plane flight.
Crucially, the Flickr method isnt limited to multiplication. It works for any mental memorization or calculation taskin other words, for simulating an arbitrary Boolean circuit or Turing machine. As I see it, this method provides probably the most convincing demonstration so far that the human brain, unaided by pencil and paper, can indeed solve arbitrary problems in the class P (albeit thousands of times more slowly than a pocket calculator). In his paper, Andy discusses possible applications of the method for cognitive science: most notably, using it to test conjectures about the working of human memory. If that or other applications pan out, thenlike many other research projects that seem explicitly designed to be as useless as possibleAndys might end up failing at that goal.An entry contained in a blog

Time for a little pet peeve.  Ive gotten numerous emails that say something like, In your last blog when what they mean is, In your last blog entry
A blog is a collection of entries (or posts).  The set of possible entries is only countably infinite, but the set of possible blogs has the cardinality of the continuum.
(In practice, the positivity of the cosmological constant does impose an upper bound of about 210^122 on the number of possible blogs.  But thats merely a contingent fact about our universe, and is not intrinsic to the notion of blog.  Logically, theres no reason for a blog ever to end  even though any particular entry, including this one, must.)Why Philosophers Should Care About Computational Complexity

Update (August 11, 2011): Thanks to everyone who offered useful feedback! I uploaded a slightly-revised version, adding a note of humility to the introduction, correcting the footnote about Cramers Conjecture, incorporating Gil Kalais point that an efficient program to pass the Turing Test could exist but be computationally intractable to find, adding some more references, and starting the statement of Valiants sample-size theorem with the word Consider instead of Fix

I just posted a 53-page essay of that name to ECCC; its what I was writing pretty much nonstop for the last two months. The essay will appear in a volume entitled Computability: Gdel, Turing, Church, and beyond, which MIT Press will be publishing next year (to coincide with Alan T.s hundredth birthday).
Note that, to explain why philosophers should care about computational complexity, I also had to touch on the related questions of why anyone should care about computational complexity, and why computational complexity theorists should care about philosophy. Anyway, heres the abstract:
One might think that, once we know something is computable, how efficiently it can be computed is a practical question with little further philosophical importance. In this essay, I offer a detailed case that one would be wrong. In particular, I argue that computational complexity theorythe field that studies the resources (such as time, space, and randomness) needed to solve computational problemsleads to new perspectives on the nature of mathematical knowledge, the strong AI debate, computationalism, the problem of logical omniscience, Humes problem of induction and Goodmans grue riddle, the foundations of quantum mechanics, economic rationality, closed timelike curves, and several other topics of philosophical interest. I end by discussing aspects of complexity theory itself that could benefit from philosophical analysis.
Weighing in with 70 footnotes and 126 references, the essay is basically a huge, sprawling mess; I hope that at least some of you will enjoy getting lost in it. Id like to thank my editor, Oron Shagrir, for kicking me for more than a year until I finally wrote this thing.My day job

Youve probably spent days, or even months, wondering why I dont update this blog more often.  What could possibly be more important to my career  besides napping, web surfing, napping again, or watching Jon Stewart?
So its time to come clean: besides my gig at Shtetl-Optimized, I also have a day job, most of which is actually performed at night.  Greg Kuperberg, who used to be my most regular commenter before he went M.I.A., has a similar day job.  If you dont already know what this day job is, its a little hard to explain.  We barely understand it ourselves.  One thing I can say is that it involves the production of documents like the following:
S. Aaronson and G. Kuperberg,  Quantum Versus Classical Proofs and Advice, quant-ph/0604056.
This paper studies whether quantum proofs are more powerful than classical proofs, or in complexity terms, whether QMA=QCMA. We prove two results about this question. First, we give a quantum oracle separation between QMA and QCMA. More concretely, we show that any quantum algorithm needs (sqrt(2n/(m+1))) queries to find an n-qubit marked state |>, even if given an m-bit classical description of |> together with a quantum black box that recognizes |>. We also prove a matching upper bound. Second, we show that, in the one previously-known case where quantum proofs seemed to help, classical proofs are basically just as powerful. In particular, Watrous gave a QMA protocol for verifying non-membership in finite groups. Under plausible group-theoretic assumptions, we give a QCMA protocol for the same problem. Even with no assumptions, our protocol makes only polynomially many queries to the group oracle. Both of our results apply equally to the problem of quantum versus classical advice  that is, of whether BQP/qpoly equals BQP/poly. We end with some conjectures about quantum versus classical oracles, and about the problem of achieving a classical oracle separation between QMA and QCMA.
Alright, suppose youre King Arthur.  Merlin, your staff wizard, claims to have solved a very hard math problem (a Holy Grail, so to speak) on which your entire kingdom depends.  The problem might involve, say, the speed of an African swallow, or the best kind of oil in which to boil heretics  the details arent important.
Being suspicious of wizards, you want to check Merlins solution, but being a king, you dont have much time to do it.  You do, however, have a quantum computer at hand (why not?).  Heres the question: is there anything Merlin could convince you of by giving you a quantum-mechanical superposition, that he couldnt convince you of by just communicating classically?
QMA, which stands for Quantum Merlin Arthur, is (basically) the class of problems for which Merlin could feasibly convince you of the answer by giving you a quantum state.  QCMA, which stands for Quantum Classical Merlin Arthur, is the class of problems for which Merlin could feasibly convince you of the answer by just communicating classically.  (Some people have suggested changing the acronym to CMQA, for Classical Merlin Quantum Arthur, since Arthur has the quantum computer while Merlin has to communicate classically.)
The key question is whether QMA and QCMA are equal.  So, do Greg and I answer that question in our paper?  Of course not  are you nuts?!  All we do is get closer to answering it than anyone before.  We do so by giving two new pieces of evidence: one suggesting that QMA and QCMA are equal, and another suggesting that theyre not.  You might not realize it, but this represents Progress.
To those who arent in the business, all of this medieval quantum intrigue might raise a question: why do we bother?  Why do we spend months writing papers that (if were lucky) maybe a hundred people will ever be aware of, and ten will ever understand?  Well, Greg can answer for himself. As for me, Ive always liked the answer once given by Bertrand Russell.  And no, this isnt my serious or official answer (nor was it Berties), but its a fine response to anyone who has to ask.
a word of advice to such of my hearers as may happen to be professors. I am allowed to use plain English because everybody knows that I could use mathematical logic if I chose. Take the statement: Some people marry their deceased wives sisters. I can express this in language which only becomes intelligible after years of study, and this gives me freedom. I suggest to young professors that their first work should be written in a jargon only to be understood by the erudite few. With that behind them, they can ever after say what they have to say in a language understanded of the people.Ask Me Anything

Update (8/16): Phew! By my count, Ive answered 139 questions over the past few days. Thanks so much to everyone for submitting them, and please dont submit any more!
Incidentally, to those of you who complain (correctly) that I no longer update this blog enough, theres a simple solution that should carry you through at least the next year. Namely, just read a few Ask Me Anything answers every week! To help you with that, Ive compiled the following abridged table of contents to my uninformed spoutings:

Whether P=NP would let you violate the Second Law
Whether mathematicians will (still) like complexity theory in the year 2100
Transhumanism and its relation to quantum computing
The hardness of simulating Newtonian physics
How much Id pay for a D-Wave One
My views on mathematical definiteness, favorite areas of CS, and favorite philosophers
How hard can problems in P get?
The higher education bubble, and whether people should think twice before going to college
Will the center of scientific gravity shift from the US to China?
My creative process (such as it is), and whether Id leave academia
Israel, Libya, Egypt
Worst-case versus best-case running time
Favorite ice cream
Favorite sci-fi writer
The status of my $25 Challenge
Wikipedia, and nerd versus Jew
How Umesh Vazirani manages students
Free jazz
Neanderthal-level machine intelligence
The value of oracles
Decision problems versus function problems
Software patents
Quantum computing and complexity breakthroughs of the past decade
Super-strong derandomization, and what Id ask an alien
Terry Tao
How I justify attending conferences
Scientific work in languages other than English
Simple things in math and CS that I dont understand
Whether Id rather solve P vs. NP or meet aliens
Borders of a Palestinian state
Why 20% of Americans cant locate the US on a world map
My greatest fears
Open-access journals
The existence of God
MIT undergrads
The history of complexity theory, and why IP=PSPACE should hold
Favorite movie, favorite novel, favorite theorem
Which charity Id donate $1,000,000 to
Favorite quantum information results of the last year
My location on the political spectrum
The 1-year anniversary of the Deolalikar Affair
Teaching people the difference between rationalism and empiricism
What happened to Physics for Doofuses?
What happened to Quantum Computing Since Democritus?
Proving P!=NP by exploiting structure of specific NP-complete problems
Zionism, pacifism, Iraq, Vietnam, death penalty, abortion
Drugs and alcohol
Computer-assisted theorem proving
Why to care about P vs. NP, and whether computers will solve it first
Obama
Whether I ever worked on P vs. NP
Yellow books
Interpreting barriers to proving P!=NP as logical independence statements
The nature of time
She believes in ghosts, hes a scientific rationalist
Research projects for undergrads
Classification of polynomial-time algorithms
Is the universe finite or infinite?
Quantum algorithms beyond Shor/Grover/quantum simulation
Will theoretical computer science converge with psychology?
Are sexual preferences socially constructed?
Should religions be judged by their scriptures?
What to do if you think you can multiply matrices in near-linear time
MathCamp
Would I want P to equal NP?
My late cat
Bosons versus photons
The relativization operator and Leibnizs Law
Do I feel guilty about my advantages, as I dine in exclusive Boston eateries?
The Aaron Swartz case



Update: Thanks for the many, many, many great questions! To keep things slightly under control, Ill be fielding questions that are asked before 9PM EST tonight.
Also, sorry my blog went down for an hour! I always count on Bluehost to not be there when I need it.

Alright, I put it off for most of the summer, but I guess its as good a time as any, now that (a) Im finally done philosophizing for a while and (b) my wife Dana is away at a workshop, her civilizing and nerdiness-moderating influences temporarily absent.
So, by popular demand, and as promised a couple months ago, for the next 24 hours (with intermittent sleep breaks), Ill once again be fielding any and all questions in the comments section. Four simple ground rules:

No multi-part questions: one question per comment and three total per person.
While you can ask anything, if its too hostile, nosy, or irritating I might not answer it
Ill only answer the first three questions about academic career advice (since in previous Ask Me Anything posts, that topic tended to drown out everything else).
No questions that require me to read an article, watch a video, etc.Al?xes in the news

Alex Halderman, University of Michigan computer security professor and my best friend from childhood (see previous Shtetl-Optimized coverage here and here), has been in the news again, with a new Internet anti-censorship system called Telex that he co-developed with Ian Goldberg, Eric Wustrow, and Scott Wolchok (see, e.g., here, here, here for more info). Basically, Telex would let interested governments or ISPs help the citizens of (say) China or Iran access content that their governments are trying to block. Having gotten hold of the Telex software (say, from a friend), the Chinese or Iranian websurfer would access an innocuous-looking website, but insert cryptographic tags into its HTTPS requests to alert an ISP along the way (not an ISP inside China or Iran) that it wanted to activate the anti-censorship service.
If you happen to be a high-level official at the State Department or a three-letter agency, or a wealthy philanthropist, I can think of few smarter things you could do than to support this kind of effort. The system that Alex and his collaborators envision wouldnt be trivial to deploy, but its certainly cheaper than aircraft carriers.
Meanwhile, in other Al?x news, my cousin Alix Genter was splashed across the cover of Philadelphia Daily News this morning (you can read the accompanying article here). What happened is that the owner of a bridal store in New Jersey called Here Comes the Bride refused to sell Alix a wedding dress, after finding out that Alix plans to marry another woman in New York State. So now supporters of gay rights are having a field day with Here Comes the Brides Yelp page.
I wish both of these Al?xes the best, as they work toward a better world in their different ways.Chicken Soup for the Complexity Soul

From the comments on my last post:
scott would you be so kind, if you have some spare time, to post a list of textbooks that youve read in math and cs?
Now this is the kind of blog topic I like: zero expenditure of emotional energy required; lends itself to snarky one-liners.   So heres a list of math and CS books that Ive read and you should too. Pitifully incomplete, but enough to get you started.

Computational Complexity, by Christos Papadimitriou
The Iliad of complexity.  An epic poem to read and reread until you can quote it by section number, until the pages fall out of the spine.  Christos is not a textbook writer but a bard  and the only problem with his tale is that it ends around the late 1980s.  Christos, if youre reading this: we want an Odyssey!


Gems of Theoretical Computer Science, by Uwe Schning and Randall Pruim
The proofs are terse, but I love the division into short, digestible gems.  Keep this one on your night table or by the toilet.  (But not until youve mastered Papadimitriou and are ready to wield BP operators like a Fortnow.)


Computational Complexity: A Modern Approach, by Sanjeev Arora
The newest entrant in the arena.  Best of all is that the current draft is free and online.  I love Sanjeevs use of lowerbound as one word.


Lecture notes by Luca Trevisan, Umesh Vazirani, John Preskill, 
I dont know if these count as textbooks, but read them anyway.


Quantum Computation and Quantum Information, by Mike & Ike (Michael Nielsen and Isaac Chuang)
The best quantum computing book.  I open it to the section on fidelity and trace distance pretty much every time I write a paper.  (Ive heard the other sections are excellent too.)


Randomized Algorithms, by Rajeev Motwani and Prabhakar Raghavan
Chernoff bounds, random walks, second eigenvalues, PCPs  a 1-1/e fraction of what you need to know about randomness.


Computers and Intractability: A Guide to the Theory of NP-Completeness, by Michael Garey and David Johnson
Changed my life when I read it at fifteen.  Since then its sat on my shelf, but Id take it down if I actually had to prove something NP-complete.


An Introduction to Computational Learning Theory, by Michael Kearns and Umesh Vazirani
Since this book was co-authored by my advisor, Ill refrain from saying anything about it except that its excellent.  (And short.)


Artificial Intelligence: A Modern Introduction, by Stuart Russell and Peter Norvig
Almost (but not quite) made me go into AI.  My favorite chapter is the last one, which carefully demolishes the arguments of John Searle and the other confuseniks.


Complexity and Real Computation, by Lenore Blum, Felix Cucker, Michael Shub, and Steve Smale
Decidability of the Mandelbrot set?  P versus NP over the complex numbers?  I may be a Boolean chauvinist, but I knows an elegant theory when I sees one.


The Art of Computer Programming, by Donald Knuth
Three-volume set looks mighty impressive on a shelf, but beware of MMIX and constant factors.


Set Theory and the Continuum Hypothesis, by Paul Cohen
The book that gave me the illusion of understanding logic.  Short and hard.  Prerequisites: None.


Topology: A First Course, by James Munkres
What every math book should be.


The Book of Numbers, by John Conway and Richard Guy
Since this is a popular book, obviously I couldnt have learned anything new from it, but it was nice to refresh my memory about octonions, Heegner numbers, and why e sqrt(163) is within 0.00000000000075 of an integer.


The Road to Reality: A Complete Guide to the Laws of the Universe, by Roger Penrose
Preface: Even if you hated fractions in elementary school, have no fear!  Ive tried to make this book accessible to you as well.
Chapter 2: Consider a Lie algebra of sheaves over the holomorphic fibre bundle PZL(Zn,5)  (Not really, but close.)
I struggled through Penroses masterpiece, but by the end, I felt like Id come as close as I ever had (and possibly ever will) to understanding post-1920s particle physics and the math underlying it.  If youre willing to invest the effort,  youll find The Road to Reality so excellent that it cancels out Shadows of the Mind, like an electron annihilating its positronic companion.6.893 Philosophy and Theoretical Computer Science

I thought Id let Shtetl-Optimized readers know about an experimental new course Im teaching this fall (starting tomorrow): 6.893 Philosophy and Theoretical Computer Science. The course was directly inspired by my Why Philosophers Should Care About Computational Complexity essay, and will cover many of the same topics. Heres the description:
This new offering will examine the relevance of modern theoretical computer science to traditional questions in philosophy, and conversely, what philosophy can contribute to theoretical computer science. Topics include: the status of the Church-Turing Thesis and its modern polynomial-time variants; quantum computing and the interpretation of quantum mechanics; complexity aspects of the strong-AI and free-will debates; complexity aspects of Darwinian evolution; the claim that computation is physical; the analog/digital distinction in computer science and physics; Kolmogorov complexity and the foundations of probability; computational learning theory and the problem of induction; bounded rationality and common knowledge; new notions of proof (probabilistic, interactive, zero-knowledge, quantum) and the nature of mathematical knowledge. Intended for graduate students and advanced undergraduates in computer science, philosophy, mathematics, and physics. Participation and discussion are an essential part of the course.
If youd like to follow remotely, the course homepage has links to lots of interesting readings, and students will also be posting their personal reactions to the class discussions as the semester progresses.
Update (Sept. 7): By overwhelming request not only from readers but from students in the class, and with several of those students extremely kind assistance, we will be making audio recordingsalthough the audio quality probably wont be great.Doofioso

From Discovery News comes a report that Bernardo Provenzano, the recently-arrested Boss of Bosses of the Sicilian Mafia, was finally caught because he relied on an encryption system that consisted of .. [cue the opening notes of The Godfather theme song] .. adding 3 to the numerical value of each letter.   Apparently this has really been a bad week for evil masterminds in Italy.The First Law of Complexodynamics

A few weeks ago, I had the pleasure of attending FQXis Setting Time Aright conference, part of which took place on a cruise from Bergen, Norway to Copenhagen, Denmark. (Why arent theoretical computer science conferences ever held on cruises? If nothing else, it certainly cuts down on attendees sneaking away from the conference venue.) This conference brought together physicists, cosmologists, philosophers, biologists, psychologists, and(for some strange reason) one quantum complexity blogger to pontificate about the existence, directionality, and nature of time. If you want to know more about the conference, check out Sean Carrolls Cosmic Variance posts here and here.
Sean also delivered the opening talk of the conference, during which (among other things) he asked a beautiful question: why does complexity or interestingness of physical systems seem to increase with time and then hit a maximum and decrease, in contrast to the entropy, which of course increases monotonically?
My purpose, in this post, is to sketch a possible answer to Seans question, drawing on concepts from Kolmogorov complexity. If this answer has been suggested before, Im sure someone will let me know in the comments section.
First, some background: we all know the Second Law, which says that the entropy of any closed system tends to increase with time until it reaches a maximum value. Here entropy is slippery to definewell come back to that laterbut somehow measures how random or generic or disordered a system is. As Sean points out in his wonderful book From Eternity to Here, the Second Law is almost a tautology: how could a system not tend to evolve to more generic configurations? if it didnt, those configurations wouldnt be generic! So the real question is not why the entropy is increasing, but why it was ever low to begin with. In other words, why did the universes initial state at the big bang contain so much order for the universes subsequent evolution to destroy? I wont address that celebrated mystery in this post, but will simply take the low entropy of the initial state as given.
The point that interests us is this: even though isolated physical systems get monotonically more entropic, they dont get monotonically more complicated or interesting. Sean didnt define what he meant by complicated or interesting hereindeed, defining those concepts was part of his challengebut he illustrated what he had in mind with the example of a coffee cup. Shamelessly ripping off his slides:

Entropy increases monotonically from left to right, but intuitively, the complexity seems highest in the middle picture: the one with all the tendrils of milk. And same is true for the whole universe: shortly after the big bang, the universe was basically just a low-entropy soup of high-energy particles. A googol years from now, after the last black holes have sputtered away in bursts of Hawking radiation, the universe will basically be just a high-entropy soup of low-energy particles. But today, in between, the universe contains interesting structures such as galaxies and brains and hot-dog-shaped novelty vehicles. We see the pattern:


In answering Seans provocative question (whether theres some law of complexodynamics that would explain his graph), it seems to me that the challenge is twofold:

Come up with a plausible formal definition of complexity.
Prove that the complexity, so defined, is large at intermediate times in natural model systems, despite being close to zero at the initial time and close to zero at late times.

To clarify: its not hard to explain, at least at a handwaving level, why the complexity should be close to zero at the initial time. Its because we assumed the entropy is close to zero, and entropy plausibly gives an upper bound on complexity. Nor is it hard to explain why the complexity should be close to zero at late times: its because the system reaches equilibrium (i.e., something resembling the uniform distribution over all possible states), which were essentially defining to be simple. At intermediate times, neither of those constraints is operative, and therefore the complexity could become large. But does it become large? How large? How could we predict? And what kind of complexity are we talking about, anyway?
After thinking on and off about these questions, I now conjecture that they can be answered using a notion called sophistication from the theory of Kolmogorov complexity. Recall that the Kolmogorov complexity of a string x is the length of the shortest computer program that outputs x (in some Turing-universal programming languagethe exact choice can be shown not to matter much). Sophistication is a more  well, sophisticated concept, but well get to that later.
As a first step, lets use Kolmogorov complexity to define entropy. Already its not quite obvious how to do that. If you start, say, a cellular automaton, or a system of billiard balls, in some simple initial configuration, and then let it evolve for a while according to dynamical laws, visually it will look like the entropy is going up. But if the system happens to be deterministic, then mathematically, its state can always be specified by giving (1) the initial state, and (2) the number of steps t its been run for. The former takes a constant number of bits to specify (independent of t), while the latter takes log(t) bits. It follows that, if we use Kolmogorov complexity as our stand-in for entropy, then the entropy can increase at most logarithmically with tmuch slower than the linear or polynomial increase that wed intuitively expect.
There are at least two ways to solve this problem. The first is to consider probabilistic systems, rather than deterministic ones. In the probabilistic case, the Kolmogorov complexity really does increase at a polynomial rate, as youd expect. The second solution is to replace the Kolmogorov complexity by the resource-bounded Kolmogorov complexity: the length of the shortest computer program that outputs the state in a short amount of time (or the size of the smallest, say, depth-3 circuit that outputs the statefor present purposes, it doesnt even matter much what kind of resource bound we impose, as long as the bound is severe enough). Even though theres a computer program only log(t) bits long to compute the state of the system after t time steps, that program will typically use an amount of time that grows with t (or even faster), so if we rule out sufficiently complex programs, we can again get our program size to increase with t at a polynomial rate.
OK, that was entropy. What about the thing Sean was calling complexitywhich, to avoid confusion with other kinds of complexity, from now on Im going to call complextropy? For this, were going to need a cluster of related ideas that go under names like sophistication, Kolmogorov structure functions, and algorithmic statistics. The backstory is that, in the 1970s (after introducing Kolmogorov complexity),Kolmogorov made an observation that was closely related to Seans observation above. A uniformly random string, he said, has close-to-maximal Kolmogorov complexity, but its also one of the least complex or interesting strings imaginable. After all, we can describe essentially everything youd ever want to know about the string by saying its random! But is there a way to formalize that intuition? Indeed there is.
First, given a set S of n-bit strings, let K(S) be the number of bits in the shortest computer program that outputs the elements of S and then halts. Also, given such a set S and an element x of S, let K(x|S) be the length of the shortest program that outputs x, given an oracle for testing membership in S. Then we can let the sophistication of x, or Soph(x), be the smallest possible value of K(S), over all sets S such that

xS and
K(x|S)  log2(|S|)  c, for some constant c. (In other words, one can distill all the nonrandom information in x just by saying that x belongs that S.)

Intuitively, Soph(x) is the length of the shortest computer program that describes, not necessarily x itself, but a set S of which x is a random or generic member. To illustrate, any string x with small Kolmogorov complexity has small sophistication, since we can let S be the singleton set {x}. However, a uniformly-random string also has small sophistication, since we can let S be the set {0,1}n of all n-bit strings. In fact, the question arises of whether there are any sophisticated strings! Apparently, after Kolmogorov raised this question in the early 1980s, it was answered in the affirmative by Alexander Shen (for more, see this paper by Gcs, Tromp, and Vitnyi). The construction is via a diagonalization argument thats a bit too complicated to fit in this blog post.
But what does any of this have to do with coffee cups? Well, at first glance, sophistication seems to have exactly the properties that we were looking for in a complextropy measure: its small for both simple strings and uniformly random strings, but large for strings in a weird third category of neither simple nor random. Unfortunately, as we defined it above, sophistication still doesnt do the job. For deterministic systems, the problem is the same as the one pointed out earlier for Kolmogorov complexity: we can always describe the systems state after t time steps by specifying the initial state, the transition rule, and t. Therefore the sophistication can never exceed log(t)+c. Even for probabilistic systems, though, we can specify the set S(t) of all possible states after t time steps by specifying the initial state, the probabilistic transition rule, and t. And, at least assuming that the probability distribution over S(t) is uniform, by a simple counting argument the state after t steps will almost always be a generic element of S(t). So again, the sophistication will almost never exceed log(t)+c. (If the distribution over S(t) is nonuniform, then some technical further arguments are needed, which I omit.)
How can we fix this problem? I think the key is to bring computational resource bounds into the picture. (We already saw a hint of this in the discussion of entropy.) In particular, suppose we define the complextropy of an n-bit string x to be something like the following:
the number of bits in the shortest computer program that runs in n log(n) time, and that outputs a nearly-uniform sample from a set S such that (i) xS, and (ii) any computer program that outputs x in n log(n) time, given an oracle that provides independent, uniform samples from S, has at least log2(|S|)-c bits, for some constant c.
Here n log(n) is just intended as a concrete example of a complexity bound: one could replace it with some other time bound, or a restriction to (say) constant-depth circuits or some other weak model of computation. The motivation for the definition is that we want some complextropy measure that will assign a value close to 0 to the first and third coffee cups in the picture, but a large value to the second coffee cup. And thus we consider the length of the shortest efficient computer program that outputs, not necessarily the target string x itself, but a sample from a probability distribution D such that x is not efficiently compressible with respect to D. (In other words, x looks to any efficient algorithm like a random or generic sample from D.)
Note that its essential for this definition that we imposed a computational efficiency requirement in two places: on the sampling algorithm, and also on the algorithm that reconstructs x given the sampling oracle. Without the first efficiency constraint, the complextropy could never exceed log(t)+c by the previous argument. Meanwhile, without the second efficiency constraint, the complextropy would increase, but then it would probably keep right on increasing, for the following reason: a time-bounded sampling algorithm wouldnt be able to sample from exactly the right set S, only a reasonable facsimile thereof, and a reconstruction algorithm with unlimited time could probably then use special properties of the target string x to reconstruct x with fewer than log2(|S|)-c bits.
But as long as we remember to put computational efficiency requirements on both algorithms, I conjecture that the complextropy will satisfy the First Law of Complexodynamics, exhibiting exactly the behavior that Sean wants: small for the initial state, large for intermediate states, then small again once the mixing has finished. I dont yet know how to prove this conjecture. But crucially, its not a hopelessly open-ended question that one tosses out just to show how wide-ranging ones thoughts are, but a relatively-bounded question about which actual theorems could be proved and actual papers published.
If you want to do so, the first step will be to instantiate everything I said above with a particular model system and particular resource constraints. One good choice could be a discretized coffee cup, consisting of a 2D array of black and white pixels (the coffee and milk), which are initially in separated components and then subject to random nearest-neighbor mixing dynamics. (E.g., at each time step, we pick an adjacent coffee pixel and milk pixel uniformly at random, and swap the two.) Can we show that for such a system, the complextropy becomes large at intermediate times (intuitively, because of the need to specify the irregular boundaries between the regions of all-black pixels, all-white pixels, and mixed black-and-white pixels)?
One could try to show such a statement either theoretically or empirically. Theoretically, I have no idea where to begin in proving it, despite a clear intuition that such a statement should hold: let me toss it out as a wonderful (I think) open problem! At an empirical level, one could simply try to plot the complextropy in some simulated system, like the discrete coffee cup, and show that it has the predicted small-large-small behavior.  One obvious difficulty here is that the complextropy, under any definition like the one I gave, is almost certainly going to be intractable to compute or even approximate. However, one could try to get around that problem the same way many others have, in empirical research inspired by Kolmogorov complexity: namely, by using something you can compute (e.g., the size of a gzip compressed file) as a rough-and-ready substitute for something you cant compute (e.g., the Kolmogorov complexity K(x)). In the interest of a full disclosure, a wonderful MIT undergrad, Lauren Oullette, recently started a research project with me where shes trying to do exactly that. So hopefully, by the end of the semester, well be able to answer Seans question at least at a physics level of rigor! Answering the question at a math/CS level of rigor could take a while longer.
PS (unrelated). Are neutrinos traveling faster than light? See this xkcd strip (which does what I was trying to do in the Deolalikar affair, but better).Repentance

This morning I got an email pointedly criticizing several aspects of this blog  including my handling of laffaire Chad Okere, and my ridiculing (as opposed to answering) people who think that if P=NP, the major implication would be that airlines could schedule their flights better.  The author summed up his critique as follows:
I like your blog. I only wish it would be a little bit more about complexity theory and things at least vaguely related. You have a knack for writing, and for making hard things easy. Thats something which separates you from the large majority of the (blogging) complexity theorists. I understand that you blog in order to procrastinate, and that you have no special obligation to write about anything you dont want to write about, but I dont believe Im alone in thinking that such talent could nonetheless be used to better ends than writing about biting vaginas.
Godammit, I muttered.  Though he overestimates my talent, the dude has a point.  In my constant battle against predictability, Ive become too self-absorbed  like Frank Gehry designing the MIT Stata Center, or a Playboy model discoursing on international politics.  Ive neglected the meat-and-potatoes that readers want and expect from me.
So, welcome to a reconceptualized shtetl.  From now on Ill be sure to ladle out the heaping helpings of complexity you crave.  The danger, of course, is that as the earnestness and scientific-ness goes up, the sexual innuendoes, heavy-handed irony, ethnic jokes, and crass ridicule will decrease proportionately.  Rest assured that Ill guard against that possibility.What is the name of this post?

No need to thank me for my turnabout  weve got work to do.  Theres a new complexity class in town, and I need you to help me name it.
My new class is like P/poly, except that the polynomial-size advice cant be trusted  you have to verify it.  Or to put it another way, its like NP intersect coNP, except that theres only one witness for each input length.  Give me that witness, and Ill correctly decide every input of size n.  Give me a different witness, and for every input of size n Ill either output the right answer or else say I dont know.
Now, anyone could make up a name for this animal  even I could!  But I want the name to be naturally extensible to further classes.  For example, if (hypothetically speaking) I was able to use a new result about the learnability of quantum states to prove that AvgBQP/qpoly is contained in AvgQMA/poly, but my proof actually yielded the stronger result that AvgBQP/qpoly is contained in the subclass of AvgQMA/poly where theres only one QMA witness for each input length, then your naming convention should immediately give me a name for that subclass.
So let the christening commence!  And for extra credit, prove or (relative to an oracle) disprove that if my class contains NP, then P=NP.And while Im at it

Yaroslav Bulatov sent me the following nice question.  Given vectors (a1,,an) and (b1,,bn) in Rn, is there an efficient algorithm to decide whether sgn(a1x1++anxn) equals sgn(b1x1++bnxn) for all x in {0,1}n?  I could think about it myself, but wouldnt it be more fun to call upon the collective expertise of my readers?  After all, this is a Serious Blog now.  I await the observation thats eluded me for the past five minutes.In Defense of Kolmogorov Complexity

I got lots of useful and interesting feedback on my last post, though I also learned a valuable sociological lesson about the two kinds of complexity theory:
If you write about the kind of complexity theory that involves acronyms like NP, BQP/qpoly, and r.s.r., people will think the issues must be difficult and arcane, even if theyre not and can be understood with very little effort. By contrast, if you write about the kind of complexity theory that can be illustrated using pictures of coffee cups, people will think the issues can be sorted out with 15 seconds of thought, and will happily propose solutions that presuppose what needs to be explained, answer a different question, or fail in simple examples.
Seriously, a large number of commenters raised two important questions, which Id like to address forthwith in this followup post.
The first question is why I omitted the notion of coarse-graining, which plays a central role in many accounts of entropy and complexity. The short answer is that I shouldnt have omitted it. In fact, as both Sean Carroll and Luca Trevisan (among others) quickly pointed out, one can tell a perfectly-reasonable story about the coffee cup by defining the complextropy, not in terms of sophistication, but in terms of the ordinary Kolmogorov complexity of a coarse-grained or smeared-out state. If you define the complextropy that way, it should increase and then decrease as desired, and furthermore, its probably easier to prove that statement than using the sophistication-based definition (though both versions seem highly nontrivial to analyze).
So, the reason I turned to sophistication was basically just the mathematicians instinct to situate every concept in the most general structure where that concept makes sense. For example, why define connectedness for polygons in the Euclidean plane, if the concept makes sense for arbitrary topological spaces? Or in our case, why define complextropy for dynamical systems that happen to have a spatial structure over which one can coarse-grain, if the concept also makes sense for arbitrary dynamical systems whose evolution is computable by an efficient algorithm? Of course, [OPEN PROBLEM ALERT] it would be wonderful to know whether the two types of complextropy can be shown to be related for those dynamical systems for which they both make sense, or whether we can construct a convincing example that separates the two.
The second question is why I invoked Kolmogorov complexity in a discussion about thermodynamics: many people seemed to think that, by doing so, I was making some novel or controversial claim. I wasnt. People like Charles Bennett, Seth Lloyd, and Wojciech Zurek have employed Kolmogorov complexity as a useful language for thermodynamics since the 1980s; I was simply following in their footsteps. Basically, what Kolmogorov complexity lets you do is talk in a well-defined way about the entropy or randomness of an individual object, without reference to any ensemble from which the object was drawn. And this is often extremely convenient: notice that Kolmogorov complexity snuck its way in even when we defined complextropy in terms of coarse-graining!
Of course, if our dynamical system is probabilistic, then we always can talk instead about the actual entropy; in that case Kolmogorov complexity basically just amounts to a shorthand. On the other hand, if our system is deterministic, then talking about the (resource-bounded) Kolmogorov complexity seems essentialsince in that case theres no true randomness at all, only pseudorandomness.
But a few commenters went further, disparaging Kolmogorov complexity itself rather than just its application to a particular problem. Heres Shtetl-Optimized regular Raoul Ohio:
As usual, my DAH (Devils Advocate Hat) is on. This is convenient, because it allows you to comment on anything without doing the work to really understanding it. Thus I will proceed to disparage the notion of using Kolmogorov Complexity (KC) for anything but entertainment.
Math is a subject where a couple of interesting definitions and a few theorems can launch a subfield such as KC. I have never studied KC  but a brief reading of the subject suggests that it started as a joke, and today a lot of people are not in on it.
 the KC of things would change as knowledge in other fields progresses. For example, what is the KC of
 = 4.66920160910299067185320382, and
 = 2.502907875095892822283902873218 ?
These are Feigenbaums constants (http://en.wikipedia.org/wiki/Feigenbaum_constants). A couple of decades ago, no one knew anything about these numbers. With the concept of analyzing discrete dynamical systems by bifurcation diagrams in hand, these can be calculated with a short program. So, did KC() and KC() drop dramatically 20 odd years ago?
using KC reminds me of physics arguments that use the wave function for the universe. Sure, there must be such a thing, but it is hard to say much about it.
On the other side of the coin, the theorems and proofs in basic KC are rather similar to those in many fields of TCS, and many SO [Shtetl-Optimized] readers might not think of these as a joke
My intuition is that the entire concept of KC is ill-posed, to borrow a term from PDE.
In the interest of full disclosure, I must mention that often in the past I have thought some topic was a bunch of hooey until I understood it, after which I thought is was profound, just like listening to Lenard [sic] Cohen.
I wrote a reply to Raoul, and then decided that it should go into a top-level post, for the edification of Kolmogorov-skeptics everywhere. So without further ado:
Hi Raoul!
I think this is indeed one of those cases where if you understood more, youd see why your dismissal was wrong. And unlike with (say) art, music, or religion, the reasons why your dismissal is wrong can be articulated in words!
Contrary to what you say, K(x) is not undefinable: Ill define it right now, as the length of the shortest prefix-free program (in some fixed universal programming language) that prints x and then halts! K(x) is uncomputable, but thats a very different issue, and something thats been known since the 1960s.
Basically, what K(x) lets you do is give a clear, observer-independent meaning to the loose notion of there not existing any patterns in a string. Already from that statement, its obvious that K(x) is going to be hard to computefor as you correctly point out, detecting the existence or nonexistence of patterns is hard!
(Though contrary to what you say, K(Feigenbaums constant) didnt suddenly become small when Feigenbaum defined the constant, any more than 42038542390523059230 suddenly became composite when I wrote it down, probably for the first time in human history. Please dont tell me that you make no distinction between mathematical truths and our knowledge of them!)
The key point is that, even without being able to compute K(x) for most xs, you can still use the definition of K(x) to give meaning to hundreds of intuitions that otherwise wouldve remained forever at a handwaving level. For example:
The overwhelming majority of strings are patternless.
If a short computer program outputs a patternless string, then it can only be doing so by generating the string randomly.
And many, many less obvious statementsevery one of which can be upgraded to a theorem once you have a mathematical definition of patternlessness!
Furthermore, the idea of Kolmogorov complexity has actually inspired some important experimental work! For example, if you could compute K, then you could compute the similarity between two DNA sequences D1 and D2 by comparing K(D1)+K(D2) to K(D1,D2).
Of course you cant compute K, but you can compute useful upper bounds on it. For example, let G(x) be the number of bits in the gzip compression of the string x. Then comparing G(D1)+G(D2) to G(D1,D2) has turned out to be a very useful way to measure similarity between DNA sequences.
Its really no different from how, even though we can never say whether a curve in the physical world is continuous or not (since that would require infinitely precise measurements), the mathematical theories dealing with continuity (e.g., calculus, topology) can still be applied in physics in all sorts of ways.What happened in the world this week

A commenter named Daniel Quilp writes:
I am absolutely stunned that you have not posted an encomium to Steve Jobs. You are a computer science professor. Jobs was the most important innovator in the field. You claim you want to reach out to the public but fail to take advantage of this opportunity. Very sad, very disappointing.
Steve Jobs was indeed one of the great American innovators, and I was extremely sorry to hear about his passing. I was riveted by the NYT obituary, from which I learned many facts about Jobs that I hadnt known before. Personally, I plan honor his memory by buying an iPhone 4S at the Apple Store near my apartment when it comes out on the 14th. (I was debating between upgrading my 3GS to a 4S and switching to an Android, leaning toward 4S because of battery life. The desire to honor the great mans memory is what pushed me over the edge.)
As for why I didnt write an encomium before: well, frankly, I dont feel like being a theoretical computer scientist gives me any more of a connection to Steve Jobs than any of the hundreds of millions of people who use his products. And when I do blog about world events, people often accuse me of jumping on a bandwagon and having nothing original to say, and tell me to stick to complexity theory. Thats life as a blogger: not only is there nothing you can post, theres nothing you can refrain from posting, that someone, somewhere, wont be absolutely stunned by.
Even so, to anyone who was hurt or offended by my lack of a Steve Jobs post, Im sorry.
And as long as Im apologizing for silence about major news of the last week, Im also sorry that I failed to congratulate the Royal Swedish Academy of Sciences for two truly magnificent decisions: first, awarding the Nobel Prize in Physics to Adam Riess, Saul Perlmutter, and Brian Schmidt for the discovery of the cosmic acceleration (see these two Cosmic Variance posts for more); second, awarding the Nobel Prize in Chemistry to Dan Shechtman for the discovery of quasicrystals. If these two textbook-changing results dont deserve Nobel Prizes, nothing does.
Since its Erev Yom Kippur, let me hereby repent for all of my countless mistakes, omissions, and lapses of judgment here at Shtetl-Optimized over the past year. In the spirit of the Kol Nidre prayer, I also beg to be released from all survey articles that I promised to write, submissions that I promised to review, deadlines that I promised to meet, and emails that I promised to answer. (Of course, if I were conventionally religious, Id also have to repent for the very act of blogging on Yom Kippur.)Earth Day, Doomsday, and Chicken Little

Its Earth Day, so time for a brief break from my laserlike, day-long focus on complexity theory, and for my long-promised post about climate change.
Let me lay my cards on the table.  I think that were in the same position with climate change today that we were with Hitler in 1938.  That position, in case youre wondering, is on the brink of a shitstorm.  And as with the lead-up to that earlier shitstorm, some people are sanely worried, some are in active denial, and the rest are in passive denial  accepting the obvious if pressed, but preferring to think about more pleasant things like NP intersect coNP.  Its frustrating even to have to defend the worried view explicitly, since its so clear which way the debate will have been settled 50 years from now.
At the same time, I cant ignore that there are thoughtful, humane, intelligent people  just like there were in the 1930s  who downplay, equivocate over, and rationalize away the shitstorm that (again from my perspective) is gathering over our heads.
After all, isnt the climate change business more complicated than all that?  Do we even know the Earth is getting warmer?  Okay, so maybe we do know, but do we really know why?  Couldnt it just be a coincidence that were pumping out billions of tons of CO2 and methane each year, and 19th-century physics tells us that will make the temperature rise, and the temperature is in fact rising as predicted?  What about feedbacks like cloud cover, ocean absorbtion, and ice caps?  And sure, maybe the feedbacks could at most buy a few decades, and maybe some of them (like melting ice caps darkening the Earths surface) are rapidly making things worse rather than better, but even so, wouldnt the loss of some low-lying countries be more than balanced out by warmer winters in Ontario?  And granted, maybe if our goal was to run a massive, irreversible geophysics experiment on an entire planet, it might be smarter to start with (say) Venus or Mars instead of Earth, but still  wouldnt it be easier to adapt to a climate unlike any the planet has experienced in the last 200 million years than to drive Priuses instead of Cherokees?  Isnt it just a question of how to allocate resources, of how to maximize expected utility?  And arent there other risks we should be more worried about, like bird flu, or out-of-control nanorobots converting the planet into grey goo?
Ill tackle some of these questions in future posts or comments  though for most of them, the professionals at RealClimate can do a better job than I can.  Today I want to try a different tack: flying over most of this well-worn ground, and aiming immediately for the one place where the climate skeptics invariably end up anyway when all of their other arguments have been exhausted.  That place is the Chicken Little Argument.
Back in the 1970s, all you academics were screaming about overpopulation, and the oil shortage, and global cooling.  Thats right, cooling: the exact opposite of warming!  And before that it was radiation poisoning, or an accidental nuclear launch, and before that probably something else.  Yet time after time, the doomsayers were wrong.  So why should this time be any different?  Why should ours be the one time when the so-called crisis is real, when its not a figment of a few scientists overheated imaginations?
The first response, of course, is that sometimes the alarmists were right.  More than once, our civilization really did face an existential threat, only to escape it by a hair.  I already mentioned Hitler, but theres another example thats closer to the subject at hand.
In the 1970s, Mario Molina and F. Sherwood Rowland realized that chlorofluorocarbons, then a common refrigerant, propellant, and cleaning solvent, could be broken down by UV light into compounds that then attacked the ozone molecules in the upper atmosphere.  Had the resulting loss of ozone continued for much longer, the increased UV light reaching the Earths surface would eventually have decimated populations of plankton and cyanobacteria, which in turn could have destabilized much of the worlds food chain.
As with global warming today, the initial response of the chemical companies was to attack the ivory-tower, tree-hugging, funding-crazed, Cassandra-like messenger.  But in 1985, Joseph Farman, Brian Gardiner, and Jonathan Shanklin looked into a weird error in ozone measurements over Antarctica, which seemed to show more than half the ozone there disappearing from September to December.  When it turned out not to be an error, even Du Pont decided that planetary suicide wasnt in its best interest, and CFCs were phased out in most of the world by 1996.  We survived that one.
But theres a deeper response to the Chicken Little Argument, one that goes straight to the meat of the issue (chicken, I suppose).  This is that, when were dealing with indexical questions  questions of the form why us?  why were we born in this era rather than a different one?  we cant apply the same rules of induction that work elsewhere.
To illustrate, consider a hypothetical planet where the population doubles every generation, until it finally depletes the planets resources and goes extinct.  (Like bacteria in a petri jar.)  Now imagine that in every generation, there are doomsayers preaching that the end is nigh, who are laughed off by folks with more common sense.  By assumption, eventually the doomsayers will be right  their having been wrong in the past is just a precondition for there being a debate in the first place.  But theres a further point.  If you imagine yourself chosen uniformly at random among all people ever to live on the planet, then with about 99% probability, youll belong to one of the last seven generations.  The assumption of exponential growth makes it not just possible, but probable, that youre near the end.
Thats one formulation (though not the best one) of the infamous Doomsday Argument, which says (roughly speaking) that the probability of human history continuing for millions of years longer is less than one would navely expect, since if it did so continue, then we would occupy an improbable position near the very beginning of that history.   Obviously cavemen could have made the same argument, and they would have been wrong.  The point is that, if everyone in history makes the Doomsday Argument, then most people who make it (or a suitable version of it) will by definition be right.
On hearing the Doomsday Argument for the first time, almost everyone thinks there must be a fallacy somewhere.  But once you accept one key assumption, the Argument is a trivial consequence of Bayes Rule.  So what is that key assumption?  Its what Nick Bostrom, in one of the only metaphysical page-turners ever written, calls the Self-Sampling Assumption (SSA).  The SSA states that, if you consider a possible history of the world to have a prior probability p, and if that history contains N>0 people who you imagine you could have been, then you should judge the probability of your being a specific one of those people within that history to be p/N.  Sound obvious?  Well, you might imagine instead that you need to weight the probability of each history by the number of people in it  so that, if a history has ten times as many people who you could have been, then you would be ten times as likely to exist in that history in the first place.  Bostrom calls this alternative the Self-Indication Assumption (SIA).
Its not hard to show that switching from SSA to SIA exactly cancels out the effect of the Doomsday Argument  bringing you back to your nave prior probabilities for each possible history.  In short, if you accept SSA then the Doomsday Argument goes through, while if you accept SIA then it doesnt.
But before you buy that SIA not SSA bumper-sticker for your SUV, let me point out the downsides.  Firstly, SIA forces you to treat your own existence as a random variable  not as something you can just condition on!  Indeed, the image that springs to mind is that of a warehouse full of souls, not all of which will get picked to inhabit a body.  And secondly, assuming its logically possible for there to be a universe with an infinite number of people, SIA implies that we must live in such a universe.  Usually, if you reach a definite empirical conclusion starting from pure thought, your best bet is to look around you.  You might find yourself in a medieval monastery or an Amsterdam coffeeshop.
On the other hand, as Bostrom observed, the SSA carries some heavy baggage of its own.  For example, it suggests the following algorithm by which the first people ever to live, call them (I dunno) Adam and Eve, could solve NP-complete problems in polynomial time.  They simply guess a random solution, having formed the firm intention to

have children (leading eventually to an exponential number of descendants) if the solution is wrong, or
have no children if the solution is right.

(For this algorithm, it really does have to be Adam and Eve, not Adam and Steve.)  Heres the punchline: the prior probability of Adam and Eves choosing a wrong solution is close to 1, but under SSA, the posterior probability is close to 0.  For if Adam and Eve guess a wrong solution, then with overwhelming probability they wouldnt be Adam and Eve to begin with  they would be one of the numerous descendants thereof.
Indeed, theres a loony, crackpot paper showing that if Adam and Eve had a quantum computer, then they could even solve PP-complete problems in polynomial time.  Every day Im dreading the Exxon ad: If the assumptions underlying the Doomsday Argument were valid, its not just that Adam and Eve could solve NP-complete problems in polynomial time.  Modulo a plausible derandomization assumption, a theorem of S. Aaronson implies they could decide the entire polynomial hierarchy!  So go ahead, buy that monster SUV.
If this discussion seems hopelessly speculative, well, thats exactly the point.  The Doomsday Argument is hopelessly speculative, but not more so than the Chicken Little Argument.  Ultimately, both arguments rest on metaphysical assumptions about why were us and not someone else  about the probability of having been born into one historical epoch rather than another.  This is not the sort of question that science gives us the tools to answer.
For me, then, the Doomsday Argument is like an ethereal missile that neutralizes the opposing missile of the Chicken Little Argument  leaving the ground troops below to slog it out based on, you know, actual facts and evidence.  So I think the environmentalists message to the climate contrarians should be as follows: if you stick to the science, then we will too.  But if you fall back on your favorite lazy meta-argument  why should the task of saving the world have fallen to this generation, and not to some other one?  then dont be surprised to find that metareasoning cuts both ways.Why did I take so long to start a blog?

This is a question recently asked by Lance Fortnow. There are a few boring answers: I thought I wouldnt have time, what with my packed schedule of websurfing, procrastinating, and sleeping. I thought the human race had already overpopulated Gods green blogosphere. I thought the bandwagon had already passed in 2003, and there was no use chasing it now. I thought it would be presumptuous (as indeed it is).
But the real answer is that to run a successful blog, I knew Id have to write about what actually mattered to me  and that included more than just the latest arXiv preprints or bizarre complexity classes. Id have to state strong opinions, make my worst fears everyone elses business, probably offend some people, and probably embarrass myself. So before I did that, I wanted to make sure I could at least do it in the best, most eloquent words  words that couldnt possibly be misunderstood.
So what happened? Did I find those words? As you can see for yourself, I didnt. What happened is that, after finishing grad school and reaching an advanced age, I started to face my mortality. Before then, I could always justify inaction by telling myself I was still preparing for the rest of my life. But once youre in the rest of your life, if youre not actually living it, then what are you doing? It occurred to me that, if you wait for the perfect opportunity to start a weblog  or switch to a new research area, or ask someone out, or whatever it is you want to do  then youre essentially just committing delayed suicide. Im sorry if that sounds trite and obvious.
Efficiency matters. Time constraints change everything. How could I have forgotten?A hackers hacker

Before someone else is absolutely stunned by my silence, let me hereby note with great sadness that Dennis Ritchie, principal designer of C, co-designer of Unix, Turing Award winner, and one of the worlds legendary computer scientists, has passed away at 70. (See here for the NYT obituary, here for a more detailed ZDNet obituary, and here for Lance Fortnows encomium.) I didnt know Ritchie, but my father did, as a science and technology writer in the 70s and 80s. And I often saw Ritchie in the halls when I spent several summers working at Bell Labs in college. Mostly, though, I know Ritchie through the beautiful language he created. Its a testament to Cs elegance and simplicity that I, though extremely far from a hacker, find it almost as easy to express my thoughts in C as I do in my mother tongue, MS-DOS QBASIC.
Update (Oct. 26): AI pioneer and LISP inventor John McCarthy has passed away as well. Its been a tough month for computing revolutionaries.Alright, alright, back to complexity

Ive learned my lesson, at least for the next day or two.
And speaking of learning  in computational learning theory, theres an obvious algorithm for learning a function from random samples.  Heres the algorithm: output any hypothesis that minimizes the error on those samples.
Im being intentionally vague about what the learning model is  since as soon as you specify  a model, it seems like some version of that algorithm is what you want to do, if you want the best tradeoff between the number of samples and the error of your hypothesis.  For example, if youre trying to learn a Boolean function from a class C, then you want to pick any hypothesis from C thats consistent with all your observations.  If youre trying to learn a Boolean function based on noisy observations, then you want to pick any hypothesis that minimizes the total number of disagreements.  If youre trying to learn a degree-d real polynomial based on observations subject to Gaussian noise, then you want to pick any degree-d polynomial that minimizes the least-squared error, and so on.
Heres my question: is the obvious algorithm always the best one, or is there a case where a different algorithm needs asymptotically fewer samples?  That is, do you ever want to pick a hypothesis that disagrees with more of your observations over one that disagrees with less?
While Im on the subject, have you ever wished you could help Scott Aaronson do his actual research, and even be thanked  by name  in the acknowledgments of one of his papers?  Well then, dont miss this chance!  All you have to do is read this seminal paper by Alon, Ben-David, Cesa-Bianchi, and Haussler, and then tell me what upper bound on the sample complexity of p-concept learning follows from their results.  (Perversely, all they prove in the paper is that some finite number of samples suffices  must be a mathematician thing.)The pedophile upper bound

Lance Fortnow now has a post up about how wonderful Graham Spanier and Joe Paterno were, and how sorry he is to see them go.
For what its worth, I take an extremely different view. Id be thrilled to see the insane football culture at many American universitiesthe culture that Spanier and Paterno epitomizedbrought down entirely, and some good might yet come of the Penn State tragedy if it helps that happen. Football should be, as it is at MIT, one of many fine extracurricular activities that are available to interested students (alongside table tennis, glassblowing, robot-building), rather than a primary reason for a universitys existence.
Whats interesting about the current scandal is precisely that it establishes some finite upper bound on what people will tolerate, and thereby illustratesjust what it takesfor the public to turn on its football heroes. Certainlythe destruction of academic standards doesnt suffice (are you kidding?). More interestingly, sexism, sexual harassment, and ordinary rapeoffenses that have brought down countless male leaders in other fieldsbarely even make a dent in public consciousness where football stars are concerned. With child rape, by contrast, one can actually find a non-negligible fraction of Americans who consider it comparable in gravity to football. (Though, as the thousands of rioting Penn State students reminded us, thats far from a universal opinion.) Many commentators have already made the obvious comparisons to the Catholic Churchs abuse scandal, and the lesson for powerful institutions the world over is indeed a similar one: sure, imprison Galileo; by all means stay silent during the Holocaust; butdont protect pedophilescrossthatline, and your otherwise all-forgiving constituentsmight finally turn on you.
I should say that both of my parents are Penn State grads, and theyre bothdisgusted right now with the culture of hooliganism therea culture that was present even in the late 60s and early 70s, but thats become much more dominant since. To the many of you at Penn State who want a university thats more than an adjunct to a literally-rapacious football program, you have this blogs admiration and support as you struggle to reclaim your great institution. Go for the touchdownWOOOOO!Simons Postdoctoral Fellowship Announcement

The Theory of Computation (TOC) group at the Computer Science and Artificial Intelligence Laboratory (CSAIL) at MIT is seeking candidates for a post-doctoral position in the general area of the theory of computation. Applicants in all areasof theory are encouraged to apply, including (but not exclusive to) algorithms, complexity theory, combinatorial optimization, cryptography, distributed computing, game theory and computation, geometry, parallel computing, and quantum computing. This fellowship is made possible by a generous gift from the Simons Foundation.
The fellowship is a two year position, starting the summer or fall of 2012. The fellowship stipend is gauged to attract the highest caliber of applicants. Generous funds for scientific travel will be available for use at the fellows discretion. Fellows will be assigned a faculty member close to their research interests from the TOC group. Fellows will be encouraged (although not required) to teach a graduate seminar in their area of research.
Eligibility: Candidates must receive their PhD during the academic year immediately preceding that in which the fellowship would begin. There are no other restrictions based on nationality or any other basis.
Application Process: Candidate applications should include a description of professional interests and goals in research. Each application should include a curriculum vitae and the names and addresses of three or more individuals who will provide letters of recommendation. Letter writers should submit their letters directly to MIT to the address below. Please submit complete applications by January 6, 2012.
Address to submit application: All application materials and recommendation letters should be sent electronically to theory-postdoc@csail.mit.edu. The candidates name should be included in the subject line of the email. Alternatively, the materials can be also sent to the following address:
Simons Postdoctoral Fellowship, c/o Joanne Hanley
MIT Computer Science and Artificial Intelligence Laboratory
The Stata Center, Building 32-G672A
32 Vassar Street
Cambridge, MA 02139, USA.In his country there is problem

So it seems that Borat  the racist, misogynist, khrum-grabbing reporter from Da Ali G Show  has become a serious public relations problem for the former Soviet Republic of Kazakhstan.  See here for an old New Yorker piece, and here for the latest on this important story.
Respek.The quantum state cannot be interpreted as something other than a quantum state

Lots of people asked me to comment on a much-discussed new preprint by Matthew Pusey, Jonathan Barrett, and Terry Rudolph (henceforth PBR),The quantum state cannot be interpreted statistically. (See here for an effusiveNature News article, here for the predictable Slashdot confusion-fest,here for a related Cosmic Varianceguest post by David Wallace, and here for a spiteful rant by Lubos Motl that hilariously misunderstands the new result as anti-quantum-mechanics.)
I recommend reading the preprint if you havent done so yet; it should only take an hour. PBRs main result reminds me a little of the No-Cloning Theorem: its a profound triviality, something that most people who thought about quantum mechanics already knew, but probably didntknowthey knew. (Some people are even making comparisons to Bells Theorem, but to me, the PBR result lacks the same surprise factor.)
To understand the new result, the first question we should askis, what exactly do PBRmean by a quantum state being statistically interpretable? Strangely, PBR spend barely a paragraph justifying their answer to this central questionbut its easy enough to explain what their answer is. Basically, PBR call something statistical if two people, who live in the same universe but have different information, could rationally disagreeabout it. (They put it differently, but Im pretty sure thats what they mean.) As for what rational means, all well need to know is that a rational person can never assign a probability of 0 to something that will actually happen.
To illustrate, suppose a coin is flipped, and you (but not I) get a tip from a reliable source that the coin probably landed heads. Then you and I will describe the coin using different probability distributions, but neither of us will be wrong or irrational, given the information we have.
In quantum mechanics, mixed statesthe most general type of statehave exactly the same observer-relative property. That isnt surprising, since mixed states include classical probability distributions as a special case. As I understand it, its this property of mixed states, more than anything else, thats encouraged many people (especially in and around the Perimeter Institute) to chant slogans like quantum states are states of knowledge, not states of nature.
By contrast,pure statesstates with perfect quantum coherenceseem intuitively much more objective. Concretely, suppose I describe a physical system using a pure state |>, and you describe the same system using a different pure state |>|>. Then it seems obvious that at least one of ushas to be flat-out wrong, our confidence misplaced! In other words, at least one of us shouldve assigned a mixed state rather than a pure state. The PBR result basically formalizes and confirms that intuition.
In the special case that |> and |> are orthogonal, the conclusion is obvious: we can just measure the system in a basis containing |> and |>. If we see outcome |>then youre unmasked as irrational, while if we see outcome |>, then Im unmasked as irrational.
So lets try a slightly more interesting, non-orthogonal example. Suppose I describe a system S using the state |0>, while you describe it using the state |+>=(|0>+|1>)/2. Even then, there are some measurements and outcomes of those measurements that would clearly reveal one of us to have been irrational. If we measure S in the {|0>,|1>} basis and get outcome |1>, then I was irrational. If we measure in the {|+>,|->} basis (where |->=(|0>-|1>)/2) and get outcome |->, then you were irrational. Furthermore, if S is any qubit that obeys quantum mechanics, then it must have a decent probability either of returning outcome |1>when measured in the {|0>,|1>} basis, or of returning outcome |->when measured in the {|+>,|->}basis.
So, are we finished? Well, PBR dont discuss the simple argument above, but I assume they wouldnt be satisfied with it. In particular, theyd probably point out that it only unmasks one of us as irrational for some measurement outcomesbut who can say what the measurement outcome will be, especially if we dont presuppose that the quantum state provides a complete description of reality?
What they want instead is a measurement thats guaranteed to unmask someone as irrational, regardless of its outcome. PBR show that this can be obtained, under one further assumption: that rational beliefs behave well under tensor products. More concretely, suppose two people with different knowledge could rationally describe the same physical system S using different pure states, say |0> or |+>respectively. Then if we consider a new system T, consisting of two independent copies of S, it should be rationally possible to describe T using any of the four states |0>|0>, |0>|+>, |+>|0>, or |+>|+>. But now, PBR point out that theres a 2-qubit orthonormal basis where the first vector is orthogonal to |0>|0>, the second vector is orthogonal to |0>|+>, the third vector is orthogonal to |+>|0>, and the fourth vector is orthogonal to |+>|+>. So, if we measure in that basis, then someonewill get unmasked as irrational regardless of the measurement result.
More generally, given any physical system S that you and I describe using different pure states |> and |>, PBR define a new system T consisting of k independent copies of S, where k is inversely proportional to the angle between |> and |>. They then construct a projective measurement M on T such that, whichever of Ms 2k possible outcomes is observed, one of the 2k possible tensor product beliefs about T gets unmasked as irrational. And thats it (well, other than a generalization to the noisy case).
So, will this theorem finally end the century-old debate about the reality of quantum statesproving, with mathematical certitude, that the ontic camp was right and the epistemic camp was wrong? To ask this question is to answer it.
(Clarification added for Lubos Motl and anyone else unwilling or unable to understand: The answer that I intended was no. I dont think the battle between the ontic and epistemic camps can ever be won, by its nature. Nor has that particular battle ever interested me greatly, except insofar as some interesting mathematical results have come out of it.)
I expect that PBRsphilosophical opponents are already hard at work on a rebuttal paper: The quantum statecan toobe interpreted statistically, or even The quantum statemustbe interpreted statistically.
I expect the rebuttal to say that, yes, obviously two people cant rationally assign different pure states to the same physical systembut only a fool wouldve ever thought otherwise, and thats not what anyone ever meant by calling quantum states statistical, and anyway its beside the point, since pure states are just a degenerate special case of the more fundamental mixed states.
I expect the rebuttal to prove a contrary theorem, using a definition of the word statistical that subtly differs from PBRs. I expect the difference between the two definitions to get buried somewhere in the body of the paper.
I expect the rebuttal to get blogged and Slashdotted. I expect the Slashdot entry to get hundreds of comments taking strong sides, not one of which will acknowledge that the entire dispute hinges on the two camps differing definitions.
Theres an important lesson here for mathematicians, theoretical computer scientists, and analytic philosophers. You want the kind of public interest in your work that the physicists enjoy? Then stop being so goddamned precise with words! The taxpayers who fund usthose who pay attention at all, that iswant a riveting show, a grand Einsteinian dispute about what is or isnt real. Who wantssome mathematical spoilsport telling them: Look, it all depends what you mean by real. If you mean, uniquely determined by the complete state of the universe, and if youre only talking about pure states, then
One final remark. In their conclusion, PBR write:
 the quantum state has the striking property of being an exponentially complicated object. Specifically, the number of real parameters needed to specify a quantum state is exponential in the number of systems n. This has a consequence for classical simulation of quantum systems. If a simulation is constrained by our assumptionsthat is, if it must store in memory a state for a quantum system, with independent preparations assigned uncorrelated statesthen it will need an amount of memory which is exponential in the number of quantum systems.
The above statement is certainly true, but it seems to me that it was already demonstratedand much more convincinglyby (for example) the exponential separations between randomized and quantum communication complexities.One down

Last summer I posed Ten Semi-Grand Challenges for Quantum Computing Theory.  Today Im pleased to report that (part of) one of my challenges has been solved  where, as always in this business, the word solved is defined broadly so as to include proven to be not really worth working on, since a solution to it would imply a solution to something else that most of us gave up on years ago.
Challenge 10 involved finding a polynomial-time quantum algorithm to PAC-learn neural networks (that is, the class TC0 of polynomial-size, constant-depth threshold circuits).   In a new ECCC preprint, Adam Klivans and Alex Sherstov show that, if theres a fast quantum algorithm to learn even depth-2 neural nets, then theres also a fast quantum algorithm for the ~n1.5-approximate shortest vector problem.  Embarrassingly for me, once you have the idea  to use Oded Regevs lattice-based public key cryptosystems  the quantum hardness of learning (say) depth 4 or 5 neural nets is immediate, while getting down to depth 2 takes another page.  This is one of those results that hangs in the wonderful balance between you couldve thought of that and nyah nyah, you didnt.
Feel free to post your own challenges in the comments section.  But please, no spouter challenges like where does the power of quantum computing come from? or is there a deeper theoretical framework for quantum algorithms?  In general, if youre going to pose a scientific challenge, you should (1) indicate some technical problem whose solution would clearly represent progress, and (2) be willing to place at least 25% odds on such progress being made within five years.  Or if youre not a gambler, pick technical problems that you yourself intend to solve  thats the approach I took with Semi-Grand Challenges 4 and 7.
Theoretical computer science is often disheartening: there are so many open problems, and a week later theyre all still open, and a week after that, theyre all still open.  Wait a year, though, or five years, or twenty, and some grad student will have had the insight thats eluded everyone else: that the problem cant be solved with any existing technique, unless Blum integers are factorable in 2n^ time for all >0.2.373

For twenty years, the fastest known algorithm to multiply two n-by-n matrices, due to Coppersmith and Winograd, took a leisurely O(n2.376) steps.  Last year, though, in hisPhD thesis, Andrew Stothers gave an improvement to O(n2.374)steps. And today, Virginia Vassilevska Williamsof Berkeley and Stanford, released a paper that gives a general methodology for analyzing Coppersmith-Winograd-type algorithms, and that improves the matrix-multiplication time to a lightning-fast O(n2.373) steps. (Virgis work was independent of Stothers, though she credits him and applies an idea of his to simplify her proof.) Full disclosure: I actually knew a month ago that this was comingI had a hell of a time keeping the secret. Id recommend that you get started memorizing <2.373, but as Russell Impagliazzo points out in the comments, the exponent might get lowered again in short order. Huge congratulations to Virgi and to Andrew for this breakthrough!

Update (Nov. 30): Last night I received an extremely gracious email from Andrew Stothers, which hes given me permission to summarize here. In the email, Andrew expressed how excited he was about Virgis new result, apologized for the confusion he caused by not mentioning his improvement to  until page 71 of his thesis (he says he doesnt know why he did it), and said that he meant to publish a paper, but was prevented from doing so by health and job issues. He also said that he didnt take issue with anything I wrote here, except that I mistakenly referred to him as Andy rather than Andrew. In response, I congratulated Andrew on his achievement; expressed how happy I was thatironicallyhis work is now finally getting some of the attention that it deserves; and promised to buy him a beer when and if Im ever in Edinburgh, a city Ive always wanted to visit. (On the other hand, I warned Andrew that his LinkedIn profile, which unselfconsciously mentions improvements to his Word and Excel skills as one of the benefits of his PhD research breaching the Coppersmith-Winograd barrier, might have earned him a place in scientific folklore forever!)
In summary, I now see Andrew as an extraordinarily nice fellow who had some bad luck andmost conspicuouslya lack of good advice from people around him. I do stand by the points that I was originally tryingto make:
(a) that this tangled situation shouldnt in any way detract from Virgis fantastic achievement, which (except for a simplification, as she discusses) must be considered completely independent of Andrews, and
(b) that theres indeed an important cautionary lesson for students here, about adequately publicizing your work (yes, theresa happy medium, between hiring a PR firm to wage a viral marketing campaign and burying your solution to a longstanding open problem so far in the body of your PhD thesis that even world experts in the subject who read your thesis will miss it).
On the other hand, I hereby apologize for anything I said that could even be perceived as slighting Andrew, his important work, or his motives.

Another Update: On the third hand, if youre one of the commenters whose beef is not about attribution, but about the entire concept of using a CS theory blog to promote major milestones in CS theory (like the breaking of the Coppersmith-Winograd barrier), then I apologize for absolutely nothing. Go read an economics or physics blog; I understand that those are entirely hype-free. Better yet, go to hell.Grab bag

Sorry for the long delay; Im recovering from a cold.  Thankfully, nothing like my Canadian-muskox-strength cold in October, but still enough to keep my brain out of service for most of the week.  On the positive side, I now have a weeks worth of websurfing to share with you.
Whats as fast-paced as Tetris or Pac-Man, playable for free on the web, and willing to tell you whether you harbor hidden biases against blacks, gays, women, or Jews?  Why, the Implicit Association Test, developed by psychologists Mahzarin Banaji, Tony Greenwald, and Brian Nosek.  If you havent played it yet, do so now  its fun!    Do you take longer to match African-American faces with words like peace, love, and wonderful and Caucasian faces with words like bad, awful, and horrible than vice versa?  Yes, if youre like 88% of white Americans and  interestingly  48% of black Americans.  (Philip Tetlock, quoted in this Washington Post article, comments that weve come a long way from Selma, Alabama, if we have to calibrate prejudice in milliseconds.)  While Im ashamed to be part of that 88% statistic, Im also relieved that, even at an involuntary, subconsious level, I apparently harbor no bias at all against Asian-Americans or gays.
While browsing Wikipedia (Earths largest procrastination resource), I came across the following Freedom House world map, which labels each country as free, partly free, or not free depending on how it scores on various indices of voting rights, free speech, etc.

I have one beef with this map: I think there should be a little red dot over Berkeley, California.
On an equally important note, while reading the Wikipedia entry for bear (dont ask), I came across my favorite paragraph in the whole encyclopedia:
In a chance encounter with a bear, the best course of action is usually to back away slowly in the direction that you came.  The bear will rarely become aggressive and approach you.  In order to protect yourself, some suggest passively lying on the ground and waiting for the bear to lose interest.  Another approach is to constantly maintain an obstacle between you and the bear, such as a thick tree or boulder.  A person is much more agile and quick than a bear allowing him or her to respond to a bears clockwise or counter-clockwise movement around the obstacle and move accordingly.  The bears frustration will eventually cause disinterest.  One can then move away from the bear to a new obstacle and continue this until he or she has created a safe distance from the bear.
Lastly, Reuters reports on an interview in which Bill Gates discusses why he hates being so rich.  My mom tells me that, when I visit Microsoft Research a few weeks from now, I should help ease Gatess burden by demanding immediate reimbursement for my travel expenses.ITCS2012 in Cambridge, MA

Since everything I write now seems to provide an occasion for bitter controversy, Ill be curious to learn whose sensibilities I inadvertently offended by posting the following announcement for next years ITCS conference. -SA

Dear Theorists:
As you know the third Innovation in Theoretical Computer Science Conference will be held in Cambridge this January:http://research.microsoft.com/en-us/um/newengland/events/itcs2012/.
REGISTRATION IS NOW OPEN and THE PROGRAM IS ONLINE.
In addition to the program, there are going to be a few novelties that we would like to point out to you.
1. GRADUATING BITS
In one session of the conference, students graduating this academic year (as well as researchers completing their postdoc this academic year) will be given few minutes to present themselves and their work.
The presentations will be grouped by University, in alphabetic order.
We hope this will give all of us an opportunity to have a synopsis of the great work being done by the graduating members of our community.
In order to speak in this special session, please send an email atsilvio.itcs12@gmail.comby DECEMBER 15.
Registration fees will be waived for presenters at Graduating Bits 2012.
If you/your students are graduating this year, or you plan to hire this year, we are encourage to attend ITCS 2012!
2. COMMUNITY BUILDING
To strengthen our (legendary!) friendship and collaboration, we will treat you to a PLAY BACK show: an improvisational theater where OUR actors will bring to life YOUR stories.
3. CHAIR RANTS
In addition to the chairof each session introducing the speakers and coauthors of the session (who will then introduce themselves and their coauthors), our chairs will provide us with their insights on the papers in their sessions.
We look forward to seeing all of you in Cambridge very soon!
All the Best
Shafi Goldwasser, Silvio Micali, and Yael Tauman KalaiIts not radiation-poisoned, its just sleeping!

Since I hadnt heard from my friend Mahmoud Ahmadinejad for a while, I figured he must be busy with his new uranium-enrichment hobby.  My suspicions werent alleviated by this excellent piece in the New York Review of Books.  What I hadnt realized is that Mahmoud is quite the joker!  And no, Im not talking about the obvious gag of funding a peaceful nuclear energy program by oil exports  Im talking about the following Pythonesque routine, which Im not making up:
IAEA: Iran, if your nuclear program is for peaceful purposes only, then why did we find traces of 36%-enriched uranium at the Natanz facility, whereas youd only need 3% enrichment for a reactor?
Iran: Oh, thats just because the equipment we bought from A. Q. Khan on the black market was contaminated.The Alternative to Resentment

A year ago, in a post entitledAnti-Complexitism, I tried to grapple with the strange phenomenonone weve seen in forcethis past weekof anonymous commenters getting angry about the mere fact of announcements, on theoretical computer science blogs, of progress on longstanding open problems in theoretical computer science. When I post something about global warming, Osama Bin Laden, or (of course) the interpretation of quantum mechanics, I expect a groundswell of anger  but a lowering of the matrix-multiplication exponent ? Huh? What wasthat about?
Well, in this case, some commenters were upset about attribution issues (which hopefully we can put behind us now, everyone agreeing about the importance of both Stothers and Vassilevska Williams contributions), while others honestly but mistakenly believed that a small improvement to  isnt a big deal (I tried to explain why theyre wrong here). What interests me in this post is the commenters who went further, positing the existence of a powerful clique of complexity bloggers thats doing something reprehensible by hyping progress in complexity theory, or by exceeding some quota (what, exactly?) on the use of the word breakthrough.
One of the sharpest responses to that paranoid worldview came (ironically) from awonderful anonymous commenton my Anti-Complexitism post, which I recommend everyone read. Here was my favorite paragraph:
The final criticism [by the anti-complexites] seems to be: complexity theory makes too much noise which people in other areas do not like. I really dont understand this one, I mean what is wrong with people in an area being excited about their area? Is that wrong? And where do we make those noise? On complexity blogs! If you dont like complexity theorists being excited about their area why are you reading these blogs? The metaphor would be an outsider going to a wedding and asking the people in the wedding with a very serious tone: why is everyone happy here?
Yesterday, in response to my reposting the above comment on Lance and Bills blog, another anonymous commenter hadsomething extremely illuminating to say:
Scott, you are missing the larger socio-economical context: its not about excitement. Its about researchers competing for scarce resources, primarily funding. The work involved in funding acquisition is generally loathed, and directly reduces the time scientists have for research and teaching. If some researchers ramp up their hype-level vis-a-vis the rest of the community, as the complexity community is believed to be doing (what with all them Goedel awards?), they are forcing (or are seen as forcing) the rest either to accept a lower level of funding with all the concomitant disadvantages, or invest more time in hype themselves. In other words, hypers are defecting in the prisoners dilemma type game scientists are playing, the objective of which is to minimise the labour involved in funding acquisition.
This is similar to teeth-whitening: in the past, it was perfectly possible to be considered attractive with natural, slightly yellowish teeth. Then some defected by bleaching, then more and more, and today natural teeth are socially hardly acceptable, certainly not if you want to be good-looking. Is that progress?
I posted a responseon Lance and Bills blog, but then decided it was important enough to repost here. So:
Dear Anonymous 2:47,
Let me see whether I understand you correctly. On the view you propose, other scientists shouldnt have praised (say) Carl Sagan for getting millions of people around the world excited about science. Rather, they should have despised him, for using hype to divert scarce funding dollars from their own fields to the fields Sagan favored (like astronomy, or Sagans preferred parts of astronomy). Sagan forced all those other scientists to accept a terrible choice: either accept reduced funding, or else sink to Sagans level, and perform the loathed task of communicating their own excitement about their own fields to the public.
Actually, therewereother scientists who drew essentially that conclusion. As an example, Sagan was famously denied membership in the National Academy of Sciences, apparently because of a few vocal NAS members who were jealous and resentful of Sagans outreach activities. The view were now being asked to accept is that those NAS members are the ones who emerge from the story the moral victors.
So let me thank you, Anonymous 2:47: its rare for anyone to explain the motivation behind angry TCS blog comments with that much candor.
Now that the real motivation has (apparently) crawled out from underneath its rock, I can examine it and refute it. The central point is simply that scienceisnta Prisoners-Dilemma-type game.  What you describe as the socially optimal equilibrium, wherenoscientists need to be bothered to communicate their excitement about their fields,is not socially optimal at allneither from the publics standpoint nor from sciences.
At the crudest level, science funding is not a fixed-size pie. For example, when Congress was debating the cancellation of the Superconducting Supercollider, a few physicists from other fields eagerly jumped on the anti-SSC bandwagon, hoping that the SSC money might then get diverted to their own fields. Ultimately, of course, the SSCwascancelled, andnoneof the money ever found its way to other areas of physics.
So, if you see people using blogs to talk about research results that excite them, then instead of resenting it, consider starting your own blog to talk about the research results that excite YOU. If your blog is well-written and interesting, Ill even add you to my blogroll, game-theoretic funding considerations be damned. Just go to WordPress.comits free, and it takes only a few minutes to set one up.The relativity of originality

An anonymous commenter asked for my opinion of The Free Will Theorem, a much-discussed recent paper by John Conway and Simon Kochen.   Ive been putting it off, but Ill finally will myself to say something.
I read The Free Will Theorem mostly as an amusing romp through the well-travelled philosophical terrain of quantum mechanics, relativity, and entanglement.   Ive always enjoyed Conways writing style, so it was a treat to see his usual jokes and puns out in full force.
Of course, the reason the paper has attracted attention is the Free Will Theorem itself, which Ill paraphrase as follows:
Suppose that (1) the laws of physics allow something like a Bell or GHZ experiment, (2) the people doing the experiment can set their detectors any way they want (i.e., in a way not determined by the previous history of the universe), and (3) something like Lorentz invariance holds (i.e. theres one reference frame where experimenter A measures first, and another where experimenter B measures first).  Then the results of the experiment are also not determined by the previous history of the universe.

Or as the authors colorfully put it: if indeed there exist any experimenters with a modicum of free will, then elementary particles must have their own share of this valuable commodity.
(Note that by free will, all Conway and Kochen mean is the property of not being determined by the previous history of the universe.  So even events with known probability distributions, like coin flips and quantum measurements, can have free will according to their definition.)
My reaction to the Free Will Theorem is threefold:

Its a very important, even if mathematically trivial, consequence of the Bell/GHZ/Kochen-Specker-type theorems.
It will be new to many physicists.
It was folklore among those who think about entanglement and nonlocality.

Ill be grateful for any references in support of the last point.  Right now, all I can offer is that I gave almost the same argument four years ago, in my review of Stephen Wolframs A New Kind of Science (see pages 9-11).  My goal there was to show that no deterministic cellular-automaton model of physics, of the sort Wolfram was advocating, could possibly explain the Bell inequality violations while respecting relativistic invariance.  I didnt think I was saying anything terribly new.
Conway and Kochen try to preempt such criticism as follows:
Physicists who feel that they already knew our main result are cautioned that it cannot be proved by arguments involving symbols such as , , , since these presuppose a large and indefinite amount of physical theory.

I find this unpersuasive.  For me, the whole point of the Bell, GHZ, and Kochen-Specker type theorems has always been that they dont presuppose quantum mechanics.  Instead they show that any physical theory compatible with certain experimental results has to have certain properties (such as nonlocality or contextuality).
I should admit that the Free Will Theorem improves on the argument in my book review in at least three ways:

It gets rid of probabilities, by going through a two-party version of the Kochen-Specker Theorem instead of through Bells inequality.  (I mentioned in my review that the argument could be redone using the GHZ paradox, which involves three parties but is deterministic.  I didnt mention that it could also be done using two-party Kochen-Specker.)
It gives a cute, memorable name  free will  to something that I referred to only by convoluted phrases like  randomness thats more fundamental than the sort Wolfram allows (by which I meant, thats not reducible to Alice and Bobs subjective uncertainty about the initial state of the universe).
It makes the assumptions more explicit.  For example, I never talked about Alice and Bobs free will in choosing the detector settings, since I thought that was just assumed in talking about Bells inequality in the first place!  (In other words, if Wolfram denied that Alice and Bob could choose the detector settings independently of each other, then he could have dispensed with Bells inequality in a much simpler way than he actually did.)

I should also admit that I like Conway and Kochens paper.  Indeed, the main question it raises for me is not how could they possibly pass this off as original? but rather do we, as scientists, sometimes put too high a premium on originality?
In all the reading Ive done in philosophy, I dont know that Ive ever once encountered an original idea  in the sense that, say, general relativity and NP-completeness were original ideas.  Indeed, whenever I read about a priority dispute between philosophers (like the infamous one between Saul Kripke and Ruth Barcan Marcus), it strikes me as absurd: all the ideas under dispute seem obvious!
But does it follow that philosophy is a waste of time?  No, I dont think it does. The same obvious idea can be expressed clumsily or eloquently, sketched in a sentence or developed into a book, brought out explicitly or left beneath the surface.  Now, Im well aware that thats not an original sentiment  nor, for that matter, is anything in this post, or probably this entire blog.  Yet here I am writing it, and here you are reading it.
You might respond that Wolfram can (and does) mount a similar defense of A New Kind of Science: that sure, lesser mortals might have realized decades ago that simple programs can produce complex behavior, but they didnt grasp the true, Earth-shattering significance of that fact.  Compared to Wolfram, though, I think Conway and Kochen have at least two things going for them: (1) they dont spend 1,200 pages denigrating the work of other people, and (2) they accept quantum mechanics.
From Ecclesiastes:
All streams run to the sea,
but the sea is not full;
to the place where the streams flow,
there they continue to flow.
All things are wearisome;
more than one can express;
the eye is not satisfied with seeing,
or the ear filled with hearing.
What has been is what will be,
and what has been done is what will be done;
there is nothing new under the sun.Quantum Algorithms for Quantum Field Theories

For weeks, Ive been meaning to blog about an important recent paper by Stephen Jordan, Keith Lee, and John Preskill, entitled Quantum Algorithms for Quantum Field Theories. So Im now doing so.
As long as Ive been in quantum computing, people have been wondering aloud about the computational power of realistic quantum field theories (for example, the Standard Model of elementary particles). But no one seemed to have any detailed analysis of this question (if theres something I missed, surely commenters will let me know). The obvious guess would be that realistic quantum field theories should provide exactly the same computational power as ordinary, nonrelativistic quantum mechanicsin other words, the power of BQP (the class of problems solvable in polynomial time by a quantum computer). That would be analogous to the situation in classical physics, where bringing in special relativity dramatically changes our understanding of space, time, matter, and energy, but seems (unlike quantum mechanics) to have little or noeffect on which computational problems can be solved efficiently. Analogously, it would seem strange if quantum field theories (QFTs)which tie together quantum mechanics, special relativity, and detailed knowledge about the elementary particles and their interactions, but seen from far enough away are just quantum mechanicsforced any major revision to quantum computing theory.
Until now, though, there seems to have been only one detailed analysis supporting that conclusion, and it applied to (2+1)-dimensionaltopological QFTs (TQFTs) only, rather than realistic (3+1)-dimensional QFTs. This was the seminal work of Freedman, Kitaev, and Wangand Freedman, Larsen, and Wangin 2000. (Six years later, Aharonov, Jones, and Landau gave a more computer-science-friendly version, by directly proving the BQP-completeness of approximating the Jones polynomial at roots of unity. The latter problem was known to be closely-related to simulating TQFTs, from the celebrated work of Witten and others in the 1980s.) To a theoretical computer scientist, dropping from three to two spatial dimensions might not sound like a big deal, but whats important is that the relevant degrees of freedom become topological, making possible a clean, simple model of computation. For realistic QFTs, by contrast, it wasnt even obvious how to definea model of computation; putting realistic QFTs on a rigorous mathematical footing remains a notorious open problem.
In their new paper, Jordan, Lee, and Preskill say that they give an algorithm, running on a conventional quantum computer, to estimate scattering probabilities in a class of QFTs called continuum 4theories.  Their algorithm uses time polynomial in the number of incoming particles in the scattering experiment and in their total energy, and inversely polynomial in the desired precision  and in the distance -c between the QFTs coupling constant  and a phase transition c. (In d=2 spatial dimensions, they say the dependence on the precision scales like (1/)2.376, the 2.376 coming from matrix multiplication. Naturally, that should now be amended to (1/)2.373.) To develop their algorithm, Jordan et al. apparently had to introduce some new techniques for coping with the error incurred by discretizing QFTs. No classical algorithm is known with similar scalingso when suitably formalized, the QFT simulation problem might indeed be in BQP-BPP, matching the uninformed doofus intuition of complexity theorists like me. Jordan et al. dont say whether the problem theyre solving is also BQP-complete; I imagine that could be a topic for future research. They also dont say whether their precision parameter bounds the variation distance between the real and simulated output distributions (rather than just the differences between probabilities of individual scattering outcomes); I hope they or someone else will be able to clarify that point.
In case it isnt obvious yet, let me make it crystal-clear that I lack the physics background to evaluate Jordan et al.s work in a serious technical way. All I can say with confidence is that the small number of people who (1) have the requisite background and (2) care about computational complexity, will probably spend non-negligible time discussing and understanding this paper in the weeks and months to come.

Conflict-of-Interest Warning: At a deep, subconscious level, I probably chose to blog about Jordan et al.s paper not for any legitimate scientific reason, but simply because I know John Preskill and Stephen Jordan personally, and, despite being physicists, theyre both tremendously-respected colleagues whove mademany outstanding contributions to quantum computing theory besides this one. Then again, everything Ive ever doneand everything youve ever donehas probably had such unsavory hidden motives as well, so whos counting? In all of history, there have only been ten or twenty people whose commitment to scientific objectivity has been absolute and pure, and since they comment on complexity blogs anonymously, well probably never even know their namesThe pee versus in-pee question

Greetings from Americas fourth-best city, Seattle, where Im attending the STOC2006 conference.  I arrived here yesterday from Americas third-best city, Boston, where I visited MIT for a week and gave a talk about The Learnability of Quantum States.  (Ill leave the best and second-best cities as exercises for the reader.)
Since tomorrows my birthday, Ill consider myself free to blog about whatever I feel like today (as opposed to most days, when I blog about whatever the invisible space antelopes tell me to).  So without further ado, heres a question that bugged me for years: why do we need to urinate on a regular basis?
I mean, I understand solid waste perfectly well, and I also understand the need to get rid of urea and the other waste products in urine.  But why constantly excrete water, something that humans and other animals regularly die from not having enough of?  Why not store the water in the body until the next time its needed?  From a Darwinian perspective, a regularly-vacating bladder would seem to make as little sense as a toothless vagina.
And yet, after minutes of diligent Wikipedia research, Ive pieced together what I believe is a complete solution to this pee versus in-pee puzzle.
The short answer is that conserving water, rather than just pissing it away (so to speak), is exactly what our bodies try to do.  But one needs to remember that, while feces comes directly from the digestive tract, urine is collected from waste products in the bloodstream.  In particular, the kidneys contain permeable membranes whose job is to let wastes like urea through, while keeping the useful stuff (like red blood cells) out.  However, as with any other filtration process, its difficult or impossible to keep all the water on one side of the barrier.
So what the body does instead is to let the water through, then slowly absorb it back into the bloodstream as needed.  Thats why your urine is darker (more concentrated) if youre dehydrated than if you arent.  At some point, though, it presumably becomes infeasible to extract more water from the bladder without also letting the toxic wastes back into the bloodstream.
Now, I know what youre thinking.  Youre thinking, why isnt my urine always dark?  In other words, why dont I always absorb as much water as possible back into my bloodstream, whether Im dehydrated or not?  Why not save the water for a (non) rainy day?
Aha, Ive got an answer to that one too.  Besides excreting wastes, another function of urine is to maintain a homeostatic balance between water and sodium in the blood.  If theres too much water (say, because you just drank six beers), your blood will be too thin, which can cause brain damage (completely apart from the other effects of the beer).  Ideally, your body would store the excess water separately from the blood  and again, thats exactly what it tries to do, but your bladder is only so big.
In summary, if you think through what my in-pee solution would actually entail, it turns out to be almost identical to the pee solution that Nature actually adopted.  One might even say that pee = in-pee.
[Note for harping relatives: now do you understand why I didnt go to medical school?]My New York Times essay on quantum computing

I have a special treat for those commenters who consider me an incorrigible publicity-hound: an essay I was invited to write for the New York Times Science section, entitled Quantum Computing Promises New Insights, Not Just Supermachines. (My original title was The Real Reasons to Study Quantum Computing.) This piece is part of a collection of essays on the future of computing, which include one on self-driving cars by Sebastian Thrun, one on online learning by Daphne Koller, and other interesting stuff (the full list is here).
In writing my essay,the basic constraints were:
(a) Id been given a rare opportunity to challenge at least tenpopular misconceptions about quantum computing, and would kick myself for years if I didnt hit all of them,
(b) I couldnt presuppose the reader had heard of quantum computing, and
(c) I had 1200 words.
Satisfying these constraints was harder than it looked, and I benefited greatly from the feedback of friends and colleagues, as well as the enormously helpfulTimes staff. I did get one request that floored me: namely, to remove all the material about interference and amplitudes (too technical), and replace it by something ordinary people could better relate tolike, say, a description of how a quantum computer would work by trying every possible answer in parallel. Eventually, though, the Gray Lady and I found a compromise that everyone liked (and that actually improved the piece): namely, Idfirst summarize the usual try all answers in parallel view, andthenexplain why it was wrong, bringing in the minus signs and Speaking Truth to Parallelism.
To accompany the essay, I also did a shortpodcast interview about quantum computing with the Times David Corcoran. (My part starts around 8:20.) Overall, Im happy with the interview, but be warned: when Corcoran asks me what quantum computers potential is, I start talking about the try all answers in parallel misconceptionand then they cut to the next question before I get to the part about itsbeing a misconception! I need to get better at delivering soundbites
One final comment: in case youre wondering, those black spots on the Times cartoon of me seem to be artifacts of whatever photo-editing software they used. Theyre not shrapnel wounds or disfiguring acne.Nerdify the world, and the women will follow

As delighted as Ive been with the popular response to this blog, its come to my attention that there are still a few readers who havent yet been angered or offended by anything Ive written. Thats why todays entry will be about women, science, and Larry Summers.
Granted, it feels strange to be blogging about why there arent more women in computer science and the other nerdly disciplines, having just come from a conference where Irit Dinur took the Best Paper Award for her combinatorial proof of the PCP Theorem. But the question remains: why arent there more Irits?
A hilarious analysis by Philip Greenspun seems like as good a starting point as any for discussing this question. Here are my favorite passages:
A lot more men than women choose to do seemingly irrational things such as become petty criminals, fly homebuilt helicopters, play video games, and keep tropical fish as pets (98 percent of the attendees at the American Cichlid Association convention that I last attended were male). Should we be surprised that it is mostly men who spend 10 years banging their heads against an equation-filled blackboard in hopes of landing a $35,000/year post-doc job?
Having been both a student and teacher at MIT, my personal explanation for men going into science is the following:
1. young men strive to achieve high status among their peer group
2. men tend to lack perspective and are unable to step back and ask the question is this peer group worth impressing?
Consider Albert Q. Mathnerd, a math undergrad at MIT (Course 18 we call it). He works hard and beats his chest to demonstrate that he is the best math nerd at MIT. This is important to Albert because most of his friends are math majors and the rest of his friends are in wimpier departments, impressed that Albert has even taken on such demanding classes. Albert never reflects on the fact that the guy who was the best math undergrad at MIT 20 years ago is now an entry-level public school teacher in Nebraska, having failed to get tenure at a 2nd tier university. When Albert goes to graduate school to get his PhD, his choice will have the same logical foundation as John Hinckleys attempt to impress Jodie Foster by shooting Ronald Reagan
What about women? Dont they want to impress their peers? Yes, but they are more discriminating about choosing those peers. Ive taught a fair number of women students in electrical engineering and computer science classes over the years. I can give you a list of the ones who had the best heads on their shoulders and were the most thoughtful about planning out the rest of their lives. Their names are on files in my medical school recommendations directory
With Occams Razor, we should not need to bring in the FBI to solve the mystery of why there are more men than women who have chosen to stick with the choice that they made at age 18 to be a professor of science or mathematics.
If you dont recognize any truth in the above, then (almost by definition) you are not a nerd. Yet Greenspuns argument immediately raises four questions:

Is academic science really such a crappy career choice?
If not, then what else is keeping more women from going into it?
Regardless of underlying causes, should we be trying to entice more women into science?
If so, how?

Let me address these questions in turn.
1. Is science really as depressing as Greenspun makes it out to be?
I can only speak for myself. Unlike most people, I dont work at all, in the sense of doing anything with the conscious goal of making money. All I do is think about what interests me, and discuss the results of that thinking with other people. As long as governments (and philanthropists like Mike Lazaridis) are willing to pay me for my non-work, Im happy to take their money. If they ever stop paying me, I guess Ill have to find some other source of income.
Of course my perspective might change once I start a tenure-track, which is part of the reason why I havent been in any hurry to do so. But for now, I cant complain about my life as a postdoc. Or rather, I can complain, but then I remember the alternatives. Can I even imagine what it would be like to grapple not with the eternal verities of QMA and PSPACE, but with the fickle whims of the stock market? My only reward being a gigantic pile of cash, most of which wouldnt even fit in my wallet when I went out for Indian buffet?
2. The trouble with because
So Greenspuns Albert Q. Mathnerd theory strikes me as at best a partial answer to why more women dont go into the nerdly sciences. But theres a stronger argument: if Greenspun were right, then we would expect even fewer women in the humanities and social sciences (which are even more cash-strapped than the sciences), and more women trading derivatives and starting software companies.
And that brings us, of course, to the crater-pocked battlefield where hardened university presidents fear to tread. Are there Darwinian reasons to expect males to be more spatial and less verbal on average, or to have a higher variance in ability (with both more Alan Turings and more George W. Bushes), etc., etc.? If you want to read an interesting discussion of these questions  one that involves, you know, actual facts and evidence  I heartily recommend this debate (both sides of it) between Steven Pinker and Elizabeth Spelke.
But what do I think about the root cause of the gender imbalance in science? Ill tell you exactly what I think: I think the question is ill-posed. When we say that A causes B, we normally mean something like if A didnt happen, then B wouldnt happen either. Thus: if John had had the same upbringing but the biological makeup of a woman, he would have become a lawyer instead of a string theorist. The trouble is, what does that even mean? With a few arguable and presumably unrepresentative exceptions (like hermaphrodites), no one on Earth has the biology of a man but the life experiences of a woman or vice versa.
To put the point differently: suppose (hypothetically) that what repelled women from computer science were all the vending-machine-fueled all-nighters, empty pizza boxes stacked to the ceiling, napping coders drooling on the office futon, etc.; and indeed that men would be repelled by such things as well, were it not for a particular gene on the Y chromosome called PGSTY-8. In that case, would the cause of the gender imbalance be genetic or cultural? This is a fascinating question, right up there with whether rocks fall because of gravity or being dropped, and whether 3+5=5+3 because addition is commutative or because they both equal 8.
3. The nerd case for feminism
Greenspuns central contention is that were not doing an ambitious high-school girl any favors by steering her into the impoverished dungeon of academic science. In his words:
If smart American women choose to go to medical, business, and law school instead of doing science, and have fabulous careers, I certainly am not going to discourage them. Imagine if one of those kind souls that Summers was speaking to had taken Condoleezza Rice aside and told her not to waste time with political science because physics was so much more challenging.
Such a soul would deserve our undying gratitude.
But seriously  I draw a different moral than Greenspun does. I think its imperative to increase the number of women in science, not for womens sake, but for sciences sake! Now would be a good place to insert your favorite joke about the computer labs full of horny, Perl-coding feminists, eager to cast off the yoke of sexism and open wide the gates of science to every young woman  whether blonde or brunette, single or possibly single, hot or extremely hot.
But theres no need to be cynical. Im not ashamed to assert that

most people want to socialize with the opposite sex, and are unhappy (and hence unproductive) if they cant;
the conscious reasons for wanting to socialize with the opposite sex often have nothing to do with fluid exchange (to use the John Nash characters phrase from A Beautiful Mind),
let he (or she) who is without subconscious Darwinian motivations cast the first stone,
human beings didnt evolve to live their lives in an 85%-male environment,
by the Pigeonhole Principle, not every straight male will be as lucky as I was to find a girlfriend in the remaining 15%, and
computer science departments could attract and retain better people of both sexes if they felt less like monasteries or pirate ships.

Naturally, kidnapping women in the dead of night and forcing them to take Randomized Algorithms is off the table. But the question remains: how can we make the nerdly sciences more attractive to women?
4. How to seduce women (into scientific careers)
I have two thoughts in this direction.
The first thought is actually a question: assuming our social support systems made it easier to do so, would many women prefer to have kids first, and then go to grad school? Thats not a rhetorical question; its a genuine request for enlightenment. I ask it for three reasons:

One of female academics most famous complaints is that, by the time theyve battled their way to tenure, theyre already verging on infertility.
If we consider the most famous female scientists  Marie Curie, Rosalind Franklin, Emmy Noether, Lise Meitner  most were in their 30s or older when they did their best work. This contrasts with the pattern for male scientists.
From an evolutionary perspective, the age at which women in the developed world start having kids is unbelievably late. That doesnt mean we should go back to auctioning off 12-year-old girls as brides in exchange for goats and oxen. But it does suggest, to me, that the currently normal ways of balancing career and family might not be Pareto-optimal.

So that was my first thought. The second thought is that, when people talk about cultural changes that would entice more women into science, they always mean changes to nerd culture. You know the sort of thing Im talking about:
Emphasize teamwork and community over intellectual combat.
Eliminate all-nighters.
Discourage questions in seminars that might hurt someones feelings.
Festoon the STOC proceedings with hearts, rainbows, and ponies.
The problem with such proposals is not just that theyre patronizing (and indeed deeply sexist in their own way), and not just that successful female scientists tend to be as competitive as anyone else. The real problem is the implicit assumption that, whenever theres a disparity between nerd culture and popular culture, the fault must lie with nerd culture.
Sure, there are nerds could stand to shower more often, read more Shakespeare and less Slashdot, etc. But there are also plenty of normals who could stand to follow a chain of logic to an inconvenient conclusion, unsheath their sarcasm swords when confronted with idiocy, and judge people more by the originality of their ideas than by whether their clothes match.
In short, if the reason more women dont study science is that theyre repelled by nerd culture, then de-nerdifying science is only one solution. The other solution is nerdifying the rest of the world! Admittedly, nerdifying the world might seem like a rather drastic way to increase the number of women in university science departments. But as you might have guessed, I want to nerdify the world for independent reasons as well.Cerebrum-stuffer from Shtetl Claus

Ho3! Home with family for the holidays and looking for something to do? Then check out the archives of our 6.893 Philosophy and Theoretical Computer Science course blog. The course just ended last week, so you can find discussions of everything from the interpretation of quantum mechanics to Occams Razor to the Church-Turing Thesis to strong AI, as well as links to student projects, including Criticisms of the Turing Test and Why You Should Ignore (Most of) Them, Barwise Inverse Relation Principle, Bayesian Surprise, Boosting, and Other Things that Begin with the Letter B, and an interactive demonstration of interactive proofs. Thanks to my TA Andy Drucker, and especially to the students, for making this such an interesting course.Updates from Kenya

Yes, Im blogging from outside Nairobi, where Ive come to investigate the true circumstances of President Obamas birth. Seriously, Dana and I are here to go on a safari for our belated honeymoonfor both of us, its our first non-work-related trip in many years. Needless to say, we both brought our laptops.
Like everyone else with an ounce of sense, Im absolutely horrified by SOPA, and inspired by the way so many Internet companies and organizations have banded together to try to prevent the United States from moving in the direction of China and Iran.
Meanwhile, on the theme of open access to information on the web, check out a New York Times article by Thomas Linabout the open science movement. Im quoted briefly toward the end.
Sorry for the light (nonexistent) blogging lately. Ill be back after Im done with the lions and hippos and so forth.The neologistas

Ever since I arrived at fellow blogger Dave Bacons house on Tuesday, the Pontiff and I have been tossing around ideas for a joint blog initiative.  Finally we hit on something: since were both neologistas  people who enjoy spending their free time coining new words  we decided to compile a list of the neologisms wed most like to see adopted by the general population.  Without further ado:
shnood: (roughly) an imposter; a person oblivious to just how trivial or wrong his ideas are.
Were there any interesting speakers at the conference?
No, just a bunch of shnoods.
The magazine New Scientist loves to feature shnoods on the cover.
Note: someone whos utterly contemptible would not be a shnood, but rather a schmuck.
iriterie: a list or compilation of people named Irit.
See the comments on the last post for an example of an iriterie.
extralusionary intelligence: intelligence in one domain that is misapplied in another.
Bobs a brilliant physicist  I bet hes onto something with his condensed-matter approach to P versus NP.
No, hes just suffering from extralusionary intelligence.
circumpolitical: So far to one end of the political spectrum that one is actually on the other end.
Professor Zimmerman mounted a circumpolitical defense of hereditary dictatorship, female genital mutilation, and the dragging of murdered homosexuals through the streets, arguing that we have no right to condemn these indigenous practices of non-Western peoples.
philosonomicon: A philosophical prolegomenon.
Daves PhD thesis begins with a philosonomicon, as does mine.
high-hanging fruit: the opposite of low-hanging fruit.
Do you ever think about the Nonabelian Hidden Subgroup Problem?
No, thats high-hanging fruit.  I like to watch other people jump for it.
napotonin: any substance that makes you want to nap.
Ohhhh  mustve been a lot of napotonin in that calzone  cant work  unnngghhhh
nontrivia: the opposite of trivia.
If youre so smart, how come youre no good at Trivial Pursuit?
Because I prefer to fill my brain with nontrivia.
In an effort to speed up the adoption of these words by the Oxford English Dictionary, Dave and I hereby ask that every comment on this post correctly use at least one of them.  Also, while youre welcome to crack the obvious jokes (Scott is a shnood, Dave suffers from extralusionary intelligence, etc.), be aware that weve just preempted them.Boycott Elsevier!

If youre in academia and havent done so yet, please take a moment to sign this online petition organized by Tyler Neylon, and pledge that you wont publish, referee, or do editorial work for any Elsevier journals. Ive been boycotting Elsevier (and most other commercial journal publishersElsevier is merely the worst) since 2004, when I first learned about their rapacious pricing policies. I couldnt possibly be happier with my choice: unlike most idealistic principles, this one gets you out of onerous work rather than committing you to it! Sure, Elsevier is huge and were tiny, but the fight against them is finally gathering steam (possibly because of Elseviers support for the Research Works Act), years after the case against them became inarguable. Since their entire business model depends on our donating free labor to them, all it will take to bring them down is for enough of us to decide were through being had. We can actually win this one  Yes We Can.
For more information, see this wonderful recent post by Fields medalist and Shtetl-Optimized commenter Timothy Gowers, entitled Elsevier  my part in its downfall. (Added: also check out this great post by Aram Harrow.) You might also enjoy a parody piece I wrote years ago, trying to imagine how Elseviers squeeze those dupes for all theyve got business model would work in any other industry.Where even the sun pulls all-nighters

Who: From left, Ashwin Nayak, Debbie Leung, Mike Mosca, your humble squinting blogger, Andris Ambainis with coffee, Patrick Hayden.
Where: Haines Junction (population 789), Yukon Territory, 100 miles east of Alaska.  One of the furthest outposts of civilization, surrounded by one of the last pristine wilderness areas on Earth.
When: We arrived here last night, after flying to Whitehorse and then battling heavy traffic (i.e., at least two other cars) for several hours on the Alaska Highway.
What: A quantum computing workshop sponsored by the CIAR (Canadian Institute for Advanced Research).
Why: I dunno, I guess the CIAR has more money than it knows what to do with.
How: You thought they wouldnt have WiFi here?Ig-nore this post

If you havent seen yet, the 2005 Ig Nobel Prizes have been announced.  Reading through the list of previous winners, I learned two things:

For weeks, Id been wondering why the shower curtains in my new apartment billow inwards. At first I thought it was because the hot water created a pressure difference, but then I found that cold water causes the same effect. Now I know why I couldnt figure it out: the explanation is sufficiently nontrivial as to have earned an Ig Nobel Prize in Physics for its discoverer.
Instead of futzing around with Recursive Fourier Sampling, I shouldve been working on more socially-relevant CS problems, like software that detects when a cat is walking across your keyboard.Whether or not God plays dice, I do

Another Update (Feb. 7): I have a new piece up at IEEE Spectrum, explaining why I made this bet. Thanks to Rachel Courtland for soliciting the piece and for her suggestions improving it.
Update: My $100,000 offer for disproving scalable quantum computing has been Slashdotted. Reading through the comments was amusing as always. The top comment suggested that winning my prize was trivial: Just point a gun at his head and ask him Convinced?' (For the record: no, I wouldnt be, even as I handed over my money. And if you want to be a street thug, why limit yourself to victims who happen to have made public bets about quantum computing?) Many people assumed I was a QC skeptic, and was offering the prize because I hoped to spur research aimed at disproving QC. (Which is actually an interesting misreading: I wonder how much pro-paranormal research has been spurred by James Randis million-dollar prize?) Other people said the bet was irrelevant since D-Wave has already built scalable QCs. (Oh, how I wish I could put the D-Wave boosters and the QC deniers in the same room, and let them duke it out with each other while leaving me alone for a while!) One person argued that it would be easy to prove the impossibility of scalable QCs, just like it wouldve been easy to prove the impossibility of scalable classical computers in 1946: the only problem is that both proofs would then be invalidated by advances in technology. (I think he understands the word proof differently than I do.) Then, buried deep in the comments, with a score of 2 out of 5, was one person who understood precisely:
I think hes saying that while a general quantum computer might be a very long way off, the underlying theory that allows such a thing to exist is on very solid ground (which is why hes putting up the money). Of course this prize might still cost him since if the news of the prize goes viral hes going to spend the next decade getting spammed by kooks.
OK, two people:
Theres some needed context. Aaronson himself works on quantum complexity theory. Much of his work deals with quantum computers (at a conceptual levelwhat is and isnt possible). Yet there are some people who reject the idea the quantum computers can scale to useful sizesincluding some very smart people like Leonid Levin (of Cook-Levin Theorem fame)and some of them send him email, questions, comments on his blog, etc. saying so. These people are essentially asserting that Aaronsons career is rooted in things that cant exist. Thus, Aaronson essentially said prove it. Its true that proving such a statement would be very difficult  But the context is that Aaronson gets mail and questions all the time from people who simply assert that scalable QC is impossible, and hes challenging them to be more formal about it. He also mentions, in fairness, that if he does have to pay out, hed consider it an honor, because it would be a great scientific advance.

For better or worse, Im now offering a US$100,000 award for a demonstration, convincing to me, that scalable quantum computing is impossible in the physical world. This award has no time limit other than my death, and is entirely at my discretion (though if you want to convince me, a good approach would be to convince most of the physics community first). I might, also at my discretion, decide to split the award among several people or groups, or give a smaller award for a discovery that dramatically weakens the possibility of scalable QC while still leaving it open. I dont promise to read every claimed refutation of QC thats emailed to me. Indeed, you neednt even bother to send me your refutation directly: just convince most of the physics community, and believe me, Ill hear about it! The prize amount will not be adjusted for inflation.
The impetus for this prize was a post on Dick Liptons blog, entitled Perpetual Motion of the 21st Century? (See also this followup post.) The post consists of a debate between well-known quantum-computing skeptic Gil Kalai and well-known quantum-computing researcher Aram Harrow (Shtetl-Optimized commenters both), about the assumptions behind the Quantum Fault-Tolerance Theorem. So far, the debate covers well-trodden ground, but I understand that it will continue for a while longer. Anyway, in the comments section of the post, I pointed out that a refutation of scalable QC would require, not merely poking this or that hole in the Fault-Tolerance Theorem, but the construction of a dramatically-new, classically-efficiently-simulable picture of physical reality: something I dont expect but would welcome as the scientific thrill of my life. Gil more-or-less dared me to put a large cash prize behind my wordsas Im now, apparently, known for doing!and I accepted his dare.
To clarify: no, I dont expect ever to have to pay the prize, but thats not, by itself, a sufficient reason for offering it. After all, I also dont expect Newt to win the Republican primary, but Im not ready to put $100,000 on the line for that belief. The real reason to offer this prize is that, if I did have to pay, at least doing so would be an honor: for Id then (presumably) simply be adding a little to the well-deserved Nobel Prize coffers of one of the greatest revolutionaries in the history of physics.
Over on Liptons blog, my offer was criticized for being like offering $100,000 to anyone who can prove that Bigfoot doesnt exist. To me, though, that completely misses the point. As I wrote there, whether Bigfoot exists is a question about the contingent history of evolution on Earth. By contrast, whether scalable quantum computing is possible is a question about the laws of physics. Its perfectly conceivable that future developments in physics would conflict with scalable quantum computing, in the same way that relativity conflicts with faster-than-light communication, and the Second Law of Thermodynamics conflicts with perpetuum mobiles. Its for such a development in physics that Im offering this prize.
Update: If anyone wants to offer a counterpart prize for a demonstration that scalable quantum computing is possible, Ill be happy for thatas Im sure, will many experimental QC groups around the world. Im certainly not offering such a prize.Called in for another cohenoscopy

Ronald de Wolf asks:
how does Leonard Cohen (the Montreal-born singer-songwriter, a.k.a. my latest hero) fit in the Cohen balance of the universe?

Id heard of him, but I knew nothing about him until Ronalds question prompted several hours of websurfing.  (Thanks a million, Ronald!)  As a result of this diligent research  as well as almost three full minutes of listening to mp3s  I can now offer the world the following
COHEN SCORECARD
Starting credit: 1 point.
Seems like a nice guy: +3 points.
Singing voice several notches below me with a sore throat: -2 points.
Songs that I cant imagine listening to for pleasure: -1 point.
Then again, I dont listen to music: 1 point back.
In his seventies, continues to attract babes like flypaper: +4 points.
Is nevertheless profoundly melancholic: -4 points.
Verdict: Inconclusive.The battle against Elsevier gains momentum

Check out this statement on The Cost of Knowledge released today, which (besides your humble blogger) has been signed by Ingrid Daubechies (President of the International Mathematical Union), Timothy Gowers, Terence Tao, Lszl Lovsz, and 29 others. The statement carefully explains the rationale for the current Elsevier boycott, and answers common questions like why single out Elsevier? and what comes next?
Also check out Timothy Gowers blog post announcing the statement. The post includes a hilarious report by investment firm Exane Paribas, explaining that the current boycott has caused Reed Elseviers stock price to fall, but presenting that as a great investment opportunity, since they fully expect the price to rebound once this boycott fails like all the previous ones. I ask you: does that not want to make you boycott Elsevier, for no other reason than to see the people who follow Exane Paribas cynical advice lose their money?
In related news, the boycott petition now has 4600+ signatures and counting. If youve already signed, great! If you havent, why not?
Update (Feb. 9): Theres now a great editorial by Gareth Cook in the Boston Globe supporting the Elsevier boycott (and analogizing it to both the Tahrir Square uprising and the Boston Tea Party!).Safari photos from Kenya

#gallery-1 {
				margin: auto;
			}
			#gallery-1 .gallery-item {
				float: left;
				margin-top: 10px;
				text-align: center;
				width: 33%;
			}
			#gallery-1 img {
				border: 2px solid #cfcfcf;
			}
			#gallery-1 .gallery-caption {
				margin-left: 0;
			}
			/* see gallery_shortcode() in wp-includes/media.php */
		
































































































(Credit for most of the photos: Dana)
I was going to write a whole long essay about

the differences between going to the zoo and visiting an ancestral environment of humanity, where elephants have grazed for millions of years;
the weird sense of familiarity, as if youre seeing how the surface of the earth is supposed to look, how it did look before humans started converting it into KFCs and parking lots;
how to tell whether an elephant charging your jeep is serious about wanting to trample you or, much more likely, just warning you to go away (apparently, it has to do with whether its ears are straight back or flapping);
the airport at Lake Naivasha (a strip of dirt in a grassy field filled with zebras, and a guy on a bicycle who shoos the zebras off the strip before a plane lands);
Britains failure, to this day, to issue any sort of apology for its detention, torture, and murder of tens of thousands of Kenyans during the waning years of its colonial rule in the 1950s;
the near-destruction by poaching, over the last century, of many of the majestic animal populations you see above;
the heroism of Richard Leakey (past director of the Kenya Wildlife Service) in overcoming decades of bureaucratic inertia to initiate a crackdown, where rangers were authorized to poach the poachers, shooting them on sight (!);
how, after Leakey almost-singlehandedly saved Kenyas wild elephants, he lost both of his legs when his plane crashed (widely suspected to be due to sabotage), and was forced from his job months later;
the benefits of safari tourism in creating a serious economic incentive for conservation, but also the drawbacks (e.g., all the jeeps making it harder for the cheetahs to hunt);
the large, obvious, anything-but-theoretical changes being wrought by global warming on the rainfall in Kenyas game parks (which changes are killing the trees, thereby eliminating the lions hiding places and making it harder for them to hunthey, at least the zebras are happy);
the Maasais innovative uses for cow dung; the resulting immature jokes on my part (homeowner to roofer: this roof you sold me is shit!);
my growing fascination, over the course of the trip, with the lesser-known corners of Mammalia (elands, dik-diks, kudus, waterbucks, topis, rock hyraxes); how this might mirror my fascination with lesser-known complexity classes like AWPP, QMA(2)/qpoly, SBP, C=P, and BPPpath;
how parts of the African savannah have better cellphone reception than my office in Stata;
how its indeed possible to catch up on Jon Stewart and The Big Bang Theory over wifi, from a tent in the Maasai Mara, while hippos bellow loudly in the river below, and elephants graze and crocodiles sun themselves on the other side.

But then I never got around to writing that essay. So enjoy the photos, and ask in the comments if you want me to say something else.Anonymous reviewing: the QWERTY of science

The journal Nature has started a three-month trial of a new peer review system.  Heres how it works: while a paper is sent out for traditional review, the authors can also choose to make it open for comments on the web.  Any such comments are public and signed, and the authors can respond to them in public.  Then, when making their acceptance decision, the editors take into account both the anonymous reviews and the public online discussion.
Personally, I think this is a phenomenal idea, and I hope it spreads to computer science sooner rather than later.  Ive always been struck by the contradiction between scientists centuries-old mistrust of secrecy  their conviction that only mushrooms grow in the dark  and their horror at signing their names to their opinions of each others work.  Are we a bunch of intellectual wusses?
Inspired by Natures experiment, Im going to try an experiment of my own.  Rather than develop my views any further (which I dont feel like doing), Im just going to stop right here and open the field to comments.  Go!Schrdingers cat is hunting masked chickens

A commenter on my last post  who, since he or she chose not to provide a name, Ill take the liberty of calling Dr. Doofus McRoofus  offers the following prediction about quantum computing:
[U]nless quantum computing can deliver something practical within the next five to ten years it will be as popular then as, say, PRAMs are today.

Four reactions:

String theory has been immensely popular for over 20 years, among a much larger community, with zero prospects for delivering anything practical (or even any contact with experiment, which  ahem  some of us have had for a decade).  Reasoning by analogy, if quantum computing became popular around 1995, that should at least put us in the upper range of McRoofuss five to ten years.
For better or worse, the funding outlook for quantum computing is much less depressing right now than for classical theoretical computer science.  Many of us have been making the case to DARPA and NSF that classical complexity should continue to be funded in part because of its relevance for quantum computing.
The right analogy is not between quantum computing and PRAMs; its between quantum computing and parallel computing.  Specific architectures, like linear optics and PRAMs, have gone in and out of fashion.  Modes  of computation, like nondeterminism, randomness, parallelism, and quantumness, have instead just gotten agglomerated onto the giant rolling snowball of complexity.  As long as the snowball itself continues to tumble down the hill (shoot  bad metaphor?), I dont see any reason for this to change.
Im no good at predicting social trends, so perhaps time will prove me wrong and Dr. McRoofus right.  But speaking for myself, Id go insane if I had to pick research topics based on popularity.  I became interested in quantum computing because of a simple trilemma: either (i) the Extended Church-Turing Thesis is false, (ii) quantum mechanics is false, or (iii) factoring is in classical polynomial time.  As I put it in my dissertation, all three possibilities seem like wild, crackpot speculations, but at least one of them is true!  The question of which will remain until its answered.Confessions of a Hebrew Philistine

I took a lot of flak for expressing wrong musical opinions last week.   Since I so enjoy the role of human flamebait, Ive decided to have another go at clarifying my views about Art in general.  See, until a few years ago, I was intimidated by art and music snobs, by the sort of person who recently deposited the following on Lance Fortnows blog:
man, the ignorance displayed here is taken to new levels. your ph.d. in computer science qualifies you as nothing musically, dumbass.  ever heard of dynamic range? go look it up.

A bit uncivil, perhaps, but doesnt this anonymous fount of musical wisdom have a point?  After all, spouting off about quantum computers, entanglement, or Gdels Theorem without studying them first would certainly qualify you as a dumbass.  So if I dont think the same about music, then arent I a big fat hypocrite?
Ah, but consider the following. If  as the snob would be first to affirm  the purpose of art is not to assert or argue anything as a research paper would, but simply to produce an emotional response in the viewer or listener, then what does it even mean to be unqualified to voice that response? Presumably one persons emotional response is as valid as anothers.  Indeed, the difficulty with the snob is that he wants it both ways.  What made Picasso the greatest artist of the twentieth century is ineffable, indescribable  and Im the one who knows enough to describe it to you.  This opera is astounding because it induces a visceral, gut response in the audience  and if you dont have that response, your gut must be mistaken.  The point is that, once youve declared something to be nonscientific, emotional, subjective, you have to allow that someone elses subjective reaction might differ from yours.
So on this day, let us celebrate our freedom from the tyranny of pretending to like stuff we dont.  Ill start the honesty ball rolling by dividing the worlds artistic output into three categories, then giving examples of each (not representative, just the first things that popped into my head).
Art thats stirred my soul
The Simpsons
Futurama
South Park
Shakespeare (comedies especially)
Tom Sawyer and Huck Finn
The Mind-Body Problem by Rebecca Goldstein
Everything by Pixar
Arcadia by Tom Stoppard
Art that maybe hasnt moved me, but that I can nevertheless agree is quite impressive, based not on what other people say but on my own experience of it
The Sistine Chapel (indeed, pretty much everything in Rome)
Them big paintings in the Louvre
Them big Buddhist temples in Kyoto
Beethoven
Mozart
The Beatles
Jazz improv
Jimi Hendrix
Early Woody Allen
Art in neither of the two above categories
Late Woody Allen
Everything in the MoMA
Picasso
Van Gogh
Weird indie films where nothing happens
Anything by David Lynch or M. Night Shyamalan
Rap (except MC Hawking)
Experimental music
PS. Theres really no need to flame me if you have different tastes, since I wont take it as a moral failing on your part.  (Except with regard to M. Night Shyamalan.)Back to safe territory

When you see me getting chased across the blogosphere by livid, paintbrush-wielding artistes, it can only mean one thing: that Ive once again abandoned my promise to stick to the Serious Complexity Theory That Im Actually Qualified To Discuss.  So Ill tell you what, whistling-pig-lovers: answer me the following; then come back for more.
Given a set of n-by-n real matrices, is there a nonzero linear combination of those matrices with rank 1?  Equivalently, given a subspace S of a bipartite n-by-n Hilbert space, does S contain a separable state?
Id like (1) a proof of NP-hardness for the exact version, and (2) more importantly, whether or not theres a decent approximation algorithm.  (For instance, an algorithm that finds a rank-1 matrix, with the sum of the squares of the entries equal to 1, whose L2-distance from the subspace of interest is at most a small additive constant more than optimal.)
So get cracking!  If you do find a decent approximation algorithm, youll have shown, among other things, that QMA(2) (QMA with two unentangled yes-provers) is in EXP.  Incredibly, right now we dont have any upper bound better than NEXP.
Oh, yes: while my brain is closed, and while I can barely turn theorems into coffee, I will offer $20 for a solution to (2).
American.My visit to D-Wave: Beyond the roast-beef sandwich

Last week I was in Vancouver, to give talks at the University of British Columbia and at the American Association for the Advancement of Science annual meeting. As part of that visit, on Friday afternoon, John Preskill, John Martinis, Michael Freedman and I accepted a gracious invitation to tour the headquarters of D-Wave Systems in Burnaby (a suburb of Vancouver). We started out in a conference room, where they served us cookies and sodas. Being the mature person that I am, the possibility of the cookies being poisoned at no point crossed my mind.
Then we started the tour of D-Waves labs. We looked under a microscope at the superconducting chips; we saw the cooling systems used to get the chips down to 20 millikelvin. In an experience that harked back to the mainframe era, we actually walked inside the giant black cubes that D-Wave was preparing for shipment. (The machines are so large partly because of the need for cooling, and partly to let engineers go in and fix things.) Afterwards, D-Wave CTO Geordie Rose gave a 2-hour presentation about their latest experimental results. Then we all went out to dinner. The D-Wave folks were extremely cordial to us and fielded all of our questions.
In spite of my announcement almost a year ago that I was retiring as Chief D-Wave Skeptic, I thought it would be fitting to give Shtetl-Optimized readers an update on what I learned from this visit. Ill start with three factual points before moving on to larger issues.
Point #1: D-Wave now has a 128-(qu)bit machine that can output approximate solutions to a particular NP-hard minimization problemnamely, the problem of minimizing the energy of 90-100 Ising spins with pairwise interactions along a certain fixed graph (the input to the machine being the tunable interaction strengths). So I hereby retire my notorious comment from 2007, about the 16-bit machine that D-Wave used for its Sudoku demonstration being no more computationally-useful than a roast-beef sandwich. D-Wave does have something today thats more computationally-useful than a roast-beef sandwich; the question is merely whether its ever more useful than your laptop. Geordie presented graphs that showed D-Waves quantum annealer solving its Ising spin problem faster than classical simulated annealing and tabu search (where faster means ignoring the time for cooling the annealer down, which seemed fair to me). Unfortunately, the data didnt go up to large input sizes, while the data that did go up to large input sizes only compared against complete classical algorithms rather than heuristic ones. (Of course, all this is leaving aside the large blowups that would likely be incurred in practice, from reducing practical optimization problems to D-Waves fixed Ising spin problem.) In summary, while the observed speedup is certainly interesting, it remains unclear exactly what to make of it, and especially, whether or not quantum coherence is playing a role.
Which brings me to Point #2. It remains true, as Ive reiterated here for years, that we have no direct evidence that quantum coherence is playing a role in the observed speedup, or indeed that entanglement between qubits is ever present in the system. (Note that, if theres no entanglement, then it becomes extremely implausible that quantum coherence could be playing a role in a speedup. For while separable-mixed-state quantum computers are not yet known to be efficiently simulable classically, we certainly dont have any examples where they give a speedup.) Last year, as reported on this blog, D-Wave had a nice Nature paper that reported quantum tunneling behavior in an 8-qubit system. However, when I asked D-Wave scientist Mohammad Amin, he said he didnt think that experiment provided any evidence for entanglement between qubits.
The obvious way to demonstrate entanglement between qubits would be to show a Bell inequality violation. (We know that this can be done in superconducting qubits, as the Schoelkopf group at Yale among others reported it a couple years ago.) Meanwhile, the obvious way to demonstrate a role for quantum coherence in the apparent speedup would be gradually to turn down the systems coherence (for example, by adding an interaction that constantly measured the qubits in the computational basis), and check that the annealers performance degraded to that of classical simulated annealing. Unfortunately, the D-Wave folks told us that neither experiment seems feasible with their current setup, basically because they dont have arbitrary local unitary transformations and measurements available. They said they want to try to demonstrate 2-qubit entanglement, but in the meantime, are open to other ideas for how to demonstrate a quantum role in the apparent speedup with their existing setup.
Point #3: D-Wave was finally able to clarify a conceptual point that had been bugging me for years. Iand apparently many others!thought D-Wave was claiming that their qubits decohere almost immediately (so that, in particular, entanglement would almost certainly never be present during the computation), but that the lack of entanglement didnt matter, for some complicated reason having to do with energy gaps. I was far from alone in regarding such a claim as incredible: as mentioned earlier, theres no evidence that a quantum computer without entanglement can solve any problem asymptotically faster than a classical computer. However, that isnt D-Waves claim. What they think is that their system decoheres almost immediately in the energy eigenbasis, but that it doesnt decohere in the computational basisso that, in particular, there would be entanglement at intermediate stages. If so, that would be perfectly fine from the standpoint of the adiabatic algorithm, which doesnt need coherence in the energy eigenbasis anyway (after all, the whole point is that, throughout the computation, you want to stay as close to the systems ground state as possible!). I understand that, given their knowledge of decoherence mechanisms, some physicists are extremely skeptical that you could have rapid decoherence in the energy basis without getting decoherence in the computational basis also. So certainly the burden is on D-Wave to demonstrate that they maintain coherence where it counts. But at least I now understand what theyre claiming, and how it would be compatible (if true) with a quantum speedup.
Let me now move on to three broader questions raised by the above points.
The first is: rather than constantly adding more qubits and issuing more hard-to-evaluate announcements, while leaving the scientific characterization of its devices in a state of limbo, why doesnt D-Wave just focus all its efforts on demonstrating entanglement, or otherwise getting stronger evidence for a quantum role in the apparent speedup? When I put this question to Mohammad Amin, he said that, if D-Wave had followed my suggestion, it would have published some interesting research papers and then gone out of businesssince thefundraising pressure is always for more qubits and more dramatic announcements, not for clearer understanding of its systems. So, let me try to get a message out to the pointy-haired bosses of the world: a single qubit that you understand is better than a thousand qubits that you dont. Theres a reason why academic quantum computing groups focus on pushing down decoherence and demonstrating entanglement in 2, 3, or 4 qubits: because that way, at least you know that the qubits are qubits! Once youve shown that the foundation is solid, then you try to scale up. So, please support D-Wave if it wants to spend money to show Bell inequality violations, or other smoking-gun evidence that its qubits are working together coherently. Youre welcome, D-Wave!
The second question is one that Ive encountered many times on the blogosphere: who cares how D-Waves system works, and whether it does or doesnt exploit quantum coherence, as long as it solves practical problems faster? Sure, maybe what D-Wave is building is really a series of interesting, useful, but still basically classical annealing devices. Maybe the word quantum is functioning here as the stone in a stone soup: attracting money, interest, and talented people to build something that, while neat, ultimately doesnt much depend on quantum mechanics at all. As long as D-Waves (literal!) black box solves the problem instances in such-and-such amount of time, why does it matter whats inside?
To see the obtuseness of this question, consider a simple thought experiment: suppose D-Wave were marketing a classical, special-purpose, $10-million computer designed to perform simulated annealing, for 90-bit Ising spin glass problems with a certain fixed topology, somewhat better than an off-the-shelf computing cluster. Would there be even 5% of the public interest that there is now? I think D-Wave itself would be the first to admit the answer is no. Indeed, Geordie Rose spoke explicitly in his presentation about the compelling nature of (as he put it) the quantum computing story, and how it was key to attracting investment. People dont care about this stuff because they want to find the ground states of Ising spin systems a bit faster; they care because they want to know whether or not the human race has finally achieved a new form of computing. So characterizing the device matters, goddammit! I pride myself on being willing to adjust my opinions on just about anything in response to new data (as Ive certainly done in D-Waves case), but the insistence that black boxes must be opened and explanations provided is something Ill carry to the grave.
Finally, given the skeptical-yet-positive tone of this post, some people will wonder whether I now regret my earlier, more unmitigated D-Wave skepticism. The answer is no! Asking questions is my job. Ill give D-Wave credit whenever it answers some of the questionsas it did on this visit!and will shift my views accordingly. But Ill also neither stop asking nor apologize for asking, until the evidence for a quantum speedup becomes clear and indisputable (as it certainly hasnt yet). On the other hand, I do regret the snowballing nastiness that developed as a combined result of my and other skeptics statements, D-Waves and its supporters statements, and the adversarial nature of the blogosphere. For the first time, I find myself really, genuinely hopingwith all my heartthat D-Wave will succeed in proving that it can do some (not necessarily universal) form of scalable quantum computation. For, if nothing else, such a success would prove to the world that my $100,000 is safe, and decisively refute the QC skeptics who, right now, are getting even further under my skin than the uncritical D-Wave boosters ever did.The physicists and the wagon

[Heres a little fable that I wrote today, while listening to a talk showing that a fault-tolerant quantum computer would need at least 100 physical qubits for every logical qubit.  Physicists are welcome to shoot back with counter-fables, as are closet computer scientists like His Holiness.]
Update: The Pontiff has accepted my challenge and posted a counter-fable to his blog.  Ive replied in his comments section with a counter-counter-fable.
One day a group of physicists ran excitedly into the computer science building.  Guess what? they cried.  You know how youre always trying to prove lower bounds, but you almost never succeed?  Well, today we proved a lower bound!
What did you prove? asked the computer scientists.
We proved that to pull a wagon through a forest, you need at least five oxen.  Its physically impossible to do it with four oxen or less, regardless of what other resources you have.
How did you prove that?
Well, we looked up the strength of a typical ox, the weight of a typical wagon, the size of every forest in a 30-mile radius
Yeah, but what if you had an ox the size of a Brontosaurus?  Or what if the forest was only two feet across?  Or what if the wagon weighed less than a fingernail?
The physicists snickered.  These are clearly unphysical assumptions.  As long as you stay within a realistic region of parameter space, our impossibility proof is airtight.
Ah, but how do you know there couldnt be some completely different method of pulling wagons  maybe even a method thats not ox-based at all?
Look, we physicists are interested in the real world, not complexity-theory la-la land.  And at least in the real world, when people want to pull wagons, oxen are what they use.
The physicists werent heard from again until almost a decade later, when they once again barged into the CS building.  Guess what? they cried.  We just discovered a loophole in the famous Five-Ox Theorem  the one we published years ago in Nature!
Whats the loophole?
Elephants!  If you had an elephant pulling the wagon, you wouldnt need any oxen at all.  With hindsight its almost obvious, but what a paradigm shift it took!
The computer scientists stared blankly.
You see, said the physicists.  This is why we never trust so-called impossibility proofs.Tell President Obama to support the Federal Research Public Access Act

If youre tired of blog posts about open science, sorry dudebut it feels great to be part a group of blogging nerds who, for once, are actually having a nonzero (and positive, I think!) impact on the political process. Yesterday, Elsevier, which had been the biggest supporter of the noxious Research Works Act, announced, under pressure from the Cost of Knowledge movement, that it was dropping its support for RWA. Only hours later, Elseviers paid cheerleaders in Congress, Darrell Issa (R-CA) and Carolyn Maloney (D-NY), announced that they were shelving the RWA for now. See this hilarious post by physicist John Baez, which translates Issa and Maloneys statement on why theyre letting the RWA die into ordinary English sentence-by-sentence.
But it gets better: Representative Mike Doyle (D-PA) has introduced a sort of anti-RWA, the Federal Research Public Access Act (or easily-pronounced FRPAA), which would require federal agencies with budgets of over $100 million to make the research they sponsor freely available less than 6 months after its publication in a peer-reviewed journal (thereby expanding the NIHs successful open-access policy). If youre a US citizen, and you care about the results of taxpayer-funded medical and other research being accessible to the public, then please sign this petition telling President Obama you support the FRPAA. Tell your coworker, husband, wife, grandmother, etc. to sign it too. Apparently the President will personally review it if it gets to 25,000 signatures by March 9.
And if youre not a US citizen: thats cool too! Support open-access initiatives in your country. (Or, if you live someplace like Syria, support the prerequisite not-getting-shot initiatives.) Just dont have a cow about my blogging American issues from time to time, like this easily-offended Aussie did over on Cosmic Variance.Mistake of the Week: The Unknown Unknown

And how is not this the most reprehensible ignorance, to think that one knows what one does not know? But I, O Athenians! in this, perhaps, differ from most men; and if I should say that I am in any thing wiser than another, it would be in this, that not having a competent knowledge of the things in Hades, I also think that I have not such knowledge.

Shtetl-Optimizeds Mistake of the Week series finally resumes today, with whats arguably the #1 mistake of all time.  This ones been noted by everyone from Defense Secretary Donald Rumsfeld, to some toga-wearing ancient dude, to the authors of the paper Unskilled and Unaware of It: How Difficulties In Recognizing Ones Own Incompetence Lead to Inflated Self-Assessments.
Rather than give examples of this mistake  where would I start? where would I stop? how often have I made it myself?  I figured itd be easier to give an example where someone didnt make it.  Today I received an email from a graduate student who had proved a quantum oracle separation, and wanted to know whether or not his result was too trivial to publish.  I get fan mail, I get hate mail, I get crank mail, I get referee requests, but this is something I almost never see.  After telling the student why his result was, indeed, too trivial to publish, I wrote:
Theres no shame in proving things that are already known, or that follow easily from what is.  Everyone does it, the more so when theyre just starting out  The very fact that you cared enough to ask me if your result is trivial bodes well for your proving something nontrivial.Big news

Judea Pearl has won a richly-deserved Turing Award, for his pioneering work on reasoning under uncertainty, Bayesian inference, and causality. Much like last years winner Leslie Valiant, Pearl has been a perfectly-plausible candidate since the 1980s; it was really just a question of when theyd get around to him. For those who dont know his work, Pearls landmark book Causality provides a wonderful introduction to at least one major strand of his thought; I read it this summer and it inverted the way I think about lots of things in statistics. (Pearls fame precedes this award, partly for a tragic reason: hes probably best known to the public as the father of the murdered journalist Daniel Pearl.)
In other big news, playing Super Mario Bros. is now known to be NP-complete, as shown in this landmark paper by Greg Aloupis, Erik Demaine, and Alan Guo. The sheer intuitiveness of the gadget constructions, at least to anyone who grew up playing Nintendo, makes this probably my favorite NP-completeness paper of all time (well, I guess tied with some papers by Cook, Karp, and Levin).Blogu Picchu

Im blogging from Machu Picchu, the famed summer home of the Inca emperors, nestled so deeply in the Andean mountains of Peru that the Spanish conquistadores never managed to find and destroy it. (Im in Peru to attend the LATIN2012 conference next week. Its a business trip, I swear!)
Ill be happy to post photos later if anyone wants. In the meantime, this just seemed like as good a time as any to break radio silence.Websbane

According to ancient complexity lore, at a saddle point high in the mountains of Oberwolfach lies buried a single flask of a mystical elixir known as Websbane, or the Hammer of Firefox.  Some say that the productivity-enhancing potion was brewed from the sweat of Erds and the toenail clippings of Euler; others that it was mixed, condensed, and extracted for the Prophesied One centuries hence who will derandomize BPP.  Yet all agree on the tonics awesome efficacy: it is said that one drop would furnish lifelong protection against Slate and Salon; a teaspoonful would lift Wikipedias stranglehold on the soul.  He who once imbibed would neither reread Onion articles from dusk till dawn, nor follow hyperlinks till scarcely a blue word remained amidst the purple, nor while away a Thursday googling a Montreal-born singer-songwriter mentioned in an email of de Wolf.  Papers would get finished  books written  reimbursement forms turned in  blog entries posted without delay.
Todays topic is what we can do until the Websbane is unearthed from its resting-ground.   I offer four suggestions below; any additions are welcome.

Use the embryo strategy.  Whenever youre procrastinating on something, someone is bound to tell you divvy it up into smaller chunks, then tackle em one at a time.   Ive found that to be terrible advice.  When Im starting a project, I have no idea how to divvy it up.  I might commit myself to writing chapters on A, B, and C, only to realize later that A and C are trivial and that everything worth saying pertains to B.   Or I might start the introduction, then freeze for days because I cant decide what belongs in the introduction and what belongs in the meat until Ive already written them.What Ive found to be more effective is what Ill call the embryo strategy. Here you simplify your project so dramatically that you can finish the entire thing (more or less) in one afternoon.  For example, if before your goal was to write a ten-page popular article about quantum computing, now your goal is to write two paragraphs.  Then, once youve finished something, you progressively add layers to it.  This seems to be the approach taken by most successful software projects, not to mention by Nature herself.  The advantages are twofold: firstly, everything is built around one initial idea.  This changes what the end product looks like, but I think for the better.  And secondly  heres the real beauty  at no point are you ever working on something that will take unimaginably long, compared to the amount of time youve already spent.  (Give or take a small additive constant.)


Exploit the quantum Zeno effect. One to keep a quantum state from drifting uncontrollably is just to measure it over and over in some fixed basis.    Roughly speaking, the mere fact that youre looking means that the state cant try anything funny. Similarly, Ive taken to having my girlfriend spend the night with me when I need to finish a paper.   What ensues is a long, romantic evening, wherein I sit at my computer and do my work, and Kelly sits at her computer and does her work.  Interestingly, her mere presence often has the effect of projecting me onto a non-procrastinating subspace.  (Kelly reports a similar effect on her as well.)


Dont eat.  When youre trying to prove theorems about quantum complexity classes, hunger is your friend and linguini-induced sleepiness your enemy.    As obvious as that sounds, it took me almost a decade fully to understand its importance.   These days I usually eat only one meal per day  my brinner  and dont even try to work till three or four hours after it.  (Does anyone know  the physiological reason why humans seem unable to multitask between brains and stomachs?)


Find yourself a boss.   When I was at Berkeley, Umesh was my boss.  That doesnt mean he told me what to work on (he didnt); it means that I got a warm fuzzy feeling from eliciting his opinion of what I had worked on.  Since graduating, to stay productive Ive had to seek out a succession of new bosses  from Avi Wigderson at IAS, to collaborators like Greg Kuperberg and Daniel Gottesman.   Indeed, if you get a long, technical email from me, its not necessarily for your benefit.  Mathematicians might be machines for turning coffee into theorems, but the fuel I run on is feedback.

Follow these rules, and you might someday become as disciplined and productive as I am.U. of Florida CS department: let it be destroyed by rising sea levels 100 years from now, not reckless administrators today

Update (4/27): A famous joke concerns an airplane delivered to the US Defense Department in the 1950s, which included a punch-card computer on board. By regulation, the contractor had to provide a list of all the components of the planeengine, wings, fuselage, etc.along with the weight of each component. One item in the list read, Computer software: 0.0 kg.
That must be a mistakeit cant weigh 0 kg! exclaimed the government inspector. Here, show me where the software is. So the contractor pointed to a stack of punched cards. OK, fine, said the government inspector. So just weigh those cards, and thats the weight of the software.
No, sir, you dont understand, replied the contractor. The software is the holes.
If the Abernathy saga proves anything, its the continuing relevance of this joke even in 2012. Abernathy is the government inspector who hears that software weighs nothing, and concludes that it does nothingor, at least, that whatever division is responsible for punching the holes in the cards, can simply be folded into the division that cuts the card paper into rectangles.

As many of you have heard by now, Cammy Abernathy, Dean of Engineering at the University of Florida, has targeted her schools Computer and Information Science and Engineering (CISE) department for disembowelment: moving most faculty to other departments, and shunting any who remain into non-research positions. Though CISE is by all accounts one of UFs strongest engineering departments, no other department faces similar cuts, and the move comes just as UF is increasing its sports budget by more than would be saved by killing computer science. (For more, see Lances blog, or letters from Eric Grimson and Zvi Galil. Also, click here to add your name to the already 7000+ petitioning UF to reconsider.)
On its face, this decision seems so boneheadedly perverse that it immediately raises the suspicion that the real reasons for it, whatever they are, have not been publicly stated. The closest I could find to a comprehensible rationale came from this comment, which speculates that the UF administration might be sabotaging its CS department as a threat to the Florida State legislature: see, keep slashing our budget, and this is the sort of thing well be forced to do! But I dont find that theory very plausible; UF must realize that the Republican-controlled legislatures likely reaction would be go ahead, knock yourselves out!
On a personal note, my parents live part-time in beautiful Sarasota, FL, home of the Mote Marine Laboratory, which does amazing work rehabilitating dolphins, manatees, and sea turtles. Having visited Sarasota just a few weeks ago, I can testify that, despite frequent hurricanes, a proven inability to hold democratic elections, and its reputation as a giant retirement compound, Florida has definite potential as a state.
Academic computer science as a whole will be fine. As for Florida, may the state prove greater than its Katherine Harrises, Rick Scotts, and Cammy Abernathys.
Update: See this document for more of the backstory on Abernathys underhanded tactics in dismantling the UF CISE department. Based on the evidence presented there, she really does deserve the scorn now being heaped on her by much of the academic world.
Another Update: UFs president issued a rather mealy-mouthed statement saying that theyre going to set aside their original evisceration proposal and find a compromise, though who knows what the compromise will look like.
In another news, Greg Kuperberg posted a comment that not only says everything I was trying to say more eloquently, but also explains why I and other CS folks care so much about this issue: because whats really at stake is the concept of Turing-universality itself. Let me repost Gregs comment in its entirety.
It looks like Dean Abernathy hasnt explained herself all that well, which is not surprising if what she is doing makes no sense. Reading the tea leaves, in particular the back-story document that Scott posted, it looks like she had it in for the CS department from the beginning of her tenure as Dean at Florida. In her interview with Stanford when she had just been appointed as dean, she already said then that we wanted to bring EE and CS closer together, even though at the time, there had been no discussion and there was no we. Then during discussions with the CS department, she refused to take no for an answer, even though she sometimes pretended to, and as time went on the actual plan looked more and more punitive. She appointed an outside chair to the department, and then in the final plan she terminated the graduate program, moved half of the department to EE, and left the other half to do teaching only. The CS department was apparently very concerned about its NRC ranking, but this ranking only came out when Abernathys wheels were already in motion. In any case everyone knows that the NRC rankings were notoriously shabby across all disciplines and the US News rankings, although hardly deep, are much less ridiculous.
So what gives? Apparently from Abernathys Stanford interview, and from her actions, she simply takes computer science to be a special case of electrical engineering. Ultimately, its a rejection of the fundamental concept of Turing universality. In this world view, there is no such thing as an abstract computer, or at best who really cares if there is one; all that really exists is electronic devices.
Scott points out that those departments that are combined EECS are really combined in name only. This is not just empirical happenstance; it comes from Turing universality and the abstract concept of a computer. Yes, in practice modern computers are electronic. However, if someone does research in compilers, much less CS theory, then really nothing at all is said about electricity. To most people in computer science, its completely peripheral that computers are electronic. Nor is this just a matter of theoretical vs applied computer science. CS theory may be theoretical, but compiler research isnt, much less other topics such as user interfaces or digital libraries.
Abernathy herself works in materials engineering and has a PhD from Stanford. Im left wondering at what point she failed to understand, or began to misunderstand or dismiss, the abstract concept of a computer. If she were dean of letters of sciences, then I could imagine an attempt to dump half of the literature department into a department of paper and printing technology, and leave the other half only to teach grammar. It would be exactly the same mistake.Time to do Scotts research again

Given vectors v1,,vm in Rn, is it NP-hard to find a unit vector w that maximizes the (absolute value of the) product of inner products, |(v1w)(vmw)|?  What about in Cn? Are these problems hard to approximate on a logarithmic scale?
$20 for answers to all three.  I should get better at doing these things myself.Bells-inequality-denialist Joy Christian offers me $200K if scalable quantum computers are built

Joy Christian is the author of numerous papers claiming to disprove Bells theorem. Yes, that Bells theorem: the famous result from the 1960s showing that no local hidden variable theory can reproduce all predictions of quantum mechanics for entangled states of two particles. Here a local hidden variable theory meansand has always meanta theory where Alice gets some classical information x, Bob gets some other classical information y (generally correlated with x), then Alice and Bob choose which respective experiments to perform, and finally Alice sees a measurement outcome thats a function only of her choice and of x (not of Bobs choice or his measurement outcome), and Bob sees a measurement outcome thats a function only of his choice and of y. In modern terms, Bell, with simplifications by Clauser et al., gave an example of a game that Alice and Bob can win at most 75% of the time under any local hidden variable theory (thats the Bell inequality), but can win 85% of the time by measuring their respective halves of an entangled state (thats the Bell inequality violation). The proofs are quite easy, both for the inequality and for its violation by quantum mechanics. Check out this problem set for the undergrad course Im currently teaching if youd like to be led through the proof yourself (its problem 7).
In case youre wondering: no, Bells Theorem has no more been disproved than the Cauchy-Schwarz Inequality, and it will never be, even if papers claiming otherwise are stacked to the moon. Like Gdels and Cantors Theorems, Bells Theorem has long been a lightning rod for incomprehension and even anger; I saw another disproof at a conference in 2003, and will doubtless see more in the future. The disproofs invariably rely on personal reinterpretations of the perfectly-clear concept of local hidden variables, to smuggle in what would normally be called non-local variables. That smuggling is accompanied by mathematical sleight-of-hand (the more, the better) to disguise the ultimately trivial error.
While Id say the aboveloudly, evento anyone who asked, I also declined several requests to write a blog post about Joy Christian and his mistakes. His papers had already been refuted ad nauseam by others (incidentally, I find myself in complete agreement with Lubo Motl on this one!), and I saw no need to pile on the poor dude. Having met him, at the Perimeter Institute and at several conferences, I found something poignant and even touching about Joys joyless quest. I mean, picture a guy who made up his mind at some point that, lets say, 2 is actually a rational number, all the mathematicians having been grievously wrong for millenniaand then unironically held to that belief his entire life, heroically withstanding the batterings of reason. Show him why 2=A2/B2 has no solution in positive integers A,B, and hell answer that you havent understood the very concept of rational number as deeply as him. Ask him what he means by rational number, and youll quickly enter the territory of the Monty Python dead parrot sketch. So why not just leave this dead parrot where it lies?
Anyway, thats what I was perfectly content to do, until Monday, when Joy left the following comment on my Whether or not God plays dice, I do post:
Scott,
You owe me 100,000 US Dollars plus five years of interest. In 2007, right under your nose (when you and I were both visiting Perimeter Institute), I demonstrated, convincing to me, that scalable quantum computing is impossible in the physical world.
He included a link to his book, in case I wanted to review his arguments against the reality of entanglement. I have to confess I had no idea that, besides disproving Bells theorem, Joy had also proved the impossibility of scalable quantum computing. Based on his previous work, I would have expected him to say that, sure, quantum computers could quickly factor 10,000-digit numbers, but nothing about that would go beyond ordinary, classical, polynomial-time Turing machinesbecause Turing himself got the very definition of Turing machines wrong, by neglecting topological octonion bivectors or something.
Be that as it may, Joy then explained that the purpose of his comment was to show that
there is absolutely nothing that would convince you to part with your 100,000. You know that, and everyone else knows that  The whole thing is just a smug scam to look smarter than the rest of us without having to do the hard work. Good luck with that.
In response, I clarified what it would take to win my bet:
As Ive said over and over, what would be necessary and sufficient would be to convince the majority of the physics community. Do you hope and expect to do that? If so, then you can expect my $100,000; if not, then not. If a scientific revolution has taken place only inside the revolutionarys head, then let the monetary rewards be likewise confined to his head.
Joy replied:
[L]et us forget about my work. It is not for you. Instead, let me make a counter offer to you. I will give you 200,000 US dollars the day someone produces an actual, working, quantum computer in a laboratory recognizable by me. If I am still alive, I will send you 200,000 US Dollars, multiplied by an appropriate inflation factor. Go build a quantum computer.
Im grateful to Joy for his exceedingly generous offer. But lets forget about money for now. Over the past few months, Ive had a real insight: the most exciting potential application of scalable quantum computers is neither breaking RSA, nor simulating quantum physics, nor Grovers algorithm, nor adiabatic optimization. Instead, its watching the people who said it was impossible try to explain themselves. That prospect, alone, would more than justify a Manhattan-project-scale investment in this field.
Postscript. If you want something about quantum foundations and hidden-variable theories of a bit more scientific interest, check out this MathOverflow question I asked on Monday, which was answered within one day by George Lowther (I then carefully wrote up the solution he sketched).
Updates (May 6). Depending on what sort of entertainment you enjoy, you might want to check out the comments section, where you can witness Joy Christian becoming increasingly unhinged in his personal attacks on me and others (our very own FQXi genius  biased and closed-minded  incompetent  Scotts reaction is a textbook case for the sociologists  As for Richard Gill, he is evidently an incompetent mathematician  I question your own intellectual abilities  your entire world view is based on an experimentally unsupported (albeit lucrative) belief and nothing else  You have been caught with your pants down and still refusing to see what is below your belly  let me point out that you are the lesser brain among the two of us. The pitiful flatness of your brain would be all too painful for everyone to see when my proposed experiment is finally done  etc., etc). To which I respond: the flatness of my brain? Also notable is Joys Tourettes-like repetition of the sentence, I will accept judgement from no man but Nature. Nature is a man?
I just posted a comment explaining the Bell/CHSH inequality in the simplest terms I know, which Ill repost here for convenience:
Look everyone, consider the following game. Two players, Alice and Bob, can agree on a strategy in advance, but from that point forward, are out of communication with each other (and dont share quantum entanglement or anything like that). After theyre separated, Alice receives a uniformly-random bit A, and Bob receives another uniformly-random bit B (uncorrelated with A). Their joint goal is for Alice to output a bit X, and Bob to output a bit Y, such that
X + Y = AB (mod 2)
or equivalently,
X XOR Y = A AND B.
They want to succeed with the largest possible probability. Its clear that one strategy they can follow is always to output X=Y=0, in which case theyll win 75% of the time (namely, in all four of the cases except A=B=1).
Furthermore, by enumerating all of Alice and Bobs possible pure strategies and then appealing to convexity, one can check that theres no strategy that lets them win more than 75% of the time. In other words, no matter what they do, they lose for one of the four possible (A,B) pairs.
Do you agree with the previous paragraph? If so, then you accept the Bell/CHSH inequality, end of story.
Of all the papers pointing out the errors in Joy Christians attempted refutations of the simple arithmetic above, my favorite is Richard Gills. Let me quote from Gills eloquent conclusion:
There remains a psychological question, why so strong a need is felt by so many researchers to disprove Bell in one way or another? At a rough guess, at least one new proposal comes up per year. Many pass by unnoticed, but from time to time one of them attracts some interest and even media attention. Having studied a number of these proposals in depth, I see two main strategies of would-be Bell-deniers.
The first strategy (the strategy, I would guess, in the case in question) is to build elaborate mathematical models of such complexity and exotic nature that the author him or herself is the probably the only person who ever worked through all the details. Somewhere in the midst of the complexity a simple mistake is made, usually resulting from suppression of an important index or variable. There is a hidden and non-local hidden variable.
The second strategy is to simply build elaborate versions of detection loophole models. Sometimes the same proposal can be interpreted in both ways at the same time, since of course either the mistake or the interpretation as a detection loophole model are both interpretations of the reader, not of the writer.
According to the Anna Karenina principle of evolutionary biology, in order for things to succeed, everything has to go exactly right, while for failure, it suffices if any one of a myriad factors is wrong. Since errors are typically accidental and not recognized, an apparently logical deduction which leads to a manifestly incorrect conclusion does not need to allow a unique diagnosis. If every apparently logical step had been taken with explicit citation of the mathematical rule which was being used, and in a specified context, one could say where the first misstep was taken. But mathematics is almost never written like that, and for good reasons. The writer and the reader, coming from the same scientic community, share a host of hidden assumptions which can safely be taken for granted, as long as no self-contradiction occurs. Saying that the error actually occurred in such-and-such an equation at such-and-such a substitution depends on various assumptions.
The author who still believes in his result will therefore claim that the diagnosis is wrong because the wrong context has been assumed.
We can be grateful for Christian that he has had the generosity to write his one page paper with a more or less complete derivation of his key result in a more or less completely explicit context, without distraction from the authors intended physical interpretation of the mathematics. The mathematics should stand on its own, the interpretation is free. My finding is that in this case, the mathematics does not stand on its own.
Update (5/7): I cant think of any better illustration than the comment thread below for my maxim that computation is clarity. In other words, if you cant explain how to simulate your theory on a computer, chances are excellent that the reason is that your theory makes no sense! The following comment of mine expands on this point:
The central concept that I find missing from the comments of David Brown, James Putnam, and Thomas Ray is that of the sanity check.
Math and computation are simply the tools of clear thought. For example, if someone tells me that a 4-by-4 array of zorks contains 25 zorks in total, and I respond that 4 times 4 is 16, not 25, Im not going to be impressed if the person then starts waxing poetic about how much more profound the physics of zorks is than my narrow and restricted notions of arithmetic. There must be a way to explain the discrepancy even at a purely arithmetical level. If there isnt, then the zork theory has failed a basic sanity check, and theres absolutely no reason to study its details further.
Likewise, the fact that Joy cant explain how to code a computer simulation of (say) his exploding toy ball experiment that would reproduce his predicted Bell/CHSH violation is extremely revealing. This is also a sanity check, and its one that Joy flunks. Granted, if he were able to explain his model clearly enough for well-intentioned people to understand how to program it on a computer, then almost certainly there would be no need to actually run the program! We could probably just calculate what the program did using pencil and paper. Nevertheless, Bram, John Sidles, and others were entirely right to harp on this simulation question, because its real role is as a sanity check. If Joys ideas are not meaningless nonsense, then theres no reason at all why we shouldnt be able to simulate his experiment on a computer and get exactly the outcome that he predicts. Until Joy passes this minimal sanity checkwhich he hasnttheres simply no need to engage in deep ruminations like the ones above about physics or philosophy or Joys Theorema Egregious.Is publishing as many STOC/FOCS papers as possible a worthy goal to fill the fleeting interlude between infinite expanses of nonexistence?

This, Im embarrassed to admit, is something Ive asked myself at various points over the last ten years.  Fortunately, thanks to this thread on Lance Fortnows blog, I now have my answer: no.Carla and me

On Friday, I drove to the University of Toronto to give a talk. This was the first time Id ever driven on a freeway alone. I didnt drive at all until a year ago, for four reasons:

Global warming.  I assuaged my conscience by buying a Prius (though admittedly, given the waiting lists for hybrids, Im probably increasing CO2 concentrations by preventing someone who drives more than I do from having my car).
Fear of getting lost. The solution to this one was Carla, my sultry female computerized travel companion (Proceed on the current route for 0.3 miles). I realize that for some guys, Carla would feel like a direct assault on their virility  especially since shes always right. But I love her, and I predict that in five years time, everyone else will want her too.
Lack of any social life that would necessitate a car.   Ive since realized that this was as much a symptom as a cause of my carlessness.
Fear of dying a gruesome death.   I havent yet licked this one, as became evident on Friday.

To avoid the traffic, I left Waterloo at 5:30am (yes, Id been up all night). Unfortunately, thats when all the trucks were out, and trucks on a freeway make me nervous. See, the problem with freeways is that there are no red lights  and therefore, no time to hunt down the neurons firing off about Futurama or BQP/qpoly, and refocus their attention on the road. Its like having to play Super Mario all the way through without pausing  the differences being that there are no stars or mushrooms, you only get one life, and its your actual life.   (Also, you cant stomp on the goombas, since theyre people too.)
So when I finally pulled into the parking garage at U of T, palms white and sweaty on the steering wheel, I started laughing hysterically: I made it!   Im still alive!   At least in this branch of the wavefunction, Im alive!   Joy to the world!   That I hadnt yet written the talk that I was to give in two hours seemed utterly insignificant.
For the ride home, I asked Carla to find me a route that avoided freeways, and ended up zigzagging through the small towns of southeast Ontario. The stoplights looked as pretty as the setting sun.